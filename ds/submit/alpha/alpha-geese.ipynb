{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOCAL:\n",
    "    !pip install -q -U kaggle-environments\n",
    "    !pip list | grep kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import bz2\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_filename = \"alpha_128_221.pth\"\n",
    "if LOCAL:\n",
    "    model_path = \"../../models/\" + model_filename\n",
    "else:\n",
    "    model_path = \"../input/hungry-geese-models/\" + model_filename\n",
    "\n",
    "# weights = torch.load(model_path)\n",
    "weights = torch.load(model_path, map_location=torch.device(\"cpu\"))\n",
    "\n",
    "PARAM = base64.b64encode(bz2.compress(pickle.dumps(weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%%writefile submission.py\n",
    "\n",
    "# This is a lightweight ML agent trained by self-play.\n",
    "# After sharing this notebook,\n",
    "# we will add Hungry Geese environment in our HandyRL library.\n",
    "# https://github.com/DeNA/HandyRL\n",
    "# We hope you enjoy reinforcement learning!\n",
    "\n",
    "\n",
    "import base64\n",
    "import bz2\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "from collections import defaultdict, deque\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from kaggle_environments.envs.hungry_geese.hungry_geese import Action, translate\n",
    "from kaggle_environments.helpers import histogram\n",
    "\n",
    "# MCTS\n",
    "\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, game, nn_agent, eps=1e-8, cpuct=1.0):\n",
    "        self.game = game\n",
    "        self.nn_agent = nn_agent\n",
    "        self.eps = eps\n",
    "        self.cpuct = cpuct\n",
    "\n",
    "        self.Qsa = {}  # 状態 s でプレイヤー i が行動 a を行ったあとの状態の状態評価値(訪問回数で平均)\n",
    "        self.Nsa = {}  # 状態 s でプレイヤー i が行動 a を行ったあとの状態への訪問回数\n",
    "        self.Ns = {}  # 状態 s の訪問回数\n",
    "        self.Ps = {}  # 状態 s でプレイヤー i の行動の評価値。policy networkの出力\n",
    "\n",
    "        self.Vs = {}  # 状態 s でのプレイヤー i の有効手\n",
    "\n",
    "        self.last_obs = None\n",
    "\n",
    "    def getActionProb(self, obs, timelimit=1.0):\n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < timelimit:\n",
    "            self.search(obs, self.last_obs)\n",
    "\n",
    "        s = self.game.stringRepresentation(obs)\n",
    "        i = obs.index\n",
    "        counts = [self.Nsa[(s, i, a)] if (s, i, a) in self.Nsa else 0 for a in range(self.game.getActionSize())]\n",
    "        prob = counts / np.sum(counts)\n",
    "\n",
    "        # print(f\"player: {i}, count: {np.sum(counts)}\")\n",
    "\n",
    "        self.last_obs = obs\n",
    "        return prob\n",
    "\n",
    "    def search(self, obs, last_obs):\n",
    "        \"\"\"\n",
    "        用語:\n",
    "            葉ノード: まだシミュレーションが行われていないノード\n",
    "        \"\"\"\n",
    "        s = self.game.stringRepresentation(obs)\n",
    "\n",
    "        # 現在の局面が葉ノードならば\n",
    "        if s not in self.Ns:\n",
    "            values = [-10] * 4\n",
    "            for i in range(4):\n",
    "                if len(obs.geese[i]) == 0:\n",
    "                    continue\n",
    "\n",
    "                # ニューラルネットワークで局面を評価する\n",
    "                self.Ps[(s, i)], values[i] = self.nn_agent.predict(obs, last_obs, i)\n",
    "\n",
    "                valids = self.game.getValidMoves(obs, last_obs, i)\n",
    "                self.Ps[(s, i)] = self.Ps[(s, i)] * valids  # masking invalid moves\n",
    "                sum_Ps_s = np.sum(self.Ps[(s, i)])\n",
    "                if sum_Ps_s > 0:\n",
    "                    self.Ps[(s, i)] /= sum_Ps_s  # renormalize\n",
    "\n",
    "                self.Vs[(s, i)] = valids\n",
    "                self.Ns[s] = 0\n",
    "\n",
    "            # 各プレイヤーの現在の局面の 状態の評価値 を返す\n",
    "            return values\n",
    "\n",
    "        best_acts = [None] * 4\n",
    "        for i in range(4):\n",
    "            if len(obs.geese[i]) == 0:\n",
    "                continue\n",
    "\n",
    "            valids = self.Vs[(s, i)]\n",
    "            cur_best = -float(\"inf\")\n",
    "            best_act = self.game.actions[-1]\n",
    "\n",
    "            # pick the action with the highest upper confidence bound\n",
    "            # 現在の局面 s でプレイヤー i の最適な行動を UCB で決定する\n",
    "            for a in range(self.game.getActionSize()):\n",
    "                if valids[a]:\n",
    "                    if (s, i, a) in self.Qsa:\n",
    "                        u = self.Qsa[(s, i, a)] + self.cpuct * self.Ps[(s, i)][a] * math.sqrt(self.Ns[s]) / (\n",
    "                            1 + self.Nsa[(s, i, a)]\n",
    "                        )\n",
    "                    else:\n",
    "                        u = self.cpuct * self.Ps[(s, i)][a] * math.sqrt(self.Ns[s] + self.eps)\n",
    "\n",
    "                    if u > cur_best:\n",
    "                        cur_best = u\n",
    "                        best_act = self.game.actions[a]\n",
    "\n",
    "            best_acts[i] = best_act\n",
    "\n",
    "        # 各プレイヤーがベストな行動を行ったあとの局面を生成\n",
    "        next_obs = self.game.getNextState(obs, last_obs, best_acts)\n",
    "\n",
    "        # 生成した次の局面を探索\n",
    "        values = self.search(next_obs, obs)\n",
    "\n",
    "        for i in range(4):\n",
    "            if len(obs.geese[i]) == 0:\n",
    "                continue\n",
    "\n",
    "            a = self.game.actions.index(best_acts[i])\n",
    "            v = values[i]\n",
    "\n",
    "            if (s, i, a) in self.Qsa:\n",
    "                self.Qsa[(s, i, a)] = (self.Nsa[(s, i, a)] * self.Qsa[(s, i, a)] + v) / (self.Nsa[(s, i, a)] + 1)\n",
    "                self.Nsa[(s, i, a)] += 1\n",
    "\n",
    "            else:\n",
    "                self.Qsa[(s, i, a)] = v\n",
    "                self.Nsa[(s, i, a)] = 1\n",
    "\n",
    "        self.Ns[s] += 1\n",
    "        return values\n",
    "\n",
    "\n",
    "class HungryGeese(object):\n",
    "    def __init__(\n",
    "        self, rows=7, columns=11, actions=[Action.NORTH, Action.SOUTH, Action.WEST, Action.EAST], hunger_rate=40\n",
    "    ):\n",
    "        self.rows = rows\n",
    "        self.columns = columns\n",
    "        self.actions = actions\n",
    "        self.hunger_rate = hunger_rate\n",
    "\n",
    "    def getActionSize(self):\n",
    "        return len(self.actions)\n",
    "\n",
    "    def getNextState(self, obs, last_obs, directions):\n",
    "        next_obs = deepcopy(obs)\n",
    "        next_obs.step += 1\n",
    "        geese = next_obs.geese\n",
    "        food = next_obs.food\n",
    "\n",
    "        for i in range(4):\n",
    "            goose = geese[i]\n",
    "\n",
    "            if len(goose) == 0:\n",
    "                continue\n",
    "\n",
    "            head = translate(goose[0], directions[i], self.columns, self.rows)\n",
    "\n",
    "            # Check action direction\n",
    "            if last_obs is not None and head == last_obs.geese[i][0]:\n",
    "                geese[i] = []\n",
    "                continue\n",
    "\n",
    "            # Consume food or drop a tail piece.\n",
    "            if head in food:\n",
    "                food.remove(head)\n",
    "            else:\n",
    "                goose.pop()\n",
    "\n",
    "            # Add New Head to the Goose.\n",
    "            goose.insert(0, head)\n",
    "\n",
    "            # If hunger strikes remove from the tail.\n",
    "            if next_obs.step % self.hunger_rate == 0:\n",
    "                if len(goose) > 0:\n",
    "                    goose.pop()\n",
    "\n",
    "        goose_positions = histogram(position for goose in geese for position in goose)\n",
    "\n",
    "        # Check for collisions.\n",
    "        for i in range(4):\n",
    "            if len(geese[i]) > 0:\n",
    "                head = geese[i][0]\n",
    "                if goose_positions[head] > 1:\n",
    "                    geese[i] = []\n",
    "\n",
    "        return next_obs\n",
    "\n",
    "    def getValidMoves(self, obs, last_obs, index):\n",
    "        geese = obs.geese\n",
    "        pos = geese[index][0]\n",
    "        obstacles = {position for goose in geese for position in goose[:-1]}\n",
    "        if last_obs is not None:\n",
    "            obstacles.add(last_obs.geese[index][0])\n",
    "\n",
    "        valid_moves = [translate(pos, action, self.columns, self.rows) not in obstacles for action in self.actions]\n",
    "\n",
    "        return valid_moves\n",
    "\n",
    "    def stringRepresentation(self, obs):\n",
    "        return str(obs.geese + obs.food)\n",
    "\n",
    "\n",
    "# Neural Network for Hungry Geese\n",
    "\n",
    "\n",
    "class TorusConv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
    "        super().__init__()\n",
    "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([x[:, :, :, -self.edge_size[1] :], x, x[:, :, :, : self.edge_size[1]]], dim=3)\n",
    "        h = torch.cat([h[:, :, -self.edge_size[0] :], h, h[:, :, : self.edge_size[0]]], dim=2)\n",
    "        h = self.conv(h)\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h\n",
    "\n",
    "\n",
    "class GeeseNetAlpha(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers, filters = 12, 128\n",
    "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p1 = nn.Linear(filters * 5 + 77, filters * 3, bias=False)\n",
    "        self.head_p2 = nn.Linear(filters * 3, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(filters * 5 + 77, filters * 3, bias=False)\n",
    "        self.head_v2 = nn.Linear(filters * 3, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h_p = F.relu_(self.conv_p(h))\n",
    "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p2 = (h_p * x[:, 1:2]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p3 = (h_p * x[:, 2:3]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p4 = (h_p * x[:, 3:4]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_avg_p1 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(-1)\n",
    "        h_avg_p2 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(1)\n",
    "\n",
    "        h_p = F.relu_(self.head_p1(torch.cat([h_head_p, h_head_p2, h_head_p3, h_head_p4, h_avg_p1, h_avg_p2], 1)))\n",
    "        p = self.head_p2(h_p)\n",
    "\n",
    "        h_v = F.relu_(self.conv_v(h))\n",
    "        h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_head_v2 = (h_v * x[:, 1:2]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_head_v3 = (h_v * x[:, 2:3]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_head_v4 = (h_v * x[:, 3:4]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_avg_v1 = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
    "        h_avg_v2 = h_v.view(h_v.size(0), h_v.size(1), -1).mean(1)\n",
    "\n",
    "        h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_head_v2, h_head_v3, h_head_v4, h_avg_v1, h_avg_v2], 1)))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return p, v  # {\"policy\": p, \"value\": v}\n",
    "\n",
    "\n",
    "class NNAgent:\n",
    "    def __init__(self, state_dict):\n",
    "        self.model = GeeseNetAlpha()\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, obs, last_obs, index):\n",
    "        x = self._make_input(obs, last_obs, index)\n",
    "        with torch.no_grad():\n",
    "            xt = torch.from_numpy(x).unsqueeze(0)\n",
    "            p, v = self.model(xt)\n",
    "\n",
    "        return p.squeeze(0).detach().numpy(), v.item()\n",
    "\n",
    "    # Input for Neural Network\n",
    "    def _make_input(self, obs, last_obs, index):\n",
    "        b = np.zeros((17, 7 * 11), dtype=np.float32)\n",
    "\n",
    "        for p, pos_list in enumerate(obs.geese):\n",
    "            # head position\n",
    "            for pos in pos_list[:1]:\n",
    "                b[0 + (p - index) % 4, pos] = 1\n",
    "            # tip position\n",
    "            for pos in pos_list[-1:]:\n",
    "                b[4 + (p - index) % 4, pos] = 1\n",
    "            # whole position\n",
    "            for pos in pos_list:\n",
    "                b[8 + (p - index) % 4, pos] = 1\n",
    "\n",
    "        # previous head position\n",
    "        if last_obs is not None:\n",
    "            for p, pos_list in enumerate(last_obs.geese):\n",
    "                for pos in pos_list[:1]:\n",
    "                    b[12 + (p - index) % 4, pos] = 1\n",
    "\n",
    "        # food\n",
    "        for pos in obs.food:\n",
    "            b[16, pos] = 1\n",
    "\n",
    "        return b.reshape(-1, 7, 11)\n",
    "\n",
    "\n",
    "# Load PyTorch Model\n",
    "\n",
    "\n",
    "PARAM = b\"xxxxxxxxxx\"\n",
    "state_dict = pickle.loads(bz2.decompress(base64.b64decode(PARAM)))\n",
    "\n",
    "game = HungryGeese()\n",
    "agent = NNAgent(state_dict)\n",
    "mcts = MCTS(game, agent)\n",
    "\n",
    "\n",
    "def alphageese_agent(obs, config):\n",
    "    action = game.actions[np.argmax(mcts.getActionProb(obs, timelimit=1.1))]  # timelimit=config.actTimeout\n",
    "    return action.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the submission file\n",
    "with open(\n",
    "    \"submission.py\",\n",
    ") as file:\n",
    "    filedata = file.read()\n",
    "\n",
    "# Replace the target string\n",
    "filedata = filedata.replace(\"xxxxxxxxxx\", PARAM.decode(\"utf-8\"))\n",
    "\n",
    "# Write the file out again\n",
    "with open(\"submission.py\", \"w\") as file:\n",
    "    file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_environments import make\n",
    "\n",
    "env = make(\"hungry_geese\", debug=True)\n",
    "\n",
    "env.reset()\n",
    "env.run([\"submission.py\", \"submission.py\", \"submission.py\", \"submission.py\"])\n",
    "env.render(mode=\"ipython\", width=800, height=700)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import bz2\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_path = {\n",
    "    \"a\": \"../input/hungry-geese-models/geese_net_fold1_best.pth\",\n",
    "    \"b\": \"../input/hungry-geese-models/geese_net_fold2_best.pth\",\n",
    "    \"c\": \"../input/hungry-geese-models/geese_net_fold4_best.pth\",\n",
    "    # \"d\": \"../input/hungry-geese-models/geese_net_fold3_best.pth\",\n",
    "    # \"e\": \"../input/hungry-geese-models/geese_net_fold4_best.pth\",\n",
    "    # \"f\": \"../input/hungry-geese-models/geese_net_fold5_best.pth\",\n",
    "}\n",
    "\n",
    "PARAM = {}\n",
    "for key, val in model_path.items():\n",
    "    # weights = torch.load(val)\n",
    "    weights = torch.load(val, map_location=torch.device(\"cpu\"))\n",
    "    PARAM[key] = base64.b64encode(bz2.compress(pickle.dumps(weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%%writefile submission.py\n",
    "\n",
    "PARAM = {\n",
    "    \"a\": b\"aaaaaaaaaa\",\n",
    "    \"b\": b\"bbbbbbbbbb\",\n",
    "    \"c\": b\"cccccccccc\",\n",
    "    # \"d\": b\"dddddddddd\",\n",
    "    # \"e\": b\"eeeeeeeeee\",\n",
    "    # \"f\": b\"ffffffffff\",\n",
    "}\n",
    "\n",
    "\n",
    "# This is a lightweight ML agent trained by self-play.\n",
    "# After sharing this notebook,\n",
    "# we will add Hungry Geese environment in our HandyRL library.\n",
    "# https://github.com/DeNA/HandyRL\n",
    "# We hope you enjoy reinforcement learning!\n",
    "\n",
    "\n",
    "import base64\n",
    "import bz2\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict, deque\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from kaggle_environments.envs.hungry_geese.hungry_geese import Action, translate\n",
    "from kaggle_environments.helpers import histogram\n",
    "\n",
    "# MCTS\n",
    "\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, game, nn_agent, eps=1e-8, cpuct=1.0, pb_c_base=19652, pb_c_init=1.25):\n",
    "        self.game = game\n",
    "        self.nn_agent = nn_agent\n",
    "        self.eps = eps\n",
    "        self.cpuct = cpuct\n",
    "        self.pb_c_base = pb_c_base\n",
    "        self.pb_c_init = pb_c_init\n",
    "\n",
    "        self.Qsa = {}  # 状態 s でプレイヤー i が行動 a を行ったあとの状態の状態評価値(訪問回数で平均)\n",
    "        self.Nsa = {}  # 状態 s でプレイヤー i が行動 a を行ったあとの状態への訪問回数\n",
    "        self.Ns = {}  # 状態 s の訪問回数\n",
    "        self.Ps = {}  # 状態 s でプレイヤー i の行動の評価値。policy networkの出力\n",
    "\n",
    "        self.Es = {}  # 状態 s でゲームが終了している場合の プレイヤー i の成績\n",
    "        self.Vs = {}  # 状態 s でのプレイヤー i の有効手\n",
    "\n",
    "        self.last_obs = None\n",
    "\n",
    "    def getActionProb(self, obs, timelimit=1.0):\n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < timelimit:\n",
    "            self.search(obs, self.last_obs)\n",
    "\n",
    "        s = self.game.stringRepresentation(obs)\n",
    "        i = obs.index\n",
    "        counts = [self.Nsa[(s, i, a)] if (s, i, a) in self.Nsa else 0 for a in range(self.game.getActionSize())]\n",
    "\n",
    "        # もっとも探索数が多い方角が2つ以上あるときは、もう一回探索する\n",
    "        if len([v for v in counts if v == max(counts)]) > 1:\n",
    "            self.search(obs, self.last_obs)\n",
    "\n",
    "        counts = [self.Nsa[(s, i, a)] if (s, i, a) in self.Nsa else 0 for a in range(self.game.getActionSize())]\n",
    "        prob = counts / np.sum(counts)\n",
    "        a = np.argmax(prob)\n",
    "\n",
    "        print(f\"step: {obs['step']}, player: {i}, value: {self.Qsa[(s, i, a)]:.3}, count: {counts} / {np.sum(counts)}\")\n",
    "\n",
    "        self.last_obs = obs\n",
    "        return a\n",
    "\n",
    "    def search(self, obs, last_obs):\n",
    "        \"\"\"\n",
    "        用語:\n",
    "            葉ノード: まだシミュレーションが行われていないノード\n",
    "        \"\"\"\n",
    "        s = self.game.stringRepresentation(obs)\n",
    "\n",
    "        if s not in self.Es:\n",
    "            self.Es[s] = self.game.getGameEnded(obs, last_obs)\n",
    "        if self.Es[s] is not None:\n",
    "            return self.Es[s]\n",
    "\n",
    "        # Aug を効かせるため、毎回推論する\n",
    "        values = [-10] * 4\n",
    "        for i in range(4):\n",
    "            if len(obs.geese[i]) == 0:\n",
    "                continue\n",
    "\n",
    "            # ニューラルネットワークで局面を評価する\n",
    "            self.Ps[(s, i)], values[i] = self.nn_agent.predict(obs, last_obs, i)\n",
    "\n",
    "            if (s, i) not in self.Vs:\n",
    "                self.Vs[(s, i)] = self.game.getValidMoves(obs, last_obs, i)\n",
    "            self.Ps[(s, i)] = self.Ps[(s, i)] * self.Vs[(s, i)]  # masking invalid moves\n",
    "            sum_Ps_s = np.sum(self.Ps[(s, i)])\n",
    "            if sum_Ps_s > 0:\n",
    "                self.Ps[(s, i)] /= sum_Ps_s  # renormalize\n",
    "\n",
    "        # 現在の局面が葉ノードならば\n",
    "        if s not in self.Ns:\n",
    "            self.Ns[s] = 0\n",
    "\n",
    "            # 各プレイヤーの現在の局面の 状態の評価値 を返す\n",
    "            return values\n",
    "\n",
    "        best_acts = [None] * 4\n",
    "        for i in range(4):\n",
    "            if len(obs.geese[i]) == 0:\n",
    "                continue\n",
    "\n",
    "            valids = self.Vs[(s, i)]\n",
    "            cur_best = -float(\"inf\")\n",
    "            best_act = self.game.actions[-1]\n",
    "\n",
    "            # pick the action with the highest upper confidence bound\n",
    "            # 現在の局面 s でプレイヤー i の最適な行動を決定する\n",
    "            for a in range(self.game.getActionSize()):\n",
    "                if valids[a]:\n",
    "\n",
    "                    # PUCT (AlphaGo)\n",
    "                    \"\"\"\n",
    "                    if (s, i, a) in self.Qsa:\n",
    "                        u = self.Qsa[(s, i, a)] + self.cpuct * self.Ps[(s, i)][a] * math.sqrt(self.Ns[s]) / (\n",
    "                            1 + self.Nsa[(s, i, a)]\n",
    "                        )\n",
    "                    else:\n",
    "                        u = self.cpuct * self.Ps[(s, i)][a] * math.sqrt(self.Ns[s] + self.eps)\n",
    "                    \"\"\"\n",
    "\n",
    "                    # PUCT (AlphaZero)\n",
    "                    \"\"\"\n",
    "                    cs = math.log((1 + self.Ns[s] + self.pb_c_base) / self.pb_c_base) + self.pb_c_init\n",
    "\n",
    "                    if (s, i, a) in self.Qsa:\n",
    "                        u = self.Qsa[(s, i, a)] + cs * self.Ps[(s, i)][a] * math.sqrt(self.Ns[s]) / (\n",
    "                            1 + self.Nsa[(s, i, a)]\n",
    "                        )\n",
    "                    else:\n",
    "                        u = cs * self.Ps[(s, i)][a] * math.sqrt(self.Ns[s] + self.eps)\n",
    "                    \"\"\"\n",
    "\n",
    "                    # Use only policy\n",
    "                    u = self.Ps[(s, i)][a]\n",
    "\n",
    "                    if u > cur_best:\n",
    "                        cur_best = u\n",
    "                        best_act = self.game.actions[a]\n",
    "\n",
    "            best_acts[i] = best_act\n",
    "\n",
    "        # 各プレイヤーがベストな行動を行ったあとの局面を生成\n",
    "        next_obs = self.game.getNextState(obs, last_obs, best_acts)\n",
    "\n",
    "        # 生成した次の局面を探索\n",
    "        values = self.search(next_obs, obs)\n",
    "\n",
    "        for i in range(4):\n",
    "            if len(obs.geese[i]) == 0:\n",
    "                continue\n",
    "\n",
    "            a = self.game.actions.index(best_acts[i])\n",
    "            v = values[i]\n",
    "\n",
    "            if (s, i, a) in self.Qsa:\n",
    "                self.Qsa[(s, i, a)] = (self.Nsa[(s, i, a)] * self.Qsa[(s, i, a)] + v) / (self.Nsa[(s, i, a)] + 1)\n",
    "                self.Nsa[(s, i, a)] += 1\n",
    "\n",
    "            else:\n",
    "                self.Qsa[(s, i, a)] = v\n",
    "                self.Nsa[(s, i, a)] = 1\n",
    "\n",
    "        self.Ns[s] += 1\n",
    "        return values\n",
    "\n",
    "\n",
    "class HungryGeese(object):\n",
    "    def __init__(\n",
    "        self, rows=7, columns=11, actions=[Action.NORTH, Action.SOUTH, Action.WEST, Action.EAST], hunger_rate=40\n",
    "    ):\n",
    "        self.rows = rows\n",
    "        self.columns = columns\n",
    "        self.actions = actions\n",
    "        self.hunger_rate = hunger_rate\n",
    "\n",
    "    def getActionSize(self):\n",
    "        return len(self.actions)\n",
    "\n",
    "    def getNextState(self, obs, last_obs, directions):\n",
    "        next_obs = deepcopy(obs)\n",
    "        next_obs.step += 1\n",
    "        geese = next_obs.geese\n",
    "        food = next_obs.food\n",
    "        new_food = 0\n",
    "\n",
    "        for i in range(4):\n",
    "            goose = geese[i]\n",
    "\n",
    "            if len(goose) == 0:\n",
    "                continue\n",
    "\n",
    "            head = translate(goose[0], directions[i], self.columns, self.rows)\n",
    "\n",
    "            # Check action direction\n",
    "            if last_obs is not None and head == last_obs.geese[i][0]:\n",
    "                geese[i] = []\n",
    "                continue\n",
    "\n",
    "            # Consume food or drop a tail piece.\n",
    "            if head in food:\n",
    "                food.remove(head)\n",
    "                new_food += 1\n",
    "            else:\n",
    "                goose.pop()\n",
    "\n",
    "            # Add New Head to the Goose.\n",
    "            goose.insert(0, head)\n",
    "\n",
    "            # If hunger strikes remove from the tail.\n",
    "            if next_obs.step % self.hunger_rate == 0:\n",
    "                if len(goose) > 0:\n",
    "                    goose.pop()\n",
    "\n",
    "            geese[i] = goose\n",
    "\n",
    "        goose_positions = histogram(position for goose in geese for position in goose)\n",
    "\n",
    "        # Check for collisions.\n",
    "        for i in range(4):\n",
    "            if len(geese[i]) > 0:\n",
    "                head = geese[i][0]\n",
    "                if goose_positions[head] > 1:\n",
    "                    geese[i] = []\n",
    "\n",
    "        if new_food > 0:\n",
    "            collisions = {position for goose in geese for position in goose}\n",
    "            available_positions = set(range(77)).difference(collisions).difference(food)\n",
    "            # Ensure we don't sample more food than available positions.\n",
    "            needed_food = min(new_food, len(available_positions))\n",
    "            food.extend(random.sample(available_positions, needed_food))\n",
    "\n",
    "        next_obs.geese = geese\n",
    "        next_obs.food = food\n",
    "\n",
    "        return next_obs\n",
    "\n",
    "    def getValidMoves(self, obs, last_obs, index):\n",
    "        geese = obs.geese\n",
    "        pos = geese[index][0]\n",
    "        obstacles = {position for goose in geese for position in goose[:-1]}\n",
    "        if last_obs is not None:\n",
    "            obstacles.add(last_obs.geese[index][0])\n",
    "\n",
    "        valid_moves = [translate(pos, action, self.columns, self.rows) not in obstacles for action in self.actions]\n",
    "\n",
    "        return valid_moves\n",
    "\n",
    "    def getGameEnded(self, obs, last_obs):\n",
    "        \"\"\"\n",
    "        return None if game is not ended.\n",
    "        \"\"\"\n",
    "        active_geese = len([goose for goose in obs.geese if len(goose) > 0])\n",
    "        if active_geese > 1 and obs.step < 199:\n",
    "            return None\n",
    "\n",
    "        rewards = [0.0] * 4\n",
    "        for p, geese in enumerate(obs.geese):\n",
    "            if len(geese) > 0:\n",
    "                rewards[p] = len(geese) + 100\n",
    "        for p, geese in enumerate(last_obs.geese):\n",
    "            if len(geese) > 0 and rewards[p] == 0:\n",
    "                rewards[p] = len(geese)\n",
    "\n",
    "        outcomes = [0.0] * 4\n",
    "        for p, r in enumerate(rewards):\n",
    "            for pp, rr in enumerate(rewards):\n",
    "                if p != pp:\n",
    "                    if r > rr:\n",
    "                        outcomes[p] += 1.0\n",
    "                    elif r < rr:\n",
    "                        outcomes[p] -= 2.0\n",
    "\n",
    "        # print(f\"outcomes: {outcomes}\")\n",
    "        return outcomes\n",
    "\n",
    "    def stringRepresentation(self, obs):\n",
    "        return str(obs.geese + obs.food)\n",
    "\n",
    "\n",
    "# Neural Network for Hungry Geese\n",
    "\n",
    "\n",
    "class TorusConv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
    "        super().__init__()\n",
    "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([x[:, :, :, -self.edge_size[1] :], x, x[:, :, :, : self.edge_size[1]]], dim=3)\n",
    "        h = torch.cat([h[:, :, -self.edge_size[0] :], h, h[:, :, : self.edge_size[0]]], dim=2)\n",
    "        h = self.conv(h)\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h\n",
    "\n",
    "\n",
    "class GeeseNetAlpha(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = 12\n",
    "        filters = 48\n",
    "        dim = 270\n",
    "\n",
    "        self.embed_step = nn.Embedding(5, 3)\n",
    "        self.embed_hunger = nn.Embedding(5, 3)\n",
    "        self.embed_diff_len = nn.Embedding(7, 4)\n",
    "        self.embed_diff_head = nn.Embedding(9, 4)\n",
    "\n",
    "        self.conv0 = TorusConv2d(25, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.conv1 = TorusConv2d(filters, filters, (5, 5), True)\n",
    "\n",
    "        self.head_p1 = nn.Linear(dim, dim // 2, bias=False)\n",
    "        self.head_p2 = nn.Linear(dim // 2, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(dim, dim // 2, bias=False)\n",
    "        self.head_v2 = nn.Linear(dim // 2, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        x_feats = x[:, -1].view(x.size(0), -1).long()\n",
    "\n",
    "        # Embedding for features\n",
    "        e_step = self.embed_step(x_feats[:, 0])\n",
    "        e_hung = self.embed_hunger(x_feats[:, 1])\n",
    "        e_diff_l = self.embed_diff_len(x_feats[:, 2:5]).view(x.size(0), -1)\n",
    "        e_diff_h = self.embed_diff_head(x_feats[:, 5:8]).view(x.size(0), -1)\n",
    "\n",
    "        x = x[:, :-1].float()\n",
    "\n",
    "        # CNN for observation\n",
    "        h = F.relu_(self.conv0(x))\n",
    "\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h = F.relu_(self.conv1(h))\n",
    "\n",
    "        # Extract head position\n",
    "        h_head = (h * x[:, :1]).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        h_head2 = (h * x[:, 1:2]).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        h_head3 = (h * x[:, 2:3]).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        h_head4 = (h * x[:, 3:4]).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        h_avg = h.view(h.size(0), h.size(1), -1).mean(-1)\n",
    "\n",
    "        # Merge features\n",
    "        h = torch.cat(\n",
    "            [\n",
    "                h_head,\n",
    "                h_head2,\n",
    "                h_head3,\n",
    "                h_head4,\n",
    "                h_avg,\n",
    "                e_step,\n",
    "                e_hung,\n",
    "                e_diff_l,\n",
    "                e_diff_h,\n",
    "            ],\n",
    "            1,\n",
    "        ).view(1, h.size(0), -1)\n",
    "\n",
    "        h_p = F.relu_(self.head_p1(h.view(x.size(0), -1)))\n",
    "        p = self.head_p2(h_p)\n",
    "\n",
    "        h_v = F.relu_(self.head_v1(h.view(x.size(0), -1)))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return p, v  # {\"policy\": p, \"value\": v}\n",
    "\n",
    "\n",
    "def identity(image):\n",
    "    return image.copy(), [0, 1, 2, 3]\n",
    "\n",
    "\n",
    "def h_flip(image):\n",
    "    image = image[:, :, ::-1]\n",
    "    return image.copy(), [0, 1, 3, 2]\n",
    "\n",
    "\n",
    "def v_flip(image):\n",
    "    image = image[:, ::-1, :]\n",
    "    return image.copy(), [1, 0, 2, 3]\n",
    "\n",
    "\n",
    "def hv_flip(image):\n",
    "    image = image[:, ::-1, ::-1]\n",
    "    return image.copy(), [1, 0, 3, 2]\n",
    "\n",
    "\n",
    "class NNAgent:\n",
    "\n",
    "    next_position_map = {}\n",
    "    for pos in range(77):\n",
    "        position = []\n",
    "        position.append((11 * (1 + pos // 11) + pos % 11) % 77)\n",
    "        position.append((11 * (-1 + pos // 11) + pos % 11) % 77)\n",
    "        position.append((11 * (pos // 11) + (pos + 1) % 11) % 77)\n",
    "        position.append((11 * (pos // 11) + (pos - 1) % 11) % 77)\n",
    "        next_position_map[pos] = set(position)\n",
    "\n",
    "    def __init__(self, state_dicts):\n",
    "        self.models = {}\n",
    "        for key, state in state_dicts.items():\n",
    "            self.models[key] = GeeseNetAlpha()\n",
    "            self.models[key].load_state_dict(state)\n",
    "            self.models[key].eval()\n",
    "\n",
    "    def predict(self, obs, last_obs, index):\n",
    "        x, info = self._make_input(obs, last_obs, index)\n",
    "\n",
    "        transform = random.choice([identity, h_flip, v_flip, hv_flip])\n",
    "        p, v = self._predict(x, transform, info)\n",
    "\n",
    "        return p, v\n",
    "\n",
    "    def _predict(self, x, transform, info=None):\n",
    "        x, slices = transform(x)\n",
    "        if info is not None:\n",
    "            x = np.concatenate([x, info], axis=0)\n",
    "\n",
    "        model_key = random.choice(list(PARAM.keys()))\n",
    "        with torch.no_grad():\n",
    "            xt = torch.from_numpy(x).unsqueeze(0)\n",
    "            p, v = self.models[model_key](xt)\n",
    "\n",
    "        p = p.squeeze(0).detach().numpy()\n",
    "        p = p[slices]\n",
    "        return p, v.item()\n",
    "\n",
    "    # Input for Neural Network\n",
    "    def _make_input(self, obs, last_obs, index):\n",
    "        x_ = []\n",
    "        x_.append(self._make_input_normal(obs, last_obs, index))\n",
    "        x_.append(self._get_reverse_cube(obs, index))\n",
    "        x_.append(self._get_next_disappear_cube(obs, index))\n",
    "        x = np.concatenate(x_)\n",
    "\n",
    "        info_ = []\n",
    "        # info_.append(self._get_step_cube_v2(obs))\n",
    "        # info_.append(self._get_length_cube(obs, index))\n",
    "        info_.append(self._get_features(obs, index))\n",
    "        info = np.concatenate(info_)\n",
    "\n",
    "        return x, info\n",
    "\n",
    "    def _make_input_normal(self, obs, last_obs, index):\n",
    "        b = np.zeros((17, 7 * 11), dtype=np.float32)\n",
    "\n",
    "        for p, pos_list in enumerate(obs.geese):\n",
    "            # head position\n",
    "            for pos in pos_list[:1]:\n",
    "                b[0 + (p - index) % 4, pos] = 1\n",
    "            # tip position\n",
    "            for pos in pos_list[-1:]:\n",
    "                b[4 + (p - index) % 4, pos] = 1\n",
    "            # whole position\n",
    "            for pos in pos_list:\n",
    "                b[8 + (p - index) % 4, pos] = 1\n",
    "\n",
    "        # previous head position\n",
    "        if last_obs is not None:\n",
    "            for p, pos_list in enumerate(last_obs.geese):\n",
    "                for pos in pos_list[:1]:\n",
    "                    b[12 + (p - index) % 4, pos] = 1\n",
    "\n",
    "        # food\n",
    "        for pos in obs.food:\n",
    "            b[16, pos] = 1\n",
    "\n",
    "        return b.reshape(-1, 7, 11)\n",
    "\n",
    "    def _get_reverse_cube(self, obs, index):\n",
    "        \"\"\"\n",
    "        尻尾から順番に 1, 0.9, 0.8, ... という並び\n",
    "        \"\"\"\n",
    "        b = np.zeros((4, 7 * 11), dtype=np.float32)\n",
    "\n",
    "        for p, geese in enumerate(obs[\"geese\"]):\n",
    "            # whole position reverse\n",
    "            for num_reverse, pos in enumerate(geese[::-1]):\n",
    "                b[(p - index) % 4, pos] = 1 - num_reverse * 0.1\n",
    "\n",
    "        return b.reshape(-1, 7, 11)\n",
    "\n",
    "    def _get_next_disappear_cube(self, obs, index):\n",
    "        \"\"\"\n",
    "        次になくなる場所: 1\n",
    "        次になくなる可能性のある場所: 0.5\n",
    "        \"\"\"\n",
    "        b = np.zeros((4, 7 * 11), dtype=np.float32)\n",
    "        step = obs[\"step\"]\n",
    "\n",
    "        # foodを食べる可能性があるか。\n",
    "        eat_food_possibility = defaultdict(int)\n",
    "        for p, geese in enumerate(obs[\"geese\"]):\n",
    "            for pos in geese[:1]:\n",
    "                if not self.next_position_map[pos].isdisjoint(obs[\"food\"]):\n",
    "                    eat_food_possibility[p] = 1\n",
    "\n",
    "        if (step % 40) == 39:  # 1つ短くなる\n",
    "            for p, geese in enumerate(obs[\"geese\"]):\n",
    "                if eat_food_possibility[p]:  # 尻尾が1、尻尾の１つ前0.5\n",
    "                    for pos in geese[-1:]:\n",
    "                        b[(p - index) % 4, pos] = 1\n",
    "                    for pos in geese[-2:-1]:\n",
    "                        b[(p - index) % 4, pos] = 0.5\n",
    "                else:  # 食べる可能性なし -> 尻尾が1, 尻尾の1つ前1\n",
    "                    for pos in geese[-2:]:\n",
    "                        b[(p - index) % 4, pos] = 1\n",
    "        else:  # 1つ短くならない\n",
    "            for p, geese in enumerate(obs[\"geese\"]):\n",
    "                if eat_food_possibility[p]:  # 食べる可能性があり -> 尻尾を0.5\n",
    "                    for pos in geese[-1:]:\n",
    "                        b[(p - index) % 4, pos] = 0.5\n",
    "                else:  # 食べる可能性なし # 尻尾を1\n",
    "                    for pos in geese[-1:]:\n",
    "                        b[(p - index) % 4, pos] = 1\n",
    "\n",
    "        return b.reshape(-1, 7, 11)\n",
    "\n",
    "    def _get_step_cube_v2(self, obs):\n",
    "        \"\"\"\n",
    "        step0: 0, step199: 1\n",
    "        step0: 0, step39 + 40n: 1\n",
    "        \"\"\"\n",
    "        b = np.zeros((1, 7, 11), dtype=np.float32)\n",
    "        step = obs[\"step\"]\n",
    "\n",
    "        b[:, :, :5] = (step % 200) / 199\n",
    "        b[:, :, 5:] = (step % 40) / 39\n",
    "\n",
    "        return b\n",
    "\n",
    "    def _get_length_cube(self, obs, index):\n",
    "        b = np.zeros((2, 7, 11), dtype=np.float32)\n",
    "\n",
    "        my_length = len(obs[\"geese\"][index])\n",
    "        opposite1_length = len(obs[\"geese\"][(index + 1) % 4])\n",
    "        opposite2_length = len(obs[\"geese\"][(index + 2) % 4])\n",
    "        opposite3_length = len(obs[\"geese\"][(index + 3) % 4])\n",
    "\n",
    "        b[0] = my_length / 10\n",
    "        max_opposite_length = max(opposite1_length, opposite2_length, opposite3_length)\n",
    "        b[1, :, 0:2] = (my_length - max_opposite_length) / 10\n",
    "        b[1, :, 2:5] = (my_length - opposite1_length) / 10\n",
    "        b[1, :, 5:8] = (my_length - opposite2_length) / 10\n",
    "        b[1, :, 8:11] = (my_length - opposite3_length) / 10\n",
    "\n",
    "        return b\n",
    "\n",
    "    def _get_features(self, obs, index):\n",
    "        b = np.zeros((7 * 11), dtype=np.float32)\n",
    "        step = obs[\"step\"]\n",
    "\n",
    "        my_goose = obs[\"geese\"][index]\n",
    "        my_length = len(my_goose)\n",
    "\n",
    "        # num step\n",
    "        b[0] = (step - 194) if step >= 195 else 0\n",
    "        b[1] = (step % 40 - 35) if step % 40 > 35 else 0\n",
    "\n",
    "        \"\"\"\n",
    "        2-4: difference between my_length and opponent length (-3 to 3)\n",
    "        \"\"\"\n",
    "        for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "            pid = (p - index) % 4\n",
    "            p_length = len(pos_list)\n",
    "\n",
    "            if pid == 0:\n",
    "                continue\n",
    "\n",
    "            b[1 + pid] = max(min(my_length - p_length, 3), -3) + 3\n",
    "\n",
    "        \"\"\"\n",
    "        5-7: difference between my head position and opponent one\n",
    "        \"\"\"\n",
    "        if my_length != 0:\n",
    "\n",
    "            for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "                pid = (p - index) % 4\n",
    "\n",
    "                if pid == 0 or len(pos_list) == 0:\n",
    "                    continue\n",
    "\n",
    "                diff = abs(my_goose[0] - pos_list[0])\n",
    "                x_ = diff % 11\n",
    "                x = min(x_, 11 - x_)\n",
    "                y_ = diff // 11\n",
    "                y = min(y_, 7 - y_)\n",
    "                b[4 + pid] = x + y\n",
    "\n",
    "        return b.reshape(1, 7, 11)\n",
    "\n",
    "\n",
    "# Load PyTorch Model\n",
    "\n",
    "\n",
    "state_dicts = {}\n",
    "for key, param in PARAM.items():\n",
    "    state_dicts[key] = pickle.loads(bz2.decompress(base64.b64decode(param)))\n",
    "\n",
    "game = HungryGeese()\n",
    "agent = NNAgent(state_dicts)\n",
    "mcts = MCTS(game, agent, pb_c_base=10, pb_c_init=1.0)\n",
    "\n",
    "\n",
    "def alphageese_agent(obs, config):\n",
    "    action = game.actions[mcts.getActionProb(obs, timelimit=0.9)]  # timelimit=config.actTimeout\n",
    "    return action.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the submission file\n",
    "with open(\n",
    "    \"submission.py\",\n",
    ") as file:\n",
    "    filedata = file.read()\n",
    "\n",
    "# Replace the target string\n",
    "for key, val in PARAM.items():\n",
    "    filedata = filedata.replace(key * 10, val.decode(\"utf-8\"))\n",
    "\n",
    "# Write the file out again\n",
    "with open(\"submission.py\", \"w\") as file:\n",
    "    file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_environments import make\n",
    "\n",
    "env = make(\"hungry_geese\", debug=True)\n",
    "\n",
    "env.reset()\n",
    "env.run([\"submission.py\", \"submission.py\", \"submission.py\", \"submission.py\"])\n",
    "env.render(mode=\"ipython\", width=800, height=700)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

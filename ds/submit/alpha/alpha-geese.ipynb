{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOCAL:\n",
    "    !pip install -q -U kaggle-environments\n",
    "    !pip list | grep kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import bz2\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_filename = \"alpha_64_409.pth\"\n",
    "if LOCAL:\n",
    "    model_path = \"../../models/\" + model_filename\n",
    "    # model_path = \"../../../models/latest.pth\"  # + model_filename\n",
    "else:\n",
    "    model_path = \"../input/hungry-geese-models/\" + model_filename\n",
    "\n",
    "# weights = torch.load(model_path)\n",
    "weights = torch.load(model_path, map_location=torch.device(\"cpu\"))\n",
    "\n",
    "PARAM = base64.b64encode(bz2.compress(pickle.dumps(weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%%writefile submission.py\n",
    "\n",
    "# This is a lightweight ML agent trained by self-play.\n",
    "# After sharing this notebook,\n",
    "# we will add Hungry Geese environment in our HandyRL library.\n",
    "# https://github.com/DeNA/HandyRL\n",
    "# We hope you enjoy reinforcement learning!\n",
    "\n",
    "\n",
    "import base64\n",
    "import bz2\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "from collections import defaultdict, deque\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from kaggle_environments.envs.hungry_geese.hungry_geese import Action, translate\n",
    "from kaggle_environments.helpers import histogram\n",
    "\n",
    "# MCTS\n",
    "\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, game, nn_agent, eps=1e-8, cpuct=1.0):\n",
    "        \"\"\"\n",
    "        Cpuct is a game-dependent constant, typically in. [0.5,5].\n",
    "        \"\"\"\n",
    "        self.game = game\n",
    "        self.nn_agent = nn_agent\n",
    "        self.eps = eps\n",
    "        self.cpuct = cpuct\n",
    "\n",
    "        self.Qsa = {}  # 状態 s でプレイヤー i が行動 a を行ったあとの状態の状態評価値(訪問回数で平均)\n",
    "        self.Nsa = {}  # 状態 s でプレイヤー i が行動 a を行ったあとの状態への訪問回数\n",
    "        self.Ns = {}  # 状態 s の訪問回数\n",
    "        self.Ps = {}  # 状態 s でプレイヤー i の行動の評価値。policy networkの出力\n",
    "\n",
    "        self.Vs = {}  # 状態 s でのプレイヤー i の有効手\n",
    "\n",
    "        self.last_obs = None\n",
    "\n",
    "    def getActionProb(self, obs, timelimit=1.0):\n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < timelimit:\n",
    "            self.search(obs, self.last_obs)\n",
    "\n",
    "        s = self.game.stringRepresentation(obs)\n",
    "        i = obs.index\n",
    "        counts = [self.Nsa[(s, i, a)] if (s, i, a) in self.Nsa else 0 for a in range(self.game.getActionSize())]\n",
    "        prob = counts / np.sum(counts)\n",
    "\n",
    "        print(f\"player: {i}, count: {counts} / {np.sum(counts)}\")\n",
    "\n",
    "        self.last_obs = obs\n",
    "        return prob\n",
    "\n",
    "    def search(self, obs, last_obs):\n",
    "        \"\"\"\n",
    "        用語:\n",
    "            葉ノード: まだシミュレーションが行われていないノード\n",
    "        \"\"\"\n",
    "        s = self.game.stringRepresentation(obs)\n",
    "\n",
    "        # 現在の局面が葉ノードならば\n",
    "        if s not in self.Ns:\n",
    "            values = [-10] * 4\n",
    "            for i in range(4):\n",
    "                if len(obs.geese[i]) == 0:\n",
    "                    continue\n",
    "\n",
    "                # ニューラルネットワークで局面を評価する\n",
    "                self.Ps[(s, i)], values[i] = self.nn_agent.predict(obs, last_obs, i)\n",
    "\n",
    "                valids = self.game.getValidMoves(obs, last_obs, i)\n",
    "                self.Ps[(s, i)] = self.Ps[(s, i)] * valids  # masking invalid moves\n",
    "                sum_Ps_s = np.sum(self.Ps[(s, i)])\n",
    "                if sum_Ps_s > 0:\n",
    "                    self.Ps[(s, i)] /= sum_Ps_s  # renormalize\n",
    "\n",
    "                self.Vs[(s, i)] = valids\n",
    "                self.Ns[s] = 0\n",
    "\n",
    "            # 各プレイヤーの現在の局面の 状態の評価値 を返す\n",
    "            return values\n",
    "\n",
    "        best_acts = [None] * 4\n",
    "        for i in range(4):\n",
    "            if len(obs.geese[i]) == 0:\n",
    "                continue\n",
    "\n",
    "            valids = self.Vs[(s, i)]\n",
    "            cur_best = -float(\"inf\")\n",
    "            best_act = self.game.actions[-1]\n",
    "\n",
    "            # pick the action with the highest upper confidence bound\n",
    "            # 現在の局面 s でプレイヤー i の最適な行動を PUCTアルゴリズム で決定する\n",
    "            for a in range(self.game.getActionSize()):\n",
    "                if valids[a]:\n",
    "                    if (s, i, a) in self.Qsa:\n",
    "                        u = self.Qsa[(s, i, a)] + self.cpuct * self.Ps[(s, i)][a] * math.sqrt(self.Ns[s]) / (\n",
    "                            1 + self.Nsa[(s, i, a)]\n",
    "                        )\n",
    "                    else:\n",
    "                        u = self.cpuct * self.Ps[(s, i)][a] * math.sqrt(self.Ns[s] + self.eps)\n",
    "\n",
    "                    if u > cur_best:\n",
    "                        cur_best = u\n",
    "                        best_act = self.game.actions[a]\n",
    "\n",
    "            best_acts[i] = best_act\n",
    "\n",
    "        # 各プレイヤーがベストな行動を行ったあとの局面を生成\n",
    "        next_obs = self.game.getNextState(obs, last_obs, best_acts)\n",
    "\n",
    "        # 生成した次の局面を探索\n",
    "        values = self.search(next_obs, obs)\n",
    "\n",
    "        for i in range(4):\n",
    "            if len(obs.geese[i]) == 0:\n",
    "                continue\n",
    "\n",
    "            a = self.game.actions.index(best_acts[i])\n",
    "            v = values[i]\n",
    "\n",
    "            if (s, i, a) in self.Qsa:\n",
    "                self.Qsa[(s, i, a)] = (self.Nsa[(s, i, a)] * self.Qsa[(s, i, a)] + v) / (self.Nsa[(s, i, a)] + 1)\n",
    "                self.Nsa[(s, i, a)] += 1\n",
    "\n",
    "            else:\n",
    "                self.Qsa[(s, i, a)] = v\n",
    "                self.Nsa[(s, i, a)] = 1\n",
    "\n",
    "        self.Ns[s] += 1\n",
    "        return values\n",
    "\n",
    "\n",
    "class HungryGeese(object):\n",
    "    def __init__(\n",
    "        self, rows=7, columns=11, actions=[Action.NORTH, Action.SOUTH, Action.WEST, Action.EAST], hunger_rate=40\n",
    "    ):\n",
    "        self.rows = rows\n",
    "        self.columns = columns\n",
    "        self.actions = actions\n",
    "        self.hunger_rate = hunger_rate\n",
    "\n",
    "    def getActionSize(self):\n",
    "        return len(self.actions)\n",
    "\n",
    "    def getNextState(self, obs, last_obs, directions):\n",
    "        next_obs = deepcopy(obs)\n",
    "        next_obs.step += 1\n",
    "        geese = next_obs.geese\n",
    "        food = next_obs.food\n",
    "\n",
    "        for i in range(4):\n",
    "            goose = geese[i]\n",
    "\n",
    "            if len(goose) == 0:\n",
    "                continue\n",
    "\n",
    "            head = translate(goose[0], directions[i], self.columns, self.rows)\n",
    "\n",
    "            # Check action direction\n",
    "            if last_obs is not None and head == last_obs.geese[i][0]:\n",
    "                geese[i] = []\n",
    "                continue\n",
    "\n",
    "            # Consume food or drop a tail piece.\n",
    "            if head in food:\n",
    "                food.remove(head)\n",
    "            else:\n",
    "                goose.pop()\n",
    "\n",
    "            # Add New Head to the Goose.\n",
    "            goose.insert(0, head)\n",
    "\n",
    "            # If hunger strikes remove from the tail.\n",
    "            if next_obs.step % self.hunger_rate == 0:\n",
    "                if len(goose) > 0:\n",
    "                    goose.pop()\n",
    "\n",
    "        goose_positions = histogram(position for goose in geese for position in goose)\n",
    "\n",
    "        # Check for collisions.\n",
    "        for i in range(4):\n",
    "            if len(geese[i]) > 0:\n",
    "                head = geese[i][0]\n",
    "                if goose_positions[head] > 1:\n",
    "                    geese[i] = []\n",
    "\n",
    "        return next_obs\n",
    "\n",
    "    def getValidMoves(self, obs, last_obs, index):\n",
    "        geese = obs.geese\n",
    "        pos = geese[index][0]\n",
    "        obstacles = {position for goose in geese for position in goose[:-1]}\n",
    "        if last_obs is not None:\n",
    "            obstacles.add(last_obs.geese[index][0])\n",
    "\n",
    "        valid_moves = [translate(pos, action, self.columns, self.rows) not in obstacles for action in self.actions]\n",
    "\n",
    "        return valid_moves\n",
    "\n",
    "    def stringRepresentation(self, obs):\n",
    "        return str(obs.geese + obs.food)\n",
    "\n",
    "\n",
    "# Neural Network for Hungry Geese\n",
    "\n",
    "\n",
    "class TorusConv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
    "        super().__init__()\n",
    "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([x[:, :, :, -self.edge_size[1] :], x, x[:, :, :, : self.edge_size[1]]], dim=3)\n",
    "        h = torch.cat([h[:, :, -self.edge_size[0] :], h, h[:, :, : self.edge_size[0]]], dim=2)\n",
    "        h = self.conv(h)\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h\n",
    "\n",
    "\n",
    "class GeeseNetAlpha(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers, filters = 12, 64\n",
    "        self.conv0 = TorusConv2d(28, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p1 = nn.Linear(filters * 5 + 77, filters * 3, bias=False)\n",
    "        self.head_p2 = nn.Linear(filters * 3, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(filters * 5 + 77, filters * 3, bias=False)\n",
    "        self.head_v2 = nn.Linear(filters * 3, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h_p = F.relu_(self.conv_p(h))\n",
    "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p2 = (h_p * x[:, 1:2]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p3 = (h_p * x[:, 2:3]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p4 = (h_p * x[:, 3:4]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_avg_p1 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(-1)\n",
    "        h_avg_p2 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(1)\n",
    "\n",
    "        h_p = F.relu_(self.head_p1(torch.cat([h_head_p, h_head_p2, h_head_p3, h_head_p4, h_avg_p1, h_avg_p2], 1)))\n",
    "        p = torch.softmax(self.head_p2(h_p), 1)\n",
    "\n",
    "        h_v = F.relu_(self.conv_v(h))\n",
    "        h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_head_v2 = (h_v * x[:, 1:2]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_head_v3 = (h_v * x[:, 2:3]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_head_v4 = (h_v * x[:, 3:4]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_avg_v1 = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
    "        h_avg_v2 = h_v.view(h_v.size(0), h_v.size(1), -1).mean(1)\n",
    "\n",
    "        h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_head_v2, h_head_v3, h_head_v4, h_avg_v1, h_avg_v2], 1)))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return p, v  # {\"policy\": p, \"value\": v}\n",
    "\n",
    "\n",
    "def identity(image):\n",
    "    return image.copy(), [0, 1, 2, 3]\n",
    "\n",
    "\n",
    "def horizontal_flip(image):\n",
    "    image = image[:, :, ::-1]\n",
    "    return image.copy(), [0, 1, 3, 2]\n",
    "\n",
    "\n",
    "def vertical_flip(image):\n",
    "    image = image[:, ::-1, :]\n",
    "    return image.copy(), [1, 0, 2, 3]\n",
    "\n",
    "\n",
    "def horizontal_vertical_flip(image):\n",
    "    image = image[:, ::-1, ::-1]\n",
    "    return image.copy(), [1, 0, 3, 2]\n",
    "\n",
    "\n",
    "class NNAgent:\n",
    "\n",
    "    next_position_map = {}\n",
    "    for pos in range(77):\n",
    "        position = []\n",
    "        position.append((11 * (1 + pos // 11) + pos % 11) % 77)\n",
    "        position.append((11 * (-1 + pos // 11) + pos % 11) % 77)\n",
    "        position.append((11 * (pos // 11) + (pos + 1) % 11) % 77)\n",
    "        position.append((11 * (pos // 11) + (pos - 1) % 11) % 77)\n",
    "        next_position_map[pos] = set(position)\n",
    "\n",
    "    def __init__(self, state_dict):\n",
    "        self.model = GeeseNetAlpha()\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, obs, last_obs, index):\n",
    "        x = self._make_input(obs, last_obs, index)\n",
    "\n",
    "        p, v = self._predict(x, identity)\n",
    "        # p_h, v_h = self._predict(x, horizontal_flip)\n",
    "        # p_v, v_v = self._predict(x, vertical_flip)\n",
    "        # p_hv, v_hv = self._predict(x, horizontal_vertical_flip)\n",
    "\n",
    "        # p = (p + p_h + p_v + p_hv) / 4\n",
    "        # v = (v + v_h + v_v + v_hv) / 4\n",
    "\n",
    "        return p, v\n",
    "\n",
    "    def _predict(self, x, transform):\n",
    "        x, slices = transform(x)\n",
    "        with torch.no_grad():\n",
    "            xt = torch.from_numpy(x).unsqueeze(0)\n",
    "            p, v = self.model(xt)\n",
    "\n",
    "        p = p.squeeze(0).detach().numpy()\n",
    "        p = p[slices]\n",
    "        return p, v.item()\n",
    "\n",
    "    # Input for Neural Network\n",
    "    def _make_input(self, obs, last_obs, index):\n",
    "        x_ = []\n",
    "        x_.append(self._make_input_normal(obs, last_obs, index))\n",
    "        x_.append(self._get_reverse_cube(obs, index))\n",
    "        x_.append(self._get_next_disappear_cube(obs, index))\n",
    "        x_.append(self._get_step_cube_v2(obs))\n",
    "        x_.append(self._get_length_cube(obs))\n",
    "        x = np.concatenate(x_)\n",
    "        return x\n",
    "\n",
    "    def _make_input_normal(self, obs, last_obs, index):\n",
    "        b = np.zeros((17, 7 * 11), dtype=np.float32)\n",
    "\n",
    "        for p, pos_list in enumerate(obs.geese):\n",
    "            # head position\n",
    "            for pos in pos_list[:1]:\n",
    "                b[0 + (p - index) % 4, pos] = 1\n",
    "            # tip position\n",
    "            for pos in pos_list[-1:]:\n",
    "                b[4 + (p - index) % 4, pos] = 1\n",
    "            # whole position\n",
    "            for pos in pos_list:\n",
    "                b[8 + (p - index) % 4, pos] = 1\n",
    "\n",
    "        # previous head position\n",
    "        if last_obs is not None:\n",
    "            for p, pos_list in enumerate(last_obs.geese):\n",
    "                for pos in pos_list[:1]:\n",
    "                    b[12 + (p - index) % 4, pos] = 1\n",
    "\n",
    "        # food\n",
    "        for pos in obs.food:\n",
    "            b[16, pos] = 1\n",
    "\n",
    "        return b.reshape(-1, 7, 11)\n",
    "\n",
    "    def _get_reverse_cube(self, obs, index):\n",
    "        \"\"\"\n",
    "        尻尾から順番に 1, 0.9, 0.8, ... という並び\n",
    "        \"\"\"\n",
    "        b = np.zeros((4, 7 * 11), dtype=np.float32)\n",
    "\n",
    "        for p, geese in enumerate(obs[\"geese\"]):\n",
    "            # whole position reverse\n",
    "            for num_reverse, pos in enumerate(geese[::-1]):\n",
    "                b[(p - index) % 4, pos] = 1 - num_reverse * 0.1\n",
    "\n",
    "        return b.reshape(-1, 7, 11)\n",
    "\n",
    "    def _get_next_disappear_cube(self, obs, index):\n",
    "        \"\"\"\n",
    "        次になくなる場所: 1\n",
    "        次になくなる可能性のある場所: 0.5\n",
    "        \"\"\"\n",
    "        b = np.zeros((4, 7 * 11), dtype=np.float32)\n",
    "        step = obs[\"step\"]\n",
    "\n",
    "        # foodを食べる可能性があるか。\n",
    "        eat_food_possibility = defaultdict(int)\n",
    "        for p, geese in enumerate(obs[\"geese\"]):\n",
    "            for pos in geese[:1]:\n",
    "                if not self.next_position_map[pos].isdisjoint(obs[\"food\"]):\n",
    "                    eat_food_possibility[p] = 1\n",
    "\n",
    "        if (step % 40) == 39:  # 1つ短くなる\n",
    "            for p, geese in enumerate(obs[\"geese\"]):\n",
    "                if eat_food_possibility[p]:  # 尻尾が1、尻尾の１つ前0.5\n",
    "                    for pos in geese[-1:]:\n",
    "                        b[(p - index) % 4, pos] = 1\n",
    "                    for pos in geese[-2:-1]:\n",
    "                        b[(p - obs[\"index\"]) % 4, pos] = 0.5\n",
    "                else:  # 食べる可能性なし -> 尻尾が1, 尻尾の1つ前1\n",
    "                    for pos in geese[-2:]:\n",
    "                        b[(p - index) % 4, pos] = 1\n",
    "        else:  # 1つ短くならない\n",
    "            for p, geese in enumerate(obs[\"geese\"]):\n",
    "                if eat_food_possibility[p]:  # 食べる可能性があり -> 尻尾を0.5\n",
    "                    for pos in geese[-1:]:\n",
    "                        b[(p - index) % 4, pos] = 0.5\n",
    "                else:  # 食べる可能性なし # 尻尾を1\n",
    "                    for pos in geese[-1:]:\n",
    "                        b[(p - index) % 4, pos] = 1\n",
    "\n",
    "        return b.reshape(-1, 7, 11)\n",
    "\n",
    "    def _get_step_cube_v2(self, obs):\n",
    "        \"\"\"\n",
    "        step0: 0, step199: 1\n",
    "        step0: 0, step39 + 40n: 1\n",
    "        \"\"\"\n",
    "        b = np.zeros((1, 7, 11), dtype=np.float32)\n",
    "        step = obs[\"step\"]\n",
    "\n",
    "        b[:, :, :5] = (step % 200) / 199\n",
    "        b[:, :, 5:] = (step % 40) / 39\n",
    "\n",
    "        return b\n",
    "\n",
    "    def _get_length_cube(self, obs):\n",
    "        b = np.zeros((2, 7, 11), dtype=np.float32)\n",
    "\n",
    "        my_length = len(obs[\"geese\"][obs[\"index\"]])\n",
    "        opposite1_length = len(obs[\"geese\"][(obs[\"index\"] + 1) % 4])\n",
    "        opposite2_length = len(obs[\"geese\"][(obs[\"index\"] + 2) % 4])\n",
    "        opposite3_length = len(obs[\"geese\"][(obs[\"index\"] + 3) % 4])\n",
    "\n",
    "        b[0] = my_length / 10\n",
    "        max_opposite_length = max(opposite1_length, opposite2_length, opposite3_length)\n",
    "        b[1, :, 0:2] = (my_length - max_opposite_length) / 10\n",
    "        b[1, :, 2:5] = (my_length - opposite1_length) / 10\n",
    "        b[1, :, 5:8] = (my_length - opposite2_length) / 10\n",
    "        b[1, :, 8:11] = (my_length - opposite3_length) / 10\n",
    "\n",
    "        return b\n",
    "\n",
    "\n",
    "# Load PyTorch Model\n",
    "\n",
    "\n",
    "PARAM = b\"xxxxxxxxxx\"\n",
    "state_dict = pickle.loads(bz2.decompress(base64.b64decode(PARAM)))\n",
    "\n",
    "game = HungryGeese()\n",
    "agent = NNAgent(state_dict)\n",
    "mcts = MCTS(game, agent, cpuct=2.0)\n",
    "\n",
    "\n",
    "def alphageese_agent(obs, config):\n",
    "    action = game.actions[np.argmax(mcts.getActionProb(obs, timelimit=1.0))]  # timelimit=config.actTimeout\n",
    "    return action.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the submission file\n",
    "with open(\n",
    "    \"submission.py\",\n",
    ") as file:\n",
    "    filedata = file.read()\n",
    "\n",
    "# Replace the target string\n",
    "filedata = filedata.replace(\"xxxxxxxxxx\", PARAM.decode(\"utf-8\"))\n",
    "\n",
    "# Write the file out again\n",
    "with open(\"submission.py\", \"w\") as file:\n",
    "    file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_environments import make\n",
    "\n",
    "env = make(\"hungry_geese\", debug=True)\n",
    "\n",
    "env.reset()\n",
    "env.run([\"submission.py\", \"submission.py\", \"submission.py\", \"submission.py\"])\n",
    "env.render(mode=\"ipython\", width=800, height=700)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

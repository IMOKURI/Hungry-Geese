{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U kaggle-environments\n",
    "!pip list | grep kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import bz2\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_path = {\n",
    "    \"a\": \"../input/hungry-geese-models/first_stage_2462.pth\",\n",
    "    \"b\": \"../input/hungry-geese-models/IMO_pretrain_1st_4_280.pth\",\n",
    "    # \"c\": \"../input/hungry-geese-models/first_stage_2237.pth\",\n",
    "    # \"d\": \"../input/hungry-geese-models/second_stage_3257.pth\",\n",
    "    # \"e\": \"../input/hungry-geese-models/CNN_first_2_2414.pth\",\n",
    "    # \"f\": \"../input/hungry-geese-models/CNN_first_2_2540.pth\",\n",
    "    # \"g\": \"../input/hungry-geese-models/CNN_first_2_2545.pth\",\n",
    "}\n",
    "\n",
    "PARAM = {}\n",
    "for key, val in model_path.items():\n",
    "    weights = torch.load(val)\n",
    "    PARAM[key] = base64.b64encode(bz2.compress(pickle.dumps(weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%%writefile submission.py\n",
    "\n",
    "# This is a lightweight ML agent trained by self-play.\n",
    "# After sharing this notebook,\n",
    "# we will add Hungry Geese environment in our HandyRL library.\n",
    "# https://github.com/DeNA/HandyRL\n",
    "# We hope you enjoy reinforcement learning!\n",
    "\n",
    "\n",
    "import base64\n",
    "import bz2\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Neural Network for Hungry Geese\n",
    "\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    def __init__(self, units0, units1, bnunits=0, bias=True):\n",
    "        super().__init__()\n",
    "        if bnunits > 0:\n",
    "            bias = False\n",
    "        self.dense = nn.Linear(units0, units1, bias=bias)\n",
    "        self.bnunits = bnunits\n",
    "        self.bn = nn.BatchNorm1d(bnunits) if bnunits > 0 else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.dense(x)\n",
    "        if self.bn is not None:\n",
    "            size = h.size()\n",
    "            h = h.view(-1, self.bnunits)\n",
    "            h = self.bn(h)\n",
    "            h = h.view(*size)\n",
    "        return h\n",
    "\n",
    "\n",
    "class TorusConv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
    "        super().__init__()\n",
    "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([x[:, :, :, -self.edge_size[1] :], x, x[:, :, :, : self.edge_size[1]]], dim=3)\n",
    "        h = torch.cat([h[:, :, -self.edge_size[0] :], h, h[:, :, : self.edge_size[0]]], dim=2)\n",
    "        h = self.conv(h)\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h\n",
    "\n",
    "\n",
    "class GeeseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers, filters = 12, 32\n",
    "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p = nn.Linear(filters, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(filters * 2, filters, bias=False)\n",
    "        self.head_v2 = nn.Linear(filters, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h_p = F.relu_(self.conv_p(h))\n",
    "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        p = self.head_p(h_head_p)\n",
    "\n",
    "        h_v = F.relu_(self.conv_v(h))\n",
    "        h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_avg_v = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
    "\n",
    "        h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_avg_v], 1)))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p, \"value\": v, \"h_head_p\": h_head_p, \"h_head_v\": h_head_v, \"h_avg_v\": h_avg_v}\n",
    "\n",
    "\n",
    "class GeeseNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        blocks, filters = 12, 32\n",
    "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(blocks)])\n",
    "\n",
    "        self.conv_p1 = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        self.conv_p2 = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p = nn.Linear(filters, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(filters * 2, filters, bias=False)\n",
    "        self.head_v2 = nn.Linear(filters, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h_p = F.relu_(self.conv_p1(h))\n",
    "        h_p = F.relu_(self.conv_p2(h_p))\n",
    "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        p = self.head_p(h_head_p)\n",
    "\n",
    "        h_v = F.relu_(self.conv_v(h))\n",
    "        h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_avg_v = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
    "        h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_avg_v], 1)))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p, \"value\": v, \"h_head_p\": h_head_p, \"h_head_v\": h_head_v, \"h_avg_v\": h_avg_v}\n",
    "\n",
    "\n",
    "class GeeseNetIMO(nn.Module):\n",
    "    class GeeseBlock(nn.Module):\n",
    "        def __init__(self, embed_dim, num_heads):\n",
    "            super().__init__()\n",
    "            self.attention = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "\n",
    "        def forward(self, x):\n",
    "            h, _ = self.attention(x, x, x)\n",
    "            return h\n",
    "\n",
    "    class GeeseControll(nn.Module):\n",
    "        def __init__(self, filters, final_filters):\n",
    "            super().__init__()\n",
    "            self.filters = filters\n",
    "            self.attention = nn.MultiheadAttention(filters, 1)\n",
    "            self.fc_control = Dense(filters * 3, final_filters, bnunits=final_filters)\n",
    "\n",
    "        def forward(self, x, e):\n",
    "            h, _ = self.attention(x, x, x)\n",
    "\n",
    "            h = torch.cat([x, e, h], dim=2).view(x.size(1), -1)\n",
    "            h = self.fc_control(h)\n",
    "            return h\n",
    "\n",
    "    class GeeseHead(nn.Module):\n",
    "        def __init__(self, filters):\n",
    "            super().__init__()\n",
    "            f = filters // 2\n",
    "            self.head_p_1 = nn.Linear(filters, f, bias=False)\n",
    "            self.head_p_2 = nn.Linear(f, 4, bias=False)\n",
    "            self.head_v_1 = nn.Linear(filters, f, bias=True)\n",
    "            self.head_v_2 = nn.Linear(f, 1, bias=True)\n",
    "\n",
    "        def forward(self, x):\n",
    "            p = self.head_p_1(x)\n",
    "            p = self.head_p_2(p)\n",
    "            v = self.head_v_1(x)\n",
    "            v = torch.tanh(self.head_v_2(v))\n",
    "            return p, v\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        blocks = 5\n",
    "        filters = 64\n",
    "        final_filters = 128\n",
    "\n",
    "        self.geese_net = GeeseNet()\n",
    "\n",
    "        self.blocks = nn.ModuleList([self.GeeseBlock(filters, 8) for _ in range(blocks)])\n",
    "        self.control = self.GeeseControll(filters, final_filters)\n",
    "        self.head = self.GeeseHead(final_filters)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        x_ = self.geese_net(x)\n",
    "        e = torch.cat([x_[\"h_head_p\"], x_[\"h_avg_v\"]], 1).view(1, x.size()[0], -1)\n",
    "        h = e\n",
    "        for block in self.blocks:\n",
    "            h = block(h)\n",
    "        h = self.control(h, e)\n",
    "        p, v = self.head(h)\n",
    "        return {\"policy\": p, \"value\": v}\n",
    "\n",
    "\n",
    "# Input for Neural Network\n",
    "\n",
    "\n",
    "NUM_ROW = 7\n",
    "NUM_COL = 11\n",
    "CENTER_ROW = NUM_ROW // 2\n",
    "CENTER_COL = NUM_COL // 2\n",
    "\n",
    "\n",
    "def to_offset(x):\n",
    "    row = CENTER_ROW - x // NUM_COL\n",
    "    col = CENTER_COL - x % NUM_COL\n",
    "    return row, col\n",
    "\n",
    "\n",
    "def to_row(offset, x):\n",
    "    return (x // NUM_COL + offset) % NUM_ROW\n",
    "\n",
    "\n",
    "def to_col(offset, x):\n",
    "    return (x + offset) % NUM_COL\n",
    "\n",
    "\n",
    "def make_input(obses):\n",
    "    b = np.zeros((17, 7 * 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "        # head position\n",
    "        for pos in pos_list[:1]:\n",
    "            b[0 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "        # tip position\n",
    "        for pos in pos_list[-1:]:\n",
    "            b[4 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "        # whole position\n",
    "        for pos in pos_list:\n",
    "            b[8 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    # previous head position\n",
    "    if len(obses) > 1:\n",
    "        obs_prev = obses[-2]\n",
    "        for p, pos_list in enumerate(obs_prev[\"geese\"]):\n",
    "            for pos in pos_list[:1]:\n",
    "                b[12 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    # food\n",
    "    for pos in obs[\"food\"]:\n",
    "        b[16, pos] = 1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)\n",
    "\n",
    "\n",
    "def make_input_centering_head_for_rule(obses):\n",
    "    b = defaultdict(list)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    player_goose_head = obs[\"geese\"][obs[\"index\"]][0]\n",
    "    o_row, o_col = to_offset(player_goose_head)\n",
    "\n",
    "    for p, geese in enumerate(obs[\"geese\"]):\n",
    "        # body position\n",
    "        for pos in geese[1:-1]:\n",
    "            if (p - obs[\"index\"]) % 4 == 0:\n",
    "                b[\"pb\"].append((to_row(o_row, pos), to_col(o_col, pos)))\n",
    "            else:\n",
    "                b[\"ob\"].append((to_row(o_row, pos), to_col(o_col, pos)))\n",
    "\n",
    "        # tip position\n",
    "        for pos in geese[-1:]:\n",
    "            if (p - obs[\"index\"]) % 4 == 0:\n",
    "                b[\"pt\"].append((to_row(o_row, pos), to_col(o_col, pos)))\n",
    "            else:\n",
    "                b[\"ot\"].append((to_row(o_row, pos), to_col(o_col, pos)))\n",
    "\n",
    "        # head position\n",
    "        for pos in geese[:1]:\n",
    "            if (p - obs[\"index\"]) % 4 == 0:\n",
    "                b[\"ph\"].append((to_row(o_row, pos), to_col(o_col, pos)))\n",
    "            else:\n",
    "                b[\"oh\"].append((to_row(o_row, pos), to_col(o_col, pos)))\n",
    "\n",
    "    # previous head position\n",
    "    if len(obses) > 1:\n",
    "        obs_prev = obses[-2]\n",
    "        for p, geese in enumerate(obs_prev[\"geese\"]):\n",
    "            for pos in geese[:1]:\n",
    "                if (p - obs[\"index\"]) % 4 == 0:\n",
    "                    b[\"pp\"].append((to_row(o_row, pos), to_col(o_col, pos)))\n",
    "\n",
    "    # food\n",
    "    for pos in obs[\"food\"]:\n",
    "        b[\"f\"].append((to_row(o_row, pos), to_col(o_col, pos)))\n",
    "\n",
    "    return b\n",
    "\n",
    "\n",
    "def distance(a, b):\n",
    "    x = b[0] - a[0]\n",
    "    y = b[1] - a[1]\n",
    "    return (x, y), abs(x) + abs(y)\n",
    "\n",
    "\n",
    "def apply_rule(b, prob):\n",
    "    \"\"\"\n",
    "    player head = (3, 5)\n",
    "    [\"NORTH\", \"SOUTH\", \"WEST\", \"EAST\"]\n",
    "    \"\"\"\n",
    "    neighbor = [(2, 5), (4, 5), (3, 4), (3, 6)]\n",
    "\n",
    "    # 隣接している場所に行けないケース\n",
    "    for i, n in enumerate(neighbor):\n",
    "        if (n in b[\"pb\"]) or (n in b[\"ob\"]) or (n in b[\"pp\"]):\n",
    "            prob[i] = -np.inf\n",
    "\n",
    "    # 次の移動で頭がぶつかる可能性のあるケース\n",
    "    # for i, h in enumerate(b[\"oh\"]):\n",
    "    #     (x, y), d = distance(b[\"ph\"][0], h)\n",
    "    #     if d == 2:\n",
    "    #         if x < 0:\n",
    "    #             prob[0] -= 10\n",
    "    #         elif x > 0:\n",
    "    #             prob[1] -= 10\n",
    "    #         if y < 0:\n",
    "    #             prob[2] -= 10\n",
    "    #         elif y > 0:\n",
    "    #             prob[3] -= 10\n",
    "\n",
    "    return prob\n",
    "\n",
    "\n",
    "# Load PyTorch Model\n",
    "\n",
    "\n",
    "PARAM = {\n",
    "    \"a\": b\"aaaaaaaaaa\",\n",
    "    \"imo_b\": b\"bbbbbbbbbb\",\n",
    "    # \"c\": b\"cccccccccc\",\n",
    "    # \"d\": b\"dddddddddd\",\n",
    "    # \"2_e\": b\"eeeeeeeeee\",\n",
    "    # \"2_f\": b\"ffffffffff\",\n",
    "    # \"2_g\": b\"gggggggggg\",\n",
    "}\n",
    "\n",
    "\n",
    "model = {}\n",
    "for key, param in PARAM.items():\n",
    "    state_dict = pickle.loads(bz2.decompress(base64.b64decode(param)))\n",
    "    if \"imo_\" in key:\n",
    "        model[key] = GeeseNetIMO()\n",
    "    elif \"2_\" in key:\n",
    "        model[key] = GeeseNet2()\n",
    "    else:\n",
    "        model[key] = GeeseNet()\n",
    "    model[key].load_state_dict(state_dict)\n",
    "    model[key].eval()\n",
    "\n",
    "\n",
    "# Main Function of Agent\n",
    "\n",
    "obses = []\n",
    "\n",
    "\n",
    "def agent(obs, _):\n",
    "    obses.append(obs)\n",
    "    x = make_input(obses)\n",
    "    y = make_input_centering_head_for_rule(obses)\n",
    "\n",
    "    preds = np.zeros((len(PARAM), 4), dtype=np.float32)\n",
    "    for i, key in enumerate(PARAM.keys()):\n",
    "        with torch.no_grad():\n",
    "            xt = torch.from_numpy(x).unsqueeze(0)\n",
    "            o = model[key](xt)\n",
    "        p = o[\"policy\"].squeeze(0).detach().numpy()\n",
    "        preds[i] = p\n",
    "\n",
    "    inf = np.mean(preds, axis=0)\n",
    "    inf = apply_rule(y, inf)\n",
    "\n",
    "    actions = [\"NORTH\", \"SOUTH\", \"WEST\", \"EAST\"]\n",
    "    return actions[np.argmax(inf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the submission file\n",
    "with open(\n",
    "    \"submission.py\",\n",
    ") as file:\n",
    "    filedata = file.read()\n",
    "\n",
    "# Replace the target string\n",
    "filedata = filedata.replace(\"aaaaaaaaaa\", PARAM[\"a\"].decode(\"utf-8\"))\n",
    "filedata = filedata.replace(\"bbbbbbbbbb\", PARAM[\"b\"].decode(\"utf-8\"))\n",
    "# filedata = filedata.replace(\"cccccccccc\", PARAM[\"c\"].decode(\"utf-8\"))\n",
    "# filedata = filedata.replace(\"dddddddddd\", PARAM[\"d\"].decode(\"utf-8\"))\n",
    "# filedata = filedata.replace(\"eeeeeeeeee\", PARAM[\"e\"].decode(\"utf-8\"))\n",
    "# filedata = filedata.replace(\"ffffffffff\", PARAM[\"f\"].decode(\"utf-8\"))\n",
    "# filedata = filedata.replace(\"gggggggggg\", PARAM[\"g\"].decode(\"utf-8\"))\n",
    "\n",
    "# Write the file out again\n",
    "with open(\"submission.py\", \"w\") as file:\n",
    "    file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_environments import make\n",
    "\n",
    "env = make(\"hungry_geese\", debug=True)\n",
    "\n",
    "env.reset()\n",
    "env.run([\"submission.py\", \"submission.py\", \"submission.py\", \"submission.py\"])\n",
    "env.render(mode=\"ipython\", width=800, height=700)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U kaggle-environments\n",
    "!pip list | grep kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import bz2\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_path = {\n",
    "    \"a\": \"../input/hungry-geese-models/first_stage_2462.pth\",\n",
    "    \"b\": \"../input/hungry-geese-models/IMO_pretrain_1st_4_280.pth\",\n",
    "    # \"c\": \"../input/hungry-geese-models/latest.pth\",\n",
    "    # \"d\": \"../input/hungry-geese-models/second_stage_3257.pth\",\n",
    "    # \"e\": \"../input/hungry-geese-models/IMO_pretrain_1st_8_550.pth\",\n",
    "    # \"f\": \"../input/hungry-geese-models/CNN_first_2_2540.pth\",\n",
    "    # \"g\": \"../input/hungry-geese-models/CNN_first_2_2545.pth\",\n",
    "}\n",
    "\n",
    "PARAM = {}\n",
    "for key, val in model_path.items():\n",
    "    weights = torch.load(val)\n",
    "    PARAM[key] = base64.b64encode(bz2.compress(pickle.dumps(weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%%writefile submission.py\n",
    "\n",
    "PARAM = {\n",
    "    \"a\": b\"aaaaaaaaaa\",\n",
    "    \"imo_b\": b\"bbbbbbbbbb\",\n",
    "    # \"2_c\": b\"cccccccccc\",\n",
    "    # \"d\": b\"dddddddddd\",\n",
    "    # \"imo_e\": b\"eeeeeeeeee\",\n",
    "    # \"2_f\": b\"ffffffffff\",\n",
    "    # \"2_g\": b\"gggggggggg\",\n",
    "}\n",
    "\n",
    "# This is a lightweight ML agent trained by self-play.\n",
    "# After sharing this notebook,\n",
    "# we will add Hungry Geese environment in our HandyRL library.\n",
    "# https://github.com/DeNA/HandyRL\n",
    "# We hope you enjoy reinforcement learning!\n",
    "\n",
    "\n",
    "import base64\n",
    "import bz2\n",
    "import math\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Neural Network for Hungry Geese\n",
    "\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    def __init__(self, units0, units1, bnunits=0, bias=True):\n",
    "        super().__init__()\n",
    "        if bnunits > 0:\n",
    "            bias = False\n",
    "        self.dense = nn.Linear(units0, units1, bias=bias)\n",
    "        self.bnunits = bnunits\n",
    "        self.bn = nn.BatchNorm1d(bnunits) if bnunits > 0 else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.dense(x)\n",
    "        if self.bn is not None:\n",
    "            size = h.size()\n",
    "            h = h.view(-1, self.bnunits)\n",
    "            h = self.bn(h)\n",
    "            h = h.view(*size)\n",
    "        return h\n",
    "\n",
    "\n",
    "class TorusConv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
    "        super().__init__()\n",
    "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([x[:, :, :, -self.edge_size[1] :], x, x[:, :, :, : self.edge_size[1]]], dim=3)\n",
    "        h = torch.cat([h[:, :, -self.edge_size[0] :], h, h[:, :, : self.edge_size[0]]], dim=2)\n",
    "        h = self.conv(h)\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h\n",
    "\n",
    "\n",
    "class Conv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h\n",
    "\n",
    "\n",
    "class ChannelSELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=8):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "# https://github.com/Kaixhin/Rainbow/blob/master/model.py\n",
    "# Factorised NoisyLinear layer with bias\n",
    "class NoisyLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, std_init=0.5):\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init = std_init\n",
    "        self.weight_mu = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        self.register_buffer(\"weight_epsilon\", torch.empty(out_features, in_features))\n",
    "        self.bias_mu = nn.Parameter(torch.empty(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.empty(out_features))\n",
    "        self.register_buffer(\"bias_epsilon\", torch.empty(out_features))\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        mu_range = 1 / math.sqrt(self.in_features)\n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weight_sigma.data.fill_(self.std_init / math.sqrt(self.in_features))\n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_sigma.data.fill_(self.std_init / math.sqrt(self.out_features))\n",
    "\n",
    "    def _scale_noise(self, size):\n",
    "        x = torch.randn(size, device=self.weight_mu.device)\n",
    "        return x.sign().mul_(x.abs().sqrt_())\n",
    "\n",
    "    def reset_noise(self):\n",
    "        epsilon_in = self._scale_noise(self.in_features)\n",
    "        epsilon_out = self._scale_noise(self.out_features)\n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
    "        self.bias_epsilon.copy_(epsilon_out)\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.training:\n",
    "            return F.linear(\n",
    "                input,\n",
    "                self.weight_mu + self.weight_sigma * self.weight_epsilon,\n",
    "                self.bias_mu + self.bias_sigma * self.bias_epsilon,\n",
    "            )\n",
    "        else:\n",
    "            return F.linear(input, self.weight_mu, self.bias_mu)\n",
    "\n",
    "\n",
    "class GeeseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers, filters = 12, 32\n",
    "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p = nn.Linear(filters, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(filters * 2, filters, bias=False)\n",
    "        self.head_v2 = nn.Linear(filters, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h_p = F.relu_(self.conv_p(h))\n",
    "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        p = self.head_p(h_head_p)\n",
    "\n",
    "        h_v = F.relu_(self.conv_v(h))\n",
    "        h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_avg_v = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
    "\n",
    "        h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_avg_v], 1)))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p, \"value\": v, \"h_head_p\": h_head_p, \"h_head_v\": h_head_v, \"h_avg_v\": h_avg_v}\n",
    "\n",
    "\n",
    "class GeeseNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers, filters = 6, 40\n",
    "\n",
    "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
    "        self.cnn_blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "        self.cse_blocks = nn.ModuleList([ChannelSELayer(filters, reduction=4) for _ in range(layers)])\n",
    "\n",
    "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p = NoisyLinear(filters, 4)\n",
    "        self.head_v1 = NoisyLinear(77, 16)\n",
    "        self.head_v2 = NoisyLinear(16, 1)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for cnn, cse in zip(self.cnn_blocks, self.cse_blocks):\n",
    "            h = cnn(h)\n",
    "            h = F.relu_(h + cse(h))\n",
    "\n",
    "        p = F.relu_(self.conv_p(h))\n",
    "        head = x[:, :1]\n",
    "        p_head = (p * head).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        p = self.head_p(p_head)\n",
    "\n",
    "        v = F.relu_(self.conv_v(h))\n",
    "        v_gap = v.view(h.size(0), h.size(1), -1).mean(1)\n",
    "        v = F.relu_(self.head_v1(v_gap))\n",
    "        v = torch.tanh(self.head_v2(v))\n",
    "\n",
    "        return {\"policy\": p, \"value\": v}\n",
    "\n",
    "    def reset_noise(self):\n",
    "        for name, module in self.named_children():\n",
    "            if \"head\" in name:\n",
    "                module.reset_noise()\n",
    "\n",
    "\n",
    "class GeeseNetIMO(nn.Module):\n",
    "    class GeeseBlock(nn.Module):\n",
    "        def __init__(self, embed_dim, num_heads):\n",
    "            super().__init__()\n",
    "            self.attention = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "\n",
    "        def forward(self, x):\n",
    "            h, _ = self.attention(x, x, x)\n",
    "            return h\n",
    "\n",
    "    class GeeseControll(nn.Module):\n",
    "        def __init__(self, filters, final_filters):\n",
    "            super().__init__()\n",
    "            self.filters = filters\n",
    "            self.attention = nn.MultiheadAttention(filters, 1)\n",
    "            self.fc_control = Dense(filters * 3, final_filters, bnunits=final_filters)\n",
    "\n",
    "        def forward(self, x, e):\n",
    "            h, _ = self.attention(x, x, x)\n",
    "\n",
    "            h = torch.cat([x, e, h], dim=2).view(x.size(1), -1)\n",
    "            h = self.fc_control(h)\n",
    "            return h\n",
    "\n",
    "    class GeeseHead(nn.Module):\n",
    "        def __init__(self, filters):\n",
    "            super().__init__()\n",
    "            f = filters // 2\n",
    "            self.head_p_1 = nn.Linear(filters, f, bias=False)\n",
    "            self.head_p_2 = nn.Linear(f, 4, bias=False)\n",
    "            self.head_v_1 = nn.Linear(filters, f, bias=True)\n",
    "            self.head_v_2 = nn.Linear(f, 1, bias=True)\n",
    "\n",
    "        def forward(self, x):\n",
    "            p = self.head_p_1(x)\n",
    "            p = self.head_p_2(p)\n",
    "            v = self.head_v_1(x)\n",
    "            v = torch.tanh(self.head_v_2(v))\n",
    "            return p, v\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        blocks = 5\n",
    "        filters = 64\n",
    "        final_filters = 128\n",
    "\n",
    "        self.geese_net = GeeseNet()\n",
    "\n",
    "        self.blocks = nn.ModuleList([self.GeeseBlock(filters, 8) for _ in range(blocks)])\n",
    "        self.control = self.GeeseControll(filters, final_filters)\n",
    "        self.head = self.GeeseHead(final_filters)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        x_ = self.geese_net(x)\n",
    "        e = torch.cat([x_[\"h_head_p\"], x_[\"h_avg_v\"]], 1).view(1, x.size()[0], -1)\n",
    "        h = e\n",
    "        for block in self.blocks:\n",
    "            h = block(h)\n",
    "        h = self.control(h, e)\n",
    "        p, v = self.head(h)\n",
    "        return {\"policy\": p, \"value\": v}\n",
    "\n",
    "\n",
    "# Input for Neural Network\n",
    "\n",
    "\n",
    "NUM_ROW = 7\n",
    "NUM_COL = 11\n",
    "CENTER_ROW = NUM_ROW // 2\n",
    "CENTER_COL = NUM_COL // 2\n",
    "\n",
    "\n",
    "def to_offset(x):\n",
    "    row = CENTER_ROW - x // NUM_COL\n",
    "    col = CENTER_COL - x % NUM_COL\n",
    "    return row, col\n",
    "\n",
    "\n",
    "def to_row(offset, x):\n",
    "    return (x // NUM_COL + offset) % NUM_ROW\n",
    "\n",
    "\n",
    "def to_col(offset, x):\n",
    "    return (x + offset) % NUM_COL\n",
    "\n",
    "\n",
    "def make_input(obses):\n",
    "    b = np.zeros((17, 7 * 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "        # head position\n",
    "        for pos in pos_list[:1]:\n",
    "            b[0 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "        # tip position\n",
    "        for pos in pos_list[-1:]:\n",
    "            b[4 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "        # whole position\n",
    "        for pos in pos_list:\n",
    "            b[8 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    # previous head position\n",
    "    if len(obses) > 1:\n",
    "        obs_prev = obses[-2]\n",
    "        for p, pos_list in enumerate(obs_prev[\"geese\"]):\n",
    "            for pos in pos_list[:1]:\n",
    "                b[12 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    # food\n",
    "    for pos in obs[\"food\"]:\n",
    "        b[16, pos] = 1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)\n",
    "\n",
    "\n",
    "def make_input_centering_head_for_rule(obses):\n",
    "    b = {}\n",
    "    for i in range(4):\n",
    "        b[i] = defaultdict(list)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    player_goose_head = obs[\"geese\"][obs[\"index\"]][0]\n",
    "    o_row, o_col = to_offset(player_goose_head)\n",
    "\n",
    "    for p, geese in enumerate(obs[\"geese\"]):\n",
    "        # whole position\n",
    "        for pos in geese:\n",
    "            b[(p - obs[\"index\"]) % 4][\"body\"].append((to_row(o_row, pos), to_col(o_col, pos)))\n",
    "\n",
    "    # previous head position\n",
    "    if len(obses) > 1:\n",
    "        obs_prev = obses[-2]\n",
    "        for p, geese in enumerate(obs_prev[\"geese\"]):\n",
    "            for pos in geese[:1]:\n",
    "                b[(p - obs[\"index\"]) % 4][\"previous\"].append((to_row(o_row, pos), to_col(o_col, pos)))\n",
    "\n",
    "    # food\n",
    "    for pos in obs[\"food\"]:\n",
    "        b[0][\"food\"].append((to_row(o_row, pos), to_col(o_col, pos)))\n",
    "\n",
    "    return b\n",
    "\n",
    "\n",
    "def distance(a, b):\n",
    "    x = b[0] - a[0]\n",
    "    y = b[1] - a[1]\n",
    "    return (x, y), abs(x) + abs(y)\n",
    "\n",
    "\n",
    "def around(a):\n",
    "    return [\n",
    "        ((a[0] - 1) % 7, a[1]),\n",
    "        ((a[0] + 1) % 7, a[1]),\n",
    "        (a[0], (a[1] - 1) % 11),\n",
    "        (a[0], (a[1] + 1) % 11),\n",
    "    ]\n",
    "\n",
    "\n",
    "def apply_rule(b, prob):\n",
    "    \"\"\"\n",
    "    player head = (3, 5)\n",
    "    [\"NORTH\", \"SOUTH\", \"WEST\", \"EAST\"]\n",
    "    \"\"\"\n",
    "    north = (2, 5)\n",
    "    south = (4, 5)\n",
    "    west = (3, 4)\n",
    "    east = (3, 6)\n",
    "    neighbor = [north, south, west, east]\n",
    "\n",
    "    # 隣接している場所に行けないケース\n",
    "    for i, n in enumerate(neighbor):\n",
    "        # 自分の直前の場所\n",
    "        if n in b[0][\"previous\"]:\n",
    "            prob[i] = -np.inf\n",
    "\n",
    "        for p in range(4):\n",
    "            # ガチョウの体がある場所 (しっぽ除く)\n",
    "            if n in b[p][\"body\"][:-1]:\n",
    "                prob[i] = -np.inf\n",
    "\n",
    "    north_2step = [(2, 4), (1, 5), (2, 6)]\n",
    "    south_2step = [(4, 4), (5, 5), (4, 6)]\n",
    "    west_2step = [(2, 4), (3, 3), (4, 4)]\n",
    "    east_2step = [(2, 6), (3, 7), (4, 6)]\n",
    "    two_step = [north_2step, south_2step, west_2step, east_2step]\n",
    "\n",
    "    # 2step 先のマスがすべて、2step後に埋まっている場合、移動不可とする\n",
    "    for i, ts in enumerate(two_step):\n",
    "        death = 0\n",
    "        for s in ts:\n",
    "            for p in range(4):\n",
    "                if s in b[p][\"body\"][:-2]:\n",
    "                    death += 1\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "        if death == len(ts):\n",
    "            prob[i] -= 10_000\n",
    "\n",
    "    # 次の移動で頭がぶつかる可能性のあるケース\n",
    "    for p in range(1, 4):\n",
    "        if b[p][\"body\"] != []:\n",
    "            (x, y), d = distance(b[0][\"body\"][0], b[p][\"body\"][0])\n",
    "            if d == 2:\n",
    "                if x < 0:\n",
    "                    prob[0] -= 100 if north in b[0][\"food\"] else 50\n",
    "                elif x > 0:\n",
    "                    prob[1] -= 100 if south in b[0][\"food\"] else 50\n",
    "                if y < 0:\n",
    "                    prob[2] -= 100 if west in b[0][\"food\"] else 50\n",
    "                elif y > 0:\n",
    "                    prob[3] -= 100 if east in b[0][\"food\"] else 50\n",
    "\n",
    "    # しっぽが伸びる可能性のあるケース\n",
    "    for i, n in enumerate(neighbor):\n",
    "        for p in range(1, 4):\n",
    "            if (\n",
    "                b[p][\"body\"] != []\n",
    "                and n == b[p][\"body\"][-1]\n",
    "                and any(food in around(b[p][\"body\"][0]) for food in b[0][\"food\"])\n",
    "            ):\n",
    "                prob[i] -= 100\n",
    "\n",
    "    return prob\n",
    "\n",
    "\n",
    "# Load PyTorch Model\n",
    "\n",
    "\n",
    "model = {}\n",
    "for key, param in PARAM.items():\n",
    "    state_dict = pickle.loads(bz2.decompress(base64.b64decode(param)))\n",
    "    if \"imo_\" in key:\n",
    "        model[key] = GeeseNetIMO()\n",
    "    elif \"2_\" in key:\n",
    "        model[key] = GeeseNet2()\n",
    "    else:\n",
    "        model[key] = GeeseNet()\n",
    "    model[key].load_state_dict(state_dict)\n",
    "    model[key].eval()\n",
    "\n",
    "\n",
    "# Main Function of Agent\n",
    "\n",
    "obses = []\n",
    "\n",
    "\n",
    "def agent(obs, _):\n",
    "    obses.append(obs)\n",
    "    x = make_input(obses)\n",
    "    y = make_input_centering_head_for_rule(obses)\n",
    "\n",
    "    preds = np.zeros((len(PARAM), 4), dtype=np.float32)\n",
    "    for i, key in enumerate(PARAM.keys()):\n",
    "        with torch.no_grad():\n",
    "            xt = torch.from_numpy(x).unsqueeze(0)\n",
    "            o = model[key](xt)\n",
    "        p = o[\"policy\"].squeeze(0).detach().numpy()\n",
    "        preds[i] = p\n",
    "\n",
    "    inf = np.mean(preds, axis=0)\n",
    "    inf = apply_rule(y, inf)\n",
    "\n",
    "    actions = [\"NORTH\", \"SOUTH\", \"WEST\", \"EAST\"]\n",
    "    return actions[np.argmax(inf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the submission file\n",
    "with open(\n",
    "    \"submission.py\",\n",
    ") as file:\n",
    "    filedata = file.read()\n",
    "\n",
    "# Replace the target string\n",
    "for key, val in PARAM.items():\n",
    "    filedata = filedata.replace(key * 10, val.decode(\"utf-8\"))\n",
    "\n",
    "# Write the file out again\n",
    "with open(\"submission.py\", \"w\") as file:\n",
    "    file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_environments import make\n",
    "\n",
    "env = make(\"hungry_geese\", debug=True)\n",
    "\n",
    "env.reset()\n",
    "env.run([\"submission.py\", \"submission.py\", \"submission.py\", \"submission.py\"])\n",
    "env.render(mode=\"ipython\", width=800, height=700)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

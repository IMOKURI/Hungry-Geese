{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import bz2\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_path = \"../input/hungry-geese-models/latest.pth\"\n",
    "\n",
    "weights = torch.load(model_path)\n",
    "\n",
    "PARAM = base64.b64encode(bz2.compress(pickle.dumps(weights)))\n",
    "state_dict = pickle.loads(bz2.decompress(base64.b64decode(PARAM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%%writefile submission.py\n",
    "\n",
    "# This is a lightweight ML agent trained by self-play.\n",
    "# After sharing this notebook,\n",
    "# we will add Hungry Geese environment in our HandyRL library.\n",
    "# https://github.com/DeNA/HandyRL\n",
    "# We hope you enjoy reinforcement learning!\n",
    "\n",
    "\n",
    "import base64\n",
    "import bz2\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Neural Network for Hungry Geese\n",
    "\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    def __init__(self, units0, units1, bnunits=0, bias=True):\n",
    "        super().__init__()\n",
    "        if bnunits > 0:\n",
    "            bias = False\n",
    "        self.dense = nn.Linear(units0, units1, bias=bias)\n",
    "        self.bnunits = bnunits\n",
    "        self.bn = nn.BatchNorm1d(bnunits) if bnunits > 0 else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.dense(x)\n",
    "        if self.bn is not None:\n",
    "            size = h.size()\n",
    "            h = h.view(-1, self.bnunits)\n",
    "            h = self.bn(h)\n",
    "            h = h.view(*size)\n",
    "        return h\n",
    "\n",
    "\n",
    "class TorusConv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
    "        super().__init__()\n",
    "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([x[:, :, :, -self.edge_size[1] :], x, x[:, :, :, : self.edge_size[1]]], dim=3)\n",
    "        h = torch.cat([h[:, :, -self.edge_size[0] :], h, h[:, :, : self.edge_size[0]]], dim=2)\n",
    "        h = self.conv(h)\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h\n",
    "\n",
    "\n",
    "class Conv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h\n",
    "\n",
    "\n",
    "class ChannelSELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=8):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "# https://github.com/Kaixhin/Rainbow/blob/master/model.py\n",
    "# Factorised NoisyLinear layer with bias\n",
    "class NoisyLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, std_init=0.5):\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init = std_init\n",
    "        self.weight_mu = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        self.register_buffer(\"weight_epsilon\", torch.empty(out_features, in_features))\n",
    "        self.bias_mu = nn.Parameter(torch.empty(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.empty(out_features))\n",
    "        self.register_buffer(\"bias_epsilon\", torch.empty(out_features))\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        mu_range = 1 / math.sqrt(self.in_features)\n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weight_sigma.data.fill_(self.std_init / math.sqrt(self.in_features))\n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_sigma.data.fill_(self.std_init / math.sqrt(self.out_features))\n",
    "\n",
    "    def _scale_noise(self, size):\n",
    "        x = torch.randn(size, device=self.weight_mu.device)\n",
    "        return x.sign().mul_(x.abs().sqrt_())\n",
    "\n",
    "    def reset_noise(self):\n",
    "        epsilon_in = self._scale_noise(self.in_features)\n",
    "        epsilon_out = self._scale_noise(self.out_features)\n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
    "        self.bias_epsilon.copy_(epsilon_out)\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.training:\n",
    "            return F.linear(\n",
    "                input,\n",
    "                self.weight_mu + self.weight_sigma * self.weight_epsilon,\n",
    "                self.bias_mu + self.bias_sigma * self.bias_epsilon,\n",
    "            )\n",
    "        else:\n",
    "            return F.linear(input, self.weight_mu, self.bias_mu)\n",
    "\n",
    "\n",
    "class GeeseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers, filters = 6, 40\n",
    "\n",
    "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
    "        self.cnn_blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "        self.cse_blocks = nn.ModuleList([ChannelSELayer(filters, reduction=4) for _ in range(layers)])\n",
    "\n",
    "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p = NoisyLinear(filters, 4)\n",
    "        self.head_v1 = NoisyLinear(77, 16)\n",
    "        self.head_v2 = NoisyLinear(16, 1)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for cnn, cse in zip(self.cnn_blocks, self.cse_blocks):\n",
    "            h = cnn(h)\n",
    "            h = F.relu_(h + cse(h))\n",
    "\n",
    "        p = F.relu_(self.conv_p(h))\n",
    "        head = x[:, :1]\n",
    "        p_head = (p * head).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        p = self.head_p(p_head)\n",
    "\n",
    "        v = F.relu_(self.conv_v(h))\n",
    "        v_gap = v.view(h.size(0), h.size(1), -1).mean(1)\n",
    "        v = F.relu_(self.head_v1(v_gap))\n",
    "        v = torch.tanh(self.head_v2(v))\n",
    "\n",
    "        return {\"policy\": p, \"value\": v}\n",
    "\n",
    "    def reset_noise(self):\n",
    "        for name, module in self.named_children():\n",
    "            if \"head\" in name:\n",
    "                module.reset_noise()\n",
    "\n",
    "\n",
    "# Input for Neural Network\n",
    "\n",
    "\n",
    "NUM_ROW = 7\n",
    "NUM_COL = 11\n",
    "CENTER_ROW = NUM_ROW // 2\n",
    "CENTER_COL = NUM_COL // 2\n",
    "\n",
    "\n",
    "def to_offset(x):\n",
    "    row = CENTER_ROW - x // NUM_COL\n",
    "    col = CENTER_COL - x % NUM_COL\n",
    "    return row, col\n",
    "\n",
    "\n",
    "def to_row(offset, x):\n",
    "    return (x // NUM_COL + offset) % NUM_ROW\n",
    "\n",
    "\n",
    "def to_col(offset, x):\n",
    "    return (x + offset) % NUM_COL\n",
    "\n",
    "\n",
    "def make_input(obses):\n",
    "    b = np.zeros((17, 7 * 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "        # head position\n",
    "        for pos in pos_list[:1]:\n",
    "            b[0 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "        # tip position\n",
    "        for pos in pos_list[-1:]:\n",
    "            b[4 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "        # whole position\n",
    "        for pos in pos_list:\n",
    "            b[8 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    # previous head position\n",
    "    if len(obses) > 1:\n",
    "        obs_prev = obses[-2]\n",
    "        for p, pos_list in enumerate(obs_prev[\"geese\"]):\n",
    "            for pos in pos_list[:1]:\n",
    "                b[12 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    # food\n",
    "    for pos in obs[\"food\"]:\n",
    "        b[16, pos] = 1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)\n",
    "\n",
    "\n",
    "def make_input_centering_head(obses):\n",
    "    b = np.zeros((17, 7, 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    player_goose_head = obs[\"geese\"][obs[\"index\"]][0]\n",
    "    o_row, o_col = to_offset(player_goose_head)\n",
    "\n",
    "    for p, geese in enumerate(obs[\"geese\"]):\n",
    "        # whole position\n",
    "        for pos in geese:\n",
    "            b[0 + (p - obs[\"index\"]) % 4, to_row(o_row, pos), to_col(o_col, pos)] = 1\n",
    "        # tip position\n",
    "        for pos in geese[-1:]:\n",
    "            b[4 + (p - obs[\"index\"]) % 4, to_row(o_row, pos), to_col(o_col, pos)] = 1\n",
    "        # head position\n",
    "        for pos in geese[:1]:\n",
    "            b[8 + (p - obs[\"index\"]) % 4, to_row(o_row, pos), to_col(o_col, pos)] = 1\n",
    "\n",
    "    # previous head position\n",
    "    if len(obses) > 1:\n",
    "        obs_prev = obses[-2]\n",
    "        for p, geese in enumerate(obs_prev[\"geese\"]):\n",
    "            for pos in geese[:1]:\n",
    "                b[12 + (p - obs[\"index\"]) % 4, to_row(o_row, pos), to_col(o_col, pos)] = 1\n",
    "\n",
    "    # food\n",
    "    for pos in obs[\"food\"]:\n",
    "        b[16, to_row(o_row, pos), to_col(o_col, pos)] = 1\n",
    "\n",
    "    return b\n",
    "\n",
    "\n",
    "# Load PyTorch Model\n",
    "\n",
    "\n",
    "PARAM = b\"xxxxxxxxxx\"\n",
    "\n",
    "state_dict = pickle.loads(bz2.decompress(base64.b64decode(PARAM)))\n",
    "model = GeeseNet()\n",
    "# model = GeeseNetA()\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Main Function of Agent\n",
    "\n",
    "obses = []\n",
    "\n",
    "\n",
    "def agent(obs, _):\n",
    "    obses.append(obs)\n",
    "    x = make_input(obses)\n",
    "    # x = make_input_centering_head(obses)\n",
    "    with torch.no_grad():\n",
    "        xt = torch.from_numpy(x).unsqueeze(0)\n",
    "        o = model(xt)\n",
    "    p = o[\"policy\"].squeeze(0).detach().numpy()\n",
    "\n",
    "    actions = [\"NORTH\", \"SOUTH\", \"WEST\", \"EAST\"]\n",
    "    return actions[np.argmax(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the submission file\n",
    "with open(\n",
    "    \"submission.py\",\n",
    ") as file:\n",
    "    filedata = file.read()\n",
    "\n",
    "# Replace the target string\n",
    "filedata = filedata.replace(\"xxxxxxxxxx\", PARAM.decode(\"utf-8\"))\n",
    "\n",
    "# Write the file out again\n",
    "with open(\"submission.py\", \"w\") as file:\n",
    "    file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_environments import make\n",
    "\n",
    "env = make(\"hungry_geese\", debug=True)\n",
    "\n",
    "env.reset()\n",
    "env.run([\"submission.py\", \"submission.py\", \"submission.py\", \"submission.py\"])\n",
    "env.render(mode=\"ipython\", width=800, height=700)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

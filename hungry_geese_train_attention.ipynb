{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abroad-piece",
    "papermill": {
     "duration": 0.025714,
     "end_time": "2021-05-12T03:01:02.640708",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.614994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About this notebook ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pressing-commercial",
    "papermill": {
     "duration": 0.024272,
     "end_time": "2021-05-12T03:01:02.689850",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.665578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "german-ethics",
    "papermill": {
     "duration": 1.852306,
     "end_time": "2021-05-12T03:01:04.566362",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.714056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "apparent-fiction",
    "papermill": {
     "duration": 0.030961,
     "end_time": "2021-05-12T03:01:04.622818",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.591857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "editorial-haiti",
    "papermill": {
     "duration": 0.024908,
     "end_time": "2021-05-12T03:01:05.115280",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.090372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "opened-python",
    "papermill": {
     "duration": 0.035637,
     "end_time": "2021-05-12T03:01:05.176119",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.140482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 440\n",
    "\n",
    "    n_class = 4\n",
    "    n_fold = 10\n",
    "\n",
    "    gradient_accumulation_steps = 3\n",
    "    max_grad_norm = 1000\n",
    "\n",
    "    num_workers = 4\n",
    "    batch_size = 1000\n",
    "\n",
    "    scheduler = \"CosineAnnealingWarmRestarts\"\n",
    "    # factor = 0.2  # ReduceLROnPlateau\n",
    "    # patience = 4  # ReduceLROnPlateau\n",
    "    # eps = 1e-6  # ReduceLROnPlateau\n",
    "    # T_max = 10  # CosineAnnealingLR\n",
    "    T_0 = 10  # CosineAnnealingWarmRestarts\n",
    "\n",
    "    criterion = \"CrossEntropyLoss\"\n",
    "    lr = 1e-3\n",
    "    min_lr = 1e-4\n",
    "    weight_decay = 1e-5\n",
    "\n",
    "    epochs = 20\n",
    "    model_name = \"geese_net\"\n",
    "    pre_train_file = \"\"\n",
    "\n",
    "    print_freq = 100\n",
    "\n",
    "    train = True\n",
    "    tuning = False\n",
    "    debug = False\n",
    "    apex = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "contained-singles",
    "papermill": {
     "duration": 0.031266,
     "end_time": "2021-05-12T03:01:05.235456",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.204190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.tuning:\n",
    "    Config.epochs = 2\n",
    "\n",
    "if Config.debug:\n",
    "    Config.epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dietary-track",
    "papermill": {
     "duration": 0.031421,
     "end_time": "2021-05-12T03:01:05.292382",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.260961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.apex:\n",
    "    from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "invalid-dispute",
    "papermill": {
     "duration": 0.169531,
     "end_time": "2021-05-12T03:01:05.488665",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.319134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robust-humanity",
    "papermill": {
     "duration": 0.024539,
     "end_time": "2021-05-12T03:01:04.672270",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.647731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "designed-effect",
    "papermill": {
     "duration": 0.031167,
     "end_time": "2021-05-12T03:01:04.728079",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.696912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"../input/hungrygeeseepisode/hungry-geese-episode/\"\n",
    "OUTPUT_DIR = \"pre-models/\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "special-broadcast",
    "outputId": "c440e1e9-5651-42ee-eb0f-08c822d7471a",
    "papermill": {
     "duration": 0.31211,
     "end_time": "2021-05-12T03:01:05.064722",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.752612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19976\n"
     ]
    }
   ],
   "source": [
    "paths = [path for path in glob.glob(BASE_DIR + \"*.json\") if \"info\" not in path]\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9976\n"
     ]
    }
   ],
   "source": [
    "# fit for memory size...\n",
    "paths = paths[:-10000]  # first stage\n",
    "# paths = paths[-10000:]  # second stage\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    paths = paths[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "treated-serum",
    "papermill": {
     "duration": 0.025219,
     "end_time": "2021-05-12T03:01:05.539482",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.514263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gothic-alloy",
    "papermill": {
     "duration": 0.070842,
     "end_time": "2021-05-12T03:01:05.642364",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.571522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=Config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "experienced-correspondence",
    "papermill": {
     "duration": 0.053842,
     "end_time": "2021-05-12T03:01:05.741858",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.688016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reverse_ns(y):\n",
    "    if y == 0:\n",
    "        return 1\n",
    "    if y == 1:\n",
    "        return 0\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_we(y):\n",
    "    if y == 2:\n",
    "        return 3\n",
    "    if y == 3:\n",
    "        return 2\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_nswe(y):\n",
    "    return reverse_ns(reverse_we(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "further-transaction",
    "papermill": {
     "duration": 0.042365,
     "end_time": "2021-05-12T03:01:05.826807",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.784442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentence(obses):\n",
    "    b = np.zeros((7 * 11), dtype=np.uint8)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "        pid = (p - obs[\"index\"]) % 4\n",
    "\n",
    "        # whole position\n",
    "        for pos in pos_list[1:-1]:\n",
    "            b[pos] = 5 + pid\n",
    "        # tip position\n",
    "        for pos in pos_list[-1:]:\n",
    "            b[pos] = 9 + pid\n",
    "        # head position\n",
    "        for pos in pos_list[:1]:\n",
    "            b[pos] = 1 + pid\n",
    "\n",
    "    # previous head position\n",
    "    if len(obses) > 1:\n",
    "        obs_prev = obses[-2]\n",
    "        for p, pos_list in enumerate(obs_prev[\"geese\"]):\n",
    "            pid = (p - obs[\"index\"]) % 4\n",
    "            if pid == 0:\n",
    "                for pos in pos_list[:1]:\n",
    "                    b[pos] = 13\n",
    "\n",
    "    # food\n",
    "    for pos in obs[\"food\"]:\n",
    "        b[pos] = 14\n",
    "\n",
    "    return b.reshape(1, 7, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pretty-aaron",
    "papermill": {
     "duration": 0.042985,
     "end_time": "2021-05-12T03:01:06.014038",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.971053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "international-secret",
    "papermill": {
     "duration": 0.064855,
     "end_time": "2021-05-12T03:01:06.121648",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.056793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset_from_json(filepath, json_object=None, standing=0):\n",
    "    if json_object is None:\n",
    "        json_open = open(path, \"r\")\n",
    "        json_load = json.load(json_open)\n",
    "    else:\n",
    "        json_load = json_object\n",
    "\n",
    "    try:\n",
    "        winner_index = np.argmax(np.argsort(json_load[\"rewards\"]) == 3 - standing)\n",
    "\n",
    "        obses = []\n",
    "        X = []\n",
    "        y = []\n",
    "        actions = {\"NORTH\": 0, \"SOUTH\": 1, \"WEST\": 2, \"EAST\": 3}\n",
    "\n",
    "        for i in range(len(json_load[\"steps\"]) - 1):\n",
    "            if json_load[\"steps\"][i][winner_index][\"status\"] == \"ACTIVE\":\n",
    "                y_ = json_load[\"steps\"][i + 1][winner_index][\"action\"]\n",
    "                if y_ is not None:\n",
    "                    step = json_load[\"steps\"][i]\n",
    "                    step[winner_index][\"observation\"][\"geese\"] = step[0][\"observation\"][\"geese\"]\n",
    "                    step[winner_index][\"observation\"][\"food\"] = step[0][\"observation\"][\"food\"]\n",
    "                    step[winner_index][\"observation\"][\"step\"] = step[0][\"observation\"][\"step\"]\n",
    "                    obses.append(step[winner_index][\"observation\"])\n",
    "                    y.append(actions[y_])\n",
    "\n",
    "                    y.append(reverse_ns(actions[y_]))  # 上下反転\n",
    "                    y.append(reverse_we(actions[y_]))  # 左右反転\n",
    "                    y.append(reverse_nswe(actions[y_]))  # 上下左右反転\n",
    "\n",
    "        for j in range(len(obses)):\n",
    "            # X_ = make_input(obses[: j + 1])\n",
    "\n",
    "            X_ = []\n",
    "            X_.append(make_sentence(obses[: j + 1]))\n",
    "            X_ = np.concatenate(X_)\n",
    "\n",
    "            X.append(X_)\n",
    "\n",
    "            X.append(X_[:, ::-1, :])  # 上下反転\n",
    "            X.append(X_[:, :, ::-1])  # 左右反転\n",
    "            X.append(X_[:, ::-1, ::-1])  # 上下左右反転\n",
    "\n",
    "        X = np.array(X, dtype=np.uint8)  # [starting_step:]\n",
    "        y = np.array(y, dtype=np.uint8)  # [starting_step:]\n",
    "\n",
    "        return X, y\n",
    "    except Exception as e:\n",
    "        if Config.debug:\n",
    "            raise Exception from e\n",
    "        else:\n",
    "            return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "4134662bdbe04a918d9809632e268ef8",
      "8ddb49ac3c91409f99a569a061a70b3d",
      "0857c0fa22b544488d65bb2c7dad18ee",
      "e33e4f894b424988b316c468bc9225ce",
      "c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "f905db5005be40b194ea150c8b0deb9f",
      "04a486aa6f454d8f92e388dba1b9ee21",
      "507d2b6a02bb43d0bb4c8c2734f19cbb"
     ]
    },
    "id": "handled-pleasure",
    "outputId": "955c1c6b-36bc-4b30-dc44-b72b05398f8c",
    "papermill": {
     "duration": 15.320591,
     "end_time": "2021-05-12T03:01:21.474816",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.154225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4e7ed261904597a7a80fa5ec02e173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9976.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num episode: 6217420\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for path in tqdm(paths[: int(len(paths))]):\n",
    "    X, y = create_dataset_from_json(path, standing=0)  # use only winners' moves\n",
    "    if X is not 0:\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "persistent-loading",
    "papermill": {
     "duration": 112.92618,
     "end_time": "2021-05-12T03:03:14.428162",
     "exception": false,
     "start_time": "2021-05-12T03:01:21.501982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# X_train, unique_index = np.unique(X_train, axis=0, return_index=True)  # remove duplicate\n",
    "# y_train = y_train[unique_index]\n",
    "\n",
    "# y_train = np.eye(4, dtype=\"uint8\")[y_train]  # to categorical\n",
    "\n",
    "# print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_:\n",
    "    X_train_sum_obs = X_train.reshape(X_train.shape[0], -1).sum(1)\n",
    "    X_train_group = np.unique(X_train_sum_obs)\n",
    "    X_train_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_:\n",
    "    X_train_unique = []\n",
    "    y_train_unique = []\n",
    "    for group in tqdm(X_train_group):\n",
    "        group_index = np.where(X_train_sum_obs == group)\n",
    "\n",
    "        X_train_ = X_train[group_index]\n",
    "        y_train_ = y_train[group_index]\n",
    "\n",
    "        X_train_, unique_index = np.unique(X_train_, axis=0, return_index=True)  # remove duplicate\n",
    "        y_train_ = y_train_[unique_index]\n",
    "\n",
    "        X_train_unique.append(X_train_)\n",
    "        y_train_unique.append(y_train_)\n",
    "\n",
    "    X_train = np.concatenate(X_train_unique)\n",
    "    y_train = np.concatenate(y_train_unique)\n",
    "\n",
    "    print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_:\n",
    "    del X_train_sum_obs\n",
    "    del X_train_group\n",
    "    del X_train_unique\n",
    "    del y_train_unique\n",
    "    del X_train_\n",
    "    del y_train_\n",
    "    del group_index\n",
    "    del unique_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype(np.long)\n",
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "micro-french",
    "papermill": {
     "duration": 0.033413,
     "end_time": "2021-05-12T03:03:15.360395",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.326982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    X_train = X_train[:1000]\n",
    "    y_train = y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "wrong-pastor",
    "outputId": "406a2f1d-0b8a-46bf-ca01-546f3110c301",
    "papermill": {
     "duration": 0.036161,
     "end_time": "2021-05-12T03:03:15.425149",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.388988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217415</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217416</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217417</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217418</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217419</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6217420 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         action\n",
       "0             3\n",
       "1             3\n",
       "2             2\n",
       "3             2\n",
       "4             3\n",
       "...         ...\n",
       "6217415       1\n",
       "6217416       2\n",
       "6217417       2\n",
       "6217418       3\n",
       "6217419       3\n",
       "\n",
       "[6217420 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(y_train, dtype=np.uint8)\n",
    "y_df.columns = [\"action\"]\n",
    "y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "touched-coordinate",
    "papermill": {
     "duration": 0.027968,
     "end_time": "2021-05-12T03:03:15.557122",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.529154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "moving-skill",
    "outputId": "7542c4b4-f7d3-444c-8450-50bffddb1892",
    "papermill": {
     "duration": 0.202337,
     "end_time": "2021-05-12T03:03:15.787529",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.585192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  action\n",
      "0     0         148646\n",
      "      1         148647\n",
      "      2         162224\n",
      "      3         162225\n",
      "1     0         148646\n",
      "      1         148647\n",
      "      2         162224\n",
      "      3         162225\n",
      "2     0         148646\n",
      "      1         148647\n",
      "      2         162224\n",
      "      3         162225\n",
      "3     0         148646\n",
      "      1         148647\n",
      "      2         162224\n",
      "      3         162225\n",
      "4     0         148647\n",
      "      1         148646\n",
      "      2         162225\n",
      "      3         162224\n",
      "5     0         148647\n",
      "      1         148646\n",
      "      2         162225\n",
      "      3         162224\n",
      "6     0         148647\n",
      "      1         148646\n",
      "      2         162225\n",
      "      3         162224\n",
      "7     0         148647\n",
      "      1         148646\n",
      "      2         162225\n",
      "      3         162224\n",
      "8     0         148647\n",
      "      1         148647\n",
      "      2         162224\n",
      "      3         162224\n",
      "9     0         148647\n",
      "      1         148647\n",
      "      2         162224\n",
      "      3         162224\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "folds = y_df.copy()\n",
    "Fold = StratifiedKFold(n_splits=Config.n_fold, shuffle=True, random_state=Config.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[\"action\"])):\n",
    "    folds.loc[val_index, \"fold\"] = int(n)\n",
    "folds[\"fold\"] = folds[\"fold\"].astype(np.uint8)\n",
    "print(folds.groupby([\"fold\", \"action\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "creative-football",
    "papermill": {
     "duration": 0.029031,
     "end_time": "2021-05-12T03:03:15.845114",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.816083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "other-murder",
    "papermill": {
     "duration": 0.037264,
     "end_time": "2021-05-12T03:03:15.911219",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.873955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, array, label):\n",
    "        self.array = array\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx], torch.tensor(self.label[idx]).long()\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, array):\n",
    "        self.array = array\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adjusted-delhi",
    "outputId": "39504950-84bc-4692-8b90-8a5b64f741e0",
    "papermill": {
     "duration": 0.063691,
     "end_time": "2021-05-12T03:03:16.003693",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.940002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "if Config.debug or False:\n",
    "    train_ds = TrainDataset(X_train, y_train)\n",
    "\n",
    "    for i in range(1):\n",
    "        obs, action = train_ds[i]\n",
    "        print(obs.shape, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceramic-startup",
    "papermill": {
     "duration": 0.02876,
     "end_time": "2021-05-12T03:03:16.061575",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.032815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[: x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "jspEE71c2Yma"
   },
   "outputs": [],
   "source": [
    "class GeeseNetImoKuri(nn.Module):\n",
    "    class GeeseNetEncoder(nn.Module):\n",
    "        def __init__(self, dim):\n",
    "            super().__init__()\n",
    "            self.dim = dim\n",
    "            self.embed = nn.Embedding(16, dim)\n",
    "            self.pe = PositionalEncoding(dim, 0)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.embed(x) * math.sqrt(self.dim)\n",
    "            x = self.pe(x)\n",
    "            return x\n",
    "\n",
    "    class GeeseNetBlock(nn.Module):\n",
    "        def __init__(self, dim, n_heads):\n",
    "            super().__init__()\n",
    "            self.attention = nn.MultiheadAttention(dim, n_heads)\n",
    "\n",
    "        def forward(self, x):\n",
    "            h, _ = self.attention(x, x, x)\n",
    "            return h\n",
    "\n",
    "    class GeeseNetHead(nn.Module):\n",
    "        def __init__(self, dim):\n",
    "            super().__init__()\n",
    "\n",
    "            self.head_p1 = nn.Linear(dim, dim // 2, bias=False)\n",
    "            self.head_p2 = nn.Linear(dim // 2, 4, bias=False)\n",
    "            self.head_v1 = nn.Linear(dim + 77, dim, bias=False)\n",
    "            self.head_v2 = nn.Linear(dim, 1, bias=False)\n",
    "\n",
    "        def forward(self, x, h):\n",
    "            zeros = torch.zeros(x.size(), dtype=torch.long, device=x.device)\n",
    "            head = torch.where(x == 1, x, zeros).view(x.size(0), x.size(1), 1)\n",
    "\n",
    "            h_head = (h * head).sum(1)\n",
    "            h_avg = h.mean(-1)\n",
    "\n",
    "            h_p = F.relu_(self.head_p1(torch.cat([h_head], 1)))\n",
    "            p = self.head_p2(h_p)\n",
    "\n",
    "            h_v = F.relu_(self.head_v1(torch.cat([h_head, h_avg], 1)))\n",
    "            v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "            return p, v\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        dim = 64\n",
    "        blocks = 5\n",
    "\n",
    "        self.encoder = self.GeeseNetEncoder(dim)\n",
    "        self.blocks = nn.ModuleList([self.GeeseNetBlock(dim, 4) for _ in range(blocks)])\n",
    "        self.head = self.GeeseNetHead(dim)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        h = self.encoder(x)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            h = block(h)\n",
    "\n",
    "        p, v = self.head(x, h)\n",
    "\n",
    "        return {\"policy\": p, \"value\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "objective-victoria",
    "outputId": "1ab137a5-e26e-4b9c-ff85-95fef713b755",
    "papermill": {
     "duration": 4.955868,
     "end_time": "2021-05-12T03:03:21.187355",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.231487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "if Config.debug or False:\n",
    "    model = GeeseNetImoKuri()\n",
    "    # print(model)\n",
    "\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"params: {params:,}\")\n",
    "\n",
    "    train_ds = TrainDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "    for obs, action in train_loader:\n",
    "        output = model(obs)\n",
    "        print(output)\n",
    "        print(f\"{torch.argmax(output['policy'], dim=1)}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "military-fiction",
    "papermill": {
     "duration": 0.033001,
     "end_time": "2021-05-12T03:03:21.255277",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.222276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sophisticated-hearts",
    "papermill": {
     "duration": 0.031759,
     "end_time": "2021-05-12T03:03:21.319849",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.288090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "designing-detective",
    "papermill": {
     "duration": 0.03139,
     "end_time": "2021-05-12T03:03:21.383038",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.351648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "passive-cooper",
    "papermill": {
     "duration": 0.038846,
     "end_time": "2021-05-12T03:03:21.454085",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.415239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(result_df):\n",
    "    preds = result_df[\"preds\"].values\n",
    "    labels = result_df[\"action\"].values\n",
    "    score = get_score(labels, preds)\n",
    "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thirty-tracy",
    "papermill": {
     "duration": 0.0293,
     "end_time": "2021-05-12T03:03:21.514179",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.484879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "introductory-brooklyn",
    "papermill": {
     "duration": 0.039424,
     "end_time": "2021-05-12T03:03:21.582969",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.543545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "raising-laugh",
    "papermill": {
     "duration": 0.042063,
     "end_time": "2021-05-12T03:03:21.654559",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.612496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (obs, action) in enumerate(train_loader):\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        y_preds = model(obs)[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "        if Config.apex:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), Config.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % Config.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print(\n",
    "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
    "                f\"Loss avg.: {losses.avg:.4f} \"\n",
    "                f\"Grad: {grad_norm:.4f} \"\n",
    "                f\"LR: {scheduler.get_last_lr()[0]:.5f}  \"\n",
    "            )\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "plain-neighbor",
    "papermill": {
     "duration": 0.041056,
     "end_time": "2021-05-12T03:03:21.726585",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.685529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (obs, action) in enumerate(valid_loader):\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(obs)[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print(\n",
    "                f\"Eval: [{step}/{len(valid_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
    "                f\"Loss avg.: {losses.avg:.4f} \"\n",
    "            )\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "integrated-classification",
    "papermill": {
     "duration": 0.029832,
     "end_time": "2021-05-12T03:03:21.786427",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.756595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "harmful-explanation",
    "papermill": {
     "duration": 0.05136,
     "end_time": "2021-05-12T03:03:21.868561",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.817201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(folds, fold):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    # X_train_folds = X_train[folds[\"fold\"] != fold]\n",
    "    # X_valid_folds = X_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    # y_train_folds = y_train[folds[\"fold\"] != fold]\n",
    "    y_valid_folds = y_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    # y_df_train_folds = y_df[folds[\"fold\"] != fold]\n",
    "    y_df_valid_folds = y_df[folds[\"fold\"] == fold]\n",
    "\n",
    "    # train_dataset = TrainDataset(X_train[folds[\"fold\"] != fold], y_train[folds[\"fold\"] != fold])\n",
    "    # valid_dataset = TrainDataset(X_train[folds[\"fold\"] == fold], y_valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        TrainDataset(X_train[folds[\"fold\"] != fold], y_train[folds[\"fold\"] != fold]),\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        TrainDataset(X_train[folds[\"fold\"] == fold], y_valid_folds),\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if Config.scheduler == \"ReduceLROnPlateau\":\n",
    "            scheduler = ReduceLROnPlateau(\n",
    "                optimizer, mode=\"min\", factor=Config.factor, patience=Config.patience, verbose=True, eps=Config.eps\n",
    "            )\n",
    "        elif Config.scheduler == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=Config.T_max, eta_min=Config.min_lr, last_epoch=-1)\n",
    "        elif Config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "            scheduler = CosineAnnealingWarmRestarts(\n",
    "                optimizer, T_0=Config.T_0, T_mult=1, eta_min=Config.min_lr, last_epoch=-1\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = GeeseNetImoKuri()\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, Config.pre_train_file)))\n",
    "    except:\n",
    "        print(f\"Skip to load pre-train weight.\")\n",
    "\n",
    "    # Disable training for value network\n",
    "    for param in model.head.head_v1.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.head.head_v2.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Use multi GPU\n",
    "    if device == torch.device(\"cuda\") and not Config.apex:\n",
    "        model = torch.nn.DataParallel(model)  # make parallel\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=Config.lr, weight_decay=Config.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # apex\n",
    "    # ====================================================\n",
    "    if Config.apex:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
    "\n",
    "    # ====================================================\n",
    "    # Criterion\n",
    "    # ====================================================\n",
    "    def get_criterion():\n",
    "        if Config.criterion == \"CrossEntropyLoss\":\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        return criterion\n",
    "\n",
    "    criterion = get_criterion()\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    best_score = 0.0\n",
    "    best_loss = np.inf\n",
    "    best_preds = None\n",
    "\n",
    "    for epoch in range(Config.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "\n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(y_valid_folds, preds.argmax(1))\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Accuracy: {score}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_best.pth\")\n",
    "            best_preds = preds\n",
    "\n",
    "        if epoch == Config.epochs - 1:\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save final model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_final.pth\")\n",
    "\n",
    "    if Config.train:\n",
    "        y_df_valid_folds[[str(c) for c in range(Config.n_class)]] = best_preds\n",
    "        y_df_valid_folds[\"preds\"] = best_preds.argmax(1)\n",
    "\n",
    "        return y_df_valid_folds\n",
    "\n",
    "    if Config.tuning:\n",
    "        score = get_score(y_df_valid_folds[\"action\"].values, best_preds.argmax(1))\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    Config.geese_net_layers = trial.suggest_int(\"layers\", 6, 18)\n",
    "    Config.geese_net_filters = trial.suggest_int(\"filters\", 32, 128)\n",
    "\n",
    "    score = train_loop(folds, 0)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "complimentary-wright",
    "papermill": {
     "duration": 0.030218,
     "end_time": "2021-05-12T03:03:21.928896",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.898678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "particular-adaptation",
    "papermill": {
     "duration": 0.04089,
     "end_time": "2021-05-12T03:03:22.000150",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.959260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if Config.train:\n",
    "        # train\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(Config.n_fold):\n",
    "            _oof_df = train_loop(folds, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df)\n",
    "            break  # fold 1つだけ\n",
    "        # CV result\n",
    "        # LOGGER.info(f\"========== CV ==========\")\n",
    "        # get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
    "\n",
    "    if Config.tuning:\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=10)\n",
    "\n",
    "        trial = study.best_trial\n",
    "        print(\"Best trial:\")\n",
    "        print(\"  Value: \", trial.value)\n",
    "        print(\"  Params: \")\n",
    "        for key, value in trial.params.items():\n",
    "            print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "backed-journal",
    "outputId": "c9f0ff3d-795e-466b-e22e-9ba21d08c874",
    "papermill": {
     "duration": 2797.64711,
     "end_time": "2021-05-12T03:49:59.678400",
     "exception": false,
     "start_time": "2021-05-12T03:03:22.031290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip to load pre-train weight.\n",
      "Epoch: [1][0/5595] Elapsed 0m 2s (remain 200m 27s) Loss avg.: 1.3863 Grad: 0.0066 LR: 0.00100  \n",
      "Epoch: [1][100/5595] Elapsed 0m 35s (remain 32m 18s) Loss avg.: 1.3858 Grad: 0.0175 LR: 0.00100  \n",
      "Epoch: [1][200/5595] Elapsed 1m 9s (remain 30m 59s) Loss avg.: 1.3856 Grad: 0.0163 LR: 0.00100  \n",
      "Epoch: [1][300/5595] Elapsed 1m 42s (remain 30m 9s) Loss avg.: 1.3856 Grad: 0.0046 LR: 0.00100  \n",
      "Epoch: [1][400/5595] Elapsed 2m 16s (remain 29m 28s) Loss avg.: 1.3855 Grad: 0.0054 LR: 0.00100  \n",
      "Epoch: [1][500/5595] Elapsed 2m 50s (remain 28m 51s) Loss avg.: 1.3855 Grad: 0.0082 LR: 0.00100  \n",
      "Epoch: [1][600/5595] Elapsed 3m 23s (remain 28m 14s) Loss avg.: 1.3855 Grad: 0.0015 LR: 0.00100  \n",
      "Epoch: [1][700/5595] Elapsed 3m 57s (remain 27m 38s) Loss avg.: 1.3855 Grad: 0.0021 LR: 0.00100  \n",
      "Epoch: [1][800/5595] Elapsed 4m 31s (remain 27m 2s) Loss avg.: 1.3855 Grad: 0.0024 LR: 0.00100  \n",
      "Epoch: [1][900/5595] Elapsed 5m 4s (remain 26m 27s) Loss avg.: 1.3854 Grad: 0.0032 LR: 0.00100  \n",
      "Epoch: [1][1000/5595] Elapsed 5m 38s (remain 25m 51s) Loss avg.: 1.3854 Grad: 0.0028 LR: 0.00100  \n",
      "Epoch: [1][1100/5595] Elapsed 6m 11s (remain 25m 16s) Loss avg.: 1.3854 Grad: 0.0097 LR: 0.00100  \n",
      "Epoch: [1][1200/5595] Elapsed 6m 44s (remain 24m 41s) Loss avg.: 1.3854 Grad: 0.0032 LR: 0.00100  \n",
      "Epoch: [1][1300/5595] Elapsed 7m 18s (remain 24m 6s) Loss avg.: 1.3854 Grad: 0.0041 LR: 0.00100  \n",
      "Epoch: [1][1400/5595] Elapsed 7m 51s (remain 23m 31s) Loss avg.: 1.3854 Grad: 0.0046 LR: 0.00100  \n",
      "Epoch: [1][1500/5595] Elapsed 8m 24s (remain 22m 56s) Loss avg.: 1.3854 Grad: 0.0018 LR: 0.00100  \n",
      "Epoch: [1][1600/5595] Elapsed 8m 58s (remain 22m 22s) Loss avg.: 1.3854 Grad: 0.0029 LR: 0.00100  \n",
      "Epoch: [1][1700/5595] Elapsed 9m 31s (remain 21m 48s) Loss avg.: 1.3854 Grad: 0.0015 LR: 0.00100  \n",
      "Epoch: [1][1800/5595] Elapsed 10m 4s (remain 21m 13s) Loss avg.: 1.3854 Grad: 0.0012 LR: 0.00100  \n",
      "Epoch: [1][1900/5595] Elapsed 10m 37s (remain 20m 39s) Loss avg.: 1.3854 Grad: 0.0041 LR: 0.00100  \n",
      "Epoch: [1][2000/5595] Elapsed 11m 11s (remain 20m 5s) Loss avg.: 1.3854 Grad: 0.0083 LR: 0.00100  \n",
      "Epoch: [1][2100/5595] Elapsed 11m 44s (remain 19m 31s) Loss avg.: 1.3854 Grad: 0.0017 LR: 0.00100  \n",
      "Epoch: [1][2200/5595] Elapsed 12m 17s (remain 18m 57s) Loss avg.: 1.3854 Grad: 0.0019 LR: 0.00100  \n",
      "Epoch: [1][2300/5595] Elapsed 12m 51s (remain 18m 23s) Loss avg.: 1.3854 Grad: 0.0051 LR: 0.00100  \n",
      "Epoch: [1][2400/5595] Elapsed 13m 24s (remain 17m 49s) Loss avg.: 1.3854 Grad: 0.0035 LR: 0.00100  \n",
      "Epoch: [1][2500/5595] Elapsed 13m 57s (remain 17m 16s) Loss avg.: 1.3854 Grad: 0.0019 LR: 0.00100  \n",
      "Epoch: [1][2600/5595] Elapsed 14m 30s (remain 16m 42s) Loss avg.: 1.3854 Grad: 0.0034 LR: 0.00100  \n",
      "Epoch: [1][2700/5595] Elapsed 15m 4s (remain 16m 8s) Loss avg.: 1.3854 Grad: 0.0046 LR: 0.00100  \n",
      "Epoch: [1][2800/5595] Elapsed 15m 37s (remain 15m 34s) Loss avg.: 1.3854 Grad: 0.0048 LR: 0.00100  \n",
      "Epoch: [1][2900/5595] Elapsed 16m 10s (remain 15m 1s) Loss avg.: 1.3854 Grad: 0.0068 LR: 0.00100  \n",
      "Epoch: [1][3000/5595] Elapsed 16m 43s (remain 14m 27s) Loss avg.: 1.3854 Grad: 0.0037 LR: 0.00100  \n",
      "Epoch: [1][3100/5595] Elapsed 17m 17s (remain 13m 54s) Loss avg.: 1.3854 Grad: 0.0030 LR: 0.00100  \n",
      "Epoch: [1][3200/5595] Elapsed 17m 50s (remain 13m 20s) Loss avg.: 1.3854 Grad: 0.0044 LR: 0.00100  \n",
      "Epoch: [1][3300/5595] Elapsed 18m 23s (remain 12m 46s) Loss avg.: 1.3854 Grad: 0.0033 LR: 0.00100  \n",
      "Epoch: [1][3400/5595] Elapsed 18m 56s (remain 12m 13s) Loss avg.: 1.3854 Grad: 0.0032 LR: 0.00100  \n",
      "Epoch: [1][3500/5595] Elapsed 19m 30s (remain 11m 39s) Loss avg.: 1.3854 Grad: 0.0051 LR: 0.00100  \n",
      "Epoch: [1][3600/5595] Elapsed 20m 3s (remain 11m 6s) Loss avg.: 1.3854 Grad: 0.0007 LR: 0.00100  \n",
      "Epoch: [1][3700/5595] Elapsed 20m 36s (remain 10m 32s) Loss avg.: 1.3854 Grad: 0.0049 LR: 0.00100  \n",
      "Epoch: [1][3800/5595] Elapsed 21m 9s (remain 9m 59s) Loss avg.: 1.3854 Grad: 0.0057 LR: 0.00100  \n",
      "Epoch: [1][3900/5595] Elapsed 21m 42s (remain 9m 25s) Loss avg.: 1.3854 Grad: 0.0013 LR: 0.00100  \n",
      "Epoch: [1][4000/5595] Elapsed 22m 16s (remain 8m 52s) Loss avg.: 1.3854 Grad: 0.0030 LR: 0.00100  \n",
      "Epoch: [1][4100/5595] Elapsed 22m 49s (remain 8m 18s) Loss avg.: 1.3854 Grad: 0.0046 LR: 0.00100  \n",
      "Epoch: [1][4200/5595] Elapsed 23m 22s (remain 7m 45s) Loss avg.: 1.3854 Grad: 0.0026 LR: 0.00100  \n",
      "Epoch: [1][4300/5595] Elapsed 23m 55s (remain 7m 11s) Loss avg.: 1.3854 Grad: 0.0018 LR: 0.00100  \n",
      "Epoch: [1][4400/5595] Elapsed 24m 28s (remain 6m 38s) Loss avg.: 1.3854 Grad: 0.0056 LR: 0.00100  \n",
      "Epoch: [1][4500/5595] Elapsed 25m 2s (remain 6m 5s) Loss avg.: 1.3854 Grad: 0.0020 LR: 0.00100  \n",
      "Epoch: [1][4600/5595] Elapsed 25m 35s (remain 5m 31s) Loss avg.: 1.3854 Grad: 0.0044 LR: 0.00100  \n",
      "Epoch: [1][4700/5595] Elapsed 26m 8s (remain 4m 58s) Loss avg.: 1.3854 Grad: 0.0027 LR: 0.00100  \n",
      "Epoch: [1][4800/5595] Elapsed 26m 41s (remain 4m 24s) Loss avg.: 1.3854 Grad: 0.0042 LR: 0.00100  \n",
      "Epoch: [1][4900/5595] Elapsed 27m 15s (remain 3m 51s) Loss avg.: 1.3854 Grad: 0.0055 LR: 0.00100  \n",
      "Epoch: [1][5000/5595] Elapsed 27m 48s (remain 3m 18s) Loss avg.: 1.3854 Grad: 0.0017 LR: 0.00100  \n",
      "Epoch: [1][5100/5595] Elapsed 28m 21s (remain 2m 44s) Loss avg.: 1.3854 Grad: 0.0014 LR: 0.00100  \n",
      "Epoch: [1][5200/5595] Elapsed 28m 54s (remain 2m 11s) Loss avg.: 1.3854 Grad: 0.0035 LR: 0.00100  \n",
      "Epoch: [1][5300/5595] Elapsed 29m 27s (remain 1m 38s) Loss avg.: 1.3854 Grad: 0.0035 LR: 0.00100  \n",
      "Epoch: [1][5400/5595] Elapsed 30m 1s (remain 1m 4s) Loss avg.: 1.3854 Grad: 0.0006 LR: 0.00100  \n",
      "Epoch: [1][5500/5595] Elapsed 30m 34s (remain 0m 31s) Loss avg.: 1.3854 Grad: 0.0034 LR: 0.00100  \n",
      "Epoch: [1][5594/5595] Elapsed 31m 5s (remain 0m 0s) Loss avg.: 1.3854 Grad: 0.0080 LR: 0.00100  \n",
      "Eval: [0/622] Elapsed 0m 0s (remain 4m 27s) Loss avg.: 1.3847 \n",
      "Eval: [100/622] Elapsed 0m 12s (remain 1m 4s) Loss avg.: 1.3849 \n",
      "Eval: [200/622] Elapsed 0m 24s (remain 0m 51s) Loss avg.: 1.3852 \n",
      "Eval: [300/622] Elapsed 0m 36s (remain 0m 38s) Loss avg.: 1.3852 \n",
      "Eval: [400/622] Elapsed 0m 48s (remain 0m 26s) Loss avg.: 1.3853 \n",
      "Eval: [500/622] Elapsed 1m 0s (remain 0m 14s) Loss avg.: 1.3854 \n",
      "Eval: [600/622] Elapsed 1m 12s (remain 0m 2s) Loss avg.: 1.3854 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 1.3854  avg_val_loss: 1.3854  time: 1941s\n",
      "Epoch 1 - Accuracy: 0.26092012442460055\n",
      "Epoch 1 - Save Best Score: 0.2609 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: [621/622] Elapsed 1m 15s (remain 0m 0s) Loss avg.: 1.3854 \n",
      "Epoch: [2][0/5595] Elapsed 0m 1s (remain 94m 14s) Loss avg.: 1.3858 Grad: 0.0019 LR: 0.00098  \n",
      "Epoch: [2][100/5595] Elapsed 0m 34s (remain 30m 59s) Loss avg.: 1.3856 Grad: 0.0014 LR: 0.00098  \n",
      "Epoch: [2][200/5595] Elapsed 1m 7s (remain 30m 6s) Loss avg.: 1.3854 Grad: 0.0023 LR: 0.00098  \n",
      "Epoch: [2][300/5595] Elapsed 1m 40s (remain 29m 27s) Loss avg.: 1.3854 Grad: 0.0021 LR: 0.00098  \n",
      "Epoch: [2][400/5595] Elapsed 2m 13s (remain 28m 52s) Loss avg.: 1.3853 Grad: 0.0019 LR: 0.00098  \n",
      "Epoch: [2][500/5595] Elapsed 2m 47s (remain 28m 18s) Loss avg.: 1.3853 Grad: 0.0046 LR: 0.00098  \n",
      "Epoch: [2][600/5595] Elapsed 3m 20s (remain 27m 44s) Loss avg.: 1.3853 Grad: 0.0034 LR: 0.00098  \n",
      "Epoch: [2][700/5595] Elapsed 3m 53s (remain 27m 9s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00098  \n",
      "Epoch: [2][800/5595] Elapsed 4m 26s (remain 26m 36s) Loss avg.: 1.3853 Grad: 0.0058 LR: 0.00098  \n",
      "Epoch: [2][900/5595] Elapsed 4m 59s (remain 26m 2s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00098  \n",
      "Epoch: [2][1000/5595] Elapsed 5m 33s (remain 25m 28s) Loss avg.: 1.3854 Grad: 0.0035 LR: 0.00098  \n",
      "Epoch: [2][1100/5595] Elapsed 6m 6s (remain 24m 55s) Loss avg.: 1.3854 Grad: 0.0060 LR: 0.00098  \n",
      "Epoch: [2][1200/5595] Elapsed 6m 39s (remain 24m 22s) Loss avg.: 1.3854 Grad: 0.0020 LR: 0.00098  \n",
      "Epoch: [2][1300/5595] Elapsed 7m 12s (remain 23m 48s) Loss avg.: 1.3854 Grad: 0.0040 LR: 0.00098  \n",
      "Epoch: [2][1400/5595] Elapsed 7m 46s (remain 23m 15s) Loss avg.: 1.3854 Grad: 0.0026 LR: 0.00098  \n",
      "Epoch: [2][1500/5595] Elapsed 8m 19s (remain 22m 42s) Loss avg.: 1.3853 Grad: 0.0036 LR: 0.00098  \n",
      "Epoch: [2][1600/5595] Elapsed 8m 52s (remain 22m 8s) Loss avg.: 1.3853 Grad: 0.0039 LR: 0.00098  \n",
      "Epoch: [2][1700/5595] Elapsed 9m 25s (remain 21m 35s) Loss avg.: 1.3854 Grad: 0.0049 LR: 0.00098  \n",
      "Epoch: [2][1800/5595] Elapsed 9m 59s (remain 21m 2s) Loss avg.: 1.3854 Grad: 0.0029 LR: 0.00098  \n",
      "Epoch: [2][1900/5595] Elapsed 10m 32s (remain 20m 29s) Loss avg.: 1.3854 Grad: 0.0024 LR: 0.00098  \n",
      "Epoch: [2][2000/5595] Elapsed 11m 5s (remain 19m 55s) Loss avg.: 1.3854 Grad: 0.0060 LR: 0.00098  \n",
      "Epoch: [2][2100/5595] Elapsed 11m 38s (remain 19m 22s) Loss avg.: 1.3854 Grad: 0.0029 LR: 0.00098  \n",
      "Epoch: [2][2200/5595] Elapsed 12m 12s (remain 18m 49s) Loss avg.: 1.3854 Grad: 0.0035 LR: 0.00098  \n",
      "Epoch: [2][2300/5595] Elapsed 12m 45s (remain 18m 15s) Loss avg.: 1.3854 Grad: 0.0051 LR: 0.00098  \n",
      "Epoch: [2][2400/5595] Elapsed 13m 18s (remain 17m 42s) Loss avg.: 1.3854 Grad: 0.0011 LR: 0.00098  \n",
      "Epoch: [2][2500/5595] Elapsed 13m 51s (remain 17m 9s) Loss avg.: 1.3854 Grad: 0.0057 LR: 0.00098  \n",
      "Epoch: [2][2600/5595] Elapsed 14m 25s (remain 16m 35s) Loss avg.: 1.3854 Grad: 0.0033 LR: 0.00098  \n",
      "Epoch: [2][2700/5595] Elapsed 14m 58s (remain 16m 2s) Loss avg.: 1.3854 Grad: 0.0022 LR: 0.00098  \n",
      "Epoch: [2][2800/5595] Elapsed 15m 31s (remain 15m 29s) Loss avg.: 1.3854 Grad: 0.0031 LR: 0.00098  \n",
      "Epoch: [2][2900/5595] Elapsed 16m 4s (remain 14m 56s) Loss avg.: 1.3854 Grad: 0.0028 LR: 0.00098  \n",
      "Epoch: [2][3000/5595] Elapsed 16m 38s (remain 14m 22s) Loss avg.: 1.3854 Grad: 0.0010 LR: 0.00098  \n",
      "Epoch: [2][3100/5595] Elapsed 17m 11s (remain 13m 49s) Loss avg.: 1.3854 Grad: 0.0026 LR: 0.00098  \n",
      "Epoch: [2][3200/5595] Elapsed 17m 44s (remain 13m 16s) Loss avg.: 1.3854 Grad: 0.0025 LR: 0.00098  \n",
      "Epoch: [2][3300/5595] Elapsed 18m 17s (remain 12m 42s) Loss avg.: 1.3854 Grad: 0.0044 LR: 0.00098  \n",
      "Epoch: [2][3400/5595] Elapsed 18m 51s (remain 12m 9s) Loss avg.: 1.3854 Grad: 0.0033 LR: 0.00098  \n",
      "Epoch: [2][3500/5595] Elapsed 19m 24s (remain 11m 36s) Loss avg.: 1.3854 Grad: 0.0022 LR: 0.00098  \n",
      "Epoch: [2][3600/5595] Elapsed 19m 57s (remain 11m 3s) Loss avg.: 1.3854 Grad: 0.0042 LR: 0.00098  \n",
      "Epoch: [2][3700/5595] Elapsed 20m 30s (remain 10m 29s) Loss avg.: 1.3854 Grad: 0.0028 LR: 0.00098  \n",
      "Epoch: [2][3800/5595] Elapsed 21m 4s (remain 9m 56s) Loss avg.: 1.3853 Grad: 0.0041 LR: 0.00098  \n",
      "Epoch: [2][3900/5595] Elapsed 21m 37s (remain 9m 23s) Loss avg.: 1.3854 Grad: 0.0013 LR: 0.00098  \n",
      "Epoch: [2][4000/5595] Elapsed 22m 10s (remain 8m 50s) Loss avg.: 1.3854 Grad: 0.0012 LR: 0.00098  \n",
      "Epoch: [2][4100/5595] Elapsed 22m 43s (remain 8m 16s) Loss avg.: 1.3854 Grad: 0.0084 LR: 0.00098  \n",
      "Epoch: [2][4200/5595] Elapsed 23m 16s (remain 7m 43s) Loss avg.: 1.3854 Grad: 0.0038 LR: 0.00098  \n",
      "Epoch: [2][4300/5595] Elapsed 23m 50s (remain 7m 10s) Loss avg.: 1.3854 Grad: 0.0021 LR: 0.00098  \n",
      "Epoch: [2][4400/5595] Elapsed 24m 23s (remain 6m 37s) Loss avg.: 1.3854 Grad: 0.0015 LR: 0.00098  \n",
      "Epoch: [2][4500/5595] Elapsed 24m 56s (remain 6m 3s) Loss avg.: 1.3854 Grad: 0.0013 LR: 0.00098  \n",
      "Epoch: [2][4600/5595] Elapsed 25m 30s (remain 5m 30s) Loss avg.: 1.3854 Grad: 0.0011 LR: 0.00098  \n",
      "Epoch: [2][4700/5595] Elapsed 26m 3s (remain 4m 57s) Loss avg.: 1.3854 Grad: 0.0048 LR: 0.00098  \n",
      "Epoch: [2][4800/5595] Elapsed 26m 36s (remain 4m 24s) Loss avg.: 1.3854 Grad: 0.0011 LR: 0.00098  \n",
      "Epoch: [2][4900/5595] Elapsed 27m 9s (remain 3m 50s) Loss avg.: 1.3854 Grad: 0.0025 LR: 0.00098  \n",
      "Epoch: [2][5000/5595] Elapsed 27m 43s (remain 3m 17s) Loss avg.: 1.3854 Grad: 0.0034 LR: 0.00098  \n",
      "Epoch: [2][5100/5595] Elapsed 28m 16s (remain 2m 44s) Loss avg.: 1.3854 Grad: 0.0039 LR: 0.00098  \n",
      "Epoch: [2][5200/5595] Elapsed 28m 49s (remain 2m 11s) Loss avg.: 1.3854 Grad: 0.0015 LR: 0.00098  \n",
      "Epoch: [2][5300/5595] Elapsed 29m 23s (remain 1m 37s) Loss avg.: 1.3853 Grad: 0.0038 LR: 0.00098  \n",
      "Epoch: [2][5400/5595] Elapsed 29m 56s (remain 1m 4s) Loss avg.: 1.3854 Grad: 0.0030 LR: 0.00098  \n",
      "Epoch: [2][5500/5595] Elapsed 30m 29s (remain 0m 31s) Loss avg.: 1.3853 Grad: 0.0052 LR: 0.00098  \n",
      "Epoch: [2][5594/5595] Elapsed 31m 1s (remain 0m 0s) Loss avg.: 1.3854 Grad: 0.0035 LR: 0.00098  \n",
      "Eval: [0/622] Elapsed 0m 0s (remain 3m 32s) Loss avg.: 1.3850 \n",
      "Eval: [100/622] Elapsed 0m 12s (remain 1m 3s) Loss avg.: 1.3851 \n",
      "Eval: [200/622] Elapsed 0m 24s (remain 0m 51s) Loss avg.: 1.3853 \n",
      "Eval: [300/622] Elapsed 0m 36s (remain 0m 38s) Loss avg.: 1.3853 \n",
      "Eval: [400/622] Elapsed 0m 48s (remain 0m 26s) Loss avg.: 1.3854 \n",
      "Eval: [500/622] Elapsed 1m 0s (remain 0m 14s) Loss avg.: 1.3854 \n",
      "Eval: [600/622] Elapsed 1m 12s (remain 0m 2s) Loss avg.: 1.3854 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 1.3854  avg_val_loss: 1.3854  time: 1936s\n",
      "Epoch 2 - Accuracy: 0.26092012442460055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: [621/622] Elapsed 1m 14s (remain 0m 0s) Loss avg.: 1.3854 \n",
      "Epoch: [3][0/5595] Elapsed 0m 1s (remain 94m 6s) Loss avg.: 1.3858 Grad: 0.0019 LR: 0.00091  \n",
      "Epoch: [3][100/5595] Elapsed 0m 34s (remain 30m 59s) Loss avg.: 1.3852 Grad: 0.0032 LR: 0.00091  \n",
      "Epoch: [3][200/5595] Elapsed 1m 7s (remain 30m 5s) Loss avg.: 1.3852 Grad: 0.0045 LR: 0.00091  \n",
      "Epoch: [3][300/5595] Elapsed 1m 40s (remain 29m 25s) Loss avg.: 1.3853 Grad: 0.0043 LR: 0.00091  \n",
      "Epoch: [3][400/5595] Elapsed 2m 13s (remain 28m 49s) Loss avg.: 1.3853 Grad: 0.0013 LR: 0.00091  \n",
      "Epoch: [3][500/5595] Elapsed 2m 46s (remain 28m 16s) Loss avg.: 1.3853 Grad: 0.0028 LR: 0.00091  \n",
      "Epoch: [3][600/5595] Elapsed 3m 20s (remain 27m 42s) Loss avg.: 1.3853 Grad: 0.0031 LR: 0.00091  \n",
      "Epoch: [3][700/5595] Elapsed 3m 53s (remain 27m 8s) Loss avg.: 1.3853 Grad: 0.0055 LR: 0.00091  \n",
      "Epoch: [3][800/5595] Elapsed 4m 26s (remain 26m 34s) Loss avg.: 1.3854 Grad: 0.0047 LR: 0.00091  \n",
      "Epoch: [3][900/5595] Elapsed 4m 59s (remain 26m 1s) Loss avg.: 1.3853 Grad: 0.0014 LR: 0.00091  \n",
      "Epoch: [3][1000/5595] Elapsed 5m 33s (remain 25m 28s) Loss avg.: 1.3853 Grad: 0.0051 LR: 0.00091  \n",
      "Epoch: [3][1100/5595] Elapsed 6m 6s (remain 24m 55s) Loss avg.: 1.3853 Grad: 0.0041 LR: 0.00091  \n",
      "Epoch: [3][1200/5595] Elapsed 6m 39s (remain 24m 22s) Loss avg.: 1.3853 Grad: 0.0007 LR: 0.00091  \n",
      "Epoch: [3][1300/5595] Elapsed 7m 12s (remain 23m 48s) Loss avg.: 1.3853 Grad: 0.0050 LR: 0.00091  \n",
      "Epoch: [3][1400/5595] Elapsed 7m 46s (remain 23m 15s) Loss avg.: 1.3853 Grad: 0.0045 LR: 0.00091  \n",
      "Epoch: [3][1500/5595] Elapsed 8m 19s (remain 22m 41s) Loss avg.: 1.3853 Grad: 0.0003 LR: 0.00091  \n",
      "Epoch: [3][1600/5595] Elapsed 8m 52s (remain 22m 8s) Loss avg.: 1.3853 Grad: 0.0030 LR: 0.00091  \n",
      "Epoch: [3][1700/5595] Elapsed 9m 25s (remain 21m 34s) Loss avg.: 1.3853 Grad: 0.0083 LR: 0.00091  \n",
      "Epoch: [3][1800/5595] Elapsed 9m 58s (remain 21m 1s) Loss avg.: 1.3853 Grad: 0.0020 LR: 0.00091  \n",
      "Epoch: [3][1900/5595] Elapsed 10m 31s (remain 20m 27s) Loss avg.: 1.3854 Grad: 0.0021 LR: 0.00091  \n",
      "Epoch: [3][2000/5595] Elapsed 11m 5s (remain 19m 54s) Loss avg.: 1.3854 Grad: 0.0020 LR: 0.00091  \n",
      "Epoch: [3][2100/5595] Elapsed 11m 38s (remain 19m 21s) Loss avg.: 1.3854 Grad: 0.0021 LR: 0.00091  \n",
      "Epoch: [3][2200/5595] Elapsed 12m 11s (remain 18m 47s) Loss avg.: 1.3854 Grad: 0.0011 LR: 0.00091  \n",
      "Epoch: [3][2300/5595] Elapsed 12m 44s (remain 18m 14s) Loss avg.: 1.3854 Grad: 0.0029 LR: 0.00091  \n",
      "Epoch: [3][2400/5595] Elapsed 13m 17s (remain 17m 41s) Loss avg.: 1.3854 Grad: 0.0031 LR: 0.00091  \n",
      "Epoch: [3][2500/5595] Elapsed 13m 51s (remain 17m 8s) Loss avg.: 1.3854 Grad: 0.0027 LR: 0.00091  \n",
      "Epoch: [3][2600/5595] Elapsed 14m 24s (remain 16m 35s) Loss avg.: 1.3853 Grad: 0.0040 LR: 0.00091  \n",
      "Epoch: [3][2700/5595] Elapsed 14m 57s (remain 16m 1s) Loss avg.: 1.3853 Grad: 0.0005 LR: 0.00091  \n",
      "Epoch: [3][2800/5595] Elapsed 15m 30s (remain 15m 28s) Loss avg.: 1.3853 Grad: 0.0019 LR: 0.00091  \n",
      "Epoch: [3][2900/5595] Elapsed 16m 4s (remain 14m 55s) Loss avg.: 1.3853 Grad: 0.0073 LR: 0.00091  \n",
      "Epoch: [3][3000/5595] Elapsed 16m 37s (remain 14m 22s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00091  \n",
      "Epoch: [3][3100/5595] Elapsed 17m 10s (remain 13m 48s) Loss avg.: 1.3853 Grad: 0.0027 LR: 0.00091  \n",
      "Epoch: [3][3200/5595] Elapsed 17m 43s (remain 13m 15s) Loss avg.: 1.3853 Grad: 0.0038 LR: 0.00091  \n",
      "Epoch: [3][3300/5595] Elapsed 18m 17s (remain 12m 42s) Loss avg.: 1.3853 Grad: 0.0020 LR: 0.00091  \n",
      "Epoch: [3][3400/5595] Elapsed 18m 50s (remain 12m 9s) Loss avg.: 1.3854 Grad: 0.0038 LR: 0.00091  \n",
      "Epoch: [3][3500/5595] Elapsed 19m 23s (remain 11m 36s) Loss avg.: 1.3854 Grad: 0.0048 LR: 0.00091  \n",
      "Epoch: [3][3600/5595] Elapsed 19m 57s (remain 11m 2s) Loss avg.: 1.3853 Grad: 0.0035 LR: 0.00091  \n",
      "Epoch: [3][3700/5595] Elapsed 20m 30s (remain 10m 29s) Loss avg.: 1.3853 Grad: 0.0028 LR: 0.00091  \n",
      "Epoch: [3][3800/5595] Elapsed 21m 3s (remain 9m 56s) Loss avg.: 1.3853 Grad: 0.0011 LR: 0.00091  \n",
      "Epoch: [3][3900/5595] Elapsed 21m 37s (remain 9m 23s) Loss avg.: 1.3853 Grad: 0.0046 LR: 0.00091  \n",
      "Epoch: [3][4000/5595] Elapsed 22m 10s (remain 8m 49s) Loss avg.: 1.3853 Grad: 0.0024 LR: 0.00091  \n",
      "Epoch: [3][4100/5595] Elapsed 22m 43s (remain 8m 16s) Loss avg.: 1.3853 Grad: 0.0094 LR: 0.00091  \n",
      "Epoch: [3][4200/5595] Elapsed 23m 16s (remain 7m 43s) Loss avg.: 1.3853 Grad: 0.0041 LR: 0.00091  \n",
      "Epoch: [3][4300/5595] Elapsed 23m 50s (remain 7m 10s) Loss avg.: 1.3853 Grad: 0.0034 LR: 0.00091  \n",
      "Epoch: [3][4400/5595] Elapsed 24m 23s (remain 6m 37s) Loss avg.: 1.3854 Grad: 0.0026 LR: 0.00091  \n",
      "Epoch: [3][4500/5595] Elapsed 24m 56s (remain 6m 3s) Loss avg.: 1.3854 Grad: 0.0020 LR: 0.00091  \n",
      "Epoch: [3][4600/5595] Elapsed 25m 29s (remain 5m 30s) Loss avg.: 1.3854 Grad: 0.0023 LR: 0.00091  \n",
      "Epoch: [3][4700/5595] Elapsed 26m 3s (remain 4m 57s) Loss avg.: 1.3854 Grad: 0.0036 LR: 0.00091  \n",
      "Epoch: [3][4800/5595] Elapsed 26m 36s (remain 4m 24s) Loss avg.: 1.3854 Grad: 0.0015 LR: 0.00091  \n",
      "Epoch: [3][4900/5595] Elapsed 27m 9s (remain 3m 50s) Loss avg.: 1.3854 Grad: 0.0016 LR: 0.00091  \n",
      "Epoch: [3][5000/5595] Elapsed 27m 42s (remain 3m 17s) Loss avg.: 1.3854 Grad: 0.0060 LR: 0.00091  \n",
      "Epoch: [3][5100/5595] Elapsed 28m 16s (remain 2m 44s) Loss avg.: 1.3854 Grad: 0.0019 LR: 0.00091  \n",
      "Epoch: [3][5200/5595] Elapsed 28m 49s (remain 2m 11s) Loss avg.: 1.3854 Grad: 0.0033 LR: 0.00091  \n",
      "Epoch: [3][5300/5595] Elapsed 29m 22s (remain 1m 37s) Loss avg.: 1.3854 Grad: 0.0046 LR: 0.00091  \n",
      "Epoch: [3][5400/5595] Elapsed 29m 55s (remain 1m 4s) Loss avg.: 1.3854 Grad: 0.0011 LR: 0.00091  \n",
      "Epoch: [3][5500/5595] Elapsed 30m 29s (remain 0m 31s) Loss avg.: 1.3854 Grad: 0.0069 LR: 0.00091  \n",
      "Epoch: [3][5594/5595] Elapsed 31m 0s (remain 0m 0s) Loss avg.: 1.3854 Grad: 0.0047 LR: 0.00091  \n",
      "Eval: [0/622] Elapsed 0m 0s (remain 3m 30s) Loss avg.: 1.3850 \n",
      "Eval: [100/622] Elapsed 0m 12s (remain 1m 3s) Loss avg.: 1.3850 \n",
      "Eval: [200/622] Elapsed 0m 24s (remain 0m 51s) Loss avg.: 1.3852 \n",
      "Eval: [300/622] Elapsed 0m 36s (remain 0m 38s) Loss avg.: 1.3852 \n",
      "Eval: [400/622] Elapsed 0m 48s (remain 0m 26s) Loss avg.: 1.3853 \n",
      "Eval: [500/622] Elapsed 1m 0s (remain 0m 14s) Loss avg.: 1.3853 \n",
      "Eval: [600/622] Elapsed 1m 12s (remain 0m 2s) Loss avg.: 1.3854 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 1.3854  avg_val_loss: 1.3854  time: 1936s\n",
      "Epoch 3 - Accuracy: 0.26092012442460055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: [621/622] Elapsed 1m 14s (remain 0m 0s) Loss avg.: 1.3854 \n",
      "Epoch: [4][0/5595] Elapsed 0m 1s (remain 93m 55s) Loss avg.: 1.3869 Grad: 0.0025 LR: 0.00081  \n",
      "Epoch: [4][100/5595] Elapsed 0m 34s (remain 30m 57s) Loss avg.: 1.3856 Grad: 0.0027 LR: 0.00081  \n",
      "Epoch: [4][200/5595] Elapsed 1m 7s (remain 30m 7s) Loss avg.: 1.3855 Grad: 0.0054 LR: 0.00081  \n",
      "Epoch: [4][300/5595] Elapsed 1m 40s (remain 29m 29s) Loss avg.: 1.3855 Grad: 0.0015 LR: 0.00081  \n",
      "Epoch: [4][400/5595] Elapsed 2m 13s (remain 28m 54s) Loss avg.: 1.3854 Grad: 0.0068 LR: 0.00081  \n",
      "Epoch: [4][500/5595] Elapsed 2m 47s (remain 28m 20s) Loss avg.: 1.3854 Grad: 0.0049 LR: 0.00081  \n",
      "Epoch: [4][600/5595] Elapsed 3m 20s (remain 27m 45s) Loss avg.: 1.3854 Grad: 0.0012 LR: 0.00081  \n",
      "Epoch: [4][700/5595] Elapsed 3m 53s (remain 27m 11s) Loss avg.: 1.3854 Grad: 0.0029 LR: 0.00081  \n",
      "Epoch: [4][800/5595] Elapsed 4m 26s (remain 26m 37s) Loss avg.: 1.3854 Grad: 0.0015 LR: 0.00081  \n",
      "Epoch: [4][900/5595] Elapsed 5m 0s (remain 26m 4s) Loss avg.: 1.3854 Grad: 0.0022 LR: 0.00081  \n",
      "Epoch: [4][1000/5595] Elapsed 5m 33s (remain 25m 30s) Loss avg.: 1.3853 Grad: 0.0065 LR: 0.00081  \n",
      "Epoch: [4][1100/5595] Elapsed 6m 6s (remain 24m 57s) Loss avg.: 1.3853 Grad: 0.0056 LR: 0.00081  \n",
      "Epoch: [4][1200/5595] Elapsed 6m 40s (remain 24m 23s) Loss avg.: 1.3853 Grad: 0.0062 LR: 0.00081  \n",
      "Epoch: [4][1300/5595] Elapsed 7m 13s (remain 23m 49s) Loss avg.: 1.3854 Grad: 0.0029 LR: 0.00081  \n",
      "Epoch: [4][1400/5595] Elapsed 7m 46s (remain 23m 16s) Loss avg.: 1.3853 Grad: 0.0040 LR: 0.00081  \n",
      "Epoch: [4][1500/5595] Elapsed 8m 19s (remain 22m 42s) Loss avg.: 1.3854 Grad: 0.0014 LR: 0.00081  \n",
      "Epoch: [4][1600/5595] Elapsed 8m 52s (remain 22m 9s) Loss avg.: 1.3854 Grad: 0.0053 LR: 0.00081  \n",
      "Epoch: [4][1700/5595] Elapsed 9m 26s (remain 21m 35s) Loss avg.: 1.3854 Grad: 0.0055 LR: 0.00081  \n",
      "Epoch: [4][1800/5595] Elapsed 9m 59s (remain 21m 2s) Loss avg.: 1.3854 Grad: 0.0016 LR: 0.00081  \n",
      "Epoch: [4][1900/5595] Elapsed 10m 32s (remain 20m 29s) Loss avg.: 1.3854 Grad: 0.0041 LR: 0.00081  \n",
      "Epoch: [4][2000/5595] Elapsed 11m 6s (remain 19m 56s) Loss avg.: 1.3854 Grad: 0.0054 LR: 0.00081  \n",
      "Epoch: [4][2100/5595] Elapsed 11m 39s (remain 19m 22s) Loss avg.: 1.3854 Grad: 0.0038 LR: 0.00081  \n",
      "Epoch: [4][2200/5595] Elapsed 12m 12s (remain 18m 49s) Loss avg.: 1.3854 Grad: 0.0060 LR: 0.00081  \n",
      "Epoch: [4][2300/5595] Elapsed 12m 45s (remain 18m 16s) Loss avg.: 1.3854 Grad: 0.0033 LR: 0.00081  \n",
      "Epoch: [4][2400/5595] Elapsed 13m 19s (remain 17m 43s) Loss avg.: 1.3854 Grad: 0.0036 LR: 0.00081  \n",
      "Epoch: [4][2500/5595] Elapsed 13m 52s (remain 17m 9s) Loss avg.: 1.3854 Grad: 0.0019 LR: 0.00081  \n",
      "Epoch: [4][2600/5595] Elapsed 14m 25s (remain 16m 36s) Loss avg.: 1.3854 Grad: 0.0057 LR: 0.00081  \n",
      "Epoch: [4][2700/5595] Elapsed 14m 59s (remain 16m 3s) Loss avg.: 1.3854 Grad: 0.0046 LR: 0.00081  \n",
      "Epoch: [4][2800/5595] Elapsed 15m 32s (remain 15m 29s) Loss avg.: 1.3854 Grad: 0.0019 LR: 0.00081  \n",
      "Epoch: [4][2900/5595] Elapsed 16m 5s (remain 14m 56s) Loss avg.: 1.3854 Grad: 0.0019 LR: 0.00081  \n",
      "Epoch: [4][3000/5595] Elapsed 16m 38s (remain 14m 23s) Loss avg.: 1.3854 Grad: 0.0030 LR: 0.00081  \n",
      "Epoch: [4][3100/5595] Elapsed 17m 12s (remain 13m 50s) Loss avg.: 1.3854 Grad: 0.0057 LR: 0.00081  \n",
      "Epoch: [4][3200/5595] Elapsed 17m 45s (remain 13m 16s) Loss avg.: 1.3854 Grad: 0.0019 LR: 0.00081  \n",
      "Epoch: [4][3300/5595] Elapsed 18m 18s (remain 12m 43s) Loss avg.: 1.3853 Grad: 0.0007 LR: 0.00081  \n",
      "Epoch: [4][3400/5595] Elapsed 18m 51s (remain 12m 10s) Loss avg.: 1.3854 Grad: 0.0019 LR: 0.00081  \n",
      "Epoch: [4][3500/5595] Elapsed 19m 25s (remain 11m 36s) Loss avg.: 1.3853 Grad: 0.0020 LR: 0.00081  \n",
      "Epoch: [4][3600/5595] Elapsed 19m 58s (remain 11m 3s) Loss avg.: 1.3853 Grad: 0.0036 LR: 0.00081  \n",
      "Epoch: [4][3700/5595] Elapsed 20m 31s (remain 10m 30s) Loss avg.: 1.3853 Grad: 0.0037 LR: 0.00081  \n",
      "Epoch: [4][3800/5595] Elapsed 21m 5s (remain 9m 57s) Loss avg.: 1.3853 Grad: 0.0008 LR: 0.00081  \n",
      "Epoch: [4][3900/5595] Elapsed 21m 38s (remain 9m 23s) Loss avg.: 1.3853 Grad: 0.0023 LR: 0.00081  \n",
      "Epoch: [4][4000/5595] Elapsed 22m 11s (remain 8m 50s) Loss avg.: 1.3853 Grad: 0.0012 LR: 0.00081  \n",
      "Epoch: [4][4100/5595] Elapsed 22m 44s (remain 8m 17s) Loss avg.: 1.3853 Grad: 0.0057 LR: 0.00081  \n",
      "Epoch: [4][4200/5595] Elapsed 23m 18s (remain 7m 43s) Loss avg.: 1.3853 Grad: 0.0031 LR: 0.00081  \n",
      "Epoch: [4][4300/5595] Elapsed 23m 51s (remain 7m 10s) Loss avg.: 1.3854 Grad: 0.0026 LR: 0.00081  \n",
      "Epoch: [4][4400/5595] Elapsed 24m 24s (remain 6m 37s) Loss avg.: 1.3854 Grad: 0.0024 LR: 0.00081  \n",
      "Epoch: [4][4500/5595] Elapsed 24m 57s (remain 6m 4s) Loss avg.: 1.3854 Grad: 0.0015 LR: 0.00081  \n",
      "Epoch: [4][4600/5595] Elapsed 25m 31s (remain 5m 30s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00081  \n",
      "Epoch: [4][4700/5595] Elapsed 26m 4s (remain 4m 57s) Loss avg.: 1.3853 Grad: 0.0034 LR: 0.00081  \n",
      "Epoch: [4][4800/5595] Elapsed 26m 37s (remain 4m 24s) Loss avg.: 1.3853 Grad: 0.0025 LR: 0.00081  \n",
      "Epoch: [4][4900/5595] Elapsed 27m 10s (remain 3m 50s) Loss avg.: 1.3853 Grad: 0.0019 LR: 0.00081  \n",
      "Epoch: [4][5000/5595] Elapsed 27m 44s (remain 3m 17s) Loss avg.: 1.3853 Grad: 0.0018 LR: 0.00081  \n",
      "Epoch: [4][5100/5595] Elapsed 28m 17s (remain 2m 44s) Loss avg.: 1.3853 Grad: 0.0013 LR: 0.00081  \n",
      "Epoch: [4][5200/5595] Elapsed 28m 50s (remain 2m 11s) Loss avg.: 1.3854 Grad: 0.0021 LR: 0.00081  \n",
      "Epoch: [4][5300/5595] Elapsed 29m 23s (remain 1m 37s) Loss avg.: 1.3854 Grad: 0.0023 LR: 0.00081  \n",
      "Epoch: [4][5400/5595] Elapsed 29m 57s (remain 1m 4s) Loss avg.: 1.3854 Grad: 0.0041 LR: 0.00081  \n",
      "Epoch: [4][5500/5595] Elapsed 30m 30s (remain 0m 31s) Loss avg.: 1.3854 Grad: 0.0025 LR: 0.00081  \n",
      "Epoch: [4][5594/5595] Elapsed 31m 1s (remain 0m 0s) Loss avg.: 1.3854 Grad: 0.0038 LR: 0.00081  \n",
      "Eval: [0/622] Elapsed 0m 0s (remain 3m 34s) Loss avg.: 1.3847 \n",
      "Eval: [100/622] Elapsed 0m 12s (remain 1m 3s) Loss avg.: 1.3849 \n",
      "Eval: [200/622] Elapsed 0m 24s (remain 0m 51s) Loss avg.: 1.3852 \n",
      "Eval: [300/622] Elapsed 0m 36s (remain 0m 38s) Loss avg.: 1.3852 \n",
      "Eval: [400/622] Elapsed 0m 48s (remain 0m 26s) Loss avg.: 1.3853 \n",
      "Eval: [500/622] Elapsed 1m 0s (remain 0m 14s) Loss avg.: 1.3853 \n",
      "Eval: [600/622] Elapsed 1m 12s (remain 0m 2s) Loss avg.: 1.3854 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 1.3854  avg_val_loss: 1.3854  time: 1937s\n",
      "Epoch 4 - Accuracy: 0.2609185160404155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: [621/622] Elapsed 1m 14s (remain 0m 0s) Loss avg.: 1.3854 \n",
      "Epoch: [5][0/5595] Elapsed 0m 0s (remain 92m 16s) Loss avg.: 1.3873 Grad: 0.0033 LR: 0.00069  \n",
      "Epoch: [5][100/5595] Elapsed 0m 34s (remain 30m 53s) Loss avg.: 1.3853 Grad: 0.0039 LR: 0.00069  \n",
      "Epoch: [5][200/5595] Elapsed 1m 7s (remain 30m 7s) Loss avg.: 1.3851 Grad: 0.0072 LR: 0.00069  \n",
      "Epoch: [5][300/5595] Elapsed 1m 40s (remain 29m 27s) Loss avg.: 1.3852 Grad: 0.0018 LR: 0.00069  \n",
      "Epoch: [5][400/5595] Elapsed 2m 13s (remain 28m 50s) Loss avg.: 1.3852 Grad: 0.0055 LR: 0.00069  \n",
      "Epoch: [5][500/5595] Elapsed 2m 46s (remain 28m 14s) Loss avg.: 1.3852 Grad: 0.0009 LR: 0.00069  \n",
      "Epoch: [5][600/5595] Elapsed 3m 19s (remain 27m 40s) Loss avg.: 1.3852 Grad: 0.0014 LR: 0.00069  \n",
      "Epoch: [5][700/5595] Elapsed 3m 53s (remain 27m 7s) Loss avg.: 1.3852 Grad: 0.0016 LR: 0.00069  \n",
      "Epoch: [5][800/5595] Elapsed 4m 26s (remain 26m 34s) Loss avg.: 1.3853 Grad: 0.0047 LR: 0.00069  \n",
      "Epoch: [5][900/5595] Elapsed 4m 59s (remain 26m 1s) Loss avg.: 1.3853 Grad: 0.0025 LR: 0.00069  \n",
      "Epoch: [5][1000/5595] Elapsed 5m 32s (remain 25m 27s) Loss avg.: 1.3852 Grad: 0.0055 LR: 0.00069  \n",
      "Epoch: [5][1100/5595] Elapsed 6m 6s (remain 24m 54s) Loss avg.: 1.3852 Grad: 0.0047 LR: 0.00069  \n",
      "Epoch: [5][1200/5595] Elapsed 6m 39s (remain 24m 21s) Loss avg.: 1.3853 Grad: 0.0035 LR: 0.00069  \n",
      "Epoch: [5][1300/5595] Elapsed 7m 12s (remain 23m 48s) Loss avg.: 1.3853 Grad: 0.0041 LR: 0.00069  \n",
      "Epoch: [5][1400/5595] Elapsed 7m 45s (remain 23m 14s) Loss avg.: 1.3853 Grad: 0.0056 LR: 0.00069  \n",
      "Epoch: [5][1500/5595] Elapsed 8m 19s (remain 22m 41s) Loss avg.: 1.3853 Grad: 0.0007 LR: 0.00069  \n",
      "Epoch: [5][1600/5595] Elapsed 8m 52s (remain 22m 8s) Loss avg.: 1.3853 Grad: 0.0020 LR: 0.00069  \n",
      "Epoch: [5][1700/5595] Elapsed 9m 25s (remain 21m 35s) Loss avg.: 1.3853 Grad: 0.0082 LR: 0.00069  \n",
      "Epoch: [5][1800/5595] Elapsed 9m 58s (remain 21m 1s) Loss avg.: 1.3853 Grad: 0.0009 LR: 0.00069  \n",
      "Epoch: [5][1900/5595] Elapsed 10m 32s (remain 20m 28s) Loss avg.: 1.3853 Grad: 0.0019 LR: 0.00069  \n",
      "Epoch: [5][2000/5595] Elapsed 11m 5s (remain 19m 55s) Loss avg.: 1.3853 Grad: 0.0042 LR: 0.00069  \n",
      "Epoch: [5][2100/5595] Elapsed 11m 38s (remain 19m 22s) Loss avg.: 1.3853 Grad: 0.0018 LR: 0.00069  \n",
      "Epoch: [5][2200/5595] Elapsed 12m 12s (remain 18m 48s) Loss avg.: 1.3853 Grad: 0.0044 LR: 0.00069  \n",
      "Epoch: [5][2300/5595] Elapsed 12m 45s (remain 18m 15s) Loss avg.: 1.3853 Grad: 0.0032 LR: 0.00069  \n",
      "Epoch: [5][2400/5595] Elapsed 13m 18s (remain 17m 42s) Loss avg.: 1.3853 Grad: 0.0021 LR: 0.00069  \n",
      "Epoch: [5][2500/5595] Elapsed 13m 51s (remain 17m 9s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00069  \n",
      "Epoch: [5][2600/5595] Elapsed 14m 25s (remain 16m 35s) Loss avg.: 1.3853 Grad: 0.0069 LR: 0.00069  \n",
      "Epoch: [5][2700/5595] Elapsed 14m 58s (remain 16m 2s) Loss avg.: 1.3853 Grad: 0.0028 LR: 0.00069  \n",
      "Epoch: [5][2800/5595] Elapsed 15m 31s (remain 15m 29s) Loss avg.: 1.3853 Grad: 0.0062 LR: 0.00069  \n",
      "Epoch: [5][2900/5595] Elapsed 16m 5s (remain 14m 56s) Loss avg.: 1.3853 Grad: 0.0037 LR: 0.00069  \n",
      "Epoch: [5][3000/5595] Elapsed 16m 38s (remain 14m 22s) Loss avg.: 1.3853 Grad: 0.0023 LR: 0.00069  \n",
      "Epoch: [5][3100/5595] Elapsed 17m 11s (remain 13m 49s) Loss avg.: 1.3853 Grad: 0.0035 LR: 0.00069  \n",
      "Epoch: [5][3200/5595] Elapsed 17m 44s (remain 13m 16s) Loss avg.: 1.3853 Grad: 0.0018 LR: 0.00069  \n",
      "Epoch: [5][3300/5595] Elapsed 18m 18s (remain 12m 43s) Loss avg.: 1.3853 Grad: 0.0019 LR: 0.00069  \n",
      "Epoch: [5][3400/5595] Elapsed 18m 51s (remain 12m 9s) Loss avg.: 1.3853 Grad: 0.0025 LR: 0.00069  \n",
      "Epoch: [5][3500/5595] Elapsed 19m 24s (remain 11m 36s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00069  \n",
      "Epoch: [5][3600/5595] Elapsed 19m 58s (remain 11m 3s) Loss avg.: 1.3853 Grad: 0.0023 LR: 0.00069  \n",
      "Epoch: [5][3700/5595] Elapsed 20m 31s (remain 10m 30s) Loss avg.: 1.3853 Grad: 0.0061 LR: 0.00069  \n",
      "Epoch: [5][3800/5595] Elapsed 21m 4s (remain 9m 56s) Loss avg.: 1.3853 Grad: 0.0028 LR: 0.00069  \n",
      "Epoch: [5][3900/5595] Elapsed 21m 37s (remain 9m 23s) Loss avg.: 1.3853 Grad: 0.0016 LR: 0.00069  \n",
      "Epoch: [5][4000/5595] Elapsed 22m 11s (remain 8m 50s) Loss avg.: 1.3853 Grad: 0.0042 LR: 0.00069  \n",
      "Epoch: [5][4100/5595] Elapsed 22m 44s (remain 8m 17s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00069  \n",
      "Epoch: [5][4200/5595] Elapsed 23m 17s (remain 7m 43s) Loss avg.: 1.3853 Grad: 0.0007 LR: 0.00069  \n",
      "Epoch: [5][4300/5595] Elapsed 23m 51s (remain 7m 10s) Loss avg.: 1.3853 Grad: 0.0009 LR: 0.00069  \n",
      "Epoch: [5][4400/5595] Elapsed 24m 24s (remain 6m 37s) Loss avg.: 1.3853 Grad: 0.0078 LR: 0.00069  \n",
      "Epoch: [5][4500/5595] Elapsed 24m 57s (remain 6m 4s) Loss avg.: 1.3853 Grad: 0.0010 LR: 0.00069  \n",
      "Epoch: [5][4600/5595] Elapsed 25m 30s (remain 5m 30s) Loss avg.: 1.3853 Grad: 0.0031 LR: 0.00069  \n",
      "Epoch: [5][4700/5595] Elapsed 26m 4s (remain 4m 57s) Loss avg.: 1.3853 Grad: 0.0030 LR: 0.00069  \n",
      "Epoch: [5][4800/5595] Elapsed 26m 37s (remain 4m 24s) Loss avg.: 1.3853 Grad: 0.0023 LR: 0.00069  \n",
      "Epoch: [5][4900/5595] Elapsed 27m 10s (remain 3m 50s) Loss avg.: 1.3853 Grad: 0.0036 LR: 0.00069  \n",
      "Epoch: [5][5000/5595] Elapsed 27m 44s (remain 3m 17s) Loss avg.: 1.3853 Grad: 0.0027 LR: 0.00069  \n",
      "Epoch: [5][5100/5595] Elapsed 28m 17s (remain 2m 44s) Loss avg.: 1.3854 Grad: 0.0012 LR: 0.00069  \n",
      "Epoch: [5][5200/5595] Elapsed 28m 50s (remain 2m 11s) Loss avg.: 1.3854 Grad: 0.0006 LR: 0.00069  \n",
      "Epoch: [5][5300/5595] Elapsed 29m 24s (remain 1m 37s) Loss avg.: 1.3854 Grad: 0.0029 LR: 0.00069  \n",
      "Epoch: [5][5400/5595] Elapsed 29m 57s (remain 1m 4s) Loss avg.: 1.3854 Grad: 0.0035 LR: 0.00069  \n",
      "Epoch: [5][5500/5595] Elapsed 30m 30s (remain 0m 31s) Loss avg.: 1.3854 Grad: 0.0050 LR: 0.00069  \n",
      "Epoch: [5][5594/5595] Elapsed 31m 1s (remain 0m 0s) Loss avg.: 1.3853 Grad: 0.0036 LR: 0.00069  \n",
      "Eval: [0/622] Elapsed 0m 0s (remain 3m 30s) Loss avg.: 1.3847 \n",
      "Eval: [100/622] Elapsed 0m 12s (remain 1m 3s) Loss avg.: 1.3849 \n",
      "Eval: [200/622] Elapsed 0m 24s (remain 0m 51s) Loss avg.: 1.3852 \n",
      "Eval: [300/622] Elapsed 0m 36s (remain 0m 38s) Loss avg.: 1.3852 \n",
      "Eval: [400/622] Elapsed 0m 48s (remain 0m 26s) Loss avg.: 1.3853 \n",
      "Eval: [500/622] Elapsed 1m 0s (remain 0m 14s) Loss avg.: 1.3853 \n",
      "Eval: [600/622] Elapsed 1m 12s (remain 0m 2s) Loss avg.: 1.3854 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 1.3853  avg_val_loss: 1.3854  time: 1937s\n",
      "Epoch 5 - Accuracy: 0.26092012442460055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: [621/622] Elapsed 1m 14s (remain 0m 0s) Loss avg.: 1.3854 \n",
      "Epoch: [6][0/5595] Elapsed 0m 0s (remain 92m 46s) Loss avg.: 1.3846 Grad: 0.0009 LR: 0.00055  \n",
      "Epoch: [6][100/5595] Elapsed 0m 34s (remain 31m 3s) Loss avg.: 1.3851 Grad: 0.0036 LR: 0.00055  \n",
      "Epoch: [6][200/5595] Elapsed 1m 7s (remain 30m 6s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00055  \n",
      "Epoch: [6][300/5595] Elapsed 1m 40s (remain 29m 28s) Loss avg.: 1.3853 Grad: 0.0008 LR: 0.00055  \n",
      "Epoch: [6][400/5595] Elapsed 2m 13s (remain 28m 53s) Loss avg.: 1.3853 Grad: 0.0022 LR: 0.00055  \n",
      "Epoch: [6][500/5595] Elapsed 2m 47s (remain 28m 19s) Loss avg.: 1.3853 Grad: 0.0016 LR: 0.00055  \n",
      "Epoch: [6][600/5595] Elapsed 3m 20s (remain 27m 44s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00055  \n",
      "Epoch: [6][700/5595] Elapsed 3m 53s (remain 27m 10s) Loss avg.: 1.3853 Grad: 0.0021 LR: 0.00055  \n",
      "Epoch: [6][800/5595] Elapsed 4m 26s (remain 26m 37s) Loss avg.: 1.3853 Grad: 0.0021 LR: 0.00055  \n",
      "Epoch: [6][900/5595] Elapsed 5m 0s (remain 26m 3s) Loss avg.: 1.3854 Grad: 0.0027 LR: 0.00055  \n",
      "Epoch: [6][1000/5595] Elapsed 5m 33s (remain 25m 30s) Loss avg.: 1.3854 Grad: 0.0044 LR: 0.00055  \n",
      "Epoch: [6][1100/5595] Elapsed 6m 6s (remain 24m 56s) Loss avg.: 1.3854 Grad: 0.0046 LR: 0.00055  \n",
      "Epoch: [6][1200/5595] Elapsed 6m 39s (remain 24m 23s) Loss avg.: 1.3854 Grad: 0.0012 LR: 0.00055  \n",
      "Epoch: [6][1300/5595] Elapsed 7m 13s (remain 23m 49s) Loss avg.: 1.3854 Grad: 0.0024 LR: 0.00055  \n",
      "Epoch: [6][1400/5595] Elapsed 7m 46s (remain 23m 16s) Loss avg.: 1.3854 Grad: 0.0017 LR: 0.00055  \n",
      "Epoch: [6][1500/5595] Elapsed 8m 19s (remain 22m 43s) Loss avg.: 1.3854 Grad: 0.0012 LR: 0.00055  \n",
      "Epoch: [6][1600/5595] Elapsed 8m 53s (remain 22m 9s) Loss avg.: 1.3854 Grad: 0.0020 LR: 0.00055  \n",
      "Epoch: [6][1700/5595] Elapsed 9m 26s (remain 21m 36s) Loss avg.: 1.3854 Grad: 0.0031 LR: 0.00055  \n",
      "Epoch: [6][1800/5595] Elapsed 9m 59s (remain 21m 3s) Loss avg.: 1.3854 Grad: 0.0040 LR: 0.00055  \n",
      "Epoch: [6][1900/5595] Elapsed 10m 32s (remain 20m 29s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00055  \n",
      "Epoch: [6][2000/5595] Elapsed 11m 6s (remain 19m 56s) Loss avg.: 1.3853 Grad: 0.0049 LR: 0.00055  \n",
      "Epoch: [6][2100/5595] Elapsed 11m 39s (remain 19m 23s) Loss avg.: 1.3854 Grad: 0.0027 LR: 0.00055  \n",
      "Epoch: [6][2200/5595] Elapsed 12m 12s (remain 18m 49s) Loss avg.: 1.3853 Grad: 0.0069 LR: 0.00055  \n",
      "Epoch: [6][2300/5595] Elapsed 12m 45s (remain 18m 16s) Loss avg.: 1.3853 Grad: 0.0056 LR: 0.00055  \n",
      "Epoch: [6][2400/5595] Elapsed 13m 19s (remain 17m 43s) Loss avg.: 1.3853 Grad: 0.0022 LR: 0.00055  \n",
      "Epoch: [6][2500/5595] Elapsed 13m 52s (remain 17m 10s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00055  \n",
      "Epoch: [6][2600/5595] Elapsed 14m 25s (remain 16m 36s) Loss avg.: 1.3853 Grad: 0.0052 LR: 0.00055  \n",
      "Epoch: [6][2700/5595] Elapsed 14m 59s (remain 16m 3s) Loss avg.: 1.3853 Grad: 0.0057 LR: 0.00055  \n",
      "Epoch: [6][2800/5595] Elapsed 15m 32s (remain 15m 30s) Loss avg.: 1.3853 Grad: 0.0051 LR: 0.00055  \n",
      "Epoch: [6][2900/5595] Elapsed 16m 5s (remain 14m 56s) Loss avg.: 1.3853 Grad: 0.0007 LR: 0.00055  \n",
      "Epoch: [6][3000/5595] Elapsed 16m 39s (remain 14m 23s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00055  \n",
      "Epoch: [6][3100/5595] Elapsed 17m 12s (remain 13m 50s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00055  \n",
      "Epoch: [6][3200/5595] Elapsed 17m 45s (remain 13m 16s) Loss avg.: 1.3853 Grad: 0.0065 LR: 0.00055  \n",
      "Epoch: [6][3300/5595] Elapsed 18m 18s (remain 12m 43s) Loss avg.: 1.3853 Grad: 0.0013 LR: 0.00055  \n",
      "Epoch: [6][3400/5595] Elapsed 18m 52s (remain 12m 10s) Loss avg.: 1.3853 Grad: 0.0013 LR: 0.00055  \n",
      "Epoch: [6][3500/5595] Elapsed 19m 25s (remain 11m 37s) Loss avg.: 1.3853 Grad: 0.0024 LR: 0.00055  \n",
      "Epoch: [6][3600/5595] Elapsed 19m 58s (remain 11m 3s) Loss avg.: 1.3853 Grad: 0.0019 LR: 0.00055  \n",
      "Epoch: [6][3700/5595] Elapsed 20m 32s (remain 10m 30s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00055  \n",
      "Epoch: [6][3800/5595] Elapsed 21m 5s (remain 9m 57s) Loss avg.: 1.3853 Grad: 0.0050 LR: 0.00055  \n",
      "Epoch: [6][3900/5595] Elapsed 21m 38s (remain 9m 23s) Loss avg.: 1.3853 Grad: 0.0021 LR: 0.00055  \n",
      "Epoch: [6][4000/5595] Elapsed 22m 11s (remain 8m 50s) Loss avg.: 1.3853 Grad: 0.0030 LR: 0.00055  \n",
      "Epoch: [6][4100/5595] Elapsed 22m 45s (remain 8m 17s) Loss avg.: 1.3853 Grad: 0.0025 LR: 0.00055  \n",
      "Epoch: [6][4200/5595] Elapsed 23m 18s (remain 7m 44s) Loss avg.: 1.3853 Grad: 0.0019 LR: 0.00055  \n",
      "Epoch: [6][4300/5595] Elapsed 23m 51s (remain 7m 10s) Loss avg.: 1.3853 Grad: 0.0032 LR: 0.00055  \n",
      "Epoch: [6][4400/5595] Elapsed 24m 25s (remain 6m 37s) Loss avg.: 1.3853 Grad: 0.0039 LR: 0.00055  \n",
      "Epoch: [6][4500/5595] Elapsed 24m 58s (remain 6m 4s) Loss avg.: 1.3853 Grad: 0.0025 LR: 0.00055  \n",
      "Epoch: [6][4600/5595] Elapsed 25m 31s (remain 5m 30s) Loss avg.: 1.3853 Grad: 0.0038 LR: 0.00055  \n",
      "Epoch: [6][4700/5595] Elapsed 26m 4s (remain 4m 57s) Loss avg.: 1.3853 Grad: 0.0037 LR: 0.00055  \n",
      "Epoch: [6][4800/5595] Elapsed 26m 38s (remain 4m 24s) Loss avg.: 1.3853 Grad: 0.0011 LR: 0.00055  \n",
      "Epoch: [6][4900/5595] Elapsed 27m 11s (remain 3m 51s) Loss avg.: 1.3853 Grad: 0.0022 LR: 0.00055  \n",
      "Epoch: [6][5000/5595] Elapsed 27m 44s (remain 3m 17s) Loss avg.: 1.3853 Grad: 0.0064 LR: 0.00055  \n",
      "Epoch: [6][5100/5595] Elapsed 28m 18s (remain 2m 44s) Loss avg.: 1.3853 Grad: 0.0018 LR: 0.00055  \n",
      "Epoch: [6][5200/5595] Elapsed 28m 51s (remain 2m 11s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00055  \n",
      "Epoch: [6][5300/5595] Elapsed 29m 24s (remain 1m 37s) Loss avg.: 1.3853 Grad: 0.0032 LR: 0.00055  \n",
      "Epoch: [6][5400/5595] Elapsed 29m 58s (remain 1m 4s) Loss avg.: 1.3853 Grad: 0.0013 LR: 0.00055  \n",
      "Epoch: [6][5500/5595] Elapsed 30m 31s (remain 0m 31s) Loss avg.: 1.3853 Grad: 0.0035 LR: 0.00055  \n",
      "Epoch: [6][5594/5595] Elapsed 31m 2s (remain 0m 0s) Loss avg.: 1.3853 Grad: 0.0078 LR: 0.00055  \n",
      "Eval: [0/622] Elapsed 0m 0s (remain 3m 30s) Loss avg.: 1.3848 \n",
      "Eval: [100/622] Elapsed 0m 12s (remain 1m 3s) Loss avg.: 1.3849 \n",
      "Eval: [200/622] Elapsed 0m 24s (remain 0m 51s) Loss avg.: 1.3852 \n",
      "Eval: [300/622] Elapsed 0m 36s (remain 0m 38s) Loss avg.: 1.3852 \n",
      "Eval: [400/622] Elapsed 0m 48s (remain 0m 26s) Loss avg.: 1.3853 \n",
      "Eval: [500/622] Elapsed 1m 0s (remain 0m 14s) Loss avg.: 1.3853 \n",
      "Eval: [600/622] Elapsed 1m 12s (remain 0m 2s) Loss avg.: 1.3853 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 1.3853  avg_val_loss: 1.3853  time: 1938s\n",
      "Epoch 6 - Accuracy: 0.2609185160404155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: [621/622] Elapsed 1m 14s (remain 0m 0s) Loss avg.: 1.3853 \n",
      "Epoch: [7][0/5595] Elapsed 0m 0s (remain 92m 14s) Loss avg.: 1.3859 Grad: 0.0013 LR: 0.00041  \n",
      "Epoch: [7][100/5595] Elapsed 0m 34s (remain 30m 55s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00041  \n",
      "Epoch: [7][200/5595] Elapsed 1m 7s (remain 30m 5s) Loss avg.: 1.3854 Grad: 0.0047 LR: 0.00041  \n",
      "Epoch: [7][300/5595] Elapsed 1m 40s (remain 29m 27s) Loss avg.: 1.3854 Grad: 0.0008 LR: 0.00041  \n",
      "Epoch: [7][400/5595] Elapsed 2m 13s (remain 28m 51s) Loss avg.: 1.3854 Grad: 0.0050 LR: 0.00041  \n",
      "Epoch: [7][500/5595] Elapsed 2m 46s (remain 28m 16s) Loss avg.: 1.3854 Grad: 0.0024 LR: 0.00041  \n",
      "Epoch: [7][600/5595] Elapsed 3m 20s (remain 27m 41s) Loss avg.: 1.3854 Grad: 0.0026 LR: 0.00041  \n",
      "Epoch: [7][700/5595] Elapsed 3m 53s (remain 27m 8s) Loss avg.: 1.3853 Grad: 0.0028 LR: 0.00041  \n",
      "Epoch: [7][800/5595] Elapsed 4m 26s (remain 26m 34s) Loss avg.: 1.3854 Grad: 0.0015 LR: 0.00041  \n",
      "Epoch: [7][900/5595] Elapsed 4m 59s (remain 26m 1s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00041  \n",
      "Epoch: [7][1000/5595] Elapsed 5m 33s (remain 25m 28s) Loss avg.: 1.3853 Grad: 0.0032 LR: 0.00041  \n",
      "Epoch: [7][1100/5595] Elapsed 6m 6s (remain 24m 55s) Loss avg.: 1.3853 Grad: 0.0041 LR: 0.00041  \n",
      "Epoch: [7][1200/5595] Elapsed 6m 39s (remain 24m 22s) Loss avg.: 1.3853 Grad: 0.0035 LR: 0.00041  \n",
      "Epoch: [7][1300/5595] Elapsed 7m 12s (remain 23m 48s) Loss avg.: 1.3853 Grad: 0.0028 LR: 0.00041  \n",
      "Epoch: [7][1400/5595] Elapsed 7m 46s (remain 23m 15s) Loss avg.: 1.3853 Grad: 0.0007 LR: 0.00041  \n",
      "Epoch: [7][1500/5595] Elapsed 8m 19s (remain 22m 42s) Loss avg.: 1.3853 Grad: 0.0005 LR: 0.00041  \n",
      "Epoch: [7][1600/5595] Elapsed 8m 52s (remain 22m 8s) Loss avg.: 1.3853 Grad: 0.0023 LR: 0.00041  \n",
      "Epoch: [7][1700/5595] Elapsed 9m 25s (remain 21m 35s) Loss avg.: 1.3853 Grad: 0.0084 LR: 0.00041  \n",
      "Epoch: [7][1800/5595] Elapsed 9m 59s (remain 21m 2s) Loss avg.: 1.3853 Grad: 0.0014 LR: 0.00041  \n",
      "Epoch: [7][1900/5595] Elapsed 10m 32s (remain 20m 29s) Loss avg.: 1.3853 Grad: 0.0012 LR: 0.00041  \n",
      "Epoch: [7][2000/5595] Elapsed 11m 5s (remain 19m 55s) Loss avg.: 1.3853 Grad: 0.0015 LR: 0.00041  \n",
      "Epoch: [7][2100/5595] Elapsed 11m 39s (remain 19m 22s) Loss avg.: 1.3853 Grad: 0.0027 LR: 0.00041  \n",
      "Epoch: [7][2200/5595] Elapsed 12m 12s (remain 18m 49s) Loss avg.: 1.3853 Grad: 0.0032 LR: 0.00041  \n",
      "Epoch: [7][2300/5595] Elapsed 12m 45s (remain 18m 16s) Loss avg.: 1.3853 Grad: 0.0061 LR: 0.00041  \n",
      "Epoch: [7][2400/5595] Elapsed 13m 18s (remain 17m 42s) Loss avg.: 1.3853 Grad: 0.0021 LR: 0.00041  \n",
      "Epoch: [7][2500/5595] Elapsed 13m 52s (remain 17m 9s) Loss avg.: 1.3853 Grad: 0.0054 LR: 0.00041  \n",
      "Epoch: [7][2600/5595] Elapsed 14m 25s (remain 16m 36s) Loss avg.: 1.3853 Grad: 0.0018 LR: 0.00041  \n",
      "Epoch: [7][2700/5595] Elapsed 14m 58s (remain 16m 2s) Loss avg.: 1.3854 Grad: 0.0018 LR: 0.00041  \n",
      "Epoch: [7][2800/5595] Elapsed 15m 32s (remain 15m 29s) Loss avg.: 1.3854 Grad: 0.0022 LR: 0.00041  \n",
      "Epoch: [7][2900/5595] Elapsed 16m 5s (remain 14m 56s) Loss avg.: 1.3854 Grad: 0.0040 LR: 0.00041  \n",
      "Epoch: [7][3000/5595] Elapsed 16m 38s (remain 14m 23s) Loss avg.: 1.3854 Grad: 0.0021 LR: 0.00041  \n",
      "Epoch: [7][3100/5595] Elapsed 17m 11s (remain 13m 49s) Loss avg.: 1.3854 Grad: 0.0032 LR: 0.00041  \n",
      "Epoch: [7][3200/5595] Elapsed 17m 45s (remain 13m 16s) Loss avg.: 1.3854 Grad: 0.0054 LR: 0.00041  \n",
      "Epoch: [7][3300/5595] Elapsed 18m 18s (remain 12m 43s) Loss avg.: 1.3854 Grad: 0.0012 LR: 0.00041  \n",
      "Epoch: [7][3400/5595] Elapsed 18m 51s (remain 12m 10s) Loss avg.: 1.3854 Grad: 0.0018 LR: 0.00041  \n",
      "Epoch: [7][3500/5595] Elapsed 19m 24s (remain 11m 36s) Loss avg.: 1.3854 Grad: 0.0015 LR: 0.00041  \n",
      "Epoch: [7][3600/5595] Elapsed 19m 58s (remain 11m 3s) Loss avg.: 1.3854 Grad: 0.0012 LR: 0.00041  \n",
      "Epoch: [7][3700/5595] Elapsed 20m 31s (remain 10m 30s) Loss avg.: 1.3854 Grad: 0.0042 LR: 0.00041  \n",
      "Epoch: [7][3800/5595] Elapsed 21m 4s (remain 9m 56s) Loss avg.: 1.3854 Grad: 0.0072 LR: 0.00041  \n",
      "Epoch: [7][3900/5595] Elapsed 21m 37s (remain 9m 23s) Loss avg.: 1.3854 Grad: 0.0041 LR: 0.00041  \n",
      "Epoch: [7][4000/5595] Elapsed 22m 11s (remain 8m 50s) Loss avg.: 1.3854 Grad: 0.0032 LR: 0.00041  \n",
      "Epoch: [7][4100/5595] Elapsed 22m 44s (remain 8m 17s) Loss avg.: 1.3854 Grad: 0.0052 LR: 0.00041  \n",
      "Epoch: [7][4200/5595] Elapsed 23m 17s (remain 7m 43s) Loss avg.: 1.3853 Grad: 0.0041 LR: 0.00041  \n",
      "Epoch: [7][4300/5595] Elapsed 23m 51s (remain 7m 10s) Loss avg.: 1.3853 Grad: 0.0025 LR: 0.00041  \n",
      "Epoch: [7][4400/5595] Elapsed 24m 24s (remain 6m 37s) Loss avg.: 1.3853 Grad: 0.0016 LR: 0.00041  \n",
      "Epoch: [7][4500/5595] Elapsed 24m 57s (remain 6m 4s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00041  \n",
      "Epoch: [7][4600/5595] Elapsed 25m 30s (remain 5m 30s) Loss avg.: 1.3853 Grad: 0.0036 LR: 0.00041  \n",
      "Epoch: [7][4700/5595] Elapsed 26m 4s (remain 4m 57s) Loss avg.: 1.3853 Grad: 0.0043 LR: 0.00041  \n",
      "Epoch: [7][4800/5595] Elapsed 26m 37s (remain 4m 24s) Loss avg.: 1.3853 Grad: 0.0007 LR: 0.00041  \n",
      "Epoch: [7][4900/5595] Elapsed 27m 10s (remain 3m 50s) Loss avg.: 1.3853 Grad: 0.0018 LR: 0.00041  \n",
      "Epoch: [7][5000/5595] Elapsed 27m 44s (remain 3m 17s) Loss avg.: 1.3853 Grad: 0.0020 LR: 0.00041  \n",
      "Epoch: [7][5100/5595] Elapsed 28m 17s (remain 2m 44s) Loss avg.: 1.3853 Grad: 0.0045 LR: 0.00041  \n",
      "Epoch: [7][5200/5595] Elapsed 28m 50s (remain 2m 11s) Loss avg.: 1.3853 Grad: 0.0038 LR: 0.00041  \n",
      "Epoch: [7][5300/5595] Elapsed 29m 23s (remain 1m 37s) Loss avg.: 1.3853 Grad: 0.0074 LR: 0.00041  \n",
      "Epoch: [7][5400/5595] Elapsed 29m 57s (remain 1m 4s) Loss avg.: 1.3853 Grad: 0.0014 LR: 0.00041  \n",
      "Epoch: [7][5500/5595] Elapsed 30m 30s (remain 0m 31s) Loss avg.: 1.3853 Grad: 0.0034 LR: 0.00041  \n",
      "Epoch: [7][5594/5595] Elapsed 31m 1s (remain 0m 0s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00041  \n",
      "Eval: [0/622] Elapsed 0m 0s (remain 3m 31s) Loss avg.: 1.3848 \n",
      "Eval: [100/622] Elapsed 0m 12s (remain 1m 3s) Loss avg.: 1.3850 \n",
      "Eval: [200/622] Elapsed 0m 24s (remain 0m 51s) Loss avg.: 1.3852 \n",
      "Eval: [300/622] Elapsed 0m 36s (remain 0m 38s) Loss avg.: 1.3852 \n",
      "Eval: [400/622] Elapsed 0m 48s (remain 0m 26s) Loss avg.: 1.3853 \n",
      "Eval: [500/622] Elapsed 1m 0s (remain 0m 14s) Loss avg.: 1.3853 \n",
      "Eval: [600/622] Elapsed 1m 12s (remain 0m 2s) Loss avg.: 1.3853 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 1.3853  avg_val_loss: 1.3853  time: 1937s\n",
      "Epoch 7 - Accuracy: 0.26092012442460055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: [621/622] Elapsed 1m 14s (remain 0m 0s) Loss avg.: 1.3853 \n",
      "Epoch: [8][0/5595] Elapsed 0m 1s (remain 94m 49s) Loss avg.: 1.3829 Grad: 0.0037 LR: 0.00029  \n",
      "Epoch: [8][100/5595] Elapsed 0m 34s (remain 31m 2s) Loss avg.: 1.3853 Grad: 0.0022 LR: 0.00029  \n",
      "Epoch: [8][200/5595] Elapsed 1m 7s (remain 30m 11s) Loss avg.: 1.3854 Grad: 0.0031 LR: 0.00029  \n",
      "Epoch: [8][300/5595] Elapsed 1m 40s (remain 29m 32s) Loss avg.: 1.3854 Grad: 0.0011 LR: 0.00029  \n",
      "Epoch: [8][400/5595] Elapsed 2m 14s (remain 28m 56s) Loss avg.: 1.3854 Grad: 0.0030 LR: 0.00029  \n",
      "Epoch: [8][500/5595] Elapsed 2m 47s (remain 28m 21s) Loss avg.: 1.3853 Grad: 0.0032 LR: 0.00029  \n",
      "Epoch: [8][600/5595] Elapsed 3m 20s (remain 27m 47s) Loss avg.: 1.3853 Grad: 0.0035 LR: 0.00029  \n",
      "Epoch: [8][700/5595] Elapsed 3m 53s (remain 27m 12s) Loss avg.: 1.3853 Grad: 0.0034 LR: 0.00029  \n",
      "Epoch: [8][800/5595] Elapsed 4m 27s (remain 26m 38s) Loss avg.: 1.3853 Grad: 0.0058 LR: 0.00029  \n",
      "Epoch: [8][900/5595] Elapsed 5m 0s (remain 26m 5s) Loss avg.: 1.3853 Grad: 0.0013 LR: 0.00029  \n",
      "Epoch: [8][1000/5595] Elapsed 5m 33s (remain 25m 31s) Loss avg.: 1.3853 Grad: 0.0043 LR: 0.00029  \n",
      "Epoch: [8][1100/5595] Elapsed 6m 7s (remain 24m 58s) Loss avg.: 1.3853 Grad: 0.0008 LR: 0.00029  \n",
      "Epoch: [8][1200/5595] Elapsed 6m 40s (remain 24m 24s) Loss avg.: 1.3853 Grad: 0.0010 LR: 0.00029  \n",
      "Epoch: [8][1300/5595] Elapsed 7m 13s (remain 23m 51s) Loss avg.: 1.3853 Grad: 0.0057 LR: 0.00029  \n",
      "Epoch: [8][1400/5595] Elapsed 7m 46s (remain 23m 17s) Loss avg.: 1.3853 Grad: 0.0018 LR: 0.00029  \n",
      "Epoch: [8][1500/5595] Elapsed 8m 20s (remain 22m 44s) Loss avg.: 1.3853 Grad: 0.0030 LR: 0.00029  \n",
      "Epoch: [8][1600/5595] Elapsed 8m 53s (remain 22m 10s) Loss avg.: 1.3853 Grad: 0.0019 LR: 0.00029  \n",
      "Epoch: [8][1700/5595] Elapsed 9m 26s (remain 21m 37s) Loss avg.: 1.3853 Grad: 0.0070 LR: 0.00029  \n",
      "Epoch: [8][1800/5595] Elapsed 9m 59s (remain 21m 3s) Loss avg.: 1.3853 Grad: 0.0032 LR: 0.00029  \n",
      "Epoch: [8][1900/5595] Elapsed 10m 33s (remain 20m 30s) Loss avg.: 1.3853 Grad: 0.0049 LR: 0.00029  \n",
      "Epoch: [8][2000/5595] Elapsed 11m 6s (remain 19m 56s) Loss avg.: 1.3853 Grad: 0.0024 LR: 0.00029  \n",
      "Epoch: [8][2100/5595] Elapsed 11m 39s (remain 19m 23s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00029  \n",
      "Epoch: [8][2200/5595] Elapsed 12m 13s (remain 18m 50s) Loss avg.: 1.3853 Grad: 0.0033 LR: 0.00029  \n",
      "Epoch: [8][2300/5595] Elapsed 12m 46s (remain 18m 17s) Loss avg.: 1.3853 Grad: 0.0019 LR: 0.00029  \n",
      "Epoch: [8][2400/5595] Elapsed 13m 19s (remain 17m 43s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00029  \n",
      "Epoch: [8][2500/5595] Elapsed 13m 52s (remain 17m 10s) Loss avg.: 1.3853 Grad: 0.0022 LR: 0.00029  \n",
      "Epoch: [8][2600/5595] Elapsed 14m 25s (remain 16m 36s) Loss avg.: 1.3853 Grad: 0.0052 LR: 0.00029  \n",
      "Epoch: [8][2700/5595] Elapsed 14m 59s (remain 16m 3s) Loss avg.: 1.3853 Grad: 0.0018 LR: 0.00029  \n",
      "Epoch: [8][2800/5595] Elapsed 15m 32s (remain 15m 30s) Loss avg.: 1.3853 Grad: 0.0016 LR: 0.00029  \n",
      "Epoch: [8][2900/5595] Elapsed 16m 5s (remain 14m 56s) Loss avg.: 1.3853 Grad: 0.0016 LR: 0.00029  \n",
      "Epoch: [8][3000/5595] Elapsed 16m 39s (remain 14m 23s) Loss avg.: 1.3853 Grad: 0.0014 LR: 0.00029  \n",
      "Epoch: [8][3100/5595] Elapsed 17m 12s (remain 13m 50s) Loss avg.: 1.3853 Grad: 0.0020 LR: 0.00029  \n",
      "Epoch: [8][3200/5595] Elapsed 17m 45s (remain 13m 16s) Loss avg.: 1.3853 Grad: 0.0015 LR: 0.00029  \n",
      "Epoch: [8][3300/5595] Elapsed 18m 18s (remain 12m 43s) Loss avg.: 1.3853 Grad: 0.0042 LR: 0.00029  \n",
      "Epoch: [8][3400/5595] Elapsed 18m 52s (remain 12m 10s) Loss avg.: 1.3853 Grad: 0.0025 LR: 0.00029  \n",
      "Epoch: [8][3500/5595] Elapsed 19m 25s (remain 11m 37s) Loss avg.: 1.3853 Grad: 0.0029 LR: 0.00029  \n",
      "Epoch: [8][3600/5595] Elapsed 19m 58s (remain 11m 3s) Loss avg.: 1.3853 Grad: 0.0018 LR: 0.00029  \n",
      "Epoch: [8][3700/5595] Elapsed 20m 32s (remain 10m 30s) Loss avg.: 1.3853 Grad: 0.0028 LR: 0.00029  \n",
      "Epoch: [8][3800/5595] Elapsed 21m 5s (remain 9m 57s) Loss avg.: 1.3853 Grad: 0.0032 LR: 0.00029  \n",
      "Epoch: [8][3900/5595] Elapsed 21m 38s (remain 9m 23s) Loss avg.: 1.3853 Grad: 0.0004 LR: 0.00029  \n",
      "Epoch: [8][4000/5595] Elapsed 22m 11s (remain 8m 50s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00029  \n",
      "Epoch: [8][4100/5595] Elapsed 22m 45s (remain 8m 17s) Loss avg.: 1.3853 Grad: 0.0033 LR: 0.00029  \n",
      "Epoch: [8][4200/5595] Elapsed 23m 18s (remain 7m 44s) Loss avg.: 1.3853 Grad: 0.0009 LR: 0.00029  \n",
      "Epoch: [8][4300/5595] Elapsed 23m 51s (remain 7m 10s) Loss avg.: 1.3853 Grad: 0.0018 LR: 0.00029  \n",
      "Epoch: [8][4400/5595] Elapsed 24m 25s (remain 6m 37s) Loss avg.: 1.3853 Grad: 0.0052 LR: 0.00029  \n",
      "Epoch: [8][4500/5595] Elapsed 24m 58s (remain 6m 4s) Loss avg.: 1.3853 Grad: 0.0043 LR: 0.00029  \n",
      "Epoch: [8][4600/5595] Elapsed 25m 31s (remain 5m 30s) Loss avg.: 1.3853 Grad: 0.0061 LR: 0.00029  \n",
      "Epoch: [8][4700/5595] Elapsed 26m 4s (remain 4m 57s) Loss avg.: 1.3853 Grad: 0.0040 LR: 0.00029  \n",
      "Epoch: [8][4800/5595] Elapsed 26m 38s (remain 4m 24s) Loss avg.: 1.3853 Grad: 0.0013 LR: 0.00029  \n",
      "Epoch: [8][4900/5595] Elapsed 27m 11s (remain 3m 51s) Loss avg.: 1.3853 Grad: 0.0012 LR: 0.00029  \n",
      "Epoch: [8][5000/5595] Elapsed 27m 44s (remain 3m 17s) Loss avg.: 1.3853 Grad: 0.0031 LR: 0.00029  \n",
      "Epoch: [8][5100/5595] Elapsed 28m 18s (remain 2m 44s) Loss avg.: 1.3853 Grad: 0.0024 LR: 0.00029  \n",
      "Epoch: [8][5200/5595] Elapsed 28m 51s (remain 2m 11s) Loss avg.: 1.3853 Grad: 0.0035 LR: 0.00029  \n",
      "Epoch: [8][5300/5595] Elapsed 29m 24s (remain 1m 37s) Loss avg.: 1.3853 Grad: 0.0006 LR: 0.00029  \n",
      "Epoch: [8][5400/5595] Elapsed 29m 57s (remain 1m 4s) Loss avg.: 1.3853 Grad: 0.0018 LR: 0.00029  \n",
      "Epoch: [8][5500/5595] Elapsed 30m 31s (remain 0m 31s) Loss avg.: 1.3853 Grad: 0.0029 LR: 0.00029  \n",
      "Epoch: [8][5594/5595] Elapsed 31m 2s (remain 0m 0s) Loss avg.: 1.3853 Grad: 0.0069 LR: 0.00029  \n",
      "Eval: [0/622] Elapsed 0m 0s (remain 3m 32s) Loss avg.: 1.3848 \n",
      "Eval: [100/622] Elapsed 0m 12s (remain 1m 3s) Loss avg.: 1.3849 \n",
      "Eval: [200/622] Elapsed 0m 24s (remain 0m 51s) Loss avg.: 1.3851 \n",
      "Eval: [300/622] Elapsed 0m 36s (remain 0m 38s) Loss avg.: 1.3852 \n",
      "Eval: [400/622] Elapsed 0m 48s (remain 0m 26s) Loss avg.: 1.3853 \n",
      "Eval: [500/622] Elapsed 1m 0s (remain 0m 14s) Loss avg.: 1.3853 \n",
      "Eval: [600/622] Elapsed 1m 12s (remain 0m 2s) Loss avg.: 1.3853 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 1.3853  avg_val_loss: 1.3853  time: 1938s\n",
      "Epoch 8 - Accuracy: 0.2609185160404155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: [621/622] Elapsed 1m 15s (remain 0m 0s) Loss avg.: 1.3853 \n",
      "Epoch: [9][0/5595] Elapsed 0m 0s (remain 90m 34s) Loss avg.: 1.3910 Grad: 0.0085 LR: 0.00019  \n",
      "Epoch: [9][100/5595] Elapsed 0m 34s (remain 30m 56s) Loss avg.: 1.3855 Grad: 0.0022 LR: 0.00019  \n",
      "Epoch: [9][200/5595] Elapsed 1m 7s (remain 30m 6s) Loss avg.: 1.3855 Grad: 0.0051 LR: 0.00019  \n",
      "Epoch: [9][300/5595] Elapsed 1m 40s (remain 29m 28s) Loss avg.: 1.3854 Grad: 0.0025 LR: 0.00019  \n",
      "Epoch: [9][400/5595] Elapsed 2m 13s (remain 28m 52s) Loss avg.: 1.3854 Grad: 0.0022 LR: 0.00019  \n",
      "Epoch: [9][500/5595] Elapsed 2m 46s (remain 28m 17s) Loss avg.: 1.3854 Grad: 0.0051 LR: 0.00019  \n",
      "Epoch: [9][600/5595] Elapsed 3m 20s (remain 27m 43s) Loss avg.: 1.3854 Grad: 0.0011 LR: 0.00019  \n",
      "Epoch: [9][700/5595] Elapsed 3m 53s (remain 27m 10s) Loss avg.: 1.3853 Grad: 0.0031 LR: 0.00019  \n",
      "Epoch: [9][800/5595] Elapsed 4m 26s (remain 26m 36s) Loss avg.: 1.3854 Grad: 0.0040 LR: 0.00019  \n",
      "Epoch: [9][900/5595] Elapsed 5m 0s (remain 26m 3s) Loss avg.: 1.3854 Grad: 0.0027 LR: 0.00019  \n",
      "Epoch: [9][1000/5595] Elapsed 5m 33s (remain 25m 30s) Loss avg.: 1.3854 Grad: 0.0040 LR: 0.00019  \n",
      "Epoch: [9][1100/5595] Elapsed 6m 6s (remain 24m 56s) Loss avg.: 1.3853 Grad: 0.0015 LR: 0.00019  \n",
      "Epoch: [9][1200/5595] Elapsed 6m 39s (remain 24m 23s) Loss avg.: 1.3854 Grad: 0.0053 LR: 0.00019  \n",
      "Epoch: [9][1300/5595] Elapsed 7m 13s (remain 23m 49s) Loss avg.: 1.3853 Grad: 0.0022 LR: 0.00019  \n",
      "Epoch: [9][1400/5595] Elapsed 7m 46s (remain 23m 16s) Loss avg.: 1.3853 Grad: 0.0065 LR: 0.00019  \n",
      "Epoch: [9][1500/5595] Elapsed 8m 19s (remain 22m 42s) Loss avg.: 1.3853 Grad: 0.0041 LR: 0.00019  \n",
      "Epoch: [9][1600/5595] Elapsed 8m 53s (remain 22m 9s) Loss avg.: 1.3853 Grad: 0.0025 LR: 0.00019  \n",
      "Epoch: [9][1700/5595] Elapsed 9m 26s (remain 21m 36s) Loss avg.: 1.3853 Grad: 0.0012 LR: 0.00019  \n",
      "Epoch: [9][1800/5595] Elapsed 9m 59s (remain 21m 3s) Loss avg.: 1.3853 Grad: 0.0013 LR: 0.00019  \n",
      "Epoch: [9][1900/5595] Elapsed 10m 32s (remain 20m 29s) Loss avg.: 1.3853 Grad: 0.0033 LR: 0.00019  \n",
      "Epoch: [9][2000/5595] Elapsed 11m 6s (remain 19m 56s) Loss avg.: 1.3853 Grad: 0.0045 LR: 0.00019  \n",
      "Epoch: [9][2100/5595] Elapsed 11m 39s (remain 19m 23s) Loss avg.: 1.3853 Grad: 0.0027 LR: 0.00019  \n",
      "Epoch: [9][2200/5595] Elapsed 12m 12s (remain 18m 49s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00019  \n",
      "Epoch: [9][2300/5595] Elapsed 12m 45s (remain 18m 16s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00019  \n",
      "Epoch: [9][2400/5595] Elapsed 13m 19s (remain 17m 43s) Loss avg.: 1.3853 Grad: 0.0010 LR: 0.00019  \n",
      "Epoch: [9][2500/5595] Elapsed 13m 52s (remain 17m 9s) Loss avg.: 1.3853 Grad: 0.0012 LR: 0.00019  \n",
      "Epoch: [9][2600/5595] Elapsed 14m 25s (remain 16m 36s) Loss avg.: 1.3853 Grad: 0.0065 LR: 0.00019  \n",
      "Epoch: [9][2700/5595] Elapsed 14m 58s (remain 16m 3s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00019  \n",
      "Epoch: [9][2800/5595] Elapsed 15m 32s (remain 15m 29s) Loss avg.: 1.3853 Grad: 0.0022 LR: 0.00019  \n",
      "Epoch: [9][2900/5595] Elapsed 16m 5s (remain 14m 56s) Loss avg.: 1.3853 Grad: 0.0030 LR: 0.00019  \n",
      "Epoch: [9][3000/5595] Elapsed 16m 38s (remain 14m 23s) Loss avg.: 1.3853 Grad: 0.0016 LR: 0.00019  \n",
      "Epoch: [9][3100/5595] Elapsed 17m 12s (remain 13m 50s) Loss avg.: 1.3853 Grad: 0.0038 LR: 0.00019  \n",
      "Epoch: [9][3200/5595] Elapsed 17m 45s (remain 13m 16s) Loss avg.: 1.3853 Grad: 0.0042 LR: 0.00019  \n",
      "Epoch: [9][3300/5595] Elapsed 18m 18s (remain 12m 43s) Loss avg.: 1.3853 Grad: 0.0027 LR: 0.00019  \n",
      "Epoch: [9][3400/5595] Elapsed 18m 51s (remain 12m 10s) Loss avg.: 1.3853 Grad: 0.0029 LR: 0.00019  \n",
      "Epoch: [9][3500/5595] Elapsed 19m 25s (remain 11m 36s) Loss avg.: 1.3853 Grad: 0.0044 LR: 0.00019  \n",
      "Epoch: [9][3600/5595] Elapsed 19m 58s (remain 11m 3s) Loss avg.: 1.3853 Grad: 0.0021 LR: 0.00019  \n",
      "Epoch: [9][3700/5595] Elapsed 20m 31s (remain 10m 30s) Loss avg.: 1.3853 Grad: 0.0014 LR: 0.00019  \n",
      "Epoch: [9][3800/5595] Elapsed 21m 4s (remain 9m 56s) Loss avg.: 1.3853 Grad: 0.0067 LR: 0.00019  \n",
      "Epoch: [9][3900/5595] Elapsed 21m 38s (remain 9m 23s) Loss avg.: 1.3853 Grad: 0.0016 LR: 0.00019  \n",
      "Epoch: [9][4000/5595] Elapsed 22m 11s (remain 8m 50s) Loss avg.: 1.3853 Grad: 0.0027 LR: 0.00019  \n",
      "Epoch: [9][4100/5595] Elapsed 22m 44s (remain 8m 17s) Loss avg.: 1.3853 Grad: 0.0023 LR: 0.00019  \n",
      "Epoch: [9][4200/5595] Elapsed 23m 17s (remain 7m 43s) Loss avg.: 1.3853 Grad: 0.0024 LR: 0.00019  \n",
      "Epoch: [9][4300/5595] Elapsed 23m 51s (remain 7m 10s) Loss avg.: 1.3853 Grad: 0.0016 LR: 0.00019  \n",
      "Epoch: [9][4400/5595] Elapsed 24m 24s (remain 6m 37s) Loss avg.: 1.3853 Grad: 0.0011 LR: 0.00019  \n",
      "Epoch: [9][4500/5595] Elapsed 24m 57s (remain 6m 3s) Loss avg.: 1.3853 Grad: 0.0019 LR: 0.00019  \n",
      "Epoch: [9][4600/5595] Elapsed 25m 30s (remain 5m 30s) Loss avg.: 1.3853 Grad: 0.0050 LR: 0.00019  \n",
      "Epoch: [9][4700/5595] Elapsed 26m 4s (remain 4m 57s) Loss avg.: 1.3853 Grad: 0.0040 LR: 0.00019  \n",
      "Epoch: [9][4800/5595] Elapsed 26m 37s (remain 4m 24s) Loss avg.: 1.3853 Grad: 0.0015 LR: 0.00019  \n",
      "Epoch: [9][4900/5595] Elapsed 27m 10s (remain 3m 50s) Loss avg.: 1.3853 Grad: 0.0041 LR: 0.00019  \n",
      "Epoch: [9][5000/5595] Elapsed 27m 43s (remain 3m 17s) Loss avg.: 1.3853 Grad: 0.0044 LR: 0.00019  \n",
      "Epoch: [9][5100/5595] Elapsed 28m 17s (remain 2m 44s) Loss avg.: 1.3853 Grad: 0.0038 LR: 0.00019  \n",
      "Epoch: [9][5200/5595] Elapsed 28m 50s (remain 2m 11s) Loss avg.: 1.3853 Grad: 0.0023 LR: 0.00019  \n",
      "Epoch: [9][5300/5595] Elapsed 29m 23s (remain 1m 37s) Loss avg.: 1.3853 Grad: 0.0093 LR: 0.00019  \n",
      "Epoch: [9][5400/5595] Elapsed 29m 56s (remain 1m 4s) Loss avg.: 1.3853 Grad: 0.0024 LR: 0.00019  \n",
      "Epoch: [9][5500/5595] Elapsed 30m 30s (remain 0m 31s) Loss avg.: 1.3853 Grad: 0.0049 LR: 0.00019  \n",
      "Epoch: [9][5594/5595] Elapsed 31m 1s (remain 0m 0s) Loss avg.: 1.3853 Grad: 0.0031 LR: 0.00019  \n",
      "Eval: [0/622] Elapsed 0m 0s (remain 3m 33s) Loss avg.: 1.3849 \n",
      "Eval: [100/622] Elapsed 0m 12s (remain 1m 3s) Loss avg.: 1.3850 \n",
      "Eval: [200/622] Elapsed 0m 24s (remain 0m 51s) Loss avg.: 1.3852 \n",
      "Eval: [300/622] Elapsed 0m 36s (remain 0m 38s) Loss avg.: 1.3852 \n",
      "Eval: [400/622] Elapsed 0m 48s (remain 0m 26s) Loss avg.: 1.3853 \n",
      "Eval: [500/622] Elapsed 1m 0s (remain 0m 14s) Loss avg.: 1.3853 \n",
      "Eval: [600/622] Elapsed 1m 12s (remain 0m 2s) Loss avg.: 1.3853 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 1.3853  avg_val_loss: 1.3853  time: 1937s\n",
      "Epoch 9 - Accuracy: 0.26092012442460055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: [621/622] Elapsed 1m 14s (remain 0m 0s) Loss avg.: 1.3853 \n",
      "Epoch: [10][0/5595] Elapsed 0m 0s (remain 90m 59s) Loss avg.: 1.3854 Grad: 0.0008 LR: 0.00012  \n",
      "Epoch: [10][100/5595] Elapsed 0m 34s (remain 30m 57s) Loss avg.: 1.3852 Grad: 0.0020 LR: 0.00012  \n",
      "Epoch: [10][200/5595] Elapsed 1m 7s (remain 30m 7s) Loss avg.: 1.3851 Grad: 0.0035 LR: 0.00012  \n",
      "Epoch: [10][300/5595] Elapsed 1m 40s (remain 29m 26s) Loss avg.: 1.3852 Grad: 0.0015 LR: 0.00012  \n",
      "Epoch: [10][400/5595] Elapsed 2m 13s (remain 28m 50s) Loss avg.: 1.3852 Grad: 0.0020 LR: 0.00012  \n",
      "Epoch: [10][500/5595] Elapsed 2m 46s (remain 28m 16s) Loss avg.: 1.3852 Grad: 0.0080 LR: 0.00012  \n",
      "Epoch: [10][600/5595] Elapsed 3m 20s (remain 27m 42s) Loss avg.: 1.3852 Grad: 0.0041 LR: 0.00012  \n",
      "Epoch: [10][700/5595] Elapsed 3m 53s (remain 27m 9s) Loss avg.: 1.3853 Grad: 0.0014 LR: 0.00012  \n",
      "Epoch: [10][800/5595] Elapsed 4m 26s (remain 26m 36s) Loss avg.: 1.3853 Grad: 0.0037 LR: 0.00012  \n",
      "Epoch: [10][900/5595] Elapsed 4m 59s (remain 26m 2s) Loss avg.: 1.3853 Grad: 0.0016 LR: 0.00012  \n",
      "Epoch: [10][1000/5595] Elapsed 5m 33s (remain 25m 29s) Loss avg.: 1.3853 Grad: 0.0050 LR: 0.00012  \n",
      "Epoch: [10][1100/5595] Elapsed 6m 6s (remain 24m 56s) Loss avg.: 1.3853 Grad: 0.0028 LR: 0.00012  \n",
      "Epoch: [10][1200/5595] Elapsed 6m 39s (remain 24m 22s) Loss avg.: 1.3854 Grad: 0.0017 LR: 0.00012  \n",
      "Epoch: [10][1300/5595] Elapsed 7m 13s (remain 23m 49s) Loss avg.: 1.3853 Grad: 0.0020 LR: 0.00012  \n",
      "Epoch: [10][1400/5595] Elapsed 7m 46s (remain 23m 15s) Loss avg.: 1.3854 Grad: 0.0030 LR: 0.00012  \n",
      "Epoch: [10][1500/5595] Elapsed 8m 19s (remain 22m 42s) Loss avg.: 1.3854 Grad: 0.0021 LR: 0.00012  \n",
      "Epoch: [10][1600/5595] Elapsed 8m 52s (remain 22m 9s) Loss avg.: 1.3854 Grad: 0.0015 LR: 0.00012  \n",
      "Epoch: [10][1700/5595] Elapsed 9m 26s (remain 21m 35s) Loss avg.: 1.3854 Grad: 0.0056 LR: 0.00012  \n",
      "Epoch: [10][1800/5595] Elapsed 9m 59s (remain 21m 2s) Loss avg.: 1.3854 Grad: 0.0010 LR: 0.00012  \n",
      "Epoch: [10][1900/5595] Elapsed 10m 32s (remain 20m 29s) Loss avg.: 1.3854 Grad: 0.0036 LR: 0.00012  \n",
      "Epoch: [10][2000/5595] Elapsed 11m 5s (remain 19m 55s) Loss avg.: 1.3854 Grad: 0.0046 LR: 0.00012  \n",
      "Epoch: [10][2100/5595] Elapsed 11m 39s (remain 19m 22s) Loss avg.: 1.3854 Grad: 0.0006 LR: 0.00012  \n",
      "Epoch: [10][2200/5595] Elapsed 12m 12s (remain 18m 49s) Loss avg.: 1.3854 Grad: 0.0042 LR: 0.00012  \n",
      "Epoch: [10][2300/5595] Elapsed 12m 45s (remain 18m 15s) Loss avg.: 1.3854 Grad: 0.0031 LR: 0.00012  \n",
      "Epoch: [10][2400/5595] Elapsed 13m 18s (remain 17m 42s) Loss avg.: 1.3854 Grad: 0.0034 LR: 0.00012  \n",
      "Epoch: [10][2500/5595] Elapsed 13m 52s (remain 17m 9s) Loss avg.: 1.3853 Grad: 0.0048 LR: 0.00012  \n",
      "Epoch: [10][2600/5595] Elapsed 14m 25s (remain 16m 36s) Loss avg.: 1.3853 Grad: 0.0062 LR: 0.00012  \n",
      "Epoch: [10][2700/5595] Elapsed 14m 58s (remain 16m 2s) Loss avg.: 1.3853 Grad: 0.0027 LR: 0.00012  \n",
      "Epoch: [10][2800/5595] Elapsed 15m 31s (remain 15m 29s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00012  \n",
      "Epoch: [10][2900/5595] Elapsed 16m 5s (remain 14m 56s) Loss avg.: 1.3853 Grad: 0.0022 LR: 0.00012  \n",
      "Epoch: [10][3000/5595] Elapsed 16m 38s (remain 14m 22s) Loss avg.: 1.3853 Grad: 0.0037 LR: 0.00012  \n",
      "Epoch: [10][3100/5595] Elapsed 17m 11s (remain 13m 49s) Loss avg.: 1.3854 Grad: 0.0019 LR: 0.00012  \n",
      "Epoch: [10][3200/5595] Elapsed 17m 44s (remain 13m 16s) Loss avg.: 1.3854 Grad: 0.0037 LR: 0.00012  \n",
      "Epoch: [10][3300/5595] Elapsed 18m 18s (remain 12m 43s) Loss avg.: 1.3854 Grad: 0.0019 LR: 0.00012  \n",
      "Epoch: [10][3400/5595] Elapsed 18m 51s (remain 12m 9s) Loss avg.: 1.3854 Grad: 0.0028 LR: 0.00012  \n",
      "Epoch: [10][3500/5595] Elapsed 19m 24s (remain 11m 36s) Loss avg.: 1.3854 Grad: 0.0027 LR: 0.00012  \n",
      "Epoch: [10][3600/5595] Elapsed 19m 57s (remain 11m 3s) Loss avg.: 1.3854 Grad: 0.0019 LR: 0.00012  \n",
      "Epoch: [10][3700/5595] Elapsed 20m 31s (remain 10m 30s) Loss avg.: 1.3854 Grad: 0.0009 LR: 0.00012  \n",
      "Epoch: [10][3800/5595] Elapsed 21m 4s (remain 9m 56s) Loss avg.: 1.3854 Grad: 0.0012 LR: 0.00012  \n",
      "Epoch: [10][3900/5595] Elapsed 21m 37s (remain 9m 23s) Loss avg.: 1.3854 Grad: 0.0025 LR: 0.00012  \n",
      "Epoch: [10][4000/5595] Elapsed 22m 10s (remain 8m 50s) Loss avg.: 1.3854 Grad: 0.0028 LR: 0.00012  \n",
      "Epoch: [10][4100/5595] Elapsed 22m 44s (remain 8m 16s) Loss avg.: 1.3854 Grad: 0.0010 LR: 0.00012  \n",
      "Epoch: [10][4200/5595] Elapsed 23m 17s (remain 7m 43s) Loss avg.: 1.3854 Grad: 0.0032 LR: 0.00012  \n",
      "Epoch: [10][4300/5595] Elapsed 23m 50s (remain 7m 10s) Loss avg.: 1.3854 Grad: 0.0017 LR: 0.00012  \n",
      "Epoch: [10][4400/5595] Elapsed 24m 23s (remain 6m 37s) Loss avg.: 1.3854 Grad: 0.0028 LR: 0.00012  \n",
      "Epoch: [10][4500/5595] Elapsed 24m 57s (remain 6m 3s) Loss avg.: 1.3854 Grad: 0.0014 LR: 0.00012  \n",
      "Epoch: [10][4600/5595] Elapsed 25m 30s (remain 5m 30s) Loss avg.: 1.3854 Grad: 0.0030 LR: 0.00012  \n",
      "Epoch: [10][4700/5595] Elapsed 26m 3s (remain 4m 57s) Loss avg.: 1.3854 Grad: 0.0026 LR: 0.00012  \n",
      "Epoch: [10][4800/5595] Elapsed 26m 36s (remain 4m 24s) Loss avg.: 1.3854 Grad: 0.0024 LR: 0.00012  \n",
      "Epoch: [10][4900/5595] Elapsed 27m 10s (remain 3m 50s) Loss avg.: 1.3854 Grad: 0.0035 LR: 0.00012  \n",
      "Epoch: [10][5000/5595] Elapsed 27m 43s (remain 3m 17s) Loss avg.: 1.3853 Grad: 0.0038 LR: 0.00012  \n",
      "Epoch: [10][5100/5595] Elapsed 28m 16s (remain 2m 44s) Loss avg.: 1.3853 Grad: 0.0011 LR: 0.00012  \n",
      "Epoch: [10][5200/5595] Elapsed 28m 49s (remain 2m 11s) Loss avg.: 1.3853 Grad: 0.0031 LR: 0.00012  \n",
      "Epoch: [10][5300/5595] Elapsed 29m 23s (remain 1m 37s) Loss avg.: 1.3853 Grad: 0.0041 LR: 0.00012  \n",
      "Epoch: [10][5400/5595] Elapsed 29m 56s (remain 1m 4s) Loss avg.: 1.3853 Grad: 0.0009 LR: 0.00012  \n",
      "Epoch: [10][5500/5595] Elapsed 30m 29s (remain 0m 31s) Loss avg.: 1.3853 Grad: 0.0011 LR: 0.00012  \n",
      "Epoch: [10][5594/5595] Elapsed 31m 1s (remain 0m 0s) Loss avg.: 1.3853 Grad: 0.0053 LR: 0.00012  \n",
      "Eval: [0/622] Elapsed 0m 0s (remain 3m 36s) Loss avg.: 1.3848 \n",
      "Eval: [100/622] Elapsed 0m 12s (remain 1m 3s) Loss avg.: 1.3849 \n",
      "Eval: [200/622] Elapsed 0m 24s (remain 0m 51s) Loss avg.: 1.3852 \n",
      "Eval: [300/622] Elapsed 0m 36s (remain 0m 38s) Loss avg.: 1.3852 \n",
      "Eval: [400/622] Elapsed 0m 48s (remain 0m 26s) Loss avg.: 1.3853 \n",
      "Eval: [500/622] Elapsed 1m 0s (remain 0m 14s) Loss avg.: 1.3853 \n",
      "Eval: [600/622] Elapsed 1m 12s (remain 0m 2s) Loss avg.: 1.3853 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 1.3853  avg_val_loss: 1.3853  time: 1936s\n",
      "Epoch 10 - Accuracy: 0.2609185160404155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: [621/622] Elapsed 1m 14s (remain 0m 0s) Loss avg.: 1.3853 \n",
      "Epoch: [11][0/5595] Elapsed 0m 0s (remain 91m 0s) Loss avg.: 1.3874 Grad: 0.0031 LR: 0.00100  \n",
      "Epoch: [11][100/5595] Elapsed 0m 34s (remain 30m 50s) Loss avg.: 1.3855 Grad: 0.0038 LR: 0.00100  \n",
      "Epoch: [11][200/5595] Elapsed 1m 7s (remain 30m 5s) Loss avg.: 1.3854 Grad: 0.0019 LR: 0.00100  \n",
      "Epoch: [11][300/5595] Elapsed 1m 40s (remain 29m 28s) Loss avg.: 1.3854 Grad: 0.0022 LR: 0.00100  \n",
      "Epoch: [11][400/5595] Elapsed 2m 13s (remain 28m 53s) Loss avg.: 1.3853 Grad: 0.0037 LR: 0.00100  \n",
      "Epoch: [11][500/5595] Elapsed 2m 47s (remain 28m 18s) Loss avg.: 1.3853 Grad: 0.0039 LR: 0.00100  \n",
      "Epoch: [11][600/5595] Elapsed 3m 20s (remain 27m 44s) Loss avg.: 1.3853 Grad: 0.0030 LR: 0.00100  \n",
      "Epoch: [11][700/5595] Elapsed 3m 53s (remain 27m 10s) Loss avg.: 1.3853 Grad: 0.0031 LR: 0.00100  \n",
      "Epoch: [11][800/5595] Elapsed 4m 26s (remain 26m 36s) Loss avg.: 1.3853 Grad: 0.0056 LR: 0.00100  \n",
      "Epoch: [11][900/5595] Elapsed 5m 0s (remain 26m 3s) Loss avg.: 1.3854 Grad: 0.0014 LR: 0.00100  \n",
      "Epoch: [11][1000/5595] Elapsed 5m 33s (remain 25m 29s) Loss avg.: 1.3853 Grad: 0.0020 LR: 0.00100  \n",
      "Epoch: [11][1100/5595] Elapsed 6m 6s (remain 24m 56s) Loss avg.: 1.3854 Grad: 0.0030 LR: 0.00100  \n",
      "Epoch: [11][1200/5595] Elapsed 6m 39s (remain 24m 22s) Loss avg.: 1.3853 Grad: 0.0027 LR: 0.00100  \n",
      "Epoch: [11][1300/5595] Elapsed 7m 13s (remain 23m 49s) Loss avg.: 1.3854 Grad: 0.0034 LR: 0.00100  \n",
      "Epoch: [11][1400/5595] Elapsed 7m 46s (remain 23m 15s) Loss avg.: 1.3854 Grad: 0.0016 LR: 0.00100  \n",
      "Epoch: [11][1500/5595] Elapsed 8m 19s (remain 22m 42s) Loss avg.: 1.3854 Grad: 0.0016 LR: 0.00100  \n",
      "Epoch: [11][1600/5595] Elapsed 8m 52s (remain 22m 9s) Loss avg.: 1.3854 Grad: 0.0014 LR: 0.00100  \n",
      "Epoch: [11][1700/5595] Elapsed 9m 26s (remain 21m 35s) Loss avg.: 1.3854 Grad: 0.0029 LR: 0.00100  \n",
      "Epoch: [11][1800/5595] Elapsed 9m 59s (remain 21m 2s) Loss avg.: 1.3854 Grad: 0.0006 LR: 0.00100  \n",
      "Epoch: [11][1900/5595] Elapsed 10m 32s (remain 20m 29s) Loss avg.: 1.3854 Grad: 0.0015 LR: 0.00100  \n",
      "Epoch: [11][2000/5595] Elapsed 11m 5s (remain 19m 55s) Loss avg.: 1.3854 Grad: 0.0065 LR: 0.00100  \n",
      "Epoch: [11][2100/5595] Elapsed 11m 39s (remain 19m 22s) Loss avg.: 1.3854 Grad: 0.0031 LR: 0.00100  \n",
      "Epoch: [11][2200/5595] Elapsed 12m 12s (remain 18m 49s) Loss avg.: 1.3854 Grad: 0.0014 LR: 0.00100  \n",
      "Epoch: [11][2300/5595] Elapsed 12m 45s (remain 18m 15s) Loss avg.: 1.3854 Grad: 0.0038 LR: 0.00100  \n",
      "Epoch: [11][2400/5595] Elapsed 13m 18s (remain 17m 42s) Loss avg.: 1.3854 Grad: 0.0033 LR: 0.00100  \n",
      "Epoch: [11][2500/5595] Elapsed 13m 51s (remain 17m 9s) Loss avg.: 1.3854 Grad: 0.0009 LR: 0.00100  \n",
      "Epoch: [11][2600/5595] Elapsed 14m 25s (remain 16m 35s) Loss avg.: 1.3854 Grad: 0.0029 LR: 0.00100  \n",
      "Epoch: [11][2700/5595] Elapsed 14m 58s (remain 16m 2s) Loss avg.: 1.3854 Grad: 0.0019 LR: 0.00100  \n",
      "Epoch: [11][2800/5595] Elapsed 15m 31s (remain 15m 29s) Loss avg.: 1.3854 Grad: 0.0016 LR: 0.00100  \n",
      "Epoch: [11][2900/5595] Elapsed 16m 4s (remain 14m 56s) Loss avg.: 1.3854 Grad: 0.0045 LR: 0.00100  \n",
      "Epoch: [11][3000/5595] Elapsed 16m 38s (remain 14m 22s) Loss avg.: 1.3854 Grad: 0.0048 LR: 0.00100  \n",
      "Epoch: [11][3100/5595] Elapsed 17m 11s (remain 13m 49s) Loss avg.: 1.3854 Grad: 0.0032 LR: 0.00100  \n",
      "Epoch: [11][3200/5595] Elapsed 17m 44s (remain 13m 16s) Loss avg.: 1.3854 Grad: 0.0026 LR: 0.00100  \n",
      "Epoch: [11][3300/5595] Elapsed 18m 18s (remain 12m 43s) Loss avg.: 1.3854 Grad: 0.0016 LR: 0.00100  \n",
      "Epoch: [11][3400/5595] Elapsed 18m 51s (remain 12m 9s) Loss avg.: 1.3854 Grad: 0.0016 LR: 0.00100  \n",
      "Epoch: [11][3500/5595] Elapsed 19m 24s (remain 11m 36s) Loss avg.: 1.3854 Grad: 0.0059 LR: 0.00100  \n",
      "Epoch: [11][3600/5595] Elapsed 19m 57s (remain 11m 3s) Loss avg.: 1.3854 Grad: 0.0016 LR: 0.00100  \n",
      "Epoch: [11][3700/5595] Elapsed 20m 31s (remain 10m 30s) Loss avg.: 1.3854 Grad: 0.0037 LR: 0.00100  \n",
      "Epoch: [11][3800/5595] Elapsed 21m 4s (remain 9m 56s) Loss avg.: 1.3854 Grad: 0.0058 LR: 0.00100  \n",
      "Epoch: [11][3900/5595] Elapsed 21m 37s (remain 9m 23s) Loss avg.: 1.3854 Grad: 0.0015 LR: 0.00100  \n",
      "Epoch: [11][4000/5595] Elapsed 22m 11s (remain 8m 50s) Loss avg.: 1.3854 Grad: 0.0030 LR: 0.00100  \n",
      "Epoch: [11][4100/5595] Elapsed 22m 44s (remain 8m 17s) Loss avg.: 1.3854 Grad: 0.0089 LR: 0.00100  \n",
      "Epoch: [11][4200/5595] Elapsed 23m 17s (remain 7m 43s) Loss avg.: 1.3854 Grad: 0.0008 LR: 0.00100  \n",
      "Epoch: [11][4300/5595] Elapsed 23m 50s (remain 7m 10s) Loss avg.: 1.3854 Grad: 0.0043 LR: 0.00100  \n",
      "Epoch: [11][4400/5595] Elapsed 24m 24s (remain 6m 37s) Loss avg.: 1.3854 Grad: 0.0032 LR: 0.00100  \n",
      "Epoch: [11][4500/5595] Elapsed 24m 57s (remain 6m 3s) Loss avg.: 1.3854 Grad: 0.0019 LR: 0.00100  \n",
      "Epoch: [11][4600/5595] Elapsed 25m 30s (remain 5m 30s) Loss avg.: 1.3854 Grad: 0.0018 LR: 0.00100  \n",
      "Epoch: [11][4700/5595] Elapsed 26m 3s (remain 4m 57s) Loss avg.: 1.3854 Grad: 0.0045 LR: 0.00100  \n",
      "Epoch: [11][4800/5595] Elapsed 26m 37s (remain 4m 24s) Loss avg.: 1.3854 Grad: 0.0034 LR: 0.00100  \n",
      "Epoch: [11][4900/5595] Elapsed 27m 10s (remain 3m 50s) Loss avg.: 1.3854 Grad: 0.0013 LR: 0.00100  \n",
      "Epoch: [11][5000/5595] Elapsed 27m 43s (remain 3m 17s) Loss avg.: 1.3854 Grad: 0.0031 LR: 0.00100  \n",
      "Epoch: [11][5100/5595] Elapsed 28m 16s (remain 2m 44s) Loss avg.: 1.3854 Grad: 0.0013 LR: 0.00100  \n",
      "Epoch: [11][5200/5595] Elapsed 28m 50s (remain 2m 11s) Loss avg.: 1.3854 Grad: 0.0030 LR: 0.00100  \n",
      "Epoch: [11][5300/5595] Elapsed 29m 23s (remain 1m 37s) Loss avg.: 1.3853 Grad: 0.0046 LR: 0.00100  \n",
      "Epoch: [11][5400/5595] Elapsed 29m 56s (remain 1m 4s) Loss avg.: 1.3853 Grad: 0.0014 LR: 0.00100  \n",
      "Epoch: [11][5500/5595] Elapsed 30m 29s (remain 0m 31s) Loss avg.: 1.3853 Grad: 0.0051 LR: 0.00100  \n",
      "Epoch: [11][5594/5595] Elapsed 31m 1s (remain 0m 0s) Loss avg.: 1.3853 Grad: 0.0021 LR: 0.00100  \n",
      "Eval: [0/622] Elapsed 0m 0s (remain 3m 34s) Loss avg.: 1.3849 \n",
      "Eval: [100/622] Elapsed 0m 12s (remain 1m 3s) Loss avg.: 1.3850 \n",
      "Eval: [200/622] Elapsed 0m 24s (remain 0m 51s) Loss avg.: 1.3852 \n",
      "Eval: [300/622] Elapsed 0m 36s (remain 0m 38s) Loss avg.: 1.3852 \n",
      "Eval: [400/622] Elapsed 0m 48s (remain 0m 26s) Loss avg.: 1.3853 \n",
      "Eval: [500/622] Elapsed 1m 0s (remain 0m 14s) Loss avg.: 1.3853 \n",
      "Eval: [600/622] Elapsed 1m 12s (remain 0m 2s) Loss avg.: 1.3853 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - avg_train_loss: 1.3853  avg_val_loss: 1.3853  time: 1936s\n",
      "Epoch 11 - Accuracy: 0.26092012442460055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: [621/622] Elapsed 1m 15s (remain 0m 0s) Loss avg.: 1.3853 \n",
      "Epoch: [12][0/5595] Elapsed 0m 0s (remain 91m 55s) Loss avg.: 1.3834 Grad: 0.0039 LR: 0.00098  \n",
      "Epoch: [12][100/5595] Elapsed 0m 34s (remain 30m 59s) Loss avg.: 1.3854 Grad: 0.0026 LR: 0.00098  \n",
      "Epoch: [12][200/5595] Elapsed 1m 7s (remain 30m 10s) Loss avg.: 1.3854 Grad: 0.0016 LR: 0.00098  \n",
      "Epoch: [12][300/5595] Elapsed 1m 40s (remain 29m 31s) Loss avg.: 1.3853 Grad: 0.0014 LR: 0.00098  \n",
      "Epoch: [12][400/5595] Elapsed 2m 13s (remain 28m 55s) Loss avg.: 1.3853 Grad: 0.0040 LR: 0.00098  \n",
      "Epoch: [12][500/5595] Elapsed 2m 47s (remain 28m 20s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00098  \n",
      "Epoch: [12][600/5595] Elapsed 3m 20s (remain 27m 46s) Loss avg.: 1.3853 Grad: 0.0019 LR: 0.00098  \n",
      "Epoch: [12][700/5595] Elapsed 3m 53s (remain 27m 12s) Loss avg.: 1.3854 Grad: 0.0043 LR: 0.00098  \n",
      "Epoch: [12][800/5595] Elapsed 4m 27s (remain 26m 38s) Loss avg.: 1.3853 Grad: 0.0021 LR: 0.00098  \n",
      "Epoch: [12][900/5595] Elapsed 5m 0s (remain 26m 5s) Loss avg.: 1.3853 Grad: 0.0035 LR: 0.00098  \n",
      "Epoch: [12][1000/5595] Elapsed 5m 33s (remain 25m 31s) Loss avg.: 1.3853 Grad: 0.0073 LR: 0.00098  \n",
      "Epoch: [12][1100/5595] Elapsed 6m 7s (remain 24m 58s) Loss avg.: 1.3853 Grad: 0.0046 LR: 0.00098  \n",
      "Epoch: [12][1200/5595] Elapsed 6m 40s (remain 24m 24s) Loss avg.: 1.3853 Grad: 0.0027 LR: 0.00098  \n",
      "Epoch: [12][1300/5595] Elapsed 7m 13s (remain 23m 50s) Loss avg.: 1.3853 Grad: 0.0063 LR: 0.00098  \n",
      "Epoch: [12][1400/5595] Elapsed 7m 46s (remain 23m 17s) Loss avg.: 1.3853 Grad: 0.0039 LR: 0.00098  \n",
      "Epoch: [12][1500/5595] Elapsed 8m 20s (remain 22m 44s) Loss avg.: 1.3853 Grad: 0.0035 LR: 0.00098  \n",
      "Epoch: [12][1600/5595] Elapsed 8m 53s (remain 22m 10s) Loss avg.: 1.3853 Grad: 0.0035 LR: 0.00098  \n",
      "Epoch: [12][1700/5595] Elapsed 9m 26s (remain 21m 37s) Loss avg.: 1.3853 Grad: 0.0006 LR: 0.00098  \n",
      "Epoch: [12][1800/5595] Elapsed 10m 0s (remain 21m 4s) Loss avg.: 1.3853 Grad: 0.0013 LR: 0.00098  \n",
      "Epoch: [12][1900/5595] Elapsed 10m 33s (remain 20m 30s) Loss avg.: 1.3853 Grad: 0.0034 LR: 0.00098  \n",
      "Epoch: [12][2000/5595] Elapsed 11m 6s (remain 19m 57s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00098  \n",
      "Epoch: [12][2100/5595] Elapsed 11m 39s (remain 19m 23s) Loss avg.: 1.3853 Grad: 0.0028 LR: 0.00098  \n",
      "Epoch: [12][2200/5595] Elapsed 12m 13s (remain 18m 50s) Loss avg.: 1.3853 Grad: 0.0029 LR: 0.00098  \n",
      "Epoch: [12][2300/5595] Elapsed 12m 46s (remain 18m 17s) Loss avg.: 1.3853 Grad: 0.0052 LR: 0.00098  \n",
      "Epoch: [12][2400/5595] Elapsed 13m 19s (remain 17m 43s) Loss avg.: 1.3853 Grad: 0.0025 LR: 0.00098  \n",
      "Epoch: [12][2500/5595] Elapsed 13m 53s (remain 17m 10s) Loss avg.: 1.3853 Grad: 0.0027 LR: 0.00098  \n",
      "Epoch: [12][2600/5595] Elapsed 14m 26s (remain 16m 37s) Loss avg.: 1.3853 Grad: 0.0087 LR: 0.00098  \n",
      "Epoch: [12][2700/5595] Elapsed 14m 59s (remain 16m 3s) Loss avg.: 1.3853 Grad: 0.0015 LR: 0.00098  \n",
      "Epoch: [12][2800/5595] Elapsed 15m 32s (remain 15m 30s) Loss avg.: 1.3853 Grad: 0.0049 LR: 0.00098  \n",
      "Epoch: [12][2900/5595] Elapsed 16m 6s (remain 14m 57s) Loss avg.: 1.3853 Grad: 0.0093 LR: 0.00098  \n",
      "Epoch: [12][3000/5595] Elapsed 16m 39s (remain 14m 23s) Loss avg.: 1.3853 Grad: 0.0018 LR: 0.00098  \n",
      "Epoch: [12][3100/5595] Elapsed 17m 12s (remain 13m 50s) Loss avg.: 1.3853 Grad: 0.0042 LR: 0.00098  \n",
      "Epoch: [12][3200/5595] Elapsed 17m 45s (remain 13m 17s) Loss avg.: 1.3853 Grad: 0.0029 LR: 0.00098  \n",
      "Epoch: [12][3300/5595] Elapsed 18m 19s (remain 12m 43s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00098  \n",
      "Epoch: [12][3400/5595] Elapsed 18m 52s (remain 12m 10s) Loss avg.: 1.3853 Grad: 0.0027 LR: 0.00098  \n",
      "Epoch: [12][3500/5595] Elapsed 19m 25s (remain 11m 37s) Loss avg.: 1.3853 Grad: 0.0044 LR: 0.00098  \n",
      "Epoch: [12][3600/5595] Elapsed 19m 59s (remain 11m 3s) Loss avg.: 1.3853 Grad: 0.0043 LR: 0.00098  \n",
      "Epoch: [12][3700/5595] Elapsed 20m 32s (remain 10m 30s) Loss avg.: 1.3853 Grad: 0.0021 LR: 0.00098  \n",
      "Epoch: [12][3800/5595] Elapsed 21m 5s (remain 9m 57s) Loss avg.: 1.3853 Grad: 0.0066 LR: 0.00098  \n",
      "Epoch: [12][3900/5595] Elapsed 21m 39s (remain 9m 24s) Loss avg.: 1.3853 Grad: 0.0009 LR: 0.00098  \n",
      "Epoch: [12][4000/5595] Elapsed 22m 12s (remain 8m 50s) Loss avg.: 1.3853 Grad: 0.0024 LR: 0.00098  \n",
      "Epoch: [12][4100/5595] Elapsed 22m 45s (remain 8m 17s) Loss avg.: 1.3853 Grad: 0.0036 LR: 0.00098  \n",
      "Epoch: [12][4200/5595] Elapsed 23m 19s (remain 7m 44s) Loss avg.: 1.3853 Grad: 0.0034 LR: 0.00098  \n",
      "Epoch: [12][4300/5595] Elapsed 23m 52s (remain 7m 10s) Loss avg.: 1.3853 Grad: 0.0016 LR: 0.00098  \n",
      "Epoch: [12][4400/5595] Elapsed 24m 25s (remain 6m 37s) Loss avg.: 1.3853 Grad: 0.0031 LR: 0.00098  \n",
      "Epoch: [12][4500/5595] Elapsed 24m 58s (remain 6m 4s) Loss avg.: 1.3853 Grad: 0.0028 LR: 0.00098  \n",
      "Epoch: [12][4600/5595] Elapsed 25m 32s (remain 5m 30s) Loss avg.: 1.3853 Grad: 0.0015 LR: 0.00098  \n",
      "Epoch: [12][4700/5595] Elapsed 26m 5s (remain 4m 57s) Loss avg.: 1.3853 Grad: 0.0034 LR: 0.00098  \n",
      "Epoch: [12][4800/5595] Elapsed 26m 38s (remain 4m 24s) Loss avg.: 1.3853 Grad: 0.0010 LR: 0.00098  \n",
      "Epoch: [12][4900/5595] Elapsed 27m 11s (remain 3m 51s) Loss avg.: 1.3853 Grad: 0.0030 LR: 0.00098  \n",
      "Epoch: [12][5000/5595] Elapsed 27m 45s (remain 3m 17s) Loss avg.: 1.3853 Grad: 0.0041 LR: 0.00098  \n",
      "Epoch: [12][5100/5595] Elapsed 28m 18s (remain 2m 44s) Loss avg.: 1.3853 Grad: 0.0002 LR: 0.00098  \n",
      "Epoch: [12][5200/5595] Elapsed 28m 51s (remain 2m 11s) Loss avg.: 1.3853 Grad: 0.0029 LR: 0.00098  \n",
      "Epoch: [12][5300/5595] Elapsed 29m 24s (remain 1m 37s) Loss avg.: 1.3853 Grad: 0.0038 LR: 0.00098  \n",
      "Epoch: [12][5400/5595] Elapsed 29m 58s (remain 1m 4s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00098  \n",
      "Epoch: [12][5500/5595] Elapsed 30m 31s (remain 0m 31s) Loss avg.: 1.3853 Grad: 0.0040 LR: 0.00098  \n",
      "Epoch: [12][5594/5595] Elapsed 31m 2s (remain 0m 0s) Loss avg.: 1.3853 Grad: 0.0120 LR: 0.00098  \n",
      "Eval: [0/622] Elapsed 0m 0s (remain 3m 34s) Loss avg.: 1.3849 \n",
      "Eval: [100/622] Elapsed 0m 12s (remain 1m 3s) Loss avg.: 1.3849 \n",
      "Eval: [200/622] Elapsed 0m 24s (remain 0m 51s) Loss avg.: 1.3852 \n",
      "Eval: [300/622] Elapsed 0m 36s (remain 0m 38s) Loss avg.: 1.3852 \n",
      "Eval: [400/622] Elapsed 0m 48s (remain 0m 26s) Loss avg.: 1.3853 \n",
      "Eval: [500/622] Elapsed 1m 0s (remain 0m 14s) Loss avg.: 1.3853 \n",
      "Eval: [600/622] Elapsed 1m 12s (remain 0m 2s) Loss avg.: 1.3853 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 - avg_train_loss: 1.3853  avg_val_loss: 1.3854  time: 1938s\n",
      "Epoch 12 - Accuracy: 0.26092012442460055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: [621/622] Elapsed 1m 15s (remain 0m 0s) Loss avg.: 1.3854 \n",
      "Epoch: [13][0/5595] Elapsed 0m 1s (remain 96m 52s) Loss avg.: 1.3846 Grad: 0.0012 LR: 0.00091  \n",
      "Epoch: [13][100/5595] Elapsed 0m 34s (remain 31m 2s) Loss avg.: 1.3853 Grad: 0.0032 LR: 0.00091  \n",
      "Epoch: [13][200/5595] Elapsed 1m 7s (remain 30m 10s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00091  \n",
      "Epoch: [13][300/5595] Elapsed 1m 40s (remain 29m 30s) Loss avg.: 1.3853 Grad: 0.0008 LR: 0.00091  \n",
      "Epoch: [13][400/5595] Elapsed 2m 13s (remain 28m 53s) Loss avg.: 1.3853 Grad: 0.0032 LR: 0.00091  \n",
      "Epoch: [13][500/5595] Elapsed 2m 47s (remain 28m 19s) Loss avg.: 1.3853 Grad: 0.0031 LR: 0.00091  \n",
      "Epoch: [13][600/5595] Elapsed 3m 20s (remain 27m 45s) Loss avg.: 1.3853 Grad: 0.0025 LR: 0.00091  \n",
      "Epoch: [13][700/5595] Elapsed 3m 53s (remain 27m 11s) Loss avg.: 1.3853 Grad: 0.0027 LR: 0.00091  \n",
      "Epoch: [13][800/5595] Elapsed 4m 26s (remain 26m 37s) Loss avg.: 1.3853 Grad: 0.0014 LR: 0.00091  \n",
      "Epoch: [13][900/5595] Elapsed 5m 0s (remain 26m 4s) Loss avg.: 1.3853 Grad: 0.0018 LR: 0.00091  \n",
      "Epoch: [13][1000/5595] Elapsed 5m 33s (remain 25m 30s) Loss avg.: 1.3853 Grad: 0.0036 LR: 0.00091  \n",
      "Epoch: [13][1100/5595] Elapsed 6m 6s (remain 24m 56s) Loss avg.: 1.3853 Grad: 0.0037 LR: 0.00091  \n",
      "Epoch: [13][1200/5595] Elapsed 6m 39s (remain 24m 23s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00091  \n",
      "Epoch: [13][1300/5595] Elapsed 7m 13s (remain 23m 49s) Loss avg.: 1.3853 Grad: 0.0015 LR: 0.00091  \n",
      "Epoch: [13][1400/5595] Elapsed 7m 46s (remain 23m 16s) Loss avg.: 1.3853 Grad: 0.0035 LR: 0.00091  \n",
      "Epoch: [13][1500/5595] Elapsed 8m 19s (remain 22m 43s) Loss avg.: 1.3853 Grad: 0.0003 LR: 0.00091  \n",
      "Epoch: [13][1600/5595] Elapsed 8m 53s (remain 22m 9s) Loss avg.: 1.3853 Grad: 0.0067 LR: 0.00091  \n",
      "Epoch: [13][1700/5595] Elapsed 9m 26s (remain 21m 36s) Loss avg.: 1.3853 Grad: 0.0051 LR: 0.00091  \n",
      "Epoch: [13][1800/5595] Elapsed 9m 59s (remain 21m 3s) Loss avg.: 1.3853 Grad: 0.0029 LR: 0.00091  \n",
      "Epoch: [13][1900/5595] Elapsed 10m 32s (remain 20m 29s) Loss avg.: 1.3853 Grad: 0.0022 LR: 0.00091  \n",
      "Epoch: [13][2000/5595] Elapsed 11m 6s (remain 19m 56s) Loss avg.: 1.3853 Grad: 0.0043 LR: 0.00091  \n",
      "Epoch: [13][2100/5595] Elapsed 11m 39s (remain 19m 22s) Loss avg.: 1.3853 Grad: 0.0030 LR: 0.00091  \n",
      "Epoch: [13][2200/5595] Elapsed 12m 12s (remain 18m 49s) Loss avg.: 1.3853 Grad: 0.0025 LR: 0.00091  \n",
      "Epoch: [13][2300/5595] Elapsed 12m 45s (remain 18m 15s) Loss avg.: 1.3853 Grad: 0.0030 LR: 0.00091  \n",
      "Epoch: [13][2400/5595] Elapsed 13m 18s (remain 17m 42s) Loss avg.: 1.3853 Grad: 0.0042 LR: 0.00091  \n",
      "Epoch: [13][2500/5595] Elapsed 13m 51s (remain 17m 8s) Loss avg.: 1.3853 Grad: 0.0033 LR: 0.00091  \n",
      "Epoch: [13][2600/5595] Elapsed 14m 24s (remain 16m 35s) Loss avg.: 1.3853 Grad: 0.0028 LR: 0.00091  \n",
      "Epoch: [13][2700/5595] Elapsed 14m 57s (remain 16m 1s) Loss avg.: 1.3853 Grad: 0.0019 LR: 0.00091  \n",
      "Epoch: [13][2800/5595] Elapsed 15m 30s (remain 15m 28s) Loss avg.: 1.3853 Grad: 0.0036 LR: 0.00091  \n",
      "Epoch: [13][2900/5595] Elapsed 16m 3s (remain 14m 54s) Loss avg.: 1.3853 Grad: 0.0061 LR: 0.00091  \n",
      "Epoch: [13][3000/5595] Elapsed 16m 36s (remain 14m 21s) Loss avg.: 1.3853 Grad: 0.0010 LR: 0.00091  \n",
      "Epoch: [13][3100/5595] Elapsed 17m 10s (remain 13m 48s) Loss avg.: 1.3853 Grad: 0.0052 LR: 0.00091  \n",
      "Epoch: [13][3200/5595] Elapsed 17m 43s (remain 13m 15s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00091  \n",
      "Epoch: [13][3300/5595] Elapsed 18m 16s (remain 12m 42s) Loss avg.: 1.3853 Grad: 0.0022 LR: 0.00091  \n",
      "Epoch: [13][3400/5595] Elapsed 18m 49s (remain 12m 8s) Loss avg.: 1.3853 Grad: 0.0027 LR: 0.00091  \n",
      "Epoch: [13][3500/5595] Elapsed 19m 22s (remain 11m 35s) Loss avg.: 1.3853 Grad: 0.0056 LR: 0.00091  \n",
      "Epoch: [13][3600/5595] Elapsed 19m 56s (remain 11m 2s) Loss avg.: 1.3853 Grad: 0.0007 LR: 0.00091  \n",
      "Epoch: [13][3700/5595] Elapsed 20m 29s (remain 10m 29s) Loss avg.: 1.3853 Grad: 0.0005 LR: 0.00091  \n",
      "Epoch: [13][3800/5595] Elapsed 21m 2s (remain 9m 55s) Loss avg.: 1.3853 Grad: 0.0049 LR: 0.00091  \n",
      "Epoch: [13][3900/5595] Elapsed 21m 35s (remain 9m 22s) Loss avg.: 1.3853 Grad: 0.0016 LR: 0.00091  \n",
      "Epoch: [13][4000/5595] Elapsed 22m 9s (remain 8m 49s) Loss avg.: 1.3853 Grad: 0.0070 LR: 0.00091  \n",
      "Epoch: [13][4100/5595] Elapsed 22m 41s (remain 8m 16s) Loss avg.: 1.3853 Grad: 0.0041 LR: 0.00091  \n",
      "Epoch: [13][4200/5595] Elapsed 23m 15s (remain 7m 42s) Loss avg.: 1.3853 Grad: 0.0010 LR: 0.00091  \n",
      "Epoch: [13][4300/5595] Elapsed 23m 48s (remain 7m 9s) Loss avg.: 1.3853 Grad: 0.0034 LR: 0.00091  \n",
      "Epoch: [13][4400/5595] Elapsed 24m 21s (remain 6m 36s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00091  \n",
      "Epoch: [13][4500/5595] Elapsed 24m 54s (remain 6m 3s) Loss avg.: 1.3853 Grad: 0.0027 LR: 0.00091  \n",
      "Epoch: [13][4600/5595] Elapsed 25m 27s (remain 5m 30s) Loss avg.: 1.3853 Grad: 0.0005 LR: 0.00091  \n",
      "Epoch: [13][4700/5595] Elapsed 26m 1s (remain 4m 56s) Loss avg.: 1.3853 Grad: 0.0014 LR: 0.00091  \n",
      "Epoch: [13][4800/5595] Elapsed 26m 34s (remain 4m 23s) Loss avg.: 1.3853 Grad: 0.0029 LR: 0.00091  \n",
      "Epoch: [13][4900/5595] Elapsed 27m 7s (remain 3m 50s) Loss avg.: 1.3853 Grad: 0.0034 LR: 0.00091  \n",
      "Epoch: [13][5000/5595] Elapsed 27m 40s (remain 3m 17s) Loss avg.: 1.3853 Grad: 0.0023 LR: 0.00091  \n",
      "Epoch: [13][5100/5595] Elapsed 28m 13s (remain 2m 44s) Loss avg.: 1.3853 Grad: 0.0022 LR: 0.00091  \n",
      "Epoch: [13][5200/5595] Elapsed 28m 46s (remain 2m 10s) Loss avg.: 1.3853 Grad: 0.0007 LR: 0.00091  \n",
      "Epoch: [13][5300/5595] Elapsed 29m 19s (remain 1m 37s) Loss avg.: 1.3853 Grad: 0.0018 LR: 0.00091  \n",
      "Epoch: [13][5400/5595] Elapsed 29m 52s (remain 1m 4s) Loss avg.: 1.3853 Grad: 0.0012 LR: 0.00091  \n",
      "Epoch: [13][5500/5595] Elapsed 30m 25s (remain 0m 31s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00091  \n",
      "Epoch: [13][5594/5595] Elapsed 30m 57s (remain 0m 0s) Loss avg.: 1.3853 Grad: 0.0075 LR: 0.00091  \n",
      "Eval: [0/622] Elapsed 0m 0s (remain 3m 38s) Loss avg.: 1.3848 \n",
      "Eval: [100/622] Elapsed 0m 12s (remain 1m 3s) Loss avg.: 1.3849 \n",
      "Eval: [200/622] Elapsed 0m 24s (remain 0m 51s) Loss avg.: 1.3851 \n",
      "Eval: [300/622] Elapsed 0m 36s (remain 0m 38s) Loss avg.: 1.3852 \n",
      "Eval: [400/622] Elapsed 0m 48s (remain 0m 26s) Loss avg.: 1.3853 \n",
      "Eval: [500/622] Elapsed 1m 0s (remain 0m 14s) Loss avg.: 1.3853 \n",
      "Eval: [600/622] Elapsed 1m 12s (remain 0m 2s) Loss avg.: 1.3853 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 - avg_train_loss: 1.3853  avg_val_loss: 1.3853  time: 1932s\n",
      "Epoch 13 - Accuracy: 0.2609185160404155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: [621/622] Elapsed 1m 15s (remain 0m 0s) Loss avg.: 1.3853 \n",
      "Epoch: [14][0/5595] Elapsed 0m 0s (remain 91m 22s) Loss avg.: 1.3827 Grad: 0.0037 LR: 0.00081  \n",
      "Epoch: [14][100/5595] Elapsed 0m 34s (remain 30m 56s) Loss avg.: 1.3854 Grad: 0.0026 LR: 0.00081  \n",
      "Epoch: [14][200/5595] Elapsed 1m 7s (remain 30m 4s) Loss avg.: 1.3853 Grad: 0.0056 LR: 0.00081  \n",
      "Epoch: [14][300/5595] Elapsed 1m 40s (remain 29m 24s) Loss avg.: 1.3853 Grad: 0.0020 LR: 0.00081  \n",
      "Epoch: [14][400/5595] Elapsed 2m 13s (remain 28m 47s) Loss avg.: 1.3853 Grad: 0.0040 LR: 0.00081  \n",
      "Epoch: [14][500/5595] Elapsed 2m 46s (remain 28m 12s) Loss avg.: 1.3853 Grad: 0.0036 LR: 0.00081  \n",
      "Epoch: [14][600/5595] Elapsed 3m 19s (remain 27m 37s) Loss avg.: 1.3853 Grad: 0.0027 LR: 0.00081  \n",
      "Epoch: [14][700/5595] Elapsed 3m 52s (remain 27m 3s) Loss avg.: 1.3854 Grad: 0.0015 LR: 0.00081  \n",
      "Epoch: [14][800/5595] Elapsed 4m 25s (remain 26m 29s) Loss avg.: 1.3853 Grad: 0.0030 LR: 0.00081  \n",
      "Epoch: [14][900/5595] Elapsed 4m 58s (remain 25m 55s) Loss avg.: 1.3853 Grad: 0.0023 LR: 0.00081  \n",
      "Epoch: [14][1000/5595] Elapsed 5m 31s (remain 25m 21s) Loss avg.: 1.3853 Grad: 0.0011 LR: 0.00081  \n",
      "Epoch: [14][1100/5595] Elapsed 6m 4s (remain 24m 47s) Loss avg.: 1.3853 Grad: 0.0048 LR: 0.00081  \n",
      "Epoch: [14][1200/5595] Elapsed 6m 37s (remain 24m 14s) Loss avg.: 1.3853 Grad: 0.0033 LR: 0.00081  \n",
      "Epoch: [14][1300/5595] Elapsed 7m 10s (remain 23m 42s) Loss avg.: 1.3853 Grad: 0.0036 LR: 0.00081  \n",
      "Epoch: [14][1400/5595] Elapsed 7m 44s (remain 23m 9s) Loss avg.: 1.3853 Grad: 0.0043 LR: 0.00081  \n",
      "Epoch: [14][1500/5595] Elapsed 8m 16s (remain 22m 35s) Loss avg.: 1.3853 Grad: 0.0025 LR: 0.00081  \n",
      "Epoch: [14][1600/5595] Elapsed 8m 49s (remain 22m 1s) Loss avg.: 1.3853 Grad: 0.0018 LR: 0.00081  \n",
      "Epoch: [14][1700/5595] Elapsed 9m 22s (remain 21m 28s) Loss avg.: 1.3853 Grad: 0.0045 LR: 0.00081  \n",
      "Epoch: [14][1800/5595] Elapsed 9m 55s (remain 20m 54s) Loss avg.: 1.3853 Grad: 0.0011 LR: 0.00081  \n",
      "Epoch: [14][1900/5595] Elapsed 10m 28s (remain 20m 21s) Loss avg.: 1.3853 Grad: 0.0055 LR: 0.00081  \n",
      "Epoch: [14][2000/5595] Elapsed 11m 1s (remain 19m 48s) Loss avg.: 1.3853 Grad: 0.0055 LR: 0.00081  \n",
      "Epoch: [14][2100/5595] Elapsed 11m 34s (remain 19m 15s) Loss avg.: 1.3854 Grad: 0.0011 LR: 0.00081  \n",
      "Epoch: [14][2200/5595] Elapsed 12m 7s (remain 18m 41s) Loss avg.: 1.3853 Grad: 0.0024 LR: 0.00081  \n",
      "Epoch: [14][2300/5595] Elapsed 12m 40s (remain 18m 8s) Loss avg.: 1.3853 Grad: 0.0033 LR: 0.00081  \n",
      "Epoch: [14][2400/5595] Elapsed 13m 13s (remain 17m 35s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00081  \n",
      "Epoch: [14][2500/5595] Elapsed 13m 46s (remain 17m 2s) Loss avg.: 1.3853 Grad: 0.0020 LR: 0.00081  \n",
      "Epoch: [14][2600/5595] Elapsed 14m 19s (remain 16m 29s) Loss avg.: 1.3853 Grad: 0.0045 LR: 0.00081  \n",
      "Epoch: [14][2700/5595] Elapsed 14m 52s (remain 15m 56s) Loss avg.: 1.3853 Grad: 0.0014 LR: 0.00081  \n",
      "Epoch: [14][2800/5595] Elapsed 15m 25s (remain 15m 23s) Loss avg.: 1.3854 Grad: 0.0033 LR: 0.00081  \n",
      "Epoch: [14][2900/5595] Elapsed 15m 58s (remain 14m 50s) Loss avg.: 1.3853 Grad: 0.0024 LR: 0.00081  \n",
      "Epoch: [14][3000/5595] Elapsed 16m 31s (remain 14m 17s) Loss avg.: 1.3853 Grad: 0.0014 LR: 0.00081  \n",
      "Epoch: [14][3100/5595] Elapsed 17m 4s (remain 13m 44s) Loss avg.: 1.3853 Grad: 0.0030 LR: 0.00081  \n",
      "Epoch: [14][3200/5595] Elapsed 17m 37s (remain 13m 11s) Loss avg.: 1.3853 Grad: 0.0031 LR: 0.00081  \n",
      "Epoch: [14][3300/5595] Elapsed 18m 11s (remain 12m 38s) Loss avg.: 1.3853 Grad: 0.0018 LR: 0.00081  \n",
      "Epoch: [14][3400/5595] Elapsed 18m 44s (remain 12m 5s) Loss avg.: 1.3853 Grad: 0.0027 LR: 0.00081  \n",
      "Epoch: [14][3500/5595] Elapsed 19m 17s (remain 11m 32s) Loss avg.: 1.3853 Grad: 0.0021 LR: 0.00081  \n",
      "Epoch: [14][3600/5595] Elapsed 19m 50s (remain 10m 59s) Loss avg.: 1.3853 Grad: 0.0028 LR: 0.00081  \n",
      "Epoch: [14][3700/5595] Elapsed 20m 23s (remain 10m 26s) Loss avg.: 1.3853 Grad: 0.0027 LR: 0.00081  \n",
      "Epoch: [14][3800/5595] Elapsed 20m 56s (remain 9m 53s) Loss avg.: 1.3853 Grad: 0.0046 LR: 0.00081  \n",
      "Epoch: [14][3900/5595] Elapsed 21m 30s (remain 9m 20s) Loss avg.: 1.3853 Grad: 0.0028 LR: 0.00081  \n",
      "Epoch: [14][4000/5595] Elapsed 22m 3s (remain 8m 47s) Loss avg.: 1.3853 Grad: 0.0031 LR: 0.00081  \n",
      "Epoch: [14][4100/5595] Elapsed 22m 36s (remain 8m 14s) Loss avg.: 1.3853 Grad: 0.0040 LR: 0.00081  \n",
      "Epoch: [14][4200/5595] Elapsed 23m 9s (remain 7m 41s) Loss avg.: 1.3853 Grad: 0.0043 LR: 0.00081  \n",
      "Epoch: [14][4300/5595] Elapsed 23m 42s (remain 7m 8s) Loss avg.: 1.3853 Grad: 0.0025 LR: 0.00081  \n",
      "Epoch: [14][4400/5595] Elapsed 24m 15s (remain 6m 35s) Loss avg.: 1.3853 Grad: 0.0073 LR: 0.00081  \n",
      "Epoch: [14][4500/5595] Elapsed 24m 49s (remain 6m 1s) Loss avg.: 1.3853 Grad: 0.0035 LR: 0.00081  \n",
      "Epoch: [14][4600/5595] Elapsed 25m 22s (remain 5m 28s) Loss avg.: 1.3853 Grad: 0.0023 LR: 0.00081  \n",
      "Epoch: [14][4700/5595] Elapsed 25m 55s (remain 4m 55s) Loss avg.: 1.3853 Grad: 0.0028 LR: 0.00081  \n",
      "Epoch: [14][4800/5595] Elapsed 26m 28s (remain 4m 22s) Loss avg.: 1.3853 Grad: 0.0016 LR: 0.00081  \n",
      "Epoch: [14][4900/5595] Elapsed 27m 2s (remain 3m 49s) Loss avg.: 1.3853 Grad: 0.0024 LR: 0.00081  \n",
      "Epoch: [14][5000/5595] Elapsed 27m 35s (remain 3m 16s) Loss avg.: 1.3853 Grad: 0.0029 LR: 0.00081  \n",
      "Epoch: [14][5100/5595] Elapsed 28m 8s (remain 2m 43s) Loss avg.: 1.3853 Grad: 0.0009 LR: 0.00081  \n",
      "Epoch: [14][5200/5595] Elapsed 28m 41s (remain 2m 10s) Loss avg.: 1.3853 Grad: 0.0028 LR: 0.00081  \n",
      "Epoch: [14][5300/5595] Elapsed 29m 14s (remain 1m 37s) Loss avg.: 1.3853 Grad: 0.0044 LR: 0.00081  \n",
      "Epoch: [14][5400/5595] Elapsed 29m 47s (remain 1m 4s) Loss avg.: 1.3854 Grad: 0.0039 LR: 0.00081  \n",
      "Epoch: [14][5500/5595] Elapsed 30m 21s (remain 0m 31s) Loss avg.: 1.3853 Grad: 0.0040 LR: 0.00081  \n",
      "Epoch: [14][5594/5595] Elapsed 30m 52s (remain 0m 0s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00081  \n",
      "Eval: [0/622] Elapsed 0m 0s (remain 3m 31s) Loss avg.: 1.3848 \n",
      "Eval: [100/622] Elapsed 0m 12s (remain 1m 3s) Loss avg.: 1.3849 \n",
      "Eval: [200/622] Elapsed 0m 24s (remain 0m 51s) Loss avg.: 1.3852 \n",
      "Eval: [300/622] Elapsed 0m 36s (remain 0m 38s) Loss avg.: 1.3852 \n",
      "Eval: [400/622] Elapsed 0m 48s (remain 0m 26s) Loss avg.: 1.3853 \n",
      "Eval: [500/622] Elapsed 1m 0s (remain 0m 14s) Loss avg.: 1.3853 \n",
      "Eval: [600/622] Elapsed 1m 12s (remain 0m 2s) Loss avg.: 1.3853 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 - avg_train_loss: 1.3853  avg_val_loss: 1.3853  time: 1928s\n",
      "Epoch 14 - Accuracy: 0.26092012442460055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: [621/622] Elapsed 1m 14s (remain 0m 0s) Loss avg.: 1.3853 \n",
      "Epoch: [15][0/5595] Elapsed 0m 0s (remain 92m 30s) Loss avg.: 1.3865 Grad: 0.0021 LR: 0.00069  \n",
      "Epoch: [15][100/5595] Elapsed 0m 34s (remain 30m 58s) Loss avg.: 1.3854 Grad: 0.0033 LR: 0.00069  \n",
      "Epoch: [15][200/5595] Elapsed 1m 7s (remain 30m 3s) Loss avg.: 1.3853 Grad: 0.0023 LR: 0.00069  \n",
      "Epoch: [15][300/5595] Elapsed 1m 40s (remain 29m 22s) Loss avg.: 1.3853 Grad: 0.0022 LR: 0.00069  \n",
      "Epoch: [15][400/5595] Elapsed 2m 13s (remain 28m 46s) Loss avg.: 1.3854 Grad: 0.0028 LR: 0.00069  \n",
      "Epoch: [15][500/5595] Elapsed 2m 46s (remain 28m 12s) Loss avg.: 1.3854 Grad: 0.0034 LR: 0.00069  \n",
      "Epoch: [15][600/5595] Elapsed 3m 19s (remain 27m 36s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00069  \n",
      "Epoch: [15][700/5595] Elapsed 3m 52s (remain 27m 2s) Loss avg.: 1.3853 Grad: 0.0014 LR: 0.00069  \n",
      "Epoch: [15][800/5595] Elapsed 4m 25s (remain 26m 30s) Loss avg.: 1.3853 Grad: 0.0030 LR: 0.00069  \n",
      "Epoch: [15][900/5595] Elapsed 4m 58s (remain 25m 55s) Loss avg.: 1.3853 Grad: 0.0011 LR: 0.00069  \n",
      "Epoch: [15][1000/5595] Elapsed 5m 31s (remain 25m 21s) Loss avg.: 1.3854 Grad: 0.0023 LR: 0.00069  \n",
      "Epoch: [15][1100/5595] Elapsed 6m 4s (remain 24m 47s) Loss avg.: 1.3854 Grad: 0.0034 LR: 0.00069  \n",
      "Epoch: [15][1200/5595] Elapsed 6m 37s (remain 24m 14s) Loss avg.: 1.3854 Grad: 0.0014 LR: 0.00069  \n",
      "Epoch: [15][1300/5595] Elapsed 7m 10s (remain 23m 41s) Loss avg.: 1.3854 Grad: 0.0017 LR: 0.00069  \n",
      "Epoch: [15][1400/5595] Elapsed 7m 43s (remain 23m 7s) Loss avg.: 1.3854 Grad: 0.0060 LR: 0.00069  \n",
      "Epoch: [15][1500/5595] Elapsed 8m 16s (remain 22m 33s) Loss avg.: 1.3854 Grad: 0.0037 LR: 0.00069  \n",
      "Epoch: [15][1600/5595] Elapsed 8m 49s (remain 22m 0s) Loss avg.: 1.3854 Grad: 0.0009 LR: 0.00069  \n",
      "Epoch: [15][1700/5595] Elapsed 9m 22s (remain 21m 27s) Loss avg.: 1.3854 Grad: 0.0038 LR: 0.00069  \n",
      "Epoch: [15][1800/5595] Elapsed 9m 55s (remain 20m 53s) Loss avg.: 1.3854 Grad: 0.0008 LR: 0.00069  \n",
      "Epoch: [15][1900/5595] Elapsed 10m 28s (remain 20m 20s) Loss avg.: 1.3854 Grad: 0.0014 LR: 0.00069  \n",
      "Epoch: [15][2000/5595] Elapsed 11m 1s (remain 19m 47s) Loss avg.: 1.3854 Grad: 0.0049 LR: 0.00069  \n",
      "Epoch: [15][2100/5595] Elapsed 11m 34s (remain 19m 14s) Loss avg.: 1.3854 Grad: 0.0016 LR: 0.00069  \n",
      "Epoch: [15][2200/5595] Elapsed 12m 7s (remain 18m 41s) Loss avg.: 1.3854 Grad: 0.0027 LR: 0.00069  \n",
      "Epoch: [15][2300/5595] Elapsed 12m 40s (remain 18m 8s) Loss avg.: 1.3854 Grad: 0.0010 LR: 0.00069  \n",
      "Epoch: [15][2400/5595] Elapsed 13m 13s (remain 17m 35s) Loss avg.: 1.3854 Grad: 0.0012 LR: 0.00069  \n",
      "Epoch: [15][2500/5595] Elapsed 13m 46s (remain 17m 2s) Loss avg.: 1.3854 Grad: 0.0024 LR: 0.00069  \n",
      "Epoch: [15][2600/5595] Elapsed 14m 19s (remain 16m 29s) Loss avg.: 1.3854 Grad: 0.0037 LR: 0.00069  \n",
      "Epoch: [15][2700/5595] Elapsed 14m 52s (remain 15m 56s) Loss avg.: 1.3854 Grad: 0.0013 LR: 0.00069  \n",
      "Epoch: [15][2800/5595] Elapsed 15m 25s (remain 15m 23s) Loss avg.: 1.3854 Grad: 0.0019 LR: 0.00069  \n",
      "Epoch: [15][2900/5595] Elapsed 15m 58s (remain 14m 50s) Loss avg.: 1.3854 Grad: 0.0026 LR: 0.00069  \n",
      "Epoch: [15][3000/5595] Elapsed 16m 32s (remain 14m 17s) Loss avg.: 1.3854 Grad: 0.0020 LR: 0.00069  \n",
      "Epoch: [15][3100/5595] Elapsed 17m 5s (remain 13m 44s) Loss avg.: 1.3854 Grad: 0.0018 LR: 0.00069  \n",
      "Epoch: [15][3200/5595] Elapsed 17m 38s (remain 13m 11s) Loss avg.: 1.3854 Grad: 0.0028 LR: 0.00069  \n",
      "Epoch: [15][3300/5595] Elapsed 18m 11s (remain 12m 38s) Loss avg.: 1.3854 Grad: 0.0040 LR: 0.00069  \n",
      "Epoch: [15][3400/5595] Elapsed 18m 44s (remain 12m 5s) Loss avg.: 1.3854 Grad: 0.0076 LR: 0.00069  \n",
      "Epoch: [15][3500/5595] Elapsed 19m 17s (remain 11m 32s) Loss avg.: 1.3854 Grad: 0.0027 LR: 0.00069  \n",
      "Epoch: [15][3600/5595] Elapsed 19m 50s (remain 10m 59s) Loss avg.: 1.3854 Grad: 0.0010 LR: 0.00069  \n",
      "Epoch: [15][3700/5595] Elapsed 20m 23s (remain 10m 26s) Loss avg.: 1.3854 Grad: 0.0035 LR: 0.00069  \n",
      "Epoch: [15][3800/5595] Elapsed 20m 56s (remain 9m 53s) Loss avg.: 1.3854 Grad: 0.0077 LR: 0.00069  \n",
      "Epoch: [15][3900/5595] Elapsed 21m 29s (remain 9m 19s) Loss avg.: 1.3854 Grad: 0.0011 LR: 0.00069  \n",
      "Epoch: [15][4000/5595] Elapsed 22m 2s (remain 8m 46s) Loss avg.: 1.3854 Grad: 0.0010 LR: 0.00069  \n",
      "Epoch: [15][4100/5595] Elapsed 22m 35s (remain 8m 13s) Loss avg.: 1.3853 Grad: 0.0022 LR: 0.00069  \n",
      "Epoch: [15][4200/5595] Elapsed 23m 8s (remain 7m 40s) Loss avg.: 1.3853 Grad: 0.0035 LR: 0.00069  \n",
      "Epoch: [15][4300/5595] Elapsed 23m 41s (remain 7m 7s) Loss avg.: 1.3854 Grad: 0.0036 LR: 0.00069  \n",
      "Epoch: [15][4400/5595] Elapsed 24m 14s (remain 6m 34s) Loss avg.: 1.3853 Grad: 0.0036 LR: 0.00069  \n",
      "Epoch: [15][4500/5595] Elapsed 24m 47s (remain 6m 1s) Loss avg.: 1.3854 Grad: 0.0020 LR: 0.00069  \n",
      "Epoch: [15][4600/5595] Elapsed 25m 20s (remain 5m 28s) Loss avg.: 1.3854 Grad: 0.0024 LR: 0.00069  \n",
      "Epoch: [15][4700/5595] Elapsed 25m 53s (remain 4m 55s) Loss avg.: 1.3854 Grad: 0.0055 LR: 0.00069  \n",
      "Epoch: [15][4800/5595] Elapsed 26m 26s (remain 4m 22s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00069  \n",
      "Epoch: [15][4900/5595] Elapsed 26m 59s (remain 3m 49s) Loss avg.: 1.3853 Grad: 0.0013 LR: 0.00069  \n",
      "Epoch: [15][5000/5595] Elapsed 27m 32s (remain 3m 16s) Loss avg.: 1.3854 Grad: 0.0028 LR: 0.00069  \n",
      "Epoch: [15][5100/5595] Elapsed 28m 5s (remain 2m 43s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00069  \n",
      "Epoch: [15][5200/5595] Elapsed 28m 38s (remain 2m 10s) Loss avg.: 1.3854 Grad: 0.0014 LR: 0.00069  \n",
      "Epoch: [15][5300/5595] Elapsed 29m 12s (remain 1m 37s) Loss avg.: 1.3854 Grad: 0.0076 LR: 0.00069  \n",
      "Epoch: [15][5400/5595] Elapsed 29m 45s (remain 1m 4s) Loss avg.: 1.3853 Grad: 0.0019 LR: 0.00069  \n",
      "Epoch: [15][5500/5595] Elapsed 30m 18s (remain 0m 31s) Loss avg.: 1.3853 Grad: 0.0011 LR: 0.00069  \n",
      "Epoch: [15][5594/5595] Elapsed 30m 49s (remain 0m 0s) Loss avg.: 1.3853 Grad: 0.0042 LR: 0.00069  \n",
      "Eval: [0/622] Elapsed 0m 0s (remain 3m 34s) Loss avg.: 1.3848 \n",
      "Eval: [100/622] Elapsed 0m 12s (remain 1m 3s) Loss avg.: 1.3850 \n",
      "Eval: [200/622] Elapsed 0m 24s (remain 0m 51s) Loss avg.: 1.3852 \n",
      "Eval: [300/622] Elapsed 0m 36s (remain 0m 38s) Loss avg.: 1.3852 \n",
      "Eval: [400/622] Elapsed 0m 48s (remain 0m 26s) Loss avg.: 1.3853 \n",
      "Eval: [500/622] Elapsed 1m 0s (remain 0m 14s) Loss avg.: 1.3853 \n",
      "Eval: [600/622] Elapsed 1m 12s (remain 0m 2s) Loss avg.: 1.3853 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 - avg_train_loss: 1.3853  avg_val_loss: 1.3853  time: 1925s\n",
      "Epoch 15 - Accuracy: 0.2609185160404155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: [621/622] Elapsed 1m 14s (remain 0m 0s) Loss avg.: 1.3853 \n",
      "Epoch: [16][0/5595] Elapsed 0m 0s (remain 91m 27s) Loss avg.: 1.3852 Grad: 0.0013 LR: 0.00055  \n",
      "Epoch: [16][100/5595] Elapsed 0m 34s (remain 30m 53s) Loss avg.: 1.3856 Grad: 0.0024 LR: 0.00055  \n",
      "Epoch: [16][200/5595] Elapsed 1m 7s (remain 30m 6s) Loss avg.: 1.3854 Grad: 0.0050 LR: 0.00055  \n",
      "Epoch: [16][300/5595] Elapsed 1m 40s (remain 29m 27s) Loss avg.: 1.3854 Grad: 0.0027 LR: 0.00055  \n",
      "Epoch: [16][400/5595] Elapsed 2m 13s (remain 28m 49s) Loss avg.: 1.3854 Grad: 0.0029 LR: 0.00055  \n",
      "Epoch: [16][500/5595] Elapsed 2m 46s (remain 28m 13s) Loss avg.: 1.3854 Grad: 0.0031 LR: 0.00055  \n",
      "Epoch: [16][600/5595] Elapsed 3m 19s (remain 27m 39s) Loss avg.: 1.3854 Grad: 0.0014 LR: 0.00055  \n",
      "Epoch: [16][700/5595] Elapsed 3m 52s (remain 27m 4s) Loss avg.: 1.3853 Grad: 0.0039 LR: 0.00055  \n",
      "Epoch: [16][800/5595] Elapsed 4m 25s (remain 26m 30s) Loss avg.: 1.3853 Grad: 0.0036 LR: 0.00055  \n",
      "Epoch: [16][900/5595] Elapsed 4m 58s (remain 25m 56s) Loss avg.: 1.3853 Grad: 0.0009 LR: 0.00055  \n",
      "Epoch: [16][1000/5595] Elapsed 5m 31s (remain 25m 22s) Loss avg.: 1.3853 Grad: 0.0060 LR: 0.00055  \n",
      "Epoch: [16][1100/5595] Elapsed 6m 4s (remain 24m 49s) Loss avg.: 1.3854 Grad: 0.0054 LR: 0.00055  \n",
      "Epoch: [16][1200/5595] Elapsed 6m 38s (remain 24m 16s) Loss avg.: 1.3854 Grad: 0.0014 LR: 0.00055  \n",
      "Epoch: [16][1300/5595] Elapsed 7m 11s (remain 23m 43s) Loss avg.: 1.3854 Grad: 0.0034 LR: 0.00055  \n",
      "Epoch: [16][1400/5595] Elapsed 7m 44s (remain 23m 10s) Loss avg.: 1.3854 Grad: 0.0054 LR: 0.00055  \n",
      "Epoch: [16][1500/5595] Elapsed 8m 17s (remain 22m 37s) Loss avg.: 1.3854 Grad: 0.0026 LR: 0.00055  \n",
      "Epoch: [16][1600/5595] Elapsed 8m 51s (remain 22m 4s) Loss avg.: 1.3854 Grad: 0.0016 LR: 0.00055  \n",
      "Epoch: [16][1700/5595] Elapsed 9m 24s (remain 21m 31s) Loss avg.: 1.3854 Grad: 0.0031 LR: 0.00055  \n",
      "Epoch: [16][1800/5595] Elapsed 9m 57s (remain 20m 58s) Loss avg.: 1.3854 Grad: 0.0010 LR: 0.00055  \n",
      "Epoch: [16][1900/5595] Elapsed 10m 30s (remain 20m 25s) Loss avg.: 1.3854 Grad: 0.0040 LR: 0.00055  \n",
      "Epoch: [16][2000/5595] Elapsed 11m 3s (remain 19m 52s) Loss avg.: 1.3854 Grad: 0.0032 LR: 0.00055  \n",
      "Epoch: [16][2100/5595] Elapsed 11m 36s (remain 19m 18s) Loss avg.: 1.3854 Grad: 0.0016 LR: 0.00055  \n",
      "Epoch: [16][2200/5595] Elapsed 12m 10s (remain 18m 45s) Loss avg.: 1.3854 Grad: 0.0034 LR: 0.00055  \n",
      "Epoch: [16][2300/5595] Elapsed 12m 43s (remain 18m 12s) Loss avg.: 1.3854 Grad: 0.0054 LR: 0.00055  \n",
      "Epoch: [16][2400/5595] Elapsed 13m 16s (remain 17m 39s) Loss avg.: 1.3854 Grad: 0.0008 LR: 0.00055  \n",
      "Epoch: [16][2500/5595] Elapsed 13m 49s (remain 17m 6s) Loss avg.: 1.3854 Grad: 0.0020 LR: 0.00055  \n",
      "Epoch: [16][2600/5595] Elapsed 14m 23s (remain 16m 33s) Loss avg.: 1.3853 Grad: 0.0069 LR: 0.00055  \n",
      "Epoch: [16][2700/5595] Elapsed 14m 56s (remain 16m 0s) Loss avg.: 1.3854 Grad: 0.0033 LR: 0.00055  \n",
      "Epoch: [16][2800/5595] Elapsed 15m 29s (remain 15m 26s) Loss avg.: 1.3854 Grad: 0.0020 LR: 0.00055  \n",
      "Epoch: [16][2900/5595] Elapsed 16m 2s (remain 14m 53s) Loss avg.: 1.3854 Grad: 0.0011 LR: 0.00055  \n",
      "Epoch: [16][3000/5595] Elapsed 16m 35s (remain 14m 20s) Loss avg.: 1.3854 Grad: 0.0015 LR: 0.00055  \n",
      "Epoch: [16][3100/5595] Elapsed 17m 8s (remain 13m 47s) Loss avg.: 1.3854 Grad: 0.0026 LR: 0.00055  \n",
      "Epoch: [16][3200/5595] Elapsed 17m 41s (remain 13m 14s) Loss avg.: 1.3854 Grad: 0.0022 LR: 0.00055  \n",
      "Epoch: [16][3300/5595] Elapsed 18m 15s (remain 12m 41s) Loss avg.: 1.3854 Grad: 0.0031 LR: 0.00055  \n",
      "Epoch: [16][3400/5595] Elapsed 18m 48s (remain 12m 7s) Loss avg.: 1.3854 Grad: 0.0043 LR: 0.00055  \n",
      "Epoch: [16][3500/5595] Elapsed 19m 21s (remain 11m 34s) Loss avg.: 1.3854 Grad: 0.0063 LR: 0.00055  \n",
      "Epoch: [16][3600/5595] Elapsed 19m 54s (remain 11m 1s) Loss avg.: 1.3854 Grad: 0.0036 LR: 0.00055  \n",
      "Epoch: [16][3700/5595] Elapsed 20m 27s (remain 10m 28s) Loss avg.: 1.3854 Grad: 0.0013 LR: 0.00055  \n",
      "Epoch: [16][3800/5595] Elapsed 21m 1s (remain 9m 55s) Loss avg.: 1.3854 Grad: 0.0043 LR: 0.00055  \n",
      "Epoch: [16][3900/5595] Elapsed 21m 34s (remain 9m 22s) Loss avg.: 1.3854 Grad: 0.0015 LR: 0.00055  \n",
      "Epoch: [16][4000/5595] Elapsed 22m 7s (remain 8m 48s) Loss avg.: 1.3854 Grad: 0.0040 LR: 0.00055  \n",
      "Epoch: [16][4100/5595] Elapsed 22m 40s (remain 8m 15s) Loss avg.: 1.3854 Grad: 0.0049 LR: 0.00055  \n",
      "Epoch: [16][4200/5595] Elapsed 23m 13s (remain 7m 42s) Loss avg.: 1.3854 Grad: 0.0016 LR: 0.00055  \n",
      "Epoch: [16][4300/5595] Elapsed 23m 46s (remain 7m 9s) Loss avg.: 1.3854 Grad: 0.0012 LR: 0.00055  \n",
      "Epoch: [16][4400/5595] Elapsed 24m 19s (remain 6m 35s) Loss avg.: 1.3854 Grad: 0.0044 LR: 0.00055  \n",
      "Epoch: [16][4500/5595] Elapsed 24m 52s (remain 6m 2s) Loss avg.: 1.3854 Grad: 0.0030 LR: 0.00055  \n",
      "Epoch: [16][4600/5595] Elapsed 25m 25s (remain 5m 29s) Loss avg.: 1.3854 Grad: 0.0016 LR: 0.00055  \n",
      "Epoch: [16][4700/5595] Elapsed 25m 58s (remain 4m 56s) Loss avg.: 1.3854 Grad: 0.0075 LR: 0.00055  \n",
      "Epoch: [16][4800/5595] Elapsed 26m 31s (remain 4m 23s) Loss avg.: 1.3854 Grad: 0.0011 LR: 0.00055  \n",
      "Epoch: [16][4900/5595] Elapsed 27m 4s (remain 3m 50s) Loss avg.: 1.3853 Grad: 0.0033 LR: 0.00055  \n",
      "Epoch: [16][5000/5595] Elapsed 27m 37s (remain 3m 16s) Loss avg.: 1.3853 Grad: 0.0053 LR: 0.00055  \n",
      "Epoch: [16][5100/5595] Elapsed 28m 11s (remain 2m 43s) Loss avg.: 1.3853 Grad: 0.0012 LR: 0.00055  \n",
      "Epoch: [16][5200/5595] Elapsed 28m 44s (remain 2m 10s) Loss avg.: 1.3853 Grad: 0.0018 LR: 0.00055  \n",
      "Epoch: [16][5300/5595] Elapsed 29m 17s (remain 1m 37s) Loss avg.: 1.3853 Grad: 0.0026 LR: 0.00055  \n",
      "Epoch: [16][5400/5595] Elapsed 29m 50s (remain 1m 4s) Loss avg.: 1.3853 Grad: 0.0008 LR: 0.00055  \n",
      "Epoch: [16][5500/5595] Elapsed 30m 23s (remain 0m 31s) Loss avg.: 1.3853 Grad: 0.0052 LR: 0.00055  \n",
      "Epoch: [16][5594/5595] Elapsed 30m 55s (remain 0m 0s) Loss avg.: 1.3853 Grad: 0.0032 LR: 0.00055  \n",
      "Eval: [0/622] Elapsed 0m 0s (remain 3m 40s) Loss avg.: 1.3848 \n",
      "Eval: [100/622] Elapsed 0m 12s (remain 1m 3s) Loss avg.: 1.3850 \n",
      "Eval: [200/622] Elapsed 0m 24s (remain 0m 51s) Loss avg.: 1.3852 \n",
      "Eval: [300/622] Elapsed 0m 36s (remain 0m 38s) Loss avg.: 1.3852 \n",
      "Eval: [400/622] Elapsed 0m 48s (remain 0m 26s) Loss avg.: 1.3853 \n",
      "Eval: [500/622] Elapsed 1m 0s (remain 0m 14s) Loss avg.: 1.3853 \n",
      "Eval: [600/622] Elapsed 1m 12s (remain 0m 2s) Loss avg.: 1.3853 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 - avg_train_loss: 1.3853  avg_val_loss: 1.3853  time: 1930s\n",
      "Epoch 16 - Accuracy: 0.26092012442460055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: [621/622] Elapsed 1m 14s (remain 0m 0s) Loss avg.: 1.3853 \n",
      "Epoch: [17][0/5595] Elapsed 0m 0s (remain 91m 42s) Loss avg.: 1.3867 Grad: 0.0023 LR: 0.00041  \n",
      "Epoch: [17][100/5595] Elapsed 0m 34s (remain 30m 51s) Loss avg.: 1.3854 Grad: 0.0027 LR: 0.00041  \n",
      "Epoch: [17][200/5595] Elapsed 1m 7s (remain 30m 1s) Loss avg.: 1.3854 Grad: 0.0014 LR: 0.00041  \n",
      "Epoch: [17][300/5595] Elapsed 1m 40s (remain 29m 24s) Loss avg.: 1.3855 Grad: 0.0015 LR: 0.00041  \n",
      "Epoch: [17][400/5595] Elapsed 2m 13s (remain 28m 48s) Loss avg.: 1.3855 Grad: 0.0025 LR: 0.00041  \n",
      "Epoch: [17][500/5595] Elapsed 2m 46s (remain 28m 14s) Loss avg.: 1.3854 Grad: 0.0035 LR: 0.00041  \n",
      "Epoch: [17][600/5595] Elapsed 3m 19s (remain 27m 40s) Loss avg.: 1.3854 Grad: 0.0037 LR: 0.00041  \n",
      "Epoch: [17][700/5595] Elapsed 3m 53s (remain 27m 6s) Loss avg.: 1.3854 Grad: 0.0027 LR: 0.00041  \n",
      "Epoch: [17][800/5595] Elapsed 4m 26s (remain 26m 33s) Loss avg.: 1.3854 Grad: 0.0033 LR: 0.00041  \n",
      "Epoch: [17][900/5595] Elapsed 4m 59s (remain 26m 0s) Loss avg.: 1.3854 Grad: 0.0022 LR: 0.00041  \n",
      "Epoch: [17][1000/5595] Elapsed 5m 32s (remain 25m 26s) Loss avg.: 1.3854 Grad: 0.0006 LR: 0.00041  \n",
      "Epoch: [17][1100/5595] Elapsed 6m 5s (remain 24m 53s) Loss avg.: 1.3854 Grad: 0.0039 LR: 0.00041  \n",
      "Epoch: [17][1200/5595] Elapsed 6m 39s (remain 24m 19s) Loss avg.: 1.3854 Grad: 0.0013 LR: 0.00041  \n",
      "Epoch: [17][1300/5595] Elapsed 7m 12s (remain 23m 46s) Loss avg.: 1.3854 Grad: 0.0034 LR: 0.00041  \n",
      "Epoch: [17][1400/5595] Elapsed 7m 45s (remain 23m 13s) Loss avg.: 1.3853 Grad: 0.0069 LR: 0.00041  \n",
      "Epoch: [17][1500/5595] Elapsed 8m 18s (remain 22m 40s) Loss avg.: 1.3853 Grad: 0.0016 LR: 0.00041  \n",
      "Epoch: [17][1600/5595] Elapsed 8m 51s (remain 22m 6s) Loss avg.: 1.3853 Grad: 0.0019 LR: 0.00041  \n",
      "Epoch: [17][1700/5595] Elapsed 9m 25s (remain 21m 33s) Loss avg.: 1.3853 Grad: 0.0020 LR: 0.00041  \n",
      "Epoch: [17][1800/5595] Elapsed 9m 57s (remain 20m 59s) Loss avg.: 1.3853 Grad: 0.0025 LR: 0.00041  \n",
      "Epoch: [17][1900/5595] Elapsed 10m 30s (remain 20m 25s) Loss avg.: 1.3853 Grad: 0.0010 LR: 0.00041  \n",
      "Epoch: [17][2000/5595] Elapsed 11m 4s (remain 19m 52s) Loss avg.: 1.3853 Grad: 0.0041 LR: 0.00041  \n",
      "Epoch: [17][2100/5595] Elapsed 11m 36s (remain 19m 19s) Loss avg.: 1.3853 Grad: 0.0012 LR: 0.00041  \n",
      "Epoch: [17][2200/5595] Elapsed 12m 9s (remain 18m 45s) Loss avg.: 1.3853 Grad: 0.0041 LR: 0.00041  \n",
      "Epoch: [17][2300/5595] Elapsed 12m 43s (remain 18m 12s) Loss avg.: 1.3853 Grad: 0.0017 LR: 0.00041  \n",
      "Epoch: [17][2400/5595] Elapsed 13m 16s (remain 17m 39s) Loss avg.: 1.3853 Grad: 0.0052 LR: 0.00041  \n",
      "Epoch: [17][2500/5595] Elapsed 13m 49s (remain 17m 6s) Loss avg.: 1.3853 Grad: 0.0004 LR: 0.00041  \n",
      "Epoch: [17][2600/5595] Elapsed 14m 22s (remain 16m 33s) Loss avg.: 1.3853 Grad: 0.0079 LR: 0.00041  \n",
      "Epoch: [17][2700/5595] Elapsed 14m 55s (remain 15m 59s) Loss avg.: 1.3853 Grad: 0.0010 LR: 0.00041  \n",
      "Epoch: [17][2800/5595] Elapsed 15m 29s (remain 15m 26s) Loss avg.: 1.3853 Grad: 0.0045 LR: 0.00041  \n",
      "Epoch: [17][2900/5595] Elapsed 16m 2s (remain 14m 53s) Loss avg.: 1.3853 Grad: 0.0038 LR: 0.00041  \n",
      "Epoch: [17][3000/5595] Elapsed 16m 35s (remain 14m 20s) Loss avg.: 1.3853 Grad: 0.0022 LR: 0.00041  \n",
      "Epoch: [17][3100/5595] Elapsed 17m 8s (remain 13m 47s) Loss avg.: 1.3853 Grad: 0.0027 LR: 0.00041  \n",
      "Epoch: [17][3200/5595] Elapsed 17m 41s (remain 13m 14s) Loss avg.: 1.3853 Grad: 0.0047 LR: 0.00041  \n",
      "Epoch: [17][3300/5595] Elapsed 18m 15s (remain 12m 41s) Loss avg.: 1.3853 Grad: 0.0018 LR: 0.00041  \n",
      "Epoch: [17][3400/5595] Elapsed 18m 48s (remain 12m 7s) Loss avg.: 1.3853 Grad: 0.0041 LR: 0.00041  \n",
      "Epoch: [17][3500/5595] Elapsed 19m 21s (remain 11m 34s) Loss avg.: 1.3853 Grad: 0.0015 LR: 0.00041  \n",
      "Epoch: [17][3600/5595] Elapsed 19m 54s (remain 11m 1s) Loss avg.: 1.3853 Grad: 0.0023 LR: 0.00041  \n",
      "Epoch: [17][3700/5595] Elapsed 20m 27s (remain 10m 28s) Loss avg.: 1.3853 Grad: 0.0008 LR: 0.00041  \n",
      "Epoch: [17][3800/5595] Elapsed 21m 0s (remain 9m 55s) Loss avg.: 1.3853 Grad: 0.0025 LR: 0.00041  \n",
      "Epoch: [17][3900/5595] Elapsed 21m 34s (remain 9m 21s) Loss avg.: 1.3853 Grad: 0.0030 LR: 0.00041  \n",
      "Epoch: [17][4000/5595] Elapsed 22m 7s (remain 8m 48s) Loss avg.: 1.3853 Grad: 0.0034 LR: 0.00041  \n",
      "Epoch: [17][4100/5595] Elapsed 22m 40s (remain 8m 15s) Loss avg.: 1.3853 Grad: 0.0065 LR: 0.00041  \n",
      "Epoch: [17][4200/5595] Elapsed 23m 13s (remain 7m 42s) Loss avg.: 1.3853 Grad: 0.0016 LR: 0.00041  \n",
      "Epoch: [17][4300/5595] Elapsed 23m 46s (remain 7m 9s) Loss avg.: 1.3853 Grad: 0.0028 LR: 0.00041  \n",
      "Epoch: [17][4400/5595] Elapsed 24m 19s (remain 6m 36s) Loss avg.: 1.3853 Grad: 0.0048 LR: 0.00041  \n",
      "Epoch: [17][4500/5595] Elapsed 24m 52s (remain 6m 2s) Loss avg.: 1.3854 Grad: 0.0006 LR: 0.00041  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-972361fa1b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-1e7be3dde8e5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0moof_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0m_oof_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0moof_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_oof_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"========== fold: {fold} result ==========\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-b52b8aa7019f>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(folds, fold)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-9ec910462f8c>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, scheduler, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/pytorch/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/pytorch/.venv/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/pytorch/.venv/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/pytorch/.venv/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.8/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.8/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "hungry-geese-train-by-episode.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2945.71762,
   "end_time": "2021-05-12T03:50:02.012348",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-12T03:00:56.294728",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04a486aa6f454d8f92e388dba1b9ee21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0857c0fa22b544488d65bb2c7dad18ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f905db5005be40b194ea150c8b0deb9f",
      "max": 1001,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "value": 1001
     }
    },
    "4134662bdbe04a918d9809632e268ef8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0857c0fa22b544488d65bb2c7dad18ee",
       "IPY_MODEL_e33e4f894b424988b316c468bc9225ce"
      ],
      "layout": "IPY_MODEL_8ddb49ac3c91409f99a569a061a70b3d"
     }
    },
    "507d2b6a02bb43d0bb4c8c2734f19cbb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ddb49ac3c91409f99a569a061a70b3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c96b7bfbdf0243a8ae1dbb3d9aedf123": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e33e4f894b424988b316c468bc9225ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_507d2b6a02bb43d0bb4c8c2734f19cbb",
      "placeholder": "​",
      "style": "IPY_MODEL_04a486aa6f454d8f92e388dba1b9ee21",
      "value": " 1001/1001 [03:35&lt;00:00,  4.64it/s]"
     }
    },
    "f905db5005be40b194ea150c8b0deb9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abroad-piece",
    "papermill": {
     "duration": 0.025714,
     "end_time": "2021-05-12T03:01:02.640708",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.614994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About this notebook ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pressing-commercial",
    "papermill": {
     "duration": 0.024272,
     "end_time": "2021-05-12T03:01:02.689850",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.665578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "german-ethics",
    "papermill": {
     "duration": 1.852306,
     "end_time": "2021-05-12T03:01:04.566362",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.714056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "apparent-fiction",
    "papermill": {
     "duration": 0.030961,
     "end_time": "2021-05-12T03:01:04.622818",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.591857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "editorial-haiti",
    "papermill": {
     "duration": 0.024908,
     "end_time": "2021-05-12T03:01:05.115280",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.090372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "opened-python",
    "papermill": {
     "duration": 0.035637,
     "end_time": "2021-05-12T03:01:05.176119",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.140482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 440\n",
    "\n",
    "    n_class = 4\n",
    "    n_fold = 10\n",
    "\n",
    "    geese_net_layers = 12\n",
    "    geese_net_filters = 64\n",
    "\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "\n",
    "    num_workers = 4\n",
    "    batch_size = 3200\n",
    "\n",
    "    scheduler = \"CosineAnnealingWarmRestarts\"\n",
    "    # factor = 0.2  # ReduceLROnPlateau\n",
    "    # patience = 4  # ReduceLROnPlateau\n",
    "    # eps = 1e-6  # ReduceLROnPlateau\n",
    "    # T_max = 10  # CosineAnnealingLR\n",
    "    T_0 = 10  # CosineAnnealingWarmRestarts\n",
    "\n",
    "    criterion = \"CrossEntropyLoss\"\n",
    "    lr = 1e-3\n",
    "    min_lr = 1e-4\n",
    "    weight_decay = 1e-5\n",
    "\n",
    "    epochs = 10\n",
    "    model_name = \"geese_net\"\n",
    "    pre_train_file = \"geese_net_fold0_best_64_bbe3e7ad850239e497e7b15eb2c6caaf2fe33938.pth\"\n",
    "\n",
    "    print_freq = 100\n",
    "\n",
    "    train = True\n",
    "    tuning = False\n",
    "    debug = False\n",
    "    apex = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "contained-singles",
    "papermill": {
     "duration": 0.031266,
     "end_time": "2021-05-12T03:01:05.235456",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.204190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.tuning:\n",
    "    Config.epochs = 2\n",
    "\n",
    "if Config.debug:\n",
    "    Config.epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dietary-track",
    "papermill": {
     "duration": 0.031421,
     "end_time": "2021-05-12T03:01:05.292382",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.260961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.apex:\n",
    "    from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "invalid-dispute",
    "papermill": {
     "duration": 0.169531,
     "end_time": "2021-05-12T03:01:05.488665",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.319134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robust-humanity",
    "papermill": {
     "duration": 0.024539,
     "end_time": "2021-05-12T03:01:04.672270",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.647731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "designed-effect",
    "papermill": {
     "duration": 0.031167,
     "end_time": "2021-05-12T03:01:04.728079",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.696912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"../input/hungrygeeseepisode/hungry-geese-episode/\"\n",
    "OUTPUT_DIR = \"pre-models/\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "special-broadcast",
    "outputId": "c440e1e9-5651-42ee-eb0f-08c822d7471a",
    "papermill": {
     "duration": 0.31211,
     "end_time": "2021-05-12T03:01:05.064722",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.752612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18380\n"
     ]
    }
   ],
   "source": [
    "paths = [path for path in glob.glob(BASE_DIR + \"*.json\") if \"info\" not in path]\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n"
     ]
    }
   ],
   "source": [
    "# fit for memory size...\n",
    "paths = paths[-11000:]\n",
    "# paths = paths[:-11000]\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    paths = paths[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "treated-serum",
    "papermill": {
     "duration": 0.025219,
     "end_time": "2021-05-12T03:01:05.539482",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.514263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gothic-alloy",
    "papermill": {
     "duration": 0.070842,
     "end_time": "2021-05-12T03:01:05.642364",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.571522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=Config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "experienced-correspondence",
    "papermill": {
     "duration": 0.053842,
     "end_time": "2021-05-12T03:01:05.741858",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.688016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reverse_ns(y):\n",
    "    if y == 0:\n",
    "        return 1\n",
    "    if y == 1:\n",
    "        return 0\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_we(y):\n",
    "    if y == 2:\n",
    "        return 3\n",
    "    if y == 3:\n",
    "        return 2\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_nswe(y):\n",
    "    return reverse_ns(reverse_we(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "further-transaction",
    "papermill": {
     "duration": 0.042365,
     "end_time": "2021-05-12T03:01:05.826807",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.784442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_position_map = {}\n",
    "for pos in range(77):\n",
    "    position = []\n",
    "    position.append((11 * (1 + pos // 11) + pos % 11) % 77)\n",
    "    position.append((11 * (-1 + pos // 11) + pos % 11) % 77)\n",
    "    position.append((11 * (pos // 11) + (pos + 1) % 11) % 77)\n",
    "    position.append((11 * (pos // 11) + (pos - 1) % 11) % 77)\n",
    "    next_position_map[pos] = set(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "naughty-clause",
    "papermill": {
     "duration": 0.058537,
     "end_time": "2021-05-12T03:01:05.928292",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.869755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_input(obses):\n",
    "    b = np.zeros((17, 7 * 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "        pid = (p - obs[\"index\"]) % 4\n",
    "\n",
    "        # head position\n",
    "        for pos in pos_list[:1]:\n",
    "            b[0 + pid, pos] = 1\n",
    "        # tip position\n",
    "        for pos in pos_list[-1:]:\n",
    "            b[4 + pid, pos] = 1\n",
    "        # whole position\n",
    "        for pos in pos_list:\n",
    "            b[8 + pid, pos] = 1\n",
    "\n",
    "    # previous head position\n",
    "    if len(obses) > 1:\n",
    "        obs_prev = obses[-2]\n",
    "        for p, pos_list in enumerate(obs_prev[\"geese\"]):\n",
    "            for pos in pos_list[:1]:\n",
    "                b[12 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    # food\n",
    "    for pos in obs[\"food\"]:\n",
    "        b[16, pos] = 1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reverse_cube(obses):\n",
    "    \"\"\"\n",
    "    尻尾から順番に 1, 0.9, 0.8, ... という並び\n",
    "    \"\"\"\n",
    "    b = np.zeros((4, 7 * 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, geese in enumerate(obs[\"geese\"]):\n",
    "        # whole position reverse\n",
    "        for num_reverse, pos in enumerate(geese[::-1]):\n",
    "            b[(p - obs[\"index\"]) % 4, pos] = 1 - num_reverse * 0.1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_disappear_cube(obses):\n",
    "    \"\"\"\n",
    "    次になくなる場所: 1\n",
    "    次になくなる可能性のある場所: 0.5\n",
    "    \"\"\"\n",
    "    b = np.zeros((4, 7 * 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "    step = obs[\"step\"]\n",
    "\n",
    "    # foodを食べる可能性があるか。\n",
    "    eat_food_possibility = defaultdict(int)\n",
    "    for p, geese in enumerate(obs[\"geese\"]):\n",
    "        for pos in geese[:1]:\n",
    "            if not next_position_map[pos].isdisjoint(obs[\"food\"]):\n",
    "                eat_food_possibility[p] = 1\n",
    "\n",
    "    if (step % 40) == 39:  # 1つ短くなる\n",
    "        for p, geese in enumerate(obs[\"geese\"]):\n",
    "            if eat_food_possibility[p]:  # 尻尾が1、尻尾の１つ前0.5\n",
    "                for pos in geese[-1:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 1\n",
    "                for pos in geese[-2:-1]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 0.5\n",
    "            else:  # 食べる可能性なし -> 尻尾が1, 尻尾の1つ前1\n",
    "                for pos in geese[-2:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 1\n",
    "    else:  # 1つ短くならない\n",
    "        for p, geese in enumerate(obs[\"geese\"]):\n",
    "            if eat_food_possibility[p]:  # 食べる可能性があり -> 尻尾を0.5\n",
    "                for pos in geese[-1:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 0.5\n",
    "            else:  # 食べる可能性なし # 尻尾を1\n",
    "                for pos in geese[-1:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_step_cube_v2(obses):\n",
    "    \"\"\"\n",
    "    step0: 0, step199: 1\n",
    "    step0: 0, step39 + 40n: 1\n",
    "    \"\"\"\n",
    "    b = np.zeros((1, 7, 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "    step = obs[\"step\"]\n",
    "\n",
    "    b[:, :, :5] = (step % 200) / 199\n",
    "    b[:, :, 5:] = (step % 40) / 39\n",
    "\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_cube(obses):\n",
    "    b = np.zeros((2, 7, 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    my_length = len(obs[\"geese\"][obs[\"index\"]])\n",
    "    opposite1_length = len(obs[\"geese\"][(obs[\"index\"] + 1) % 4])\n",
    "    opposite2_length = len(obs[\"geese\"][(obs[\"index\"] + 2) % 4])\n",
    "    opposite3_length = len(obs[\"geese\"][(obs[\"index\"] + 3) % 4])\n",
    "\n",
    "    b[0] = my_length / 10\n",
    "    max_opposite_length = max(opposite1_length, opposite2_length, opposite3_length)\n",
    "    b[1, :, 0:2] = (my_length - max_opposite_length) / 10\n",
    "    b[1, :, 2:5] = (my_length - opposite1_length) / 10\n",
    "    b[1, :, 5:8] = (my_length - opposite2_length) / 10\n",
    "    b[1, :, 8:11] = (my_length - opposite3_length) / 10\n",
    "\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pretty-aaron",
    "papermill": {
     "duration": 0.042985,
     "end_time": "2021-05-12T03:01:06.014038",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.971053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "international-secret",
    "papermill": {
     "duration": 0.064855,
     "end_time": "2021-05-12T03:01:06.121648",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.056793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset_from_json(filepath, json_object=None, standing=0):\n",
    "    if json_object is None:\n",
    "        json_open = open(path, \"r\")\n",
    "        json_load = json.load(json_open)\n",
    "    else:\n",
    "        json_load = json_object\n",
    "\n",
    "    try:\n",
    "        winner_index = np.argmax(np.argsort(json_load[\"rewards\"]) == 3 - standing)\n",
    "\n",
    "        obses = []\n",
    "        X = []\n",
    "        y = []\n",
    "        actions = {\"NORTH\": 0, \"SOUTH\": 1, \"WEST\": 2, \"EAST\": 3}\n",
    "\n",
    "        for i in range(len(json_load[\"steps\"]) - 1):\n",
    "            if json_load[\"steps\"][i][winner_index][\"status\"] == \"ACTIVE\":\n",
    "                y_ = json_load[\"steps\"][i + 1][winner_index][\"action\"]\n",
    "                if y_ is not None:\n",
    "                    step = json_load[\"steps\"][i]\n",
    "                    step[winner_index][\"observation\"][\"geese\"] = step[0][\"observation\"][\"geese\"]\n",
    "                    step[winner_index][\"observation\"][\"food\"] = step[0][\"observation\"][\"food\"]\n",
    "                    step[winner_index][\"observation\"][\"step\"] = step[0][\"observation\"][\"step\"]\n",
    "                    obses.append(step[winner_index][\"observation\"])\n",
    "                    y.append(actions[y_])\n",
    "\n",
    "                    y.append(reverse_ns(actions[y_]))  # 上下反転\n",
    "                    y.append(reverse_we(actions[y_]))  # 左右反転\n",
    "                    y.append(reverse_nswe(actions[y_]))  # 上下左右反転\n",
    "\n",
    "        for j in range(len(obses)):\n",
    "            # X_ = make_input(obses[: j + 1])\n",
    "\n",
    "            X_ = []\n",
    "            X_.append(make_input(obses[: j + 1]))\n",
    "            X_.append(get_reverse_cube(obses[: j + 1]))\n",
    "            X_.append(get_next_disappear_cube(obses[: j + 1]))\n",
    "            X_.append(get_step_cube_v2(obses[: j + 1]))\n",
    "            X_.append(get_length_cube(obses[: j + 1]))\n",
    "            X_ = np.concatenate(X_)\n",
    "\n",
    "            X.append(X_)\n",
    "\n",
    "            X.append(X_[:, ::-1, :])  # 上下反転\n",
    "            X.append(X_[:, :, ::-1])  # 左右反転\n",
    "            X.append(X_[:, ::-1, ::-1])  # 上下左右反転\n",
    "\n",
    "        X = np.array(X, dtype=np.float16)  # [starting_step:]\n",
    "        y = np.array(y, dtype=np.uint8)  # [starting_step:]\n",
    "\n",
    "        return X, y\n",
    "    except Exception as e:\n",
    "        # raise Exception from e\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "4134662bdbe04a918d9809632e268ef8",
      "8ddb49ac3c91409f99a569a061a70b3d",
      "0857c0fa22b544488d65bb2c7dad18ee",
      "e33e4f894b424988b316c468bc9225ce",
      "c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "f905db5005be40b194ea150c8b0deb9f",
      "04a486aa6f454d8f92e388dba1b9ee21",
      "507d2b6a02bb43d0bb4c8c2734f19cbb"
     ]
    },
    "id": "handled-pleasure",
    "outputId": "955c1c6b-36bc-4b30-dc44-b72b05398f8c",
    "papermill": {
     "duration": 15.320591,
     "end_time": "2021-05-12T03:01:21.474816",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.154225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488f825897e64854b6a6f9f6572932a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num episode: 6885564\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for path in tqdm(paths[: int(len(paths))]):\n",
    "    X, y = create_dataset_from_json(path, standing=0)  # use only winners' moves\n",
    "    if X is not 0:\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "persistent-loading",
    "papermill": {
     "duration": 112.92618,
     "end_time": "2021-05-12T03:03:14.428162",
     "exception": false,
     "start_time": "2021-05-12T03:01:21.501982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# X_train, unique_index = np.unique(X_train, axis=0, return_index=True)  # remove duplicate\n",
    "# y_train = y_train[unique_index]\n",
    "\n",
    "# y_train = np.eye(4, dtype=\"uint8\")[y_train]  # to categorical\n",
    "\n",
    "# print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_:\n",
    "    X_train_sum_obs = X_train.reshape(X_train.shape[0], -1).sum(1)\n",
    "    X_train_group = np.unique(X_train_sum_obs)\n",
    "    X_train_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_:\n",
    "    X_train_unique = []\n",
    "    y_train_unique = []\n",
    "    for group in tqdm(X_train_group):\n",
    "        group_index = np.where(X_train_sum_obs == group)\n",
    "\n",
    "        X_train_ = X_train[group_index]\n",
    "        y_train_ = y_train[group_index]\n",
    "\n",
    "        X_train_, unique_index = np.unique(X_train_, axis=0, return_index=True)  # remove duplicate\n",
    "        y_train_ = y_train_[unique_index]\n",
    "\n",
    "        X_train_unique.append(X_train_)\n",
    "        y_train_unique.append(y_train_)\n",
    "\n",
    "    X_train = np.concatenate(X_train_unique)\n",
    "    y_train = np.concatenate(y_train_unique)\n",
    "\n",
    "    print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_:\n",
    "    del X_train_sum_obs\n",
    "    del X_train_group\n",
    "    del X_train_unique\n",
    "    del y_train_unique\n",
    "    del X_train_\n",
    "    del y_train_\n",
    "    del group_index\n",
    "    del unique_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "micro-french",
    "papermill": {
     "duration": 0.033413,
     "end_time": "2021-05-12T03:03:15.360395",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.326982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    X_train = X_train[:1000]\n",
    "    y_train = y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "wrong-pastor",
    "outputId": "406a2f1d-0b8a-46bf-ca01-546f3110c301",
    "papermill": {
     "duration": 0.036161,
     "end_time": "2021-05-12T03:03:15.425149",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.388988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6885559</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6885560</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6885561</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6885562</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6885563</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6885564 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         action\n",
       "0             1\n",
       "1             0\n",
       "2             1\n",
       "3             0\n",
       "4             2\n",
       "...         ...\n",
       "6885559       3\n",
       "6885560       1\n",
       "6885561       0\n",
       "6885562       1\n",
       "6885563       0\n",
       "\n",
       "[6885564 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(y_train, dtype=np.uint8)\n",
    "y_df.columns = [\"action\"]\n",
    "y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "touched-coordinate",
    "papermill": {
     "duration": 0.027968,
     "end_time": "2021-05-12T03:03:15.557122",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.529154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "moving-skill",
    "outputId": "7542c4b4-f7d3-444c-8450-50bffddb1892",
    "papermill": {
     "duration": 0.202337,
     "end_time": "2021-05-12T03:03:15.787529",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.585192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  action\n",
      "0     0         164414\n",
      "      1         164414\n",
      "      2         179864\n",
      "      3         179865\n",
      "1     0         164414\n",
      "      1         164414\n",
      "      2         179864\n",
      "      3         179865\n",
      "2     0         164413\n",
      "      1         164414\n",
      "      2         179865\n",
      "      3         179865\n",
      "3     0         164413\n",
      "      1         164414\n",
      "      2         179865\n",
      "      3         179865\n",
      "4     0         164413\n",
      "      1         164414\n",
      "      2         179865\n",
      "      3         179864\n",
      "5     0         164413\n",
      "      1         164414\n",
      "      2         179865\n",
      "      3         179864\n",
      "6     0         164414\n",
      "      1         164413\n",
      "      2         179865\n",
      "      3         179864\n",
      "7     0         164414\n",
      "      1         164413\n",
      "      2         179865\n",
      "      3         179864\n",
      "8     0         164414\n",
      "      1         164413\n",
      "      2         179864\n",
      "      3         179865\n",
      "9     0         164414\n",
      "      1         164413\n",
      "      2         179864\n",
      "      3         179865\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "folds = y_df.copy()\n",
    "Fold = StratifiedKFold(n_splits=Config.n_fold, shuffle=True, random_state=Config.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[\"action\"])):\n",
    "    folds.loc[val_index, \"fold\"] = int(n)\n",
    "folds[\"fold\"] = folds[\"fold\"].astype(np.uint8)\n",
    "print(folds.groupby([\"fold\", \"action\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "creative-football",
    "papermill": {
     "duration": 0.029031,
     "end_time": "2021-05-12T03:03:15.845114",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.816083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "other-murder",
    "papermill": {
     "duration": 0.037264,
     "end_time": "2021-05-12T03:03:15.911219",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.873955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, array, label):\n",
    "        self.array = array\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx], torch.tensor(self.label[idx]).long()\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, array):\n",
    "        self.array = array\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adjusted-delhi",
    "outputId": "39504950-84bc-4692-8b90-8a5b64f741e0",
    "papermill": {
     "duration": 0.063691,
     "end_time": "2021-05-12T03:03:16.003693",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.940002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "if Config.debug or False:\n",
    "    train_ds = TrainDataset(X_train, y_train)\n",
    "\n",
    "    for i in range(1):\n",
    "        obs, action = train_ds[i]\n",
    "        print(obs.shape, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceramic-startup",
    "papermill": {
     "duration": 0.02876,
     "end_time": "2021-05-12T03:03:16.061575",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.032815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "unique-trick",
    "papermill": {
     "duration": 0.039055,
     "end_time": "2021-05-12T03:03:16.130239",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.091184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TorusConv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
    "        super().__init__()\n",
    "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([x[:, :, :, -self.edge_size[1] :], x, x[:, :, :, : self.edge_size[1]]], dim=3)\n",
    "        h = torch.cat([h[:, :, -self.edge_size[0] :], h, h[:, :, : self.edge_size[0]]], dim=2)\n",
    "        h = self.conv(h)\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "jspEE71c2Yma"
   },
   "outputs": [],
   "source": [
    "class GeeseNetAlpha(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = Config.geese_net_layers\n",
    "        filters = Config.geese_net_filters\n",
    "\n",
    "        self.conv0 = TorusConv2d(28, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p1 = nn.Linear(filters * 5 + 77, filters * 3, bias=False)\n",
    "        self.head_p2 = nn.Linear(filters * 3, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(filters * 5 + 77, filters * 3, bias=False)\n",
    "        self.head_v2 = nn.Linear(filters * 3, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h_p = F.relu_(self.conv_p(h))\n",
    "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p2 = (h_p * x[:, 1:2]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p3 = (h_p * x[:, 2:3]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p4 = (h_p * x[:, 3:4]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_avg_p1 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(-1)\n",
    "        h_avg_p2 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(1)\n",
    "\n",
    "        h_p = F.relu_(self.head_p1(torch.cat([h_head_p, h_head_p2, h_head_p3, h_head_p4, h_avg_p1, h_avg_p2], 1)))\n",
    "        p = self.head_p2(h_p)\n",
    "\n",
    "        h_v = F.relu_(self.conv_v(h))\n",
    "        h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_head_v2 = (h_v * x[:, 1:2]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_head_v3 = (h_v * x[:, 2:3]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_head_v4 = (h_v * x[:, 3:4]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_avg_v1 = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
    "        h_avg_v2 = h_v.view(h_v.size(0), h_v.size(1), -1).mean(1)\n",
    "\n",
    "        h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_head_v2, h_head_v3, h_head_v4, h_avg_v1, h_avg_v2], 1)))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p, \"value\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "objective-victoria",
    "outputId": "1ab137a5-e26e-4b9c-ff85-95fef713b755",
    "papermill": {
     "duration": 4.955868,
     "end_time": "2021-05-12T03:03:21.187355",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.231487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "if Config.debug or False:\n",
    "    model = GeeseNetAlpha()\n",
    "    # print(model)\n",
    "\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"params: {params:,}\")\n",
    "\n",
    "    train_ds = TrainDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "    for obs, action in train_loader:\n",
    "        output = model(obs)\n",
    "        print(output)\n",
    "        print(f\"{torch.argmax(output['policy'], dim=1)}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "military-fiction",
    "papermill": {
     "duration": 0.033001,
     "end_time": "2021-05-12T03:03:21.255277",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.222276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sophisticated-hearts",
    "papermill": {
     "duration": 0.031759,
     "end_time": "2021-05-12T03:03:21.319849",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.288090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "designing-detective",
    "papermill": {
     "duration": 0.03139,
     "end_time": "2021-05-12T03:03:21.383038",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.351648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "passive-cooper",
    "papermill": {
     "duration": 0.038846,
     "end_time": "2021-05-12T03:03:21.454085",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.415239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(result_df):\n",
    "    preds = result_df[\"preds\"].values\n",
    "    labels = result_df[\"action\"].values\n",
    "    score = get_score(labels, preds)\n",
    "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thirty-tracy",
    "papermill": {
     "duration": 0.0293,
     "end_time": "2021-05-12T03:03:21.514179",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.484879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "introductory-brooklyn",
    "papermill": {
     "duration": 0.039424,
     "end_time": "2021-05-12T03:03:21.582969",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.543545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "raising-laugh",
    "papermill": {
     "duration": 0.042063,
     "end_time": "2021-05-12T03:03:21.654559",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.612496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (obs, action) in enumerate(train_loader):\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        y_preds = model(obs.float())[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "        if Config.apex:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), Config.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % Config.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print(\n",
    "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
    "                f\"Loss avg.: {losses.avg:.4f} \"\n",
    "                f\"Grad: {grad_norm:.4f} \"\n",
    "                f\"LR: {scheduler.get_last_lr()[0]:.5f}  \"\n",
    "            )\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "plain-neighbor",
    "papermill": {
     "duration": 0.041056,
     "end_time": "2021-05-12T03:03:21.726585",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.685529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (obs, action) in enumerate(valid_loader):\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(obs)[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print(\n",
    "                f\"Eval: [{step}/{len(valid_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
    "                f\"Loss avg.: {losses.avg:.4f} \"\n",
    "            )\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "integrated-classification",
    "papermill": {
     "duration": 0.029832,
     "end_time": "2021-05-12T03:03:21.786427",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.756595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "harmful-explanation",
    "papermill": {
     "duration": 0.05136,
     "end_time": "2021-05-12T03:03:21.868561",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.817201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(folds, fold):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    # X_train_folds = X_train[folds[\"fold\"] != fold]\n",
    "    # X_valid_folds = X_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    # y_train_folds = y_train[folds[\"fold\"] != fold]\n",
    "    y_valid_folds = y_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    # y_df_train_folds = y_df[folds[\"fold\"] != fold]\n",
    "    y_df_valid_folds = y_df[folds[\"fold\"] == fold]\n",
    "\n",
    "    # train_dataset = TrainDataset(X_train[folds[\"fold\"] != fold], y_train[folds[\"fold\"] != fold])\n",
    "    # valid_dataset = TrainDataset(X_train[folds[\"fold\"] == fold], y_valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        TrainDataset(X_train[folds[\"fold\"] != fold], y_train[folds[\"fold\"] != fold]),\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        TrainDataset(X_train[folds[\"fold\"] == fold], y_valid_folds),\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if Config.scheduler == \"ReduceLROnPlateau\":\n",
    "            scheduler = ReduceLROnPlateau(\n",
    "                optimizer, mode=\"min\", factor=Config.factor, patience=Config.patience, verbose=True, eps=Config.eps\n",
    "            )\n",
    "        elif Config.scheduler == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=Config.T_max, eta_min=Config.min_lr, last_epoch=-1)\n",
    "        elif Config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "            scheduler = CosineAnnealingWarmRestarts(\n",
    "                optimizer, T_0=Config.T_0, T_mult=1, eta_min=Config.min_lr, last_epoch=-1\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = GeeseNetAlpha()\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, Config.pre_train_file)))\n",
    "    except:\n",
    "        print(f\"Failed to load pre-train weight.\")\n",
    "\n",
    "    # Disable training for value network\n",
    "    for param in model.conv_v.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.head_v1.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.head_v2.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Use multi GPU\n",
    "    if device == torch.device(\"cuda\") and not Config.apex:\n",
    "        model = torch.nn.DataParallel(model)  # make parallel\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=Config.lr, weight_decay=Config.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # apex\n",
    "    # ====================================================\n",
    "    if Config.apex:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
    "\n",
    "    # ====================================================\n",
    "    # Criterion\n",
    "    # ====================================================\n",
    "    def get_criterion():\n",
    "        if Config.criterion == \"CrossEntropyLoss\":\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        return criterion\n",
    "\n",
    "    criterion = get_criterion()\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    best_score = 0.0\n",
    "    best_loss = np.inf\n",
    "    best_preds = None\n",
    "\n",
    "    for epoch in range(Config.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "\n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(y_valid_folds, preds.argmax(1))\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Accuracy: {score}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_best.pth\")\n",
    "            best_preds = preds\n",
    "\n",
    "        if epoch == Config.epochs - 1:\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save final model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_final.pth\")\n",
    "\n",
    "    if Config.train:\n",
    "        y_df_valid_folds[[str(c) for c in range(Config.n_class)]] = best_preds\n",
    "        y_df_valid_folds[\"preds\"] = best_preds.argmax(1)\n",
    "\n",
    "        return y_df_valid_folds\n",
    "\n",
    "    if Config.tuning:\n",
    "        score = get_score(y_df_valid_folds[\"action\"].values, best_preds.argmax(1))\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    Config.geese_net_layers = trial.suggest_int(\"layers\", 6, 18)\n",
    "    Config.geese_net_filters = trial.suggest_int(\"filters\", 32, 128)\n",
    "\n",
    "    score = train_loop(folds, 0)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "complimentary-wright",
    "papermill": {
     "duration": 0.030218,
     "end_time": "2021-05-12T03:03:21.928896",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.898678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "particular-adaptation",
    "papermill": {
     "duration": 0.04089,
     "end_time": "2021-05-12T03:03:22.000150",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.959260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if Config.train:\n",
    "        # train\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(Config.n_fold):\n",
    "            _oof_df = train_loop(folds, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df)\n",
    "            break  # fold 1つだけ\n",
    "        # CV result\n",
    "        # LOGGER.info(f\"========== CV ==========\")\n",
    "        # get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
    "\n",
    "    if Config.tuning:\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=10)\n",
    "\n",
    "        trial = study.best_trial\n",
    "        print(\"Best trial:\")\n",
    "        print(\"  Value: \", trial.value)\n",
    "        print(\"  Params: \")\n",
    "        for key, value in trial.params.items():\n",
    "            print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "backed-journal",
    "outputId": "c9f0ff3d-795e-466b-e22e-9ba21d08c874",
    "papermill": {
     "duration": 2797.64711,
     "end_time": "2021-05-12T03:49:59.678400",
     "exception": false,
     "start_time": "2021-05-12T03:03:22.031290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/1936] Elapsed 0m 5s (remain 176m 17s) Loss avg.: 0.4478 Grad: 0.2341 LR: 0.00100  \n",
      "Epoch: [1][100/1936] Elapsed 1m 17s (remain 23m 22s) Loss avg.: 0.4619 Grad: 0.3070 LR: 0.00100  \n",
      "Epoch: [1][200/1936] Elapsed 2m 28s (remain 21m 24s) Loss avg.: 0.4617 Grad: 0.2188 LR: 0.00100  \n",
      "Epoch: [1][300/1936] Elapsed 3m 40s (remain 19m 59s) Loss avg.: 0.4609 Grad: 0.3170 LR: 0.00100  \n",
      "Epoch: [1][400/1936] Elapsed 4m 52s (remain 18m 39s) Loss avg.: 0.4609 Grad: 0.2148 LR: 0.00100  \n",
      "Epoch: [1][500/1936] Elapsed 6m 4s (remain 17m 22s) Loss avg.: 0.4606 Grad: 0.2329 LR: 0.00100  \n",
      "Epoch: [1][600/1936] Elapsed 7m 15s (remain 16m 7s) Loss avg.: 0.4602 Grad: 0.2047 LR: 0.00100  \n",
      "Epoch: [1][700/1936] Elapsed 8m 27s (remain 14m 53s) Loss avg.: 0.4599 Grad: 0.2868 LR: 0.00100  \n",
      "Epoch: [1][800/1936] Elapsed 9m 38s (remain 13m 40s) Loss avg.: 0.4598 Grad: 0.3099 LR: 0.00100  \n",
      "Epoch: [1][900/1936] Elapsed 10m 50s (remain 12m 27s) Loss avg.: 0.4594 Grad: 0.2018 LR: 0.00100  \n",
      "Epoch: [1][1000/1936] Elapsed 12m 2s (remain 11m 14s) Loss avg.: 0.4593 Grad: 0.2078 LR: 0.00100  \n",
      "Epoch: [1][1100/1936] Elapsed 13m 13s (remain 10m 2s) Loss avg.: 0.4590 Grad: 0.2396 LR: 0.00100  \n",
      "Epoch: [1][1200/1936] Elapsed 14m 25s (remain 8m 49s) Loss avg.: 0.4588 Grad: 0.1928 LR: 0.00100  \n",
      "Epoch: [1][1300/1936] Elapsed 15m 37s (remain 7m 37s) Loss avg.: 0.4585 Grad: 0.1544 LR: 0.00100  \n",
      "Epoch: [1][1400/1936] Elapsed 16m 48s (remain 6m 25s) Loss avg.: 0.4584 Grad: 0.2933 LR: 0.00100  \n",
      "Epoch: [1][1500/1936] Elapsed 18m 0s (remain 5m 13s) Loss avg.: 0.4583 Grad: 0.2789 LR: 0.00100  \n",
      "Epoch: [1][1600/1936] Elapsed 19m 12s (remain 4m 1s) Loss avg.: 0.4581 Grad: 0.2046 LR: 0.00100  \n",
      "Epoch: [1][1700/1936] Elapsed 20m 23s (remain 2m 49s) Loss avg.: 0.4579 Grad: 0.2718 LR: 0.00100  \n",
      "Epoch: [1][1800/1936] Elapsed 21m 35s (remain 1m 37s) Loss avg.: 0.4578 Grad: 0.2141 LR: 0.00100  \n",
      "Epoch: [1][1900/1936] Elapsed 22m 47s (remain 0m 25s) Loss avg.: 0.4577 Grad: 0.2002 LR: 0.00100  \n",
      "Epoch: [1][1935/1936] Elapsed 23m 12s (remain 0m 0s) Loss avg.: 0.4576 Grad: 0.1969 LR: 0.00100  \n",
      "Eval: [0/216] Elapsed 0m 0s (remain 3m 25s) Loss avg.: 0.4700 \n",
      "Eval: [100/216] Elapsed 0m 22s (remain 0m 25s) Loss avg.: 0.4627 \n",
      "Eval: [200/216] Elapsed 0m 43s (remain 0m 3s) Loss avg.: 0.4615 \n",
      "Eval: [215/216] Elapsed 0m 46s (remain 0m 0s) Loss avg.: 0.4611 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4576  avg_val_loss: 0.4611  time: 1439s\n",
      "Epoch 1 - Accuracy: 0.799509699269632\n",
      "Epoch 1 - Save Best Score: 0.7995 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1936] Elapsed 0m 1s (remain 64m 29s) Loss avg.: 0.4712 Grad: 0.1920 LR: 0.00098  \n",
      "Epoch: [2][100/1936] Elapsed 1m 13s (remain 22m 20s) Loss avg.: 0.4498 Grad: 0.2377 LR: 0.00098  \n",
      "Epoch: [2][200/1936] Elapsed 2m 25s (remain 20m 55s) Loss avg.: 0.4512 Grad: 0.2140 LR: 0.00098  \n",
      "Epoch: [2][300/1936] Elapsed 3m 37s (remain 19m 39s) Loss avg.: 0.4512 Grad: 0.1962 LR: 0.00098  \n",
      "Epoch: [2][400/1936] Elapsed 4m 48s (remain 18m 25s) Loss avg.: 0.4510 Grad: 0.1867 LR: 0.00098  \n",
      "Epoch: [2][500/1936] Elapsed 6m 0s (remain 17m 13s) Loss avg.: 0.4513 Grad: 0.1819 LR: 0.00098  \n",
      "Epoch: [2][600/1936] Elapsed 7m 12s (remain 16m 0s) Loss avg.: 0.4513 Grad: 0.1808 LR: 0.00098  \n",
      "Epoch: [2][700/1936] Elapsed 8m 24s (remain 14m 48s) Loss avg.: 0.4514 Grad: 0.2159 LR: 0.00098  \n",
      "Epoch: [2][800/1936] Elapsed 9m 35s (remain 13m 35s) Loss avg.: 0.4514 Grad: 0.1916 LR: 0.00098  \n",
      "Epoch: [2][900/1936] Elapsed 10m 47s (remain 12m 23s) Loss avg.: 0.4515 Grad: 0.1855 LR: 0.00098  \n",
      "Epoch: [2][1000/1936] Elapsed 11m 59s (remain 11m 11s) Loss avg.: 0.4515 Grad: 0.2714 LR: 0.00098  \n",
      "Epoch: [2][1100/1936] Elapsed 13m 10s (remain 9m 59s) Loss avg.: 0.4515 Grad: 0.2532 LR: 0.00098  \n",
      "Epoch: [2][1200/1936] Elapsed 14m 22s (remain 8m 47s) Loss avg.: 0.4516 Grad: 0.2227 LR: 0.00098  \n",
      "Epoch: [2][1300/1936] Elapsed 15m 34s (remain 7m 36s) Loss avg.: 0.4516 Grad: 0.2020 LR: 0.00098  \n",
      "Epoch: [2][1400/1936] Elapsed 16m 45s (remain 6m 24s) Loss avg.: 0.4515 Grad: 0.2363 LR: 0.00098  \n",
      "Epoch: [2][1500/1936] Elapsed 17m 57s (remain 5m 12s) Loss avg.: 0.4515 Grad: 0.2234 LR: 0.00098  \n",
      "Epoch: [2][1600/1936] Elapsed 19m 9s (remain 4m 0s) Loss avg.: 0.4516 Grad: 0.2170 LR: 0.00098  \n",
      "Epoch: [2][1700/1936] Elapsed 20m 20s (remain 2m 48s) Loss avg.: 0.4514 Grad: 0.1866 LR: 0.00098  \n",
      "Epoch: [2][1800/1936] Elapsed 21m 32s (remain 1m 36s) Loss avg.: 0.4514 Grad: 0.2275 LR: 0.00098  \n",
      "Epoch: [2][1900/1936] Elapsed 22m 44s (remain 0m 25s) Loss avg.: 0.4515 Grad: 0.2114 LR: 0.00098  \n",
      "Epoch: [2][1935/1936] Elapsed 23m 9s (remain 0m 0s) Loss avg.: 0.4515 Grad: 0.2356 LR: 0.00098  \n",
      "Eval: [0/216] Elapsed 0m 0s (remain 3m 17s) Loss avg.: 0.4586 \n",
      "Eval: [100/216] Elapsed 0m 22s (remain 0m 25s) Loss avg.: 0.4555 \n",
      "Eval: [200/216] Elapsed 0m 43s (remain 0m 3s) Loss avg.: 0.4548 \n",
      "Eval: [215/216] Elapsed 0m 46s (remain 0m 0s) Loss avg.: 0.4544 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4515  avg_val_loss: 0.4544  time: 1436s\n",
      "Epoch 2 - Accuracy: 0.8024912970168047\n",
      "Epoch 2 - Save Best Score: 0.8025 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1936] Elapsed 0m 2s (remain 65m 8s) Loss avg.: 0.4496 Grad: 0.1786 LR: 0.00091  \n",
      "Epoch: [3][100/1936] Elapsed 1m 13s (remain 22m 19s) Loss avg.: 0.4475 Grad: 0.2071 LR: 0.00091  \n",
      "Epoch: [3][200/1936] Elapsed 2m 25s (remain 20m 55s) Loss avg.: 0.4462 Grad: 0.2117 LR: 0.00091  \n",
      "Epoch: [3][300/1936] Elapsed 3m 37s (remain 19m 38s) Loss avg.: 0.4460 Grad: 0.2263 LR: 0.00091  \n",
      "Epoch: [3][400/1936] Elapsed 4m 48s (remain 18m 25s) Loss avg.: 0.4460 Grad: 0.2244 LR: 0.00091  \n",
      "Epoch: [3][500/1936] Elapsed 6m 0s (remain 17m 12s) Loss avg.: 0.4465 Grad: 0.2627 LR: 0.00091  \n",
      "Epoch: [3][600/1936] Elapsed 7m 11s (remain 15m 59s) Loss avg.: 0.4466 Grad: 0.1825 LR: 0.00091  \n",
      "Epoch: [3][700/1936] Elapsed 8m 23s (remain 14m 47s) Loss avg.: 0.4470 Grad: 0.2040 LR: 0.00091  \n",
      "Epoch: [3][800/1936] Elapsed 9m 35s (remain 13m 35s) Loss avg.: 0.4475 Grad: 0.2215 LR: 0.00091  \n",
      "Epoch: [3][900/1936] Elapsed 10m 47s (remain 12m 23s) Loss avg.: 0.4476 Grad: 0.1812 LR: 0.00091  \n",
      "Epoch: [3][1000/1936] Elapsed 11m 58s (remain 11m 11s) Loss avg.: 0.4477 Grad: 0.2100 LR: 0.00091  \n",
      "Epoch: [3][1100/1936] Elapsed 13m 10s (remain 9m 59s) Loss avg.: 0.4476 Grad: 0.2385 LR: 0.00091  \n",
      "Epoch: [3][1200/1936] Elapsed 14m 21s (remain 8m 47s) Loss avg.: 0.4475 Grad: 0.2406 LR: 0.00091  \n",
      "Epoch: [3][1300/1936] Elapsed 15m 33s (remain 7m 35s) Loss avg.: 0.4475 Grad: 0.1861 LR: 0.00091  \n",
      "Epoch: [3][1400/1936] Elapsed 16m 45s (remain 6m 23s) Loss avg.: 0.4474 Grad: 0.2330 LR: 0.00091  \n",
      "Epoch: [3][1500/1936] Elapsed 17m 56s (remain 5m 12s) Loss avg.: 0.4475 Grad: 0.2095 LR: 0.00091  \n",
      "Epoch: [3][1600/1936] Elapsed 19m 8s (remain 4m 0s) Loss avg.: 0.4475 Grad: 0.2491 LR: 0.00091  \n",
      "Epoch: [3][1700/1936] Elapsed 20m 20s (remain 2m 48s) Loss avg.: 0.4476 Grad: 0.1700 LR: 0.00091  \n",
      "Epoch: [3][1800/1936] Elapsed 21m 31s (remain 1m 36s) Loss avg.: 0.4476 Grad: 0.2358 LR: 0.00091  \n",
      "Epoch: [3][1900/1936] Elapsed 22m 43s (remain 0m 25s) Loss avg.: 0.4476 Grad: 0.1794 LR: 0.00091  \n",
      "Epoch: [3][1935/1936] Elapsed 23m 8s (remain 0m 0s) Loss avg.: 0.4477 Grad: 0.2828 LR: 0.00091  \n",
      "Eval: [0/216] Elapsed 0m 0s (remain 3m 27s) Loss avg.: 0.4601 \n",
      "Eval: [100/216] Elapsed 0m 21s (remain 0m 25s) Loss avg.: 0.4549 \n",
      "Eval: [200/216] Elapsed 0m 43s (remain 0m 3s) Loss avg.: 0.4540 \n",
      "Eval: [215/216] Elapsed 0m 45s (remain 0m 0s) Loss avg.: 0.4536 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.4477  avg_val_loss: 0.4536  time: 1435s\n",
      "Epoch 3 - Accuracy: 0.8032740935027892\n",
      "Epoch 3 - Save Best Score: 0.8033 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/1936] Elapsed 0m 1s (remain 63m 10s) Loss avg.: 0.4657 Grad: 0.2071 LR: 0.00081  \n",
      "Epoch: [4][100/1936] Elapsed 1m 13s (remain 22m 22s) Loss avg.: 0.4442 Grad: 0.1747 LR: 0.00081  \n",
      "Epoch: [4][200/1936] Elapsed 2m 25s (remain 20m 56s) Loss avg.: 0.4432 Grad: 0.2139 LR: 0.00081  \n",
      "Epoch: [4][300/1936] Elapsed 3m 37s (remain 19m 39s) Loss avg.: 0.4427 Grad: 0.2007 LR: 0.00081  \n",
      "Epoch: [4][400/1936] Elapsed 4m 48s (remain 18m 25s) Loss avg.: 0.4430 Grad: 0.2252 LR: 0.00081  \n",
      "Epoch: [4][500/1936] Elapsed 6m 0s (remain 17m 12s) Loss avg.: 0.4435 Grad: 0.1961 LR: 0.00081  \n",
      "Epoch: [4][600/1936] Elapsed 7m 12s (remain 15m 59s) Loss avg.: 0.4437 Grad: 0.2427 LR: 0.00081  \n",
      "Epoch: [4][700/1936] Elapsed 8m 23s (remain 14m 47s) Loss avg.: 0.4438 Grad: 0.1674 LR: 0.00081  \n",
      "Epoch: [4][800/1936] Elapsed 9m 35s (remain 13m 35s) Loss avg.: 0.4436 Grad: 0.1667 LR: 0.00081  \n",
      "Epoch: [4][900/1936] Elapsed 10m 47s (remain 12m 23s) Loss avg.: 0.4439 Grad: 0.1885 LR: 0.00081  \n",
      "Epoch: [4][1000/1936] Elapsed 11m 59s (remain 11m 11s) Loss avg.: 0.4439 Grad: 0.2051 LR: 0.00081  \n",
      "Epoch: [4][1100/1936] Elapsed 13m 10s (remain 9m 59s) Loss avg.: 0.4440 Grad: 0.1727 LR: 0.00081  \n",
      "Epoch: [4][1200/1936] Elapsed 14m 22s (remain 8m 47s) Loss avg.: 0.4441 Grad: 0.2129 LR: 0.00081  \n",
      "Epoch: [4][1300/1936] Elapsed 15m 34s (remain 7m 35s) Loss avg.: 0.4441 Grad: 0.2037 LR: 0.00081  \n",
      "Epoch: [4][1400/1936] Elapsed 16m 45s (remain 6m 24s) Loss avg.: 0.4441 Grad: 0.2059 LR: 0.00081  \n",
      "Epoch: [4][1500/1936] Elapsed 17m 57s (remain 5m 12s) Loss avg.: 0.4441 Grad: 0.1840 LR: 0.00081  \n",
      "Epoch: [4][1600/1936] Elapsed 19m 9s (remain 4m 0s) Loss avg.: 0.4441 Grad: 0.1821 LR: 0.00081  \n",
      "Epoch: [4][1700/1936] Elapsed 20m 20s (remain 2m 48s) Loss avg.: 0.4441 Grad: 0.2245 LR: 0.00081  \n",
      "Epoch: [4][1800/1936] Elapsed 21m 32s (remain 1m 36s) Loss avg.: 0.4441 Grad: 0.1738 LR: 0.00081  \n",
      "Epoch: [4][1900/1936] Elapsed 22m 44s (remain 0m 25s) Loss avg.: 0.4442 Grad: 0.1938 LR: 0.00081  \n",
      "Epoch: [4][1935/1936] Elapsed 23m 9s (remain 0m 0s) Loss avg.: 0.4442 Grad: 0.2006 LR: 0.00081  \n",
      "Eval: [0/216] Elapsed 0m 0s (remain 3m 20s) Loss avg.: 0.4556 \n",
      "Eval: [100/216] Elapsed 0m 21s (remain 0m 24s) Loss avg.: 0.4532 \n",
      "Eval: [200/216] Elapsed 0m 42s (remain 0m 3s) Loss avg.: 0.4523 \n",
      "Eval: [215/216] Elapsed 0m 45s (remain 0m 0s) Loss avg.: 0.4518 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.4442  avg_val_loss: 0.4518  time: 1436s\n",
      "Epoch 4 - Accuracy: 0.8039697512333764\n",
      "Epoch 4 - Save Best Score: 0.8040 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/1936] Elapsed 0m 1s (remain 63m 46s) Loss avg.: 0.4601 Grad: 0.2066 LR: 0.00069  \n",
      "Epoch: [5][100/1936] Elapsed 1m 13s (remain 22m 17s) Loss avg.: 0.4415 Grad: 0.1952 LR: 0.00069  \n",
      "Epoch: [5][200/1936] Elapsed 2m 25s (remain 20m 53s) Loss avg.: 0.4404 Grad: 0.1905 LR: 0.00069  \n",
      "Epoch: [5][300/1936] Elapsed 3m 37s (remain 19m 38s) Loss avg.: 0.4401 Grad: 0.1554 LR: 0.00069  \n",
      "Epoch: [5][400/1936] Elapsed 4m 48s (remain 18m 24s) Loss avg.: 0.4400 Grad: 0.1550 LR: 0.00069  \n",
      "Epoch: [5][500/1936] Elapsed 6m 0s (remain 17m 11s) Loss avg.: 0.4399 Grad: 0.1891 LR: 0.00069  \n",
      "Epoch: [5][600/1936] Elapsed 7m 11s (remain 15m 59s) Loss avg.: 0.4398 Grad: 0.1952 LR: 0.00069  \n",
      "Epoch: [5][700/1936] Elapsed 8m 23s (remain 14m 46s) Loss avg.: 0.4400 Grad: 0.1751 LR: 0.00069  \n",
      "Epoch: [5][800/1936] Elapsed 9m 34s (remain 13m 34s) Loss avg.: 0.4401 Grad: 0.1506 LR: 0.00069  \n",
      "Epoch: [5][900/1936] Elapsed 10m 46s (remain 12m 22s) Loss avg.: 0.4401 Grad: 0.1785 LR: 0.00069  \n",
      "Epoch: [5][1000/1936] Elapsed 11m 58s (remain 11m 10s) Loss avg.: 0.4401 Grad: 0.1429 LR: 0.00069  \n",
      "Epoch: [5][1100/1936] Elapsed 13m 9s (remain 9m 59s) Loss avg.: 0.4400 Grad: 0.2089 LR: 0.00069  \n",
      "Epoch: [5][1200/1936] Elapsed 14m 21s (remain 8m 47s) Loss avg.: 0.4402 Grad: 0.1862 LR: 0.00069  \n",
      "Epoch: [5][1300/1936] Elapsed 15m 33s (remain 7m 35s) Loss avg.: 0.4403 Grad: 0.1968 LR: 0.00069  \n",
      "Epoch: [5][1400/1936] Elapsed 16m 44s (remain 6m 23s) Loss avg.: 0.4405 Grad: 0.1584 LR: 0.00069  \n",
      "Epoch: [5][1500/1936] Elapsed 17m 56s (remain 5m 11s) Loss avg.: 0.4405 Grad: 0.1585 LR: 0.00069  \n",
      "Epoch: [5][1600/1936] Elapsed 19m 8s (remain 4m 0s) Loss avg.: 0.4405 Grad: 0.2231 LR: 0.00069  \n",
      "Epoch: [5][1700/1936] Elapsed 20m 19s (remain 2m 48s) Loss avg.: 0.4406 Grad: 0.2113 LR: 0.00069  \n",
      "Epoch: [5][1800/1936] Elapsed 21m 31s (remain 1m 36s) Loss avg.: 0.4408 Grad: 0.2090 LR: 0.00069  \n",
      "Epoch: [5][1900/1936] Elapsed 22m 43s (remain 0m 25s) Loss avg.: 0.4408 Grad: 0.1846 LR: 0.00069  \n",
      "Epoch: [5][1935/1936] Elapsed 23m 8s (remain 0m 0s) Loss avg.: 0.4408 Grad: 0.2497 LR: 0.00069  \n",
      "Eval: [0/216] Elapsed 0m 0s (remain 3m 19s) Loss avg.: 0.4490 \n",
      "Eval: [100/216] Elapsed 0m 21s (remain 0m 24s) Loss avg.: 0.4498 \n",
      "Eval: [200/216] Elapsed 0m 42s (remain 0m 3s) Loss avg.: 0.4490 \n",
      "Eval: [215/216] Elapsed 0m 45s (remain 0m 0s) Loss avg.: 0.4486 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.4408  avg_val_loss: 0.4486  time: 1435s\n",
      "Epoch 5 - Accuracy: 0.8054089930100196\n",
      "Epoch 5 - Save Best Score: 0.8054 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/1936] Elapsed 0m 1s (remain 62m 34s) Loss avg.: 0.4273 Grad: 0.2411 LR: 0.00055  \n",
      "Epoch: [6][100/1936] Elapsed 1m 13s (remain 22m 18s) Loss avg.: 0.4349 Grad: 0.1760 LR: 0.00055  \n",
      "Epoch: [6][200/1936] Elapsed 2m 25s (remain 20m 54s) Loss avg.: 0.4351 Grad: 0.2150 LR: 0.00055  \n",
      "Epoch: [6][300/1936] Elapsed 3m 36s (remain 19m 38s) Loss avg.: 0.4344 Grad: 0.1798 LR: 0.00055  \n",
      "Epoch: [6][400/1936] Elapsed 4m 48s (remain 18m 24s) Loss avg.: 0.4348 Grad: 0.3159 LR: 0.00055  \n",
      "Epoch: [6][500/1936] Elapsed 6m 0s (remain 17m 11s) Loss avg.: 0.4350 Grad: 0.2057 LR: 0.00055  \n",
      "Epoch: [6][600/1936] Elapsed 7m 12s (remain 15m 59s) Loss avg.: 0.4354 Grad: 0.1798 LR: 0.00055  \n",
      "Epoch: [6][700/1936] Elapsed 8m 23s (remain 14m 47s) Loss avg.: 0.4356 Grad: 0.2162 LR: 0.00055  \n",
      "Epoch: [6][800/1936] Elapsed 9m 35s (remain 13m 35s) Loss avg.: 0.4358 Grad: 0.2098 LR: 0.00055  \n",
      "Epoch: [6][900/1936] Elapsed 10m 46s (remain 12m 23s) Loss avg.: 0.4358 Grad: 0.1857 LR: 0.00055  \n",
      "Epoch: [6][1000/1936] Elapsed 11m 58s (remain 11m 11s) Loss avg.: 0.4361 Grad: 0.1669 LR: 0.00055  \n",
      "Epoch: [6][1100/1936] Elapsed 13m 10s (remain 9m 59s) Loss avg.: 0.4361 Grad: 0.1837 LR: 0.00055  \n",
      "Epoch: [6][1200/1936] Elapsed 14m 21s (remain 8m 47s) Loss avg.: 0.4364 Grad: 0.1600 LR: 0.00055  \n",
      "Epoch: [6][1300/1936] Elapsed 15m 33s (remain 7m 35s) Loss avg.: 0.4365 Grad: 0.1897 LR: 0.00055  \n",
      "Epoch: [6][1400/1936] Elapsed 16m 45s (remain 6m 23s) Loss avg.: 0.4366 Grad: 0.1924 LR: 0.00055  \n",
      "Epoch: [6][1500/1936] Elapsed 17m 57s (remain 5m 12s) Loss avg.: 0.4367 Grad: 0.1720 LR: 0.00055  \n",
      "Epoch: [6][1600/1936] Elapsed 19m 8s (remain 4m 0s) Loss avg.: 0.4368 Grad: 0.2773 LR: 0.00055  \n",
      "Epoch: [6][1700/1936] Elapsed 20m 20s (remain 2m 48s) Loss avg.: 0.4367 Grad: 0.1778 LR: 0.00055  \n",
      "Epoch: [6][1800/1936] Elapsed 21m 32s (remain 1m 36s) Loss avg.: 0.4369 Grad: 0.1895 LR: 0.00055  \n",
      "Epoch: [6][1900/1936] Elapsed 22m 43s (remain 0m 25s) Loss avg.: 0.4371 Grad: 0.1970 LR: 0.00055  \n",
      "Epoch: [6][1935/1936] Elapsed 23m 8s (remain 0m 0s) Loss avg.: 0.4371 Grad: 0.1817 LR: 0.00055  \n",
      "Eval: [0/216] Elapsed 0m 0s (remain 3m 27s) Loss avg.: 0.4454 \n",
      "Eval: [100/216] Elapsed 0m 21s (remain 0m 25s) Loss avg.: 0.4478 \n",
      "Eval: [200/216] Elapsed 0m 43s (remain 0m 3s) Loss avg.: 0.4472 \n",
      "Eval: [215/216] Elapsed 0m 46s (remain 0m 0s) Loss avg.: 0.4468 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.4371  avg_val_loss: 0.4468  time: 1436s\n",
      "Epoch 6 - Accuracy: 0.8064009225089571\n",
      "Epoch 6 - Save Best Score: 0.8064 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/1936] Elapsed 0m 1s (remain 62m 21s) Loss avg.: 0.4284 Grad: 0.1852 LR: 0.00041  \n",
      "Epoch: [7][100/1936] Elapsed 1m 13s (remain 22m 18s) Loss avg.: 0.4310 Grad: 0.2139 LR: 0.00041  \n",
      "Epoch: [7][200/1936] Elapsed 2m 25s (remain 20m 54s) Loss avg.: 0.4314 Grad: 0.1808 LR: 0.00041  \n",
      "Epoch: [7][300/1936] Elapsed 3m 37s (remain 19m 38s) Loss avg.: 0.4316 Grad: 0.2047 LR: 0.00041  \n",
      "Epoch: [7][400/1936] Elapsed 4m 48s (remain 18m 25s) Loss avg.: 0.4315 Grad: 0.1875 LR: 0.00041  \n",
      "Epoch: [7][500/1936] Elapsed 6m 0s (remain 17m 12s) Loss avg.: 0.4316 Grad: 0.1849 LR: 0.00041  \n",
      "Epoch: [7][600/1936] Elapsed 7m 12s (remain 15m 59s) Loss avg.: 0.4322 Grad: 0.2330 LR: 0.00041  \n",
      "Epoch: [7][700/1936] Elapsed 8m 23s (remain 14m 47s) Loss avg.: 0.4323 Grad: 0.2176 LR: 0.00041  \n",
      "Epoch: [7][800/1936] Elapsed 9m 35s (remain 13m 35s) Loss avg.: 0.4322 Grad: 0.2275 LR: 0.00041  \n",
      "Epoch: [7][900/1936] Elapsed 10m 47s (remain 12m 23s) Loss avg.: 0.4324 Grad: 0.2219 LR: 0.00041  \n",
      "Epoch: [7][1000/1936] Elapsed 11m 58s (remain 11m 11s) Loss avg.: 0.4324 Grad: 0.2127 LR: 0.00041  \n",
      "Epoch: [7][1100/1936] Elapsed 13m 10s (remain 9m 59s) Loss avg.: 0.4324 Grad: 0.1992 LR: 0.00041  \n",
      "Epoch: [7][1200/1936] Elapsed 14m 22s (remain 8m 47s) Loss avg.: 0.4325 Grad: 0.1810 LR: 0.00041  \n",
      "Epoch: [7][1300/1936] Elapsed 15m 33s (remain 7m 35s) Loss avg.: 0.4326 Grad: 0.1883 LR: 0.00041  \n",
      "Epoch: [7][1400/1936] Elapsed 16m 45s (remain 6m 23s) Loss avg.: 0.4325 Grad: 0.1729 LR: 0.00041  \n",
      "Epoch: [7][1500/1936] Elapsed 17m 57s (remain 5m 12s) Loss avg.: 0.4325 Grad: 0.2106 LR: 0.00041  \n",
      "Epoch: [7][1600/1936] Elapsed 19m 8s (remain 4m 0s) Loss avg.: 0.4326 Grad: 0.1994 LR: 0.00041  \n",
      "Epoch: [7][1700/1936] Elapsed 20m 20s (remain 2m 48s) Loss avg.: 0.4328 Grad: 0.2098 LR: 0.00041  \n",
      "Epoch: [7][1800/1936] Elapsed 21m 31s (remain 1m 36s) Loss avg.: 0.4329 Grad: 0.1749 LR: 0.00041  \n",
      "Epoch: [7][1900/1936] Elapsed 22m 43s (remain 0m 25s) Loss avg.: 0.4330 Grad: 0.2062 LR: 0.00041  \n",
      "Epoch: [7][1935/1936] Elapsed 23m 8s (remain 0m 0s) Loss avg.: 0.4331 Grad: 0.1683 LR: 0.00041  \n",
      "Eval: [0/216] Elapsed 0m 0s (remain 3m 27s) Loss avg.: 0.4471 \n",
      "Eval: [100/216] Elapsed 0m 21s (remain 0m 25s) Loss avg.: 0.4474 \n",
      "Eval: [200/216] Elapsed 0m 43s (remain 0m 3s) Loss avg.: 0.4467 \n",
      "Eval: [215/216] Elapsed 0m 45s (remain 0m 0s) Loss avg.: 0.4462 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.4331  avg_val_loss: 0.4462  time: 1435s\n",
      "Epoch 7 - Accuracy: 0.8071662912438622\n",
      "Epoch 7 - Save Best Score: 0.8072 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/1936] Elapsed 0m 1s (remain 63m 8s) Loss avg.: 0.4204 Grad: 0.1881 LR: 0.00029  \n",
      "Epoch: [8][100/1936] Elapsed 1m 13s (remain 22m 19s) Loss avg.: 0.4272 Grad: 0.1965 LR: 0.00029  \n",
      "Epoch: [8][200/1936] Elapsed 2m 25s (remain 20m 56s) Loss avg.: 0.4283 Grad: 0.1775 LR: 0.00029  \n",
      "Epoch: [8][300/1936] Elapsed 3m 37s (remain 19m 39s) Loss avg.: 0.4284 Grad: 0.1960 LR: 0.00029  \n",
      "Epoch: [8][400/1936] Elapsed 4m 48s (remain 18m 25s) Loss avg.: 0.4286 Grad: 0.2252 LR: 0.00029  \n",
      "Epoch: [8][500/1936] Elapsed 6m 0s (remain 17m 12s) Loss avg.: 0.4286 Grad: 0.2100 LR: 0.00029  \n",
      "Epoch: [8][600/1936] Elapsed 7m 12s (remain 16m 0s) Loss avg.: 0.4283 Grad: 0.1855 LR: 0.00029  \n",
      "Epoch: [8][700/1936] Elapsed 8m 23s (remain 14m 47s) Loss avg.: 0.4285 Grad: 0.1920 LR: 0.00029  \n",
      "Epoch: [8][800/1936] Elapsed 9m 35s (remain 13m 35s) Loss avg.: 0.4284 Grad: 0.1992 LR: 0.00029  \n",
      "Epoch: [8][900/1936] Elapsed 10m 47s (remain 12m 23s) Loss avg.: 0.4284 Grad: 0.1991 LR: 0.00029  \n",
      "Epoch: [8][1000/1936] Elapsed 11m 59s (remain 11m 11s) Loss avg.: 0.4285 Grad: 0.1900 LR: 0.00029  \n",
      "Epoch: [8][1100/1936] Elapsed 13m 10s (remain 9m 59s) Loss avg.: 0.4285 Grad: 0.1941 LR: 0.00029  \n",
      "Epoch: [8][1200/1936] Elapsed 14m 22s (remain 8m 47s) Loss avg.: 0.4285 Grad: 0.2399 LR: 0.00029  \n",
      "Epoch: [8][1300/1936] Elapsed 15m 34s (remain 7m 35s) Loss avg.: 0.4286 Grad: 0.2005 LR: 0.00029  \n",
      "Epoch: [8][1400/1936] Elapsed 16m 45s (remain 6m 24s) Loss avg.: 0.4286 Grad: 0.1842 LR: 0.00029  \n",
      "Epoch: [8][1500/1936] Elapsed 17m 57s (remain 5m 12s) Loss avg.: 0.4287 Grad: 0.2035 LR: 0.00029  \n",
      "Epoch: [8][1600/1936] Elapsed 19m 9s (remain 4m 0s) Loss avg.: 0.4288 Grad: 0.1749 LR: 0.00029  \n",
      "Epoch: [8][1700/1936] Elapsed 20m 20s (remain 2m 48s) Loss avg.: 0.4289 Grad: 0.2189 LR: 0.00029  \n",
      "Epoch: [8][1800/1936] Elapsed 21m 32s (remain 1m 36s) Loss avg.: 0.4289 Grad: 0.1834 LR: 0.00029  \n",
      "Epoch: [8][1900/1936] Elapsed 22m 44s (remain 0m 25s) Loss avg.: 0.4290 Grad: 0.1922 LR: 0.00029  \n",
      "Epoch: [8][1935/1936] Elapsed 23m 9s (remain 0m 0s) Loss avg.: 0.4290 Grad: 0.2049 LR: 0.00029  \n",
      "Eval: [0/216] Elapsed 0m 0s (remain 3m 16s) Loss avg.: 0.4485 \n",
      "Eval: [100/216] Elapsed 0m 21s (remain 0m 24s) Loss avg.: 0.4477 \n",
      "Eval: [200/216] Elapsed 0m 42s (remain 0m 3s) Loss avg.: 0.4468 \n",
      "Eval: [215/216] Elapsed 0m 45s (remain 0m 0s) Loss avg.: 0.4462 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.4290  avg_val_loss: 0.4462  time: 1436s\n",
      "Epoch 8 - Accuracy: 0.8073333071917067\n",
      "Epoch 8 - Save Best Score: 0.8073 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/1936] Elapsed 0m 2s (remain 72m 58s) Loss avg.: 0.4319 Grad: 0.1814 LR: 0.00019  \n",
      "Epoch: [9][100/1936] Elapsed 1m 14s (remain 22m 25s) Loss avg.: 0.4265 Grad: 0.1940 LR: 0.00019  \n",
      "Epoch: [9][200/1936] Elapsed 2m 25s (remain 20m 57s) Loss avg.: 0.4240 Grad: 0.2050 LR: 0.00019  \n",
      "Epoch: [9][300/1936] Elapsed 3m 37s (remain 19m 40s) Loss avg.: 0.4241 Grad: 0.2091 LR: 0.00019  \n",
      "Epoch: [9][400/1936] Elapsed 4m 49s (remain 18m 27s) Loss avg.: 0.4241 Grad: 0.1983 LR: 0.00019  \n",
      "Epoch: [9][500/1936] Elapsed 6m 0s (remain 17m 13s) Loss avg.: 0.4242 Grad: 0.2078 LR: 0.00019  \n",
      "Epoch: [9][600/1936] Elapsed 7m 12s (remain 16m 0s) Loss avg.: 0.4247 Grad: 0.1884 LR: 0.00019  \n",
      "Epoch: [9][700/1936] Elapsed 8m 24s (remain 14m 48s) Loss avg.: 0.4247 Grad: 0.2178 LR: 0.00019  \n",
      "Epoch: [9][800/1936] Elapsed 9m 35s (remain 13m 35s) Loss avg.: 0.4246 Grad: 0.2100 LR: 0.00019  \n",
      "Epoch: [9][900/1936] Elapsed 10m 47s (remain 12m 23s) Loss avg.: 0.4245 Grad: 0.2236 LR: 0.00019  \n",
      "Epoch: [9][1000/1936] Elapsed 11m 59s (remain 11m 11s) Loss avg.: 0.4246 Grad: 0.2295 LR: 0.00019  \n",
      "Epoch: [9][1100/1936] Elapsed 13m 10s (remain 9m 59s) Loss avg.: 0.4244 Grad: 0.2095 LR: 0.00019  \n",
      "Epoch: [9][1200/1936] Elapsed 14m 22s (remain 8m 47s) Loss avg.: 0.4246 Grad: 0.1938 LR: 0.00019  \n",
      "Epoch: [9][1300/1936] Elapsed 15m 34s (remain 7m 36s) Loss avg.: 0.4246 Grad: 0.1955 LR: 0.00019  \n",
      "Epoch: [9][1400/1936] Elapsed 16m 46s (remain 6m 24s) Loss avg.: 0.4247 Grad: 0.2751 LR: 0.00019  \n",
      "Epoch: [9][1500/1936] Elapsed 17m 57s (remain 5m 12s) Loss avg.: 0.4249 Grad: 0.2011 LR: 0.00019  \n",
      "Epoch: [9][1600/1936] Elapsed 19m 9s (remain 4m 0s) Loss avg.: 0.4249 Grad: 0.2226 LR: 0.00019  \n",
      "Epoch: [9][1700/1936] Elapsed 20m 20s (remain 2m 48s) Loss avg.: 0.4249 Grad: 0.2099 LR: 0.00019  \n",
      "Epoch: [9][1800/1936] Elapsed 21m 32s (remain 1m 36s) Loss avg.: 0.4249 Grad: 0.2330 LR: 0.00019  \n",
      "Epoch: [9][1900/1936] Elapsed 22m 44s (remain 0m 25s) Loss avg.: 0.4250 Grad: 0.2054 LR: 0.00019  \n",
      "Epoch: [9][1935/1936] Elapsed 23m 9s (remain 0m 0s) Loss avg.: 0.4250 Grad: 0.1742 LR: 0.00019  \n",
      "Eval: [0/216] Elapsed 0m 0s (remain 3m 16s) Loss avg.: 0.4435 \n",
      "Eval: [100/216] Elapsed 0m 21s (remain 0m 25s) Loss avg.: 0.4466 \n",
      "Eval: [200/216] Elapsed 0m 43s (remain 0m 3s) Loss avg.: 0.4457 \n",
      "Eval: [215/216] Elapsed 0m 46s (remain 0m 0s) Loss avg.: 0.4451 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.4250  avg_val_loss: 0.4451  time: 1436s\n",
      "Epoch 9 - Accuracy: 0.8076470067111364\n",
      "Epoch 9 - Save Best Score: 0.8076 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/1936] Elapsed 0m 1s (remain 62m 21s) Loss avg.: 0.4161 Grad: 0.2179 LR: 0.00012  \n",
      "Epoch: [10][100/1936] Elapsed 1m 13s (remain 22m 18s) Loss avg.: 0.4183 Grad: 0.1958 LR: 0.00012  \n",
      "Epoch: [10][200/1936] Elapsed 2m 25s (remain 20m 54s) Loss avg.: 0.4196 Grad: 0.1963 LR: 0.00012  \n",
      "Epoch: [10][300/1936] Elapsed 3m 37s (remain 19m 38s) Loss avg.: 0.4201 Grad: 0.2054 LR: 0.00012  \n",
      "Epoch: [10][400/1936] Elapsed 4m 48s (remain 18m 25s) Loss avg.: 0.4204 Grad: 0.2254 LR: 0.00012  \n",
      "Epoch: [10][500/1936] Elapsed 6m 0s (remain 17m 12s) Loss avg.: 0.4204 Grad: 0.2252 LR: 0.00012  \n",
      "Epoch: [10][600/1936] Elapsed 7m 12s (remain 16m 0s) Loss avg.: 0.4207 Grad: 0.2209 LR: 0.00012  \n",
      "Epoch: [10][700/1936] Elapsed 8m 23s (remain 14m 47s) Loss avg.: 0.4208 Grad: 0.1987 LR: 0.00012  \n",
      "Epoch: [10][800/1936] Elapsed 9m 35s (remain 13m 35s) Loss avg.: 0.4212 Grad: 0.2005 LR: 0.00012  \n",
      "Epoch: [10][900/1936] Elapsed 10m 47s (remain 12m 23s) Loss avg.: 0.4213 Grad: 0.2116 LR: 0.00012  \n",
      "Epoch: [10][1000/1936] Elapsed 11m 58s (remain 11m 11s) Loss avg.: 0.4213 Grad: 0.2191 LR: 0.00012  \n",
      "Epoch: [10][1100/1936] Elapsed 13m 10s (remain 9m 59s) Loss avg.: 0.4216 Grad: 0.2560 LR: 0.00012  \n",
      "Epoch: [10][1200/1936] Elapsed 14m 22s (remain 8m 47s) Loss avg.: 0.4216 Grad: 0.2072 LR: 0.00012  \n",
      "Epoch: [10][1300/1936] Elapsed 15m 33s (remain 7m 35s) Loss avg.: 0.4217 Grad: 0.2084 LR: 0.00012  \n",
      "Epoch: [10][1400/1936] Elapsed 16m 45s (remain 6m 24s) Loss avg.: 0.4218 Grad: 0.2118 LR: 0.00012  \n",
      "Epoch: [10][1500/1936] Elapsed 17m 57s (remain 5m 12s) Loss avg.: 0.4219 Grad: 0.2029 LR: 0.00012  \n",
      "Epoch: [10][1600/1936] Elapsed 19m 9s (remain 4m 0s) Loss avg.: 0.4218 Grad: 0.2020 LR: 0.00012  \n",
      "Epoch: [10][1700/1936] Elapsed 20m 20s (remain 2m 48s) Loss avg.: 0.4219 Grad: 0.2005 LR: 0.00012  \n",
      "Epoch: [10][1800/1936] Elapsed 21m 32s (remain 1m 36s) Loss avg.: 0.4220 Grad: 0.2569 LR: 0.00012  \n",
      "Epoch: [10][1900/1936] Elapsed 22m 44s (remain 0m 25s) Loss avg.: 0.4220 Grad: 0.2221 LR: 0.00012  \n",
      "Epoch: [10][1935/1936] Elapsed 23m 9s (remain 0m 0s) Loss avg.: 0.4220 Grad: 0.1922 LR: 0.00012  \n",
      "Eval: [0/216] Elapsed 0m 0s (remain 3m 22s) Loss avg.: 0.4440 \n",
      "Eval: [100/216] Elapsed 0m 21s (remain 0m 25s) Loss avg.: 0.4471 \n",
      "Eval: [200/216] Elapsed 0m 43s (remain 0m 3s) Loss avg.: 0.4461 \n",
      "Eval: [215/216] Elapsed 0m 46s (remain 0m 0s) Loss avg.: 0.4456 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.4220  avg_val_loss: 0.4456  time: 1436s\n",
      "Epoch 10 - Accuracy: 0.807446587573723\n",
      "Epoch 10 - Save final model\n",
      "========== fold: 0 result ==========\n",
      "Score: 0.80765\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "hungry-geese-train-by-episode.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2945.71762,
   "end_time": "2021-05-12T03:50:02.012348",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-12T03:00:56.294728",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04a486aa6f454d8f92e388dba1b9ee21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0857c0fa22b544488d65bb2c7dad18ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f905db5005be40b194ea150c8b0deb9f",
      "max": 1001,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "value": 1001
     }
    },
    "4134662bdbe04a918d9809632e268ef8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0857c0fa22b544488d65bb2c7dad18ee",
       "IPY_MODEL_e33e4f894b424988b316c468bc9225ce"
      ],
      "layout": "IPY_MODEL_8ddb49ac3c91409f99a569a061a70b3d"
     }
    },
    "507d2b6a02bb43d0bb4c8c2734f19cbb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ddb49ac3c91409f99a569a061a70b3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c96b7bfbdf0243a8ae1dbb3d9aedf123": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e33e4f894b424988b316c468bc9225ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_507d2b6a02bb43d0bb4c8c2734f19cbb",
      "placeholder": "​",
      "style": "IPY_MODEL_04a486aa6f454d8f92e388dba1b9ee21",
      "value": " 1001/1001 [03:35&lt;00:00,  4.64it/s]"
     }
    },
    "f905db5005be40b194ea150c8b0deb9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

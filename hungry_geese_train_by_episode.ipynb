{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abroad-piece",
    "papermill": {
     "duration": 0.025714,
     "end_time": "2021-05-12T03:01:02.640708",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.614994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About this notebook ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pressing-commercial",
    "papermill": {
     "duration": 0.024272,
     "end_time": "2021-05-12T03:01:02.689850",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.665578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "german-ethics",
    "papermill": {
     "duration": 1.852306,
     "end_time": "2021-05-12T03:01:04.566362",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.714056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "apparent-fiction",
    "papermill": {
     "duration": 0.030961,
     "end_time": "2021-05-12T03:01:04.622818",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.591857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robust-humanity",
    "papermill": {
     "duration": 0.024539,
     "end_time": "2021-05-12T03:01:04.672270",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.647731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "designed-effect",
    "papermill": {
     "duration": 0.031167,
     "end_time": "2021-05-12T03:01:04.728079",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.696912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"../input/hungrygeeseepisode/hungry-geese-episode/\"\n",
    "OUTPUT_DIR = \"pre-models/\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "special-broadcast",
    "outputId": "c440e1e9-5651-42ee-eb0f-08c822d7471a",
    "papermill": {
     "duration": 0.31211,
     "end_time": "2021-05-12T03:01:05.064722",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.752612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16521\n"
     ]
    }
   ],
   "source": [
    "paths = [path for path in glob.glob(BASE_DIR + \"*.json\") if \"info\" not in path]\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "editorial-haiti",
    "papermill": {
     "duration": 0.024908,
     "end_time": "2021-05-12T03:01:05.115280",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.090372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "opened-python",
    "papermill": {
     "duration": 0.035637,
     "end_time": "2021-05-12T03:01:05.176119",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.140482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 440\n",
    "\n",
    "    n_class = 4\n",
    "    n_fold = 10\n",
    "\n",
    "    geese_net_layers = 12\n",
    "    geese_net_filters = 32\n",
    "\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "\n",
    "    num_workers = 4\n",
    "    batch_size = 3200\n",
    "\n",
    "    scheduler = \"CosineAnnealingWarmRestarts\"\n",
    "    # factor = 0.2  # ReduceLROnPlateau\n",
    "    # patience = 4  # ReduceLROnPlateau\n",
    "    # eps = 1e-6  # ReduceLROnPlateau\n",
    "    # T_max = 10  # CosineAnnealingLR\n",
    "    T_0 = 10  # CosineAnnealingWarmRestarts\n",
    "\n",
    "    criterion = \"CrossEntropyLoss\"\n",
    "    lr = 1e-3\n",
    "    min_lr = 1e-4\n",
    "    weight_decay = 1e-5\n",
    "\n",
    "    epochs = 10\n",
    "    model_name = \"geese_net\"\n",
    "\n",
    "    print_freq = 100\n",
    "\n",
    "    train = True\n",
    "    tuning = False\n",
    "    debug = False\n",
    "    apex = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "contained-singles",
    "papermill": {
     "duration": 0.031266,
     "end_time": "2021-05-12T03:01:05.235456",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.204190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.tuning:\n",
    "    Config.epochs = 2\n",
    "\n",
    "if Config.debug:\n",
    "    Config.epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dietary-track",
    "papermill": {
     "duration": 0.031421,
     "end_time": "2021-05-12T03:01:05.292382",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.260961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.apex:\n",
    "    from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "invalid-dispute",
    "papermill": {
     "duration": 0.169531,
     "end_time": "2021-05-12T03:01:05.488665",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.319134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "treated-serum",
    "papermill": {
     "duration": 0.025219,
     "end_time": "2021-05-12T03:01:05.539482",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.514263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gothic-alloy",
    "papermill": {
     "duration": 0.070842,
     "end_time": "2021-05-12T03:01:05.642364",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.571522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=Config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "experienced-correspondence",
    "papermill": {
     "duration": 0.053842,
     "end_time": "2021-05-12T03:01:05.741858",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.688016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reverse_ns(y):\n",
    "    if y == 0:\n",
    "        return 1\n",
    "    if y == 1:\n",
    "        return 0\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_we(y):\n",
    "    if y == 2:\n",
    "        return 3\n",
    "    if y == 3:\n",
    "        return 2\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_nswe(y):\n",
    "    return reverse_ns(reverse_we(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "further-transaction",
    "papermill": {
     "duration": 0.042365,
     "end_time": "2021-05-12T03:01:05.826807",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.784442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "naughty-clause",
    "papermill": {
     "duration": 0.058537,
     "end_time": "2021-05-12T03:01:05.928292",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.869755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_input(obses):\n",
    "    b = np.zeros((17, 7 * 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "        pid = (p - obs[\"index\"]) % 4\n",
    "\n",
    "        # head position\n",
    "        for pos in pos_list[:1]:\n",
    "            b[0 + pid, pos] = 1\n",
    "        # tip position\n",
    "        for pos in pos_list[-1:]:\n",
    "            b[4 + pid, pos] = 1\n",
    "        # whole position\n",
    "        for pos in pos_list:\n",
    "            b[8 + pid, pos] = 1\n",
    "\n",
    "    # previous head position\n",
    "    if len(obses) > 1:\n",
    "        obs_prev = obses[-2]\n",
    "        for p, pos_list in enumerate(obs_prev[\"geese\"]):\n",
    "            for pos in pos_list[:1]:\n",
    "                b[12 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    # food\n",
    "    for pos in obs[\"food\"]:\n",
    "        b[16, pos] = 1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "i6lOS7itC0da"
   },
   "outputs": [],
   "source": [
    "def observation_num_step(obses):\n",
    "    b = np.zeros((7, 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    b[0, 0] = obs[\"step\"]  # 0-198\n",
    "\n",
    "    return b.reshape(1, 7, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pretty-aaron",
    "papermill": {
     "duration": 0.042985,
     "end_time": "2021-05-12T03:01:06.014038",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.971053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "international-secret",
    "papermill": {
     "duration": 0.064855,
     "end_time": "2021-05-12T03:01:06.121648",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.056793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset_from_json(filepath, json_object=None, standing=0):\n",
    "    if json_object is None:\n",
    "        json_open = open(path, \"r\")\n",
    "        json_load = json.load(json_open)\n",
    "    else:\n",
    "        json_load = json_object\n",
    "\n",
    "    try:\n",
    "        winner_index = np.argmax(np.argsort(json_load[\"rewards\"]) == 3 - standing)\n",
    "\n",
    "        obses = []\n",
    "        X = []\n",
    "        y = []\n",
    "        actions = {\"NORTH\": 0, \"SOUTH\": 1, \"WEST\": 2, \"EAST\": 3}\n",
    "\n",
    "        for i in range(len(json_load[\"steps\"]) - 1):\n",
    "            if json_load[\"steps\"][i][winner_index][\"status\"] == \"ACTIVE\":\n",
    "                y_ = json_load[\"steps\"][i + 1][winner_index][\"action\"]\n",
    "                if y_ is not None:\n",
    "                    step = json_load[\"steps\"][i]\n",
    "                    step[winner_index][\"observation\"][\"geese\"] = step[0][\"observation\"][\"geese\"]\n",
    "                    step[winner_index][\"observation\"][\"food\"] = step[0][\"observation\"][\"food\"]\n",
    "                    step[winner_index][\"observation\"][\"step\"] = step[0][\"observation\"][\"step\"]\n",
    "                    obses.append(step[winner_index][\"observation\"])\n",
    "                    y.append(actions[y_])\n",
    "\n",
    "                    y.append(reverse_ns(actions[y_]))  # 上下反転\n",
    "                    y.append(reverse_we(actions[y_]))  # 左右反転\n",
    "                    y.append(reverse_nswe(actions[y_]))  # 上下左右反転\n",
    "\n",
    "        for j in range(len(obses)):\n",
    "            # X_ = make_input(obses[: j + 1])\n",
    "\n",
    "            X_ = []\n",
    "            X_.append(make_input(obses[: j + 1]))\n",
    "            # X_.append(observation_num_step(obses[: j + 1]))\n",
    "            X_ = np.concatenate(X_)\n",
    "\n",
    "            X.append(X_)\n",
    "\n",
    "            X.append(X_[:, ::-1, :])  # 上下反転\n",
    "            X.append(X_[:, :, ::-1])  # 左右反転\n",
    "            X.append(X_[:, ::-1, ::-1])  # 上下左右反転\n",
    "\n",
    "        X = np.array(X, dtype=np.uint8)  # [starting_step:]\n",
    "        y = np.array(y, dtype=np.uint8)  # [starting_step:]\n",
    "\n",
    "        return X, y\n",
    "    except:\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "4134662bdbe04a918d9809632e268ef8",
      "8ddb49ac3c91409f99a569a061a70b3d",
      "0857c0fa22b544488d65bb2c7dad18ee",
      "e33e4f894b424988b316c468bc9225ce",
      "c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "f905db5005be40b194ea150c8b0deb9f",
      "04a486aa6f454d8f92e388dba1b9ee21",
      "507d2b6a02bb43d0bb4c8c2734f19cbb"
     ]
    },
    "id": "handled-pleasure",
    "outputId": "955c1c6b-36bc-4b30-dc44-b72b05398f8c",
    "papermill": {
     "duration": 15.320591,
     "end_time": "2021-05-12T03:01:21.474816",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.154225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664049eee3ce4841af370f31b15bd0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=16521.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num episode: 10343040\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for path in tqdm(paths[: int(len(paths))]):\n",
    "    X, y = create_dataset_from_json(path, standing=0)  # use only winners' moves\n",
    "    if X is not 0:\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "persistent-loading",
    "papermill": {
     "duration": 112.92618,
     "end_time": "2021-05-12T03:03:14.428162",
     "exception": false,
     "start_time": "2021-05-12T03:01:21.501982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# X_train, unique_index = np.unique(X_train, axis=0, return_index=True)  # remove duplicate\n",
    "# y_train = y_train[unique_index]\n",
    "\n",
    "# y_train = np.eye(4, dtype=\"uint8\")[y_train]  # to categorical\n",
    "\n",
    "# print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sum_obs = X_train.reshape(X_train.shape[0], -1).sum(1)\n",
    "X_train_group = np.unique(X_train_sum_obs)\n",
    "X_train_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9086d8f5397645338c31a4cfa346cb89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=75.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num episode: 10341154\n"
     ]
    }
   ],
   "source": [
    "X_train_unique = []\n",
    "y_train_unique = []\n",
    "for group in tqdm(X_train_group):\n",
    "    group_index = np.where(X_train_sum_obs == group)\n",
    "\n",
    "    X_train_ = X_train[group_index]\n",
    "    y_train_ = y_train[group_index]\n",
    "\n",
    "    X_train_, unique_index = np.unique(X_train_, axis=0, return_index=True)  # remove duplicate\n",
    "    y_train_ = y_train_[unique_index]\n",
    "\n",
    "    X_train_unique.append(X_train_)\n",
    "    y_train_unique.append(y_train_)\n",
    "\n",
    "X_train = np.concatenate(X_train_unique)\n",
    "y_train = np.concatenate(y_train_unique)\n",
    "\n",
    "print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_sum_obs\n",
    "del X_train_group\n",
    "del X_train_unique\n",
    "del y_train_unique\n",
    "del X_train_\n",
    "del y_train_\n",
    "del group_index\n",
    "del unique_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "micro-french",
    "papermill": {
     "duration": 0.033413,
     "end_time": "2021-05-12T03:03:15.360395",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.326982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    X_train = X_train[:1000]\n",
    "    y_train = y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "wrong-pastor",
    "outputId": "406a2f1d-0b8a-46bf-ca01-546f3110c301",
    "papermill": {
     "duration": 0.036161,
     "end_time": "2021-05-12T03:03:15.425149",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.388988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10341149</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10341150</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10341151</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10341152</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10341153</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10341154 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          action\n",
       "0              2\n",
       "1              3\n",
       "2              1\n",
       "3              2\n",
       "4              0\n",
       "...          ...\n",
       "10341149       3\n",
       "10341150       3\n",
       "10341151       2\n",
       "10341152       2\n",
       "10341153       3\n",
       "\n",
       "[10341154 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(y_train, dtype=np.uint8)\n",
    "y_df.columns = [\"action\"]\n",
    "y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "touched-coordinate",
    "papermill": {
     "duration": 0.027968,
     "end_time": "2021-05-12T03:03:15.557122",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.529154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "moving-skill",
    "outputId": "7542c4b4-f7d3-444c-8450-50bffddb1892",
    "papermill": {
     "duration": 0.202337,
     "end_time": "2021-05-12T03:03:15.787529",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.585192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  action\n",
      "0     0         246342\n",
      "      1         246342\n",
      "      2         270716\n",
      "      3         270716\n",
      "1     0         246342\n",
      "      1         246342\n",
      "      2         270716\n",
      "      3         270716\n",
      "2     0         246342\n",
      "      1         246342\n",
      "      2         270716\n",
      "      3         270716\n",
      "3     0         246342\n",
      "      1         246342\n",
      "      2         270716\n",
      "      3         270716\n",
      "4     0         246342\n",
      "      1         246342\n",
      "      2         270716\n",
      "      3         270715\n",
      "5     0         246342\n",
      "      1         246342\n",
      "      2         270716\n",
      "      3         270715\n",
      "6     0         246342\n",
      "      1         246342\n",
      "      2         270716\n",
      "      3         270715\n",
      "7     0         246342\n",
      "      1         246342\n",
      "      2         270716\n",
      "      3         270715\n",
      "8     0         246342\n",
      "      1         246342\n",
      "      2         270715\n",
      "      3         270716\n",
      "9     0         246342\n",
      "      1         246342\n",
      "      2         270715\n",
      "      3         270716\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "folds = y_df.copy()\n",
    "Fold = StratifiedKFold(n_splits=Config.n_fold, shuffle=True, random_state=Config.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[\"action\"])):\n",
    "    folds.loc[val_index, \"fold\"] = int(n)\n",
    "folds[\"fold\"] = folds[\"fold\"].astype(np.uint8)\n",
    "print(folds.groupby([\"fold\", \"action\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "creative-football",
    "papermill": {
     "duration": 0.029031,
     "end_time": "2021-05-12T03:03:15.845114",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.816083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "other-murder",
    "papermill": {
     "duration": 0.037264,
     "end_time": "2021-05-12T03:03:15.911219",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.873955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, array, label):\n",
    "        self.array = array\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx], torch.tensor(self.label[idx]).long()\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, array):\n",
    "        self.array = array\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adjusted-delhi",
    "outputId": "39504950-84bc-4692-8b90-8a5b64f741e0",
    "papermill": {
     "duration": 0.063691,
     "end_time": "2021-05-12T03:03:16.003693",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.940002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "if Config.debug or False:\n",
    "    train_ds = TrainDataset(X_train, y_train)\n",
    "\n",
    "    for i in range(1):\n",
    "        obs, action = train_ds[i]\n",
    "        print(obs.shape, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceramic-startup",
    "papermill": {
     "duration": 0.02876,
     "end_time": "2021-05-12T03:03:16.061575",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.032815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "unique-trick",
    "papermill": {
     "duration": 0.039055,
     "end_time": "2021-05-12T03:03:16.130239",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.091184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TorusConv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
    "        super().__init__()\n",
    "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([x[:, :, :, -self.edge_size[1] :], x, x[:, :, :, : self.edge_size[1]]], dim=3)\n",
    "        h = torch.cat([h[:, :, -self.edge_size[0] :], h, h[:, :, : self.edge_size[0]]], dim=2)\n",
    "        h = self.conv(h)\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "extra-bradford",
    "papermill": {
     "duration": 0.042421,
     "end_time": "2021-05-12T03:03:16.202024",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.159603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GeeseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers, filters = 12, 32\n",
    "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p = nn.Linear(filters, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(filters * 2, filters, bias=False)\n",
    "        self.head_v2 = nn.Linear(filters, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h_p = F.relu_(self.conv_p(h))\n",
    "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        p = self.head_p(h_head_p)\n",
    "\n",
    "        h_v = F.relu_(self.conv_v(h))\n",
    "        h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_avg_v = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
    "\n",
    "        h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_avg_v], 1)))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p, \"value\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "jspEE71c2Yma"
   },
   "outputs": [],
   "source": [
    "class GeeseNetAlpha(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = Config.geese_net_layers\n",
    "        filters = Config.geese_net_filters\n",
    "\n",
    "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p1 = nn.Linear(filters * 5 + 77, filters * 3, bias=False)\n",
    "        self.head_p2 = nn.Linear(filters * 3, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(filters * 5 + 77, filters * 3, bias=False)\n",
    "        self.head_v2 = nn.Linear(filters * 3, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h_p = F.relu_(self.conv_p(h))\n",
    "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p2 = (h_p * x[:, 1:2]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p3 = (h_p * x[:, 2:3]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p4 = (h_p * x[:, 3:4]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_avg_p1 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(-1)\n",
    "        h_avg_p2 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(1)\n",
    "\n",
    "        h_p = F.relu_(self.head_p1(torch.cat([h_head_p, h_head_p2, h_head_p3, h_head_p4, h_avg_p1, h_avg_p2], 1)))\n",
    "        p = self.head_p2(h_p)\n",
    "\n",
    "        h_v = F.relu_(self.conv_v(h))\n",
    "        h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_head_v2 = (h_v * x[:, 1:2]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_head_v3 = (h_v * x[:, 2:3]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_head_v4 = (h_v * x[:, 3:4]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_avg_v1 = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
    "        h_avg_v2 = h_v.view(h_v.size(0), h_v.size(1), -1).mean(1)\n",
    "\n",
    "        h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_head_v2, h_head_v3, h_head_v4, h_avg_v1, h_avg_v2], 1)))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p, \"value\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "objective-victoria",
    "outputId": "1ab137a5-e26e-4b9c-ff85-95fef713b755",
    "papermill": {
     "duration": 4.955868,
     "end_time": "2021-05-12T03:03:21.187355",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.231487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "if Config.debug or False:\n",
    "    model = GeeseNetAlpha()\n",
    "    # print(model)\n",
    "\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"params: {params:,}\")\n",
    "\n",
    "    train_ds = TrainDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "    for obs, action in train_loader:\n",
    "        output = model(obs)\n",
    "        print(output)\n",
    "        print(f\"{torch.argmax(output['policy'], dim=1)}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "military-fiction",
    "papermill": {
     "duration": 0.033001,
     "end_time": "2021-05-12T03:03:21.255277",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.222276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sophisticated-hearts",
    "papermill": {
     "duration": 0.031759,
     "end_time": "2021-05-12T03:03:21.319849",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.288090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "designing-detective",
    "papermill": {
     "duration": 0.03139,
     "end_time": "2021-05-12T03:03:21.383038",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.351648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "passive-cooper",
    "papermill": {
     "duration": 0.038846,
     "end_time": "2021-05-12T03:03:21.454085",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.415239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(result_df):\n",
    "    preds = result_df[\"preds\"].values\n",
    "    labels = result_df[\"action\"].values\n",
    "    score = get_score(labels, preds)\n",
    "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thirty-tracy",
    "papermill": {
     "duration": 0.0293,
     "end_time": "2021-05-12T03:03:21.514179",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.484879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "introductory-brooklyn",
    "papermill": {
     "duration": 0.039424,
     "end_time": "2021-05-12T03:03:21.582969",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.543545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "raising-laugh",
    "papermill": {
     "duration": 0.042063,
     "end_time": "2021-05-12T03:03:21.654559",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.612496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (obs, action) in enumerate(train_loader):\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        y_preds = model(obs.float())[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "        if Config.apex:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), Config.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % Config.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print(\n",
    "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
    "                f\"Loss avg.: {losses.avg:.4f} \"\n",
    "                f\"Grad: {grad_norm:.4f} \"\n",
    "                f\"LR: {scheduler.get_last_lr()[0]:.5f}  \"\n",
    "            )\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "plain-neighbor",
    "papermill": {
     "duration": 0.041056,
     "end_time": "2021-05-12T03:03:21.726585",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.685529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (obs, action) in enumerate(valid_loader):\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(obs)[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print(\n",
    "                f\"Eval: [{step}/{len(valid_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
    "                f\"Loss avg.: {losses.avg:.4f} \"\n",
    "            )\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "integrated-classification",
    "papermill": {
     "duration": 0.029832,
     "end_time": "2021-05-12T03:03:21.786427",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.756595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "harmful-explanation",
    "papermill": {
     "duration": 0.05136,
     "end_time": "2021-05-12T03:03:21.868561",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.817201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(folds, fold):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    # X_train_folds = X_train[folds[\"fold\"] != fold]\n",
    "    # X_valid_folds = X_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    # y_train_folds = y_train[folds[\"fold\"] != fold]\n",
    "    y_valid_folds = y_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    # y_df_train_folds = y_df[folds[\"fold\"] != fold]\n",
    "    y_df_valid_folds = y_df[folds[\"fold\"] == fold]\n",
    "\n",
    "    # train_dataset = TrainDataset(X_train[folds[\"fold\"] != fold], y_train[folds[\"fold\"] != fold])\n",
    "    # valid_dataset = TrainDataset(X_train[folds[\"fold\"] == fold], y_valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        TrainDataset(X_train[folds[\"fold\"] != fold], y_train[folds[\"fold\"] != fold]),\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        TrainDataset(X_train[folds[\"fold\"] == fold], y_valid_folds),\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if Config.scheduler == \"ReduceLROnPlateau\":\n",
    "            scheduler = ReduceLROnPlateau(\n",
    "                optimizer, mode=\"min\", factor=Config.factor, patience=Config.patience, verbose=True, eps=Config.eps\n",
    "            )\n",
    "        elif Config.scheduler == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=Config.T_max, eta_min=Config.min_lr, last_epoch=-1)\n",
    "        elif Config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "            scheduler = CosineAnnealingWarmRestarts(\n",
    "                optimizer, T_0=Config.T_0, T_mult=1, eta_min=Config.min_lr, last_epoch=-1\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = GeeseNetAlpha()\n",
    "\n",
    "    # Disable training for value network\n",
    "    for param in model.conv_v.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.head_v1.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.head_v2.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Use multi GPU\n",
    "    if device == torch.device(\"cuda\") and not Config.apex:\n",
    "        model = torch.nn.DataParallel(model)  # make parallel\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=Config.lr, weight_decay=Config.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # apex\n",
    "    # ====================================================\n",
    "    if Config.apex:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
    "\n",
    "    # ====================================================\n",
    "    # Criterion\n",
    "    # ====================================================\n",
    "    def get_criterion():\n",
    "        if Config.criterion == \"CrossEntropyLoss\":\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        return criterion\n",
    "\n",
    "    criterion = get_criterion()\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    best_score = 0.0\n",
    "    best_loss = np.inf\n",
    "    best_preds = None\n",
    "\n",
    "    for epoch in range(Config.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "\n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(y_valid_folds, preds.argmax(1))\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Accuracy: {score}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_best.pth\")\n",
    "            best_preds = preds\n",
    "\n",
    "        if epoch == Config.epochs - 1:\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save final model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_final.pth\")\n",
    "\n",
    "    if Config.train:\n",
    "        y_df_valid_folds[[str(c) for c in range(Config.n_class)]] = best_preds\n",
    "        y_df_valid_folds[\"preds\"] = best_preds.argmax(1)\n",
    "\n",
    "        return y_df_valid_folds\n",
    "\n",
    "    if Config.tuning:\n",
    "        score = get_score(y_df_valid_folds[\"action\"].values, best_preds.argmax(1))\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    Config.geese_net_layers = trial.suggest_int(\"layers\", 6, 18)\n",
    "    Config.geese_net_filters = trial.suggest_int(\"filters\", 32, 128)\n",
    "\n",
    "    score = train_loop(folds, 0)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "complimentary-wright",
    "papermill": {
     "duration": 0.030218,
     "end_time": "2021-05-12T03:03:21.928896",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.898678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "particular-adaptation",
    "papermill": {
     "duration": 0.04089,
     "end_time": "2021-05-12T03:03:22.000150",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.959260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if Config.train:\n",
    "        # train\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(Config.n_fold):\n",
    "            _oof_df = train_loop(folds, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df)\n",
    "            break  # fold 1つだけ\n",
    "        # CV result\n",
    "        # LOGGER.info(f\"========== CV ==========\")\n",
    "        # get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
    "\n",
    "    if Config.tuning:\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=10)\n",
    "\n",
    "        trial = study.best_trial\n",
    "        print(\"Best trial:\")\n",
    "        print(\"  Value: \", trial.value)\n",
    "        print(\"  Params: \")\n",
    "        for key, value in trial.params.items():\n",
    "            print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "backed-journal",
    "outputId": "c9f0ff3d-795e-466b-e22e-9ba21d08c874",
    "papermill": {
     "duration": 2797.64711,
     "end_time": "2021-05-12T03:49:59.678400",
     "exception": false,
     "start_time": "2021-05-12T03:03:22.031290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2908] Elapsed 0m 5s (remain 251m 54s) Loss avg.: 1.3991 Grad: 0.3362 LR: 0.00100  \n",
      "Epoch: [1][100/2908] Elapsed 0m 34s (remain 16m 5s) Loss avg.: 0.7386 Grad: 0.4362 LR: 0.00100  \n",
      "Epoch: [1][200/2908] Elapsed 1m 4s (remain 14m 23s) Loss avg.: 0.6667 Grad: 0.9285 LR: 0.00100  \n",
      "Epoch: [1][300/2908] Elapsed 1m 33s (remain 13m 30s) Loss avg.: 0.6341 Grad: 0.6344 LR: 0.00100  \n",
      "Epoch: [1][400/2908] Elapsed 2m 3s (remain 12m 49s) Loss avg.: 0.6125 Grad: 0.5833 LR: 0.00100  \n",
      "Epoch: [1][500/2908] Elapsed 2m 32s (remain 12m 13s) Loss avg.: 0.5978 Grad: 0.7187 LR: 0.00100  \n",
      "Epoch: [1][600/2908] Elapsed 3m 2s (remain 11m 38s) Loss avg.: 0.5863 Grad: 0.6420 LR: 0.00100  \n",
      "Epoch: [1][700/2908] Elapsed 3m 31s (remain 11m 5s) Loss avg.: 0.5770 Grad: 0.6399 LR: 0.00100  \n",
      "Epoch: [1][800/2908] Elapsed 4m 0s (remain 10m 33s) Loss avg.: 0.5693 Grad: 0.6931 LR: 0.00100  \n",
      "Epoch: [1][900/2908] Elapsed 4m 30s (remain 10m 1s) Loss avg.: 0.5632 Grad: 0.4609 LR: 0.00100  \n",
      "Epoch: [1][1000/2908] Elapsed 4m 59s (remain 9m 30s) Loss avg.: 0.5578 Grad: 0.7345 LR: 0.00100  \n",
      "Epoch: [1][1100/2908] Elapsed 5m 28s (remain 8m 59s) Loss avg.: 0.5530 Grad: 0.6664 LR: 0.00100  \n",
      "Epoch: [1][1200/2908] Elapsed 5m 58s (remain 8m 29s) Loss avg.: 0.5488 Grad: 0.4663 LR: 0.00100  \n",
      "Epoch: [1][1300/2908] Elapsed 6m 27s (remain 7m 59s) Loss avg.: 0.5453 Grad: 0.6239 LR: 0.00100  \n",
      "Epoch: [1][1400/2908] Elapsed 6m 57s (remain 7m 28s) Loss avg.: 0.5422 Grad: 0.6252 LR: 0.00100  \n",
      "Epoch: [1][1500/2908] Elapsed 7m 26s (remain 6m 58s) Loss avg.: 0.5393 Grad: 0.4437 LR: 0.00100  \n",
      "Epoch: [1][1600/2908] Elapsed 7m 56s (remain 6m 28s) Loss avg.: 0.5368 Grad: 0.5595 LR: 0.00100  \n",
      "Epoch: [1][1700/2908] Elapsed 8m 25s (remain 5m 58s) Loss avg.: 0.5342 Grad: 0.4209 LR: 0.00100  \n",
      "Epoch: [1][1800/2908] Elapsed 8m 55s (remain 5m 28s) Loss avg.: 0.5321 Grad: 0.3995 LR: 0.00100  \n",
      "Epoch: [1][1900/2908] Elapsed 9m 24s (remain 4m 59s) Loss avg.: 0.5302 Grad: 0.3772 LR: 0.00100  \n",
      "Epoch: [1][2000/2908] Elapsed 9m 54s (remain 4m 29s) Loss avg.: 0.5283 Grad: 0.4129 LR: 0.00100  \n",
      "Epoch: [1][2100/2908] Elapsed 10m 23s (remain 3m 59s) Loss avg.: 0.5266 Grad: 0.4395 LR: 0.00100  \n",
      "Epoch: [1][2200/2908] Elapsed 10m 53s (remain 3m 29s) Loss avg.: 0.5250 Grad: 0.4286 LR: 0.00100  \n",
      "Epoch: [1][2300/2908] Elapsed 11m 22s (remain 3m 0s) Loss avg.: 0.5234 Grad: 0.5846 LR: 0.00100  \n",
      "Epoch: [1][2400/2908] Elapsed 11m 52s (remain 2m 30s) Loss avg.: 0.5221 Grad: 0.4259 LR: 0.00100  \n",
      "Epoch: [1][2500/2908] Elapsed 12m 21s (remain 2m 0s) Loss avg.: 0.5207 Grad: 0.3216 LR: 0.00100  \n",
      "Epoch: [1][2600/2908] Elapsed 12m 51s (remain 1m 31s) Loss avg.: 0.5195 Grad: 0.5592 LR: 0.00100  \n",
      "Epoch: [1][2700/2908] Elapsed 13m 20s (remain 1m 1s) Loss avg.: 0.5183 Grad: 0.3385 LR: 0.00100  \n",
      "Epoch: [1][2800/2908] Elapsed 13m 50s (remain 0m 31s) Loss avg.: 0.5172 Grad: 0.4036 LR: 0.00100  \n",
      "Epoch: [1][2900/2908] Elapsed 14m 20s (remain 0m 2s) Loss avg.: 0.5161 Grad: 0.2958 LR: 0.00100  \n",
      "Epoch: [1][2907/2908] Elapsed 14m 22s (remain 0m 0s) Loss avg.: 0.5161 Grad: 0.4532 LR: 0.00100  \n",
      "Eval: [0/324] Elapsed 0m 1s (remain 7m 5s) Loss avg.: 0.8061 \n",
      "Eval: [100/324] Elapsed 0m 9s (remain 0m 21s) Loss avg.: 0.5502 \n",
      "Eval: [200/324] Elapsed 0m 18s (remain 0m 11s) Loss avg.: 0.5170 \n",
      "Eval: [300/324] Elapsed 0m 26s (remain 0m 2s) Loss avg.: 0.4944 \n",
      "Eval: [323/324] Elapsed 0m 28s (remain 0m 0s) Loss avg.: 0.4867 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.5161  avg_val_loss: 0.4867  time: 892s\n",
      "Epoch 1 - Accuracy: 0.7871873174769561\n",
      "Epoch 1 - Save Best Score: 0.7872 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2908] Elapsed 0m 2s (remain 113m 37s) Loss avg.: 0.4835 Grad: 0.3310 LR: 0.00098  \n",
      "Epoch: [2][100/2908] Elapsed 0m 31s (remain 14m 45s) Loss avg.: 0.4811 Grad: 0.3873 LR: 0.00098  \n",
      "Epoch: [2][200/2908] Elapsed 1m 1s (remain 13m 45s) Loss avg.: 0.4823 Grad: 0.4820 LR: 0.00098  \n",
      "Epoch: [2][300/2908] Elapsed 1m 30s (remain 13m 5s) Loss avg.: 0.4831 Grad: 0.5453 LR: 0.00098  \n",
      "Epoch: [2][400/2908] Elapsed 2m 0s (remain 12m 31s) Loss avg.: 0.4826 Grad: 0.3340 LR: 0.00098  \n",
      "Epoch: [2][500/2908] Elapsed 2m 29s (remain 12m 0s) Loss avg.: 0.4825 Grad: 0.2905 LR: 0.00098  \n",
      "Epoch: [2][600/2908] Elapsed 2m 59s (remain 11m 28s) Loss avg.: 0.4820 Grad: 0.3123 LR: 0.00098  \n",
      "Epoch: [2][700/2908] Elapsed 3m 28s (remain 10m 57s) Loss avg.: 0.4817 Grad: 0.4236 LR: 0.00098  \n",
      "Epoch: [2][800/2908] Elapsed 3m 58s (remain 10m 26s) Loss avg.: 0.4815 Grad: 0.3969 LR: 0.00098  \n",
      "Epoch: [2][900/2908] Elapsed 4m 27s (remain 9m 56s) Loss avg.: 0.4815 Grad: 0.3485 LR: 0.00098  \n",
      "Epoch: [2][1000/2908] Elapsed 4m 57s (remain 9m 25s) Loss avg.: 0.4815 Grad: 0.2699 LR: 0.00098  \n",
      "Epoch: [2][1100/2908] Elapsed 5m 26s (remain 8m 55s) Loss avg.: 0.4811 Grad: 0.4767 LR: 0.00098  \n",
      "Epoch: [2][1200/2908] Elapsed 5m 55s (remain 8m 25s) Loss avg.: 0.4812 Grad: 0.3208 LR: 0.00098  \n",
      "Epoch: [2][1300/2908] Elapsed 6m 25s (remain 7m 56s) Loss avg.: 0.4808 Grad: 0.3374 LR: 0.00098  \n",
      "Epoch: [2][1400/2908] Elapsed 6m 54s (remain 7m 26s) Loss avg.: 0.4807 Grad: 0.5085 LR: 0.00098  \n",
      "Epoch: [2][1500/2908] Elapsed 7m 24s (remain 6m 56s) Loss avg.: 0.4806 Grad: 0.3035 LR: 0.00098  \n",
      "Epoch: [2][1600/2908] Elapsed 7m 53s (remain 6m 26s) Loss avg.: 0.4805 Grad: 0.3722 LR: 0.00098  \n",
      "Epoch: [2][1700/2908] Elapsed 8m 23s (remain 5m 56s) Loss avg.: 0.4804 Grad: 0.3207 LR: 0.00098  \n",
      "Epoch: [2][1800/2908] Elapsed 8m 52s (remain 5m 27s) Loss avg.: 0.4803 Grad: 0.3692 LR: 0.00098  \n",
      "Epoch: [2][1900/2908] Elapsed 9m 21s (remain 4m 57s) Loss avg.: 0.4802 Grad: 0.3275 LR: 0.00098  \n",
      "Epoch: [2][2000/2908] Elapsed 9m 51s (remain 4m 28s) Loss avg.: 0.4800 Grad: 0.3608 LR: 0.00098  \n",
      "Epoch: [2][2100/2908] Elapsed 10m 21s (remain 3m 58s) Loss avg.: 0.4799 Grad: 0.3441 LR: 0.00098  \n",
      "Epoch: [2][2200/2908] Elapsed 10m 50s (remain 3m 28s) Loss avg.: 0.4798 Grad: 0.3093 LR: 0.00098  \n",
      "Epoch: [2][2300/2908] Elapsed 11m 19s (remain 2m 59s) Loss avg.: 0.4797 Grad: 0.4038 LR: 0.00098  \n",
      "Epoch: [2][2400/2908] Elapsed 11m 49s (remain 2m 29s) Loss avg.: 0.4796 Grad: 0.3091 LR: 0.00098  \n",
      "Epoch: [2][2500/2908] Elapsed 12m 18s (remain 2m 0s) Loss avg.: 0.4794 Grad: 0.3843 LR: 0.00098  \n",
      "Epoch: [2][2600/2908] Elapsed 12m 47s (remain 1m 30s) Loss avg.: 0.4792 Grad: 0.3058 LR: 0.00098  \n",
      "Epoch: [2][2700/2908] Elapsed 13m 17s (remain 1m 1s) Loss avg.: 0.4791 Grad: 0.2419 LR: 0.00098  \n",
      "Epoch: [2][2800/2908] Elapsed 13m 46s (remain 0m 31s) Loss avg.: 0.4790 Grad: 0.3892 LR: 0.00098  \n",
      "Epoch: [2][2900/2908] Elapsed 14m 16s (remain 0m 2s) Loss avg.: 0.4788 Grad: 0.2772 LR: 0.00098  \n",
      "Epoch: [2][2907/2908] Elapsed 14m 18s (remain 0m 0s) Loss avg.: 0.4788 Grad: 0.2422 LR: 0.00098  \n",
      "Eval: [0/324] Elapsed 0m 1s (remain 7m 3s) Loss avg.: 0.8039 \n",
      "Eval: [100/324] Elapsed 0m 9s (remain 0m 21s) Loss avg.: 0.5426 \n",
      "Eval: [200/324] Elapsed 0m 18s (remain 0m 11s) Loss avg.: 0.5075 \n",
      "Eval: [300/324] Elapsed 0m 26s (remain 0m 2s) Loss avg.: 0.4834 \n",
      "Eval: [323/324] Elapsed 0m 28s (remain 0m 0s) Loss avg.: 0.4756 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4788  avg_val_loss: 0.4756  time: 888s\n",
      "Epoch 2 - Accuracy: 0.7925590552703952\n",
      "Epoch 2 - Save Best Score: 0.7926 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/2908] Elapsed 0m 2s (remain 111m 53s) Loss avg.: 0.4767 Grad: 0.2628 LR: 0.00091  \n",
      "Epoch: [3][100/2908] Elapsed 0m 31s (remain 14m 40s) Loss avg.: 0.4721 Grad: 0.2676 LR: 0.00091  \n",
      "Epoch: [3][200/2908] Elapsed 1m 0s (remain 13m 41s) Loss avg.: 0.4724 Grad: 0.4102 LR: 0.00091  \n",
      "Epoch: [3][300/2908] Elapsed 1m 30s (remain 13m 2s) Loss avg.: 0.4715 Grad: 0.3174 LR: 0.00091  \n",
      "Epoch: [3][400/2908] Elapsed 1m 59s (remain 12m 29s) Loss avg.: 0.4714 Grad: 0.3136 LR: 0.00091  \n",
      "Epoch: [3][500/2908] Elapsed 2m 29s (remain 11m 56s) Loss avg.: 0.4711 Grad: 0.2740 LR: 0.00091  \n",
      "Epoch: [3][600/2908] Elapsed 2m 58s (remain 11m 25s) Loss avg.: 0.4717 Grad: 0.4138 LR: 0.00091  \n",
      "Epoch: [3][700/2908] Elapsed 3m 27s (remain 10m 54s) Loss avg.: 0.4715 Grad: 0.3217 LR: 0.00091  \n",
      "Epoch: [3][800/2908] Elapsed 3m 57s (remain 10m 23s) Loss avg.: 0.4716 Grad: 0.2819 LR: 0.00091  \n",
      "Epoch: [3][900/2908] Elapsed 4m 26s (remain 9m 53s) Loss avg.: 0.4715 Grad: 0.3127 LR: 0.00091  \n",
      "Epoch: [3][1000/2908] Elapsed 4m 55s (remain 9m 23s) Loss avg.: 0.4715 Grad: 0.2631 LR: 0.00091  \n",
      "Epoch: [3][1100/2908] Elapsed 5m 25s (remain 8m 53s) Loss avg.: 0.4715 Grad: 0.3266 LR: 0.00091  \n",
      "Epoch: [3][1200/2908] Elapsed 5m 54s (remain 8m 24s) Loss avg.: 0.4716 Grad: 0.2838 LR: 0.00091  \n",
      "Epoch: [3][1300/2908] Elapsed 6m 24s (remain 7m 54s) Loss avg.: 0.4715 Grad: 0.3341 LR: 0.00091  \n",
      "Epoch: [3][1400/2908] Elapsed 6m 53s (remain 7m 24s) Loss avg.: 0.4714 Grad: 0.3115 LR: 0.00091  \n",
      "Epoch: [3][1500/2908] Elapsed 7m 23s (remain 6m 55s) Loss avg.: 0.4713 Grad: 0.2840 LR: 0.00091  \n",
      "Epoch: [3][1600/2908] Elapsed 7m 52s (remain 6m 25s) Loss avg.: 0.4713 Grad: 0.3243 LR: 0.00091  \n",
      "Epoch: [3][1700/2908] Elapsed 8m 21s (remain 5m 56s) Loss avg.: 0.4712 Grad: 0.2460 LR: 0.00091  \n",
      "Epoch: [3][1800/2908] Elapsed 8m 51s (remain 5m 26s) Loss avg.: 0.4711 Grad: 0.2219 LR: 0.00091  \n",
      "Epoch: [3][1900/2908] Elapsed 9m 20s (remain 4m 56s) Loss avg.: 0.4711 Grad: 0.2468 LR: 0.00091  \n",
      "Epoch: [3][2000/2908] Elapsed 9m 50s (remain 4m 27s) Loss avg.: 0.4710 Grad: 0.2601 LR: 0.00091  \n",
      "Epoch: [3][2100/2908] Elapsed 10m 19s (remain 3m 58s) Loss avg.: 0.4709 Grad: 0.2967 LR: 0.00091  \n",
      "Epoch: [3][2200/2908] Elapsed 10m 49s (remain 3m 28s) Loss avg.: 0.4709 Grad: 0.2440 LR: 0.00091  \n",
      "Epoch: [3][2300/2908] Elapsed 11m 18s (remain 2m 59s) Loss avg.: 0.4709 Grad: 0.3068 LR: 0.00091  \n",
      "Epoch: [3][2400/2908] Elapsed 11m 47s (remain 2m 29s) Loss avg.: 0.4709 Grad: 0.3391 LR: 0.00091  \n",
      "Epoch: [3][2500/2908] Elapsed 12m 17s (remain 1m 59s) Loss avg.: 0.4709 Grad: 0.2491 LR: 0.00091  \n",
      "Epoch: [3][2600/2908] Elapsed 12m 46s (remain 1m 30s) Loss avg.: 0.4708 Grad: 0.2525 LR: 0.00091  \n",
      "Epoch: [3][2700/2908] Elapsed 13m 16s (remain 1m 1s) Loss avg.: 0.4707 Grad: 0.2183 LR: 0.00091  \n",
      "Epoch: [3][2800/2908] Elapsed 13m 45s (remain 0m 31s) Loss avg.: 0.4707 Grad: 0.2666 LR: 0.00091  \n",
      "Epoch: [3][2900/2908] Elapsed 14m 15s (remain 0m 2s) Loss avg.: 0.4707 Grad: 0.3202 LR: 0.00091  \n",
      "Epoch: [3][2907/2908] Elapsed 14m 17s (remain 0m 0s) Loss avg.: 0.4707 Grad: 0.2440 LR: 0.00091  \n",
      "Eval: [0/324] Elapsed 0m 1s (remain 7m 3s) Loss avg.: 0.7957 \n",
      "Eval: [100/324] Elapsed 0m 9s (remain 0m 21s) Loss avg.: 0.5404 \n",
      "Eval: [200/324] Elapsed 0m 18s (remain 0m 11s) Loss avg.: 0.5037 \n",
      "Eval: [300/324] Elapsed 0m 26s (remain 0m 2s) Loss avg.: 0.4793 \n",
      "Eval: [323/324] Elapsed 0m 28s (remain 0m 0s) Loss avg.: 0.4715 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.4707  avg_val_loss: 0.4715  time: 887s\n",
      "Epoch 3 - Accuracy: 0.7947677049770046\n",
      "Epoch 3 - Save Best Score: 0.7948 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/2908] Elapsed 0m 2s (remain 112m 57s) Loss avg.: 0.4904 Grad: 0.4175 LR: 0.00081  \n",
      "Epoch: [4][100/2908] Elapsed 0m 31s (remain 14m 42s) Loss avg.: 0.4677 Grad: 0.2330 LR: 0.00081  \n",
      "Epoch: [4][200/2908] Elapsed 1m 1s (remain 13m 42s) Loss avg.: 0.4668 Grad: 0.2136 LR: 0.00081  \n",
      "Epoch: [4][300/2908] Elapsed 1m 30s (remain 13m 5s) Loss avg.: 0.4662 Grad: 0.2289 LR: 0.00081  \n",
      "Epoch: [4][400/2908] Elapsed 1m 59s (remain 12m 30s) Loss avg.: 0.4661 Grad: 0.3105 LR: 0.00081  \n",
      "Epoch: [4][500/2908] Elapsed 2m 29s (remain 11m 57s) Loss avg.: 0.4662 Grad: 0.3674 LR: 0.00081  \n",
      "Epoch: [4][600/2908] Elapsed 2m 58s (remain 11m 26s) Loss avg.: 0.4661 Grad: 0.2830 LR: 0.00081  \n",
      "Epoch: [4][700/2908] Elapsed 3m 28s (remain 10m 55s) Loss avg.: 0.4661 Grad: 0.2420 LR: 0.00081  \n",
      "Epoch: [4][800/2908] Elapsed 3m 57s (remain 10m 25s) Loss avg.: 0.4660 Grad: 0.3127 LR: 0.00081  \n",
      "Epoch: [4][900/2908] Elapsed 4m 27s (remain 9m 54s) Loss avg.: 0.4662 Grad: 0.2348 LR: 0.00081  \n",
      "Epoch: [4][1000/2908] Elapsed 4m 56s (remain 9m 24s) Loss avg.: 0.4662 Grad: 0.2291 LR: 0.00081  \n",
      "Epoch: [4][1100/2908] Elapsed 5m 26s (remain 8m 55s) Loss avg.: 0.4662 Grad: 0.2207 LR: 0.00081  \n",
      "Epoch: [4][1200/2908] Elapsed 5m 55s (remain 8m 25s) Loss avg.: 0.4661 Grad: 0.2868 LR: 0.00081  \n",
      "Epoch: [4][1300/2908] Elapsed 6m 24s (remain 7m 55s) Loss avg.: 0.4660 Grad: 0.2835 LR: 0.00081  \n",
      "Epoch: [4][1400/2908] Elapsed 6m 54s (remain 7m 25s) Loss avg.: 0.4660 Grad: 0.2441 LR: 0.00081  \n",
      "Epoch: [4][1500/2908] Elapsed 7m 23s (remain 6m 55s) Loss avg.: 0.4660 Grad: 0.2146 LR: 0.00081  \n",
      "Epoch: [4][1600/2908] Elapsed 7m 53s (remain 6m 26s) Loss avg.: 0.4662 Grad: 0.2902 LR: 0.00081  \n",
      "Epoch: [4][1700/2908] Elapsed 8m 22s (remain 5m 56s) Loss avg.: 0.4661 Grad: 0.2647 LR: 0.00081  \n",
      "Epoch: [4][1800/2908] Elapsed 8m 51s (remain 5m 26s) Loss avg.: 0.4661 Grad: 0.2139 LR: 0.00081  \n",
      "Epoch: [4][1900/2908] Elapsed 9m 21s (remain 4m 57s) Loss avg.: 0.4661 Grad: 0.2525 LR: 0.00081  \n",
      "Epoch: [4][2000/2908] Elapsed 9m 51s (remain 4m 27s) Loss avg.: 0.4660 Grad: 0.3100 LR: 0.00081  \n",
      "Epoch: [4][2100/2908] Elapsed 10m 20s (remain 3m 58s) Loss avg.: 0.4660 Grad: 0.3025 LR: 0.00081  \n",
      "Epoch: [4][2200/2908] Elapsed 10m 49s (remain 3m 28s) Loss avg.: 0.4660 Grad: 0.2900 LR: 0.00081  \n",
      "Epoch: [4][2300/2908] Elapsed 11m 19s (remain 2m 59s) Loss avg.: 0.4659 Grad: 0.2093 LR: 0.00081  \n",
      "Epoch: [4][2400/2908] Elapsed 11m 48s (remain 2m 29s) Loss avg.: 0.4659 Grad: 0.2594 LR: 0.00081  \n",
      "Epoch: [4][2500/2908] Elapsed 12m 18s (remain 2m 0s) Loss avg.: 0.4659 Grad: 0.2710 LR: 0.00081  \n",
      "Epoch: [4][2600/2908] Elapsed 12m 47s (remain 1m 30s) Loss avg.: 0.4659 Grad: 0.2082 LR: 0.00081  \n",
      "Epoch: [4][2700/2908] Elapsed 13m 17s (remain 1m 1s) Loss avg.: 0.4659 Grad: 0.2144 LR: 0.00081  \n",
      "Epoch: [4][2800/2908] Elapsed 13m 46s (remain 0m 31s) Loss avg.: 0.4658 Grad: 0.2265 LR: 0.00081  \n",
      "Epoch: [4][2900/2908] Elapsed 14m 16s (remain 0m 2s) Loss avg.: 0.4658 Grad: 0.2480 LR: 0.00081  \n",
      "Epoch: [4][2907/2908] Elapsed 14m 18s (remain 0m 0s) Loss avg.: 0.4657 Grad: 0.2417 LR: 0.00081  \n",
      "Eval: [0/324] Elapsed 0m 1s (remain 6m 48s) Loss avg.: 0.7913 \n",
      "Eval: [100/324] Elapsed 0m 9s (remain 0m 21s) Loss avg.: 0.5357 \n",
      "Eval: [200/324] Elapsed 0m 18s (remain 0m 11s) Loss avg.: 0.4992 \n",
      "Eval: [300/324] Elapsed 0m 26s (remain 0m 2s) Loss avg.: 0.4745 \n",
      "Eval: [323/324] Elapsed 0m 28s (remain 0m 0s) Loss avg.: 0.4667 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.4657  avg_val_loss: 0.4667  time: 888s\n",
      "Epoch 4 - Accuracy: 0.7974472883119496\n",
      "Epoch 4 - Save Best Score: 0.7974 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/2908] Elapsed 0m 2s (remain 114m 56s) Loss avg.: 0.4571 Grad: 0.2573 LR: 0.00069  \n",
      "Epoch: [5][100/2908] Elapsed 0m 31s (remain 14m 45s) Loss avg.: 0.4608 Grad: 0.2152 LR: 0.00069  \n",
      "Epoch: [5][200/2908] Elapsed 1m 1s (remain 13m 45s) Loss avg.: 0.4606 Grad: 0.2297 LR: 0.00069  \n",
      "Epoch: [5][300/2908] Elapsed 1m 30s (remain 13m 7s) Loss avg.: 0.4615 Grad: 0.2083 LR: 0.00069  \n",
      "Epoch: [5][400/2908] Elapsed 2m 0s (remain 12m 32s) Loss avg.: 0.4614 Grad: 0.2309 LR: 0.00069  \n",
      "Epoch: [5][500/2908] Elapsed 2m 29s (remain 11m 59s) Loss avg.: 0.4617 Grad: 0.2345 LR: 0.00069  \n",
      "Epoch: [5][600/2908] Elapsed 2m 59s (remain 11m 27s) Loss avg.: 0.4618 Grad: 0.1890 LR: 0.00069  \n",
      "Epoch: [5][700/2908] Elapsed 3m 28s (remain 10m 56s) Loss avg.: 0.4617 Grad: 0.2556 LR: 0.00069  \n",
      "Epoch: [5][800/2908] Elapsed 3m 57s (remain 10m 25s) Loss avg.: 0.4615 Grad: 0.2493 LR: 0.00069  \n",
      "Epoch: [5][900/2908] Elapsed 4m 27s (remain 9m 55s) Loss avg.: 0.4615 Grad: 0.4046 LR: 0.00069  \n",
      "Epoch: [5][1000/2908] Elapsed 4m 56s (remain 9m 25s) Loss avg.: 0.4615 Grad: 0.2227 LR: 0.00069  \n",
      "Epoch: [5][1100/2908] Elapsed 5m 26s (remain 8m 55s) Loss avg.: 0.4615 Grad: 0.2910 LR: 0.00069  \n",
      "Epoch: [5][1200/2908] Elapsed 5m 55s (remain 8m 25s) Loss avg.: 0.4614 Grad: 0.2995 LR: 0.00069  \n",
      "Epoch: [5][1300/2908] Elapsed 6m 25s (remain 7m 55s) Loss avg.: 0.4614 Grad: 0.2123 LR: 0.00069  \n",
      "Epoch: [5][1400/2908] Elapsed 6m 54s (remain 7m 25s) Loss avg.: 0.4616 Grad: 0.2085 LR: 0.00069  \n",
      "Epoch: [5][1500/2908] Elapsed 7m 23s (remain 6m 56s) Loss avg.: 0.4617 Grad: 0.2812 LR: 0.00069  \n",
      "Epoch: [5][1600/2908] Elapsed 7m 53s (remain 6m 26s) Loss avg.: 0.4617 Grad: 0.2890 LR: 0.00069  \n",
      "Epoch: [5][1700/2908] Elapsed 8m 22s (remain 5m 56s) Loss avg.: 0.4617 Grad: 0.1986 LR: 0.00069  \n",
      "Epoch: [5][1800/2908] Elapsed 8m 52s (remain 5m 27s) Loss avg.: 0.4618 Grad: 0.2689 LR: 0.00069  \n",
      "Epoch: [5][1900/2908] Elapsed 9m 21s (remain 4m 57s) Loss avg.: 0.4619 Grad: 0.2789 LR: 0.00069  \n",
      "Epoch: [5][2000/2908] Elapsed 9m 51s (remain 4m 27s) Loss avg.: 0.4619 Grad: 0.2078 LR: 0.00069  \n",
      "Epoch: [5][2100/2908] Elapsed 10m 20s (remain 3m 58s) Loss avg.: 0.4618 Grad: 0.2222 LR: 0.00069  \n",
      "Epoch: [5][2200/2908] Elapsed 10m 49s (remain 3m 28s) Loss avg.: 0.4619 Grad: 0.2405 LR: 0.00069  \n",
      "Epoch: [5][2300/2908] Elapsed 11m 19s (remain 2m 59s) Loss avg.: 0.4618 Grad: 0.1998 LR: 0.00069  \n",
      "Epoch: [5][2400/2908] Elapsed 11m 48s (remain 2m 29s) Loss avg.: 0.4619 Grad: 0.2114 LR: 0.00069  \n",
      "Epoch: [5][2500/2908] Elapsed 12m 17s (remain 2m 0s) Loss avg.: 0.4619 Grad: 0.3022 LR: 0.00069  \n",
      "Epoch: [5][2600/2908] Elapsed 12m 47s (remain 1m 30s) Loss avg.: 0.4619 Grad: 0.2403 LR: 0.00069  \n",
      "Epoch: [5][2700/2908] Elapsed 13m 17s (remain 1m 1s) Loss avg.: 0.4619 Grad: 0.2148 LR: 0.00069  \n",
      "Epoch: [5][2800/2908] Elapsed 13m 46s (remain 0m 31s) Loss avg.: 0.4618 Grad: 0.2246 LR: 0.00069  \n",
      "Epoch: [5][2900/2908] Elapsed 14m 16s (remain 0m 2s) Loss avg.: 0.4618 Grad: 0.2079 LR: 0.00069  \n",
      "Epoch: [5][2907/2908] Elapsed 14m 18s (remain 0m 0s) Loss avg.: 0.4618 Grad: 0.2003 LR: 0.00069  \n",
      "Eval: [0/324] Elapsed 0m 1s (remain 6m 59s) Loss avg.: 0.7929 \n",
      "Eval: [100/324] Elapsed 0m 9s (remain 0m 21s) Loss avg.: 0.5356 \n",
      "Eval: [200/324] Elapsed 0m 18s (remain 0m 11s) Loss avg.: 0.4985 \n",
      "Eval: [300/324] Elapsed 0m 26s (remain 0m 2s) Loss avg.: 0.4733 \n",
      "Eval: [323/324] Elapsed 0m 28s (remain 0m 0s) Loss avg.: 0.4655 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.4618  avg_val_loss: 0.4655  time: 887s\n",
      "Epoch 5 - Accuracy: 0.7973670265231366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/2908] Elapsed 0m 2s (remain 116m 57s) Loss avg.: 0.4652 Grad: 0.2623 LR: 0.00055  \n",
      "Epoch: [6][100/2908] Elapsed 0m 31s (remain 14m 46s) Loss avg.: 0.4578 Grad: 0.2671 LR: 0.00055  \n",
      "Epoch: [6][200/2908] Elapsed 1m 1s (remain 13m 49s) Loss avg.: 0.4575 Grad: 0.3031 LR: 0.00055  \n",
      "Epoch: [6][300/2908] Elapsed 1m 31s (remain 13m 8s) Loss avg.: 0.4574 Grad: 0.2070 LR: 0.00055  \n",
      "Epoch: [6][400/2908] Elapsed 2m 0s (remain 12m 32s) Loss avg.: 0.4580 Grad: 0.2295 LR: 0.00055  \n",
      "Epoch: [6][500/2908] Elapsed 2m 29s (remain 11m 59s) Loss avg.: 0.4583 Grad: 0.2617 LR: 0.00055  \n",
      "Epoch: [6][600/2908] Elapsed 2m 59s (remain 11m 28s) Loss avg.: 0.4582 Grad: 0.1933 LR: 0.00055  \n",
      "Epoch: [6][700/2908] Elapsed 3m 28s (remain 10m 56s) Loss avg.: 0.4584 Grad: 0.2206 LR: 0.00055  \n",
      "Epoch: [6][800/2908] Elapsed 3m 58s (remain 10m 26s) Loss avg.: 0.4583 Grad: 0.2402 LR: 0.00055  \n",
      "Epoch: [6][900/2908] Elapsed 4m 27s (remain 9m 55s) Loss avg.: 0.4581 Grad: 0.2366 LR: 0.00055  \n",
      "Epoch: [6][1000/2908] Elapsed 4m 57s (remain 9m 25s) Loss avg.: 0.4580 Grad: 0.2818 LR: 0.00055  \n",
      "Epoch: [6][1100/2908] Elapsed 5m 26s (remain 8m 55s) Loss avg.: 0.4579 Grad: 0.2336 LR: 0.00055  \n",
      "Epoch: [6][1200/2908] Elapsed 5m 55s (remain 8m 25s) Loss avg.: 0.4581 Grad: 0.1984 LR: 0.00055  \n",
      "Epoch: [6][1300/2908] Elapsed 6m 25s (remain 7m 55s) Loss avg.: 0.4583 Grad: 0.1769 LR: 0.00055  \n",
      "Epoch: [6][1400/2908] Elapsed 6m 54s (remain 7m 26s) Loss avg.: 0.4584 Grad: 0.1846 LR: 0.00055  \n",
      "Epoch: [6][1500/2908] Elapsed 7m 24s (remain 6m 56s) Loss avg.: 0.4585 Grad: 0.2084 LR: 0.00055  \n",
      "Epoch: [6][1600/2908] Elapsed 7m 53s (remain 6m 26s) Loss avg.: 0.4586 Grad: 0.2634 LR: 0.00055  \n",
      "Epoch: [6][1700/2908] Elapsed 8m 22s (remain 5m 56s) Loss avg.: 0.4585 Grad: 0.2624 LR: 0.00055  \n",
      "Epoch: [6][1800/2908] Elapsed 8m 52s (remain 5m 27s) Loss avg.: 0.4586 Grad: 0.3273 LR: 0.00055  \n",
      "Epoch: [6][1900/2908] Elapsed 9m 21s (remain 4m 57s) Loss avg.: 0.4585 Grad: 0.2074 LR: 0.00055  \n",
      "Epoch: [6][2000/2908] Elapsed 9m 51s (remain 4m 28s) Loss avg.: 0.4586 Grad: 0.2290 LR: 0.00055  \n",
      "Epoch: [6][2100/2908] Elapsed 10m 20s (remain 3m 58s) Loss avg.: 0.4586 Grad: 0.2779 LR: 0.00055  \n",
      "Epoch: [6][2200/2908] Elapsed 10m 50s (remain 3m 28s) Loss avg.: 0.4586 Grad: 0.2612 LR: 0.00055  \n",
      "Epoch: [6][2300/2908] Elapsed 11m 19s (remain 2m 59s) Loss avg.: 0.4585 Grad: 0.2689 LR: 0.00055  \n",
      "Epoch: [6][2400/2908] Elapsed 11m 48s (remain 2m 29s) Loss avg.: 0.4585 Grad: 0.2672 LR: 0.00055  \n",
      "Epoch: [6][2500/2908] Elapsed 12m 18s (remain 2m 0s) Loss avg.: 0.4586 Grad: 0.2753 LR: 0.00055  \n",
      "Epoch: [6][2600/2908] Elapsed 12m 47s (remain 1m 30s) Loss avg.: 0.4585 Grad: 0.2330 LR: 0.00055  \n",
      "Epoch: [6][2700/2908] Elapsed 13m 17s (remain 1m 1s) Loss avg.: 0.4586 Grad: 0.2384 LR: 0.00055  \n",
      "Epoch: [6][2800/2908] Elapsed 13m 46s (remain 0m 31s) Loss avg.: 0.4586 Grad: 0.2460 LR: 0.00055  \n",
      "Epoch: [6][2900/2908] Elapsed 14m 16s (remain 0m 2s) Loss avg.: 0.4587 Grad: 0.2524 LR: 0.00055  \n",
      "Epoch: [6][2907/2908] Elapsed 14m 18s (remain 0m 0s) Loss avg.: 0.4586 Grad: 0.2170 LR: 0.00055  \n",
      "Eval: [0/324] Elapsed 0m 1s (remain 7m 7s) Loss avg.: 0.7840 \n",
      "Eval: [100/324] Elapsed 0m 9s (remain 0m 21s) Loss avg.: 0.5324 \n",
      "Eval: [200/324] Elapsed 0m 18s (remain 0m 11s) Loss avg.: 0.4958 \n",
      "Eval: [300/324] Elapsed 0m 26s (remain 0m 2s) Loss avg.: 0.4710 \n",
      "Eval: [323/324] Elapsed 0m 28s (remain 0m 0s) Loss avg.: 0.4632 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.4586  avg_val_loss: 0.4632  time: 888s\n",
      "Epoch 6 - Accuracy: 0.7986773244007442\n",
      "Epoch 6 - Save Best Score: 0.7987 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/2908] Elapsed 0m 2s (remain 118m 50s) Loss avg.: 0.4613 Grad: 0.2300 LR: 0.00041  \n",
      "Epoch: [7][100/2908] Elapsed 0m 32s (remain 14m 55s) Loss avg.: 0.4550 Grad: 0.2422 LR: 0.00041  \n",
      "Epoch: [7][200/2908] Elapsed 1m 1s (remain 13m 49s) Loss avg.: 0.4548 Grad: 0.2108 LR: 0.00041  \n",
      "Epoch: [7][300/2908] Elapsed 1m 31s (remain 13m 8s) Loss avg.: 0.4551 Grad: 0.2240 LR: 0.00041  \n",
      "Epoch: [7][400/2908] Elapsed 2m 0s (remain 12m 32s) Loss avg.: 0.4554 Grad: 0.2016 LR: 0.00041  \n",
      "Epoch: [7][500/2908] Elapsed 2m 29s (remain 11m 59s) Loss avg.: 0.4555 Grad: 0.2222 LR: 0.00041  \n",
      "Epoch: [7][600/2908] Elapsed 2m 59s (remain 11m 28s) Loss avg.: 0.4556 Grad: 0.2109 LR: 0.00041  \n",
      "Epoch: [7][700/2908] Elapsed 3m 28s (remain 10m 56s) Loss avg.: 0.4558 Grad: 0.2266 LR: 0.00041  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "human-arena",
    "papermill": {
     "duration": 0.209774,
     "end_time": "2021-05-12T03:50:00.096860",
     "exception": false,
     "start_time": "2021-05-12T03:49:59.887086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "hungry-geese-train-by-episode.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2945.71762,
   "end_time": "2021-05-12T03:50:02.012348",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-12T03:00:56.294728",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04a486aa6f454d8f92e388dba1b9ee21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0857c0fa22b544488d65bb2c7dad18ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f905db5005be40b194ea150c8b0deb9f",
      "max": 1001,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "value": 1001
     }
    },
    "4134662bdbe04a918d9809632e268ef8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0857c0fa22b544488d65bb2c7dad18ee",
       "IPY_MODEL_e33e4f894b424988b316c468bc9225ce"
      ],
      "layout": "IPY_MODEL_8ddb49ac3c91409f99a569a061a70b3d"
     }
    },
    "507d2b6a02bb43d0bb4c8c2734f19cbb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ddb49ac3c91409f99a569a061a70b3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c96b7bfbdf0243a8ae1dbb3d9aedf123": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e33e4f894b424988b316c468bc9225ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_507d2b6a02bb43d0bb4c8c2734f19cbb",
      "placeholder": "​",
      "style": "IPY_MODEL_04a486aa6f454d8f92e388dba1b9ee21",
      "value": " 1001/1001 [03:35&lt;00:00,  4.64it/s]"
     }
    },
    "f905db5005be40b194ea150c8b0deb9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

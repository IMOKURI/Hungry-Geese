{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 2945.71762,
      "end_time": "2021-05-12T03:50:02.012348",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-05-12T03:00:56.294728",
      "version": "2.3.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4134662bdbe04a918d9809632e268ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8ddb49ac3c91409f99a569a061a70b3d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0857c0fa22b544488d65bb2c7dad18ee",
              "IPY_MODEL_e33e4f894b424988b316c468bc9225ce"
            ]
          }
        },
        "8ddb49ac3c91409f99a569a061a70b3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0857c0fa22b544488d65bb2c7dad18ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c96b7bfbdf0243a8ae1dbb3d9aedf123",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1001,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1001,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f905db5005be40b194ea150c8b0deb9f"
          }
        },
        "e33e4f894b424988b316c468bc9225ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_04a486aa6f454d8f92e388dba1b9ee21",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1001/1001 [03:35&lt;00:00,  4.64it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_507d2b6a02bb43d0bb4c8c2734f19cbb"
          }
        },
        "c96b7bfbdf0243a8ae1dbb3d9aedf123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f905db5005be40b194ea150c8b0deb9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "04a486aa6f454d8f92e388dba1b9ee21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "507d2b6a02bb43d0bb4c8c2734f19cbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "colab": {
      "name": "hungry-geese-train-by-episode.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IMOKURI/Hungry-Geese/blob/main/hungry_geese_train_by_episode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.025714,
          "end_time": "2021-05-12T03:01:02.640708",
          "exception": false,
          "start_time": "2021-05-12T03:01:02.614994",
          "status": "completed"
        },
        "tags": [],
        "id": "abroad-piece"
      },
      "source": [
        "# About this notebook ..."
      ],
      "id": "abroad-piece"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX0zm2Gdvr7u"
      },
      "source": [
        "## Prepare for Colab"
      ],
      "id": "GX0zm2Gdvr7u"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tFzcJBNvvJ5"
      },
      "source": [
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n"
      ],
      "id": "2tFzcJBNvvJ5",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKDVdCItvx_T"
      },
      "source": [
        "COMPETE = \"hungry-geese\"\n",
        "DATASETS = [\n",
        "    \"imokuri/hungrygeeseepisode\",\n",
        "]\n",
        "KERNEL_OUTPUTS = [\n",
        "    # \"imokuri/notebook8d5846e909\",\n",
        "    # \"imokuri/notebook42cdc46ffc\",\n",
        "]\n",
        "PACKAGES = []\n"
      ],
      "id": "QKDVdCItvx_T",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRvzBjztxH02",
        "outputId": "8fab44ba-fca5-4247-a8dd-b9013fc24897"
      },
      "source": [
        "if IN_COLAB:\n",
        "    # Work around for python2 exception.\n",
        "    !python2 -m pip uninstall kaggle -y\n",
        "    !python3 -m pip uninstall kaggle -y\n",
        "    !python3 -m pip install -U -q kaggle\n"
      ],
      "id": "cRvzBjztxH02",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping kaggle as it is not installed.\u001b[0m\n",
            "Uninstalling kaggle-1.5.12:\n",
            "  Successfully uninstalled kaggle-1.5.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8YygQsTv-a7",
        "outputId": "f31b0c87-c0b0-4cc2-c137-b5838c2b61d9"
      },
      "source": [
        "if IN_COLAB:\n",
        "    !pip install -q -U git+https://github.com/IMOKURI/kaggle_on_google_colab.git\n",
        "\n",
        "    from kaggle_on_google_colab import setup\n",
        "    kaggle = setup.Setup()\n",
        "    kaggle.dirs(COMPETE)\n",
        "\n",
        "    # !kaggle competitions download -p /content/zip {COMPETE}\n",
        "    # !unzip -q -n /content/zip/{COMPETE}.zip -d /content/{COMPETE}/input/{COMPETE}\n",
        "\n",
        "    for dataset in DATASETS:\n",
        "        dataset_name = dataset.split(\"/\")[-1]\n",
        "        !kaggle datasets download -p /content/zip {dataset}\n",
        "        !unzip -q -n /content/zip/{dataset_name}.zip -d /content/{COMPETE}/input/{dataset_name}\n",
        "\n",
        "    for kernel in KERNEL_OUTPUTS:\n",
        "        kernel_name = kernel.split(\"/\")[-1]\n",
        "        !kaggle kernels output -p /content/{COMPETE}/input/{kernel_name} {kernel}\n",
        "\n",
        "    for package in PACKAGES:\n",
        "        !pip install -q {package}\n",
        "\n",
        "    %cd /content/{COMPETE}/output\n"
      ],
      "id": "F8YygQsTv-a7",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for kaggle-on-google-colab (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Download 100%.\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/19425049.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20467787.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20467787_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20468380.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20468380_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20468874.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20468874_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20468933.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20468933_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20468946.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20468946_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20469389.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20469389_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20470192.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20470192_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20470193.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20470193_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20470329.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20470329_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20470331.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20470331_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20470921.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20470921_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20471730.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20471730_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20472740.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20472740_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20473234.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20465529_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20473234_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20465529.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20464679.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20451311_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20452566.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20452566_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20453182.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20453182_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20453642.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20453642_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20453646.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20453646_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20458719.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20458719_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20459968.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20459968_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20460361.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20460361_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20460598.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20460598_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20461100.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20461100_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20461611.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20461611_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20461637.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20461637_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20462427.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20462427_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20464290.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20464290_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20464679_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20474463.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20474463_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20475273.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20486394_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20486916.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20486916_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20490649.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20490649_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20491461.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20491461_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20492168.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20492168_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20492172.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20492172_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20492294.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20492294_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20494013.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20494013_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20494559.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20494559_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20494863.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20494863_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20494902.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20494902_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20494981.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20494981_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20496527.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20496527_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20498550.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20498550_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20486394.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20485490_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20485490.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20484378_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20475273_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20475818.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20475818_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20475823.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20475823_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20476276.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20476276_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20476281.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20476281_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20476811.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20476811_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20477883.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20477883_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20451311.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20478245.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20478970.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20478970_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20479137.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20479137_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20479202.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20479202_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20479366.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20479366_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20482907.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20482907_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20483463.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20483463_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20484378.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20478245_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20499875.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20449646_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20446994_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20411262_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20411810.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20411810_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20412752.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20412752_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20414917.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20414917_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20415698.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20415698_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20416764.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20416764_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20417040.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20417040_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20417663.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20417663_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20417922.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20417922_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20418324.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20418324_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20420038.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20420038_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20420277.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20420277_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20421561.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20421561_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20422203.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20422203_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20411262.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20422744.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20409660_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20409527_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20398358.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20398358_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20399979.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20399979_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20400544.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20400544_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20402425.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20402425_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20403008.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20403008_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20403146.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20403146_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20404059.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20404059_info.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20404346.json\n",
            "Output file downloaded to /content/hungry-geese/input/notebook8d5846e909/20404346_info.json\n",
            "User cancelled operation\n",
            "/content/hungry-geese/output\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.024272,
          "end_time": "2021-05-12T03:01:02.689850",
          "exception": false,
          "start_time": "2021-05-12T03:01:02.665578",
          "status": "completed"
        },
        "tags": [],
        "id": "pressing-commercial"
      },
      "source": [
        "## Library"
      ],
      "id": "pressing-commercial"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:02.750196Z",
          "iopub.status.busy": "2021-05-12T03:01:02.749580Z",
          "iopub.status.idle": "2021-05-12T03:01:04.566183Z",
          "shell.execute_reply": "2021-05-12T03:01:04.565458Z"
        },
        "papermill": {
          "duration": 1.852306,
          "end_time": "2021-05-12T03:01:04.566362",
          "exception": false,
          "start_time": "2021-05-12T03:01:02.714056",
          "status": "completed"
        },
        "tags": [],
        "id": "german-ethics"
      },
      "source": [
        "import glob\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import warnings\n",
        "from contextlib import contextmanager\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.optim import SGD, Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm.notebook import tqdm"
      ],
      "id": "german-ethics",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:04.621034Z",
          "iopub.status.busy": "2021-05-12T03:01:04.620187Z",
          "iopub.status.idle": "2021-05-12T03:01:04.622713Z",
          "shell.execute_reply": "2021-05-12T03:01:04.622327Z"
        },
        "papermill": {
          "duration": 0.030961,
          "end_time": "2021-05-12T03:01:04.622818",
          "exception": false,
          "start_time": "2021-05-12T03:01:04.591857",
          "status": "completed"
        },
        "tags": [],
        "id": "apparent-fiction"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "apparent-fiction",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.024539,
          "end_time": "2021-05-12T03:01:04.672270",
          "exception": false,
          "start_time": "2021-05-12T03:01:04.647731",
          "status": "completed"
        },
        "tags": [],
        "id": "robust-humanity"
      },
      "source": [
        "## Load Data"
      ],
      "id": "robust-humanity"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:04.725686Z",
          "iopub.status.busy": "2021-05-12T03:01:04.724981Z",
          "iopub.status.idle": "2021-05-12T03:01:04.727535Z",
          "shell.execute_reply": "2021-05-12T03:01:04.727956Z"
        },
        "papermill": {
          "duration": 0.031167,
          "end_time": "2021-05-12T03:01:04.728079",
          "exception": false,
          "start_time": "2021-05-12T03:01:04.696912",
          "status": "completed"
        },
        "tags": [],
        "id": "designed-effect"
      },
      "source": [
        "BASE_DIR = \"../input/hungrygeeseepisode/hungry-geese-episode/\"\n",
        "OUTPUT_DIR = \"pre-models/\"\n",
        "\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)"
      ],
      "id": "designed-effect",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:04.780710Z",
          "iopub.status.busy": "2021-05-12T03:01:04.780213Z",
          "iopub.status.idle": "2021-05-12T03:01:05.064607Z",
          "shell.execute_reply": "2021-05-12T03:01:05.064145Z"
        },
        "papermill": {
          "duration": 0.31211,
          "end_time": "2021-05-12T03:01:05.064722",
          "exception": false,
          "start_time": "2021-05-12T03:01:04.752612",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "special-broadcast",
        "outputId": "c440e1e9-5651-42ee-eb0f-08c822d7471a"
      },
      "source": [
        "paths = [path for path in glob.glob(BASE_DIR + \"*.json\") if \"info\" not in path]\n",
        "print(len(paths))"
      ],
      "id": "special-broadcast",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.024908,
          "end_time": "2021-05-12T03:01:05.115280",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.090372",
          "status": "completed"
        },
        "tags": [],
        "id": "editorial-haiti"
      },
      "source": [
        "## Config"
      ],
      "id": "editorial-haiti"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:05.173654Z",
          "iopub.status.busy": "2021-05-12T03:01:05.172793Z",
          "iopub.status.idle": "2021-05-12T03:01:05.175299Z",
          "shell.execute_reply": "2021-05-12T03:01:05.175845Z"
        },
        "papermill": {
          "duration": 0.035637,
          "end_time": "2021-05-12T03:01:05.176119",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.140482",
          "status": "completed"
        },
        "tags": [],
        "id": "opened-python"
      },
      "source": [
        "class Config:\n",
        "    seed = 440\n",
        "\n",
        "    n_class = 4\n",
        "    n_fold = 5\n",
        "\n",
        "    gradient_accumulation_steps = 1\n",
        "    max_grad_norm = 1000\n",
        "\n",
        "    num_workers = 4\n",
        "    batch_size = 800\n",
        "\n",
        "    scheduler = \"CosineAnnealingWarmRestarts\"\n",
        "    # factor = 0.2  # ReduceLROnPlateau\n",
        "    # patience = 4  # ReduceLROnPlateau\n",
        "    # eps = 1e-6  # ReduceLROnPlateau\n",
        "    # T_max = 10  # CosineAnnealingLR\n",
        "    T_0 = 10  # CosineAnnealingWarmRestarts\n",
        "\n",
        "    criterion = \"CrossEntropyLoss\"\n",
        "    lr = 1e-3\n",
        "    min_lr = 5e-5\n",
        "    weight_decay = 0\n",
        "\n",
        "    epochs = 10\n",
        "    model_name = \"geese_net\"\n",
        "\n",
        "    print_freq = 100\n",
        "\n",
        "    train = True\n",
        "    debug = False\n",
        "    apex = False"
      ],
      "id": "opened-python",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:05.233296Z",
          "iopub.status.busy": "2021-05-12T03:01:05.232628Z",
          "iopub.status.idle": "2021-05-12T03:01:05.235351Z",
          "shell.execute_reply": "2021-05-12T03:01:05.234953Z"
        },
        "papermill": {
          "duration": 0.031266,
          "end_time": "2021-05-12T03:01:05.235456",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.204190",
          "status": "completed"
        },
        "tags": [],
        "id": "contained-singles"
      },
      "source": [
        "if Config.debug:\n",
        "    Config.epochs = 1"
      ],
      "id": "contained-singles",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:05.290450Z",
          "iopub.status.busy": "2021-05-12T03:01:05.289701Z",
          "iopub.status.idle": "2021-05-12T03:01:05.291811Z",
          "shell.execute_reply": "2021-05-12T03:01:05.292268Z"
        },
        "papermill": {
          "duration": 0.031421,
          "end_time": "2021-05-12T03:01:05.292382",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.260961",
          "status": "completed"
        },
        "tags": [],
        "id": "dietary-track"
      },
      "source": [
        "if Config.apex:\n",
        "    from apex import amp"
      ],
      "id": "dietary-track",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:05.485693Z",
          "iopub.status.busy": "2021-05-12T03:01:05.483279Z",
          "iopub.status.idle": "2021-05-12T03:01:05.488061Z",
          "shell.execute_reply": "2021-05-12T03:01:05.488530Z"
        },
        "papermill": {
          "duration": 0.169531,
          "end_time": "2021-05-12T03:01:05.488665",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.319134",
          "status": "completed"
        },
        "tags": [],
        "id": "invalid-dispute"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "id": "invalid-dispute",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.025219,
          "end_time": "2021-05-12T03:01:05.539482",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.514263",
          "status": "completed"
        },
        "tags": [],
        "id": "treated-serum"
      },
      "source": [
        "## Utils"
      ],
      "id": "treated-serum"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:05.622688Z",
          "iopub.status.busy": "2021-05-12T03:01:05.621871Z",
          "iopub.status.idle": "2021-05-12T03:01:05.642197Z",
          "shell.execute_reply": "2021-05-12T03:01:05.640797Z"
        },
        "papermill": {
          "duration": 0.070842,
          "end_time": "2021-05-12T03:01:05.642364",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.571522",
          "status": "completed"
        },
        "tags": [],
        "id": "gothic-alloy"
      },
      "source": [
        "@contextmanager\n",
        "def timer(name):\n",
        "    t0 = time.time()\n",
        "    LOGGER.info(f\"[{name}] start\")\n",
        "    yield\n",
        "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
        "\n",
        "\n",
        "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
        "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
        "\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler1 = StreamHandler()\n",
        "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
        "    handler2 = FileHandler(filename=log_file)\n",
        "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(handler1)\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "\n",
        "LOGGER = init_logger()\n",
        "\n",
        "\n",
        "def seed_torch(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "seed_torch(seed=Config.seed)"
      ],
      "id": "gothic-alloy",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:05.736939Z",
          "iopub.status.busy": "2021-05-12T03:01:05.736146Z",
          "iopub.status.idle": "2021-05-12T03:01:05.741693Z",
          "shell.execute_reply": "2021-05-12T03:01:05.741081Z"
        },
        "papermill": {
          "duration": 0.053842,
          "end_time": "2021-05-12T03:01:05.741858",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.688016",
          "status": "completed"
        },
        "tags": [],
        "id": "experienced-correspondence"
      },
      "source": [
        "def reverse_ns(y):\n",
        "    if y == 0:\n",
        "        return 1\n",
        "    if y == 1:\n",
        "        return 0\n",
        "    return y\n",
        "\n",
        "def reverse_we(y):\n",
        "    if y == 2:\n",
        "        return 3\n",
        "    if y == 3:\n",
        "        return 2\n",
        "    return y\n",
        "\n",
        "def reverse_nswe(y):\n",
        "    return reverse_ns(reverse_we(y))"
      ],
      "id": "experienced-correspondence",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.042365,
          "end_time": "2021-05-12T03:01:05.826807",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.784442",
          "status": "completed"
        },
        "tags": [],
        "id": "further-transaction"
      },
      "source": [
        "## Observation"
      ],
      "id": "further-transaction"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:05.923923Z",
          "iopub.status.busy": "2021-05-12T03:01:05.922723Z",
          "iopub.status.idle": "2021-05-12T03:01:05.927158Z",
          "shell.execute_reply": "2021-05-12T03:01:05.928120Z"
        },
        "papermill": {
          "duration": 0.058537,
          "end_time": "2021-05-12T03:01:05.928292",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.869755",
          "status": "completed"
        },
        "tags": [],
        "id": "naughty-clause"
      },
      "source": [
        "def make_input(obses):\n",
        "    b = np.zeros((17, 7 * 11), dtype=np.float32)\n",
        "    obs = obses[-1]\n",
        "\n",
        "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
        "        pid = (p - obs[\"index\"]) % 4\n",
        "\n",
        "        # head position\n",
        "        for pos in pos_list[:1]:\n",
        "            b[0 + pid, pos] = 1\n",
        "        # tip position\n",
        "        for pos in pos_list[-1:]:\n",
        "            b[4 + pid, pos] = 1\n",
        "        # whole position\n",
        "        for pos in pos_list:\n",
        "            b[8 + pid, pos] = 1\n",
        "\n",
        "    # previous head position\n",
        "    if len(obses) > 1:\n",
        "        obs_prev = obses[-2]\n",
        "        for p, pos_list in enumerate(obs_prev[\"geese\"]):\n",
        "            for pos in pos_list[:1]:\n",
        "                b[12 + (p - obs[\"index\"]) % 4, pos] = 1\n",
        "\n",
        "    # food\n",
        "    for pos in obs[\"food\"]:\n",
        "        b[16, pos] = 1\n",
        "\n",
        "    return b.reshape(-1, 7, 11)"
      ],
      "id": "naughty-clause",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6lOS7itC0da"
      },
      "source": [
        "def observation_num_step(obses):\n",
        "    b = np.zeros((7, 11), dtype=np.float32)\n",
        "    obs = obses[-1]\n",
        "\n",
        "    num_step = obs[\"step\"]  # 0-198\n",
        "    b[0, 0] = num_step / 198\n",
        "\n",
        "    return b.reshape(1, 7, 11)"
      ],
      "id": "i6lOS7itC0da",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.042985,
          "end_time": "2021-05-12T03:01:06.014038",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.971053",
          "status": "completed"
        },
        "tags": [],
        "id": "pretty-aaron"
      },
      "source": [
        "## Data"
      ],
      "id": "pretty-aaron"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:06.111097Z",
          "iopub.status.busy": "2021-05-12T03:01:06.110359Z",
          "iopub.status.idle": "2021-05-12T03:01:06.120495Z",
          "shell.execute_reply": "2021-05-12T03:01:06.121470Z"
        },
        "papermill": {
          "duration": 0.064855,
          "end_time": "2021-05-12T03:01:06.121648",
          "exception": false,
          "start_time": "2021-05-12T03:01:06.056793",
          "status": "completed"
        },
        "tags": [],
        "id": "international-secret"
      },
      "source": [
        "def create_dataset_from_json(filepath, json_object=None, standing=0):\n",
        "    if json_object is None:\n",
        "        json_open = open(path, \"r\")\n",
        "        json_load = json.load(json_open)\n",
        "    else:\n",
        "        json_load = json_object\n",
        "\n",
        "    try:\n",
        "        winner_index = np.argmax(np.argsort(json_load[\"rewards\"]) == 3 - standing)\n",
        "\n",
        "        obses = []\n",
        "        X = []\n",
        "        y = []\n",
        "        actions = {\"NORTH\": 0, \"SOUTH\": 1, \"WEST\": 2, \"EAST\": 3}\n",
        "\n",
        "        for i in range(len(json_load[\"steps\"]) - 1):\n",
        "            if json_load[\"steps\"][i][winner_index][\"status\"] == \"ACTIVE\":\n",
        "                y_ = json_load[\"steps\"][i + 1][winner_index][\"action\"]\n",
        "                if y_ is not None:\n",
        "                    step = json_load[\"steps\"][i]\n",
        "                    step[winner_index][\"observation\"][\"geese\"] = step[0][\"observation\"][\"geese\"]\n",
        "                    step[winner_index][\"observation\"][\"food\"] = step[0][\"observation\"][\"food\"]\n",
        "                    step[winner_index][\"observation\"][\"step\"] = step[0][\"observation\"][\"step\"]\n",
        "                    obses.append(step[winner_index][\"observation\"])\n",
        "                    y.append(actions[y_])\n",
        "\n",
        "                    y.append(reverse_ns(actions[y_]))  # ä¸Šä¸‹åè»¢\n",
        "                    y.append(reverse_we(actions[y_]))  # å·¦å³åè»¢\n",
        "                    y.append(reverse_nswe(actions[y_]))  # ä¸Šä¸‹å·¦å³åè»¢\n",
        "\n",
        "        for j in range(len(obses)):\n",
        "            # X_ = make_input(obses[: j + 1])\n",
        "\n",
        "            X_ = []\n",
        "            X_.append(make_input(obses[: j + 1]))\n",
        "            # X_.append(observation_num_step(obses[: j + 1]))\n",
        "            X_ = np.concatenate(X_)\n",
        "\n",
        "            X.append(X_)\n",
        "\n",
        "            X.append(X_[:, ::-1, :])  # ä¸Šä¸‹åè»¢\n",
        "            X.append(X_[:, :, ::-1])  # å·¦å³åè»¢\n",
        "            X.append(X_[:, ::-1, ::-1])  # ä¸Šä¸‹å·¦å³åè»¢\n",
        "\n",
        "        X = np.array(X, dtype=np.float32)  # [starting_step:]\n",
        "        y = np.array(y, dtype=np.uint8)  # [starting_step:]\n",
        "\n",
        "        return X, y\n",
        "    except:\n",
        "        return 0, 0"
      ],
      "id": "international-secret",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:06.210574Z",
          "iopub.status.busy": "2021-05-12T03:01:06.209744Z",
          "iopub.status.idle": "2021-05-12T03:01:21.474698Z",
          "shell.execute_reply": "2021-05-12T03:01:21.474263Z"
        },
        "papermill": {
          "duration": 15.320591,
          "end_time": "2021-05-12T03:01:21.474816",
          "exception": false,
          "start_time": "2021-05-12T03:01:06.154225",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "4134662bdbe04a918d9809632e268ef8",
            "8ddb49ac3c91409f99a569a061a70b3d",
            "0857c0fa22b544488d65bb2c7dad18ee",
            "e33e4f894b424988b316c468bc9225ce",
            "c96b7bfbdf0243a8ae1dbb3d9aedf123",
            "f905db5005be40b194ea150c8b0deb9f",
            "04a486aa6f454d8f92e388dba1b9ee21",
            "507d2b6a02bb43d0bb4c8c2734f19cbb"
          ]
        },
        "id": "handled-pleasure",
        "outputId": "955c1c6b-36bc-4b30-dc44-b72b05398f8c"
      },
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for path in tqdm(paths[: int(len(paths))]):\n",
        "    X, y = create_dataset_from_json(path, standing=0)  # use only winners' moves\n",
        "    if X is not 0:\n",
        "        X_train.append(X)\n",
        "        y_train.append(y)\n",
        "        \n",
        "X_train = np.concatenate(X_train)\n",
        "y_train = np.concatenate(y_train)\n",
        "\n",
        "print(f\"Num episode: {len(X_train)}\")"
      ],
      "id": "handled-pleasure",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4134662bdbe04a918d9809632e268ef8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1001.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Num episode: 642304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:02:25.736079Z",
          "iopub.status.busy": "2021-05-12T03:02:25.694905Z",
          "iopub.status.idle": "2021-05-12T03:03:14.427579Z",
          "shell.execute_reply": "2021-05-12T03:03:14.428005Z"
        },
        "papermill": {
          "duration": 112.92618,
          "end_time": "2021-05-12T03:03:14.428162",
          "exception": false,
          "start_time": "2021-05-12T03:01:21.501982",
          "status": "completed"
        },
        "tags": [],
        "id": "persistent-loading"
      },
      "source": [
        "# TODO: ãƒ‡ãƒ¼ã‚¿ã‚’uniqueã«ã—ãŸã„ãŒãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ã«ãªã£ã¦ã—ã¾ã†ã€‚\n",
        "\n",
        "# X_train, unique_index = np.unique(X_train, axis=0, return_index=True)  # remove duplicate\n",
        "# y_train = y_train[unique_index]\n",
        "\n",
        "# y_train = np.eye(4, dtype=\"uint8\")[y_train]  # to categorical\n",
        "\n",
        "# print(f\"Num episode: {len(X_train)}\")"
      ],
      "id": "persistent-loading",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:15.358147Z",
          "iopub.status.busy": "2021-05-12T03:03:15.357428Z",
          "iopub.status.idle": "2021-05-12T03:03:15.360295Z",
          "shell.execute_reply": "2021-05-12T03:03:15.359841Z"
        },
        "papermill": {
          "duration": 0.033413,
          "end_time": "2021-05-12T03:03:15.360395",
          "exception": false,
          "start_time": "2021-05-12T03:03:15.326982",
          "status": "completed"
        },
        "tags": [],
        "id": "micro-french"
      },
      "source": [
        "if Config.debug:\n",
        "    X_train = X_train[:1000]\n",
        "    y_train = y_train[:1000]"
      ],
      "id": "micro-french",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:15.421673Z",
          "iopub.status.busy": "2021-05-12T03:03:15.421167Z",
          "iopub.status.idle": "2021-05-12T03:03:15.425045Z",
          "shell.execute_reply": "2021-05-12T03:03:15.424564Z"
        },
        "papermill": {
          "duration": 0.036161,
          "end_time": "2021-05-12T03:03:15.425149",
          "exception": false,
          "start_time": "2021-05-12T03:03:15.388988",
          "status": "completed"
        },
        "tags": [],
        "id": "wrong-pastor",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "406a2f1d-0b8a-46bf-ca01-546f3110c301"
      },
      "source": [
        "y_df = pd.DataFrame(y_train)\n",
        "y_df.columns = [\"action\"]\n",
        "y_df"
      ],
      "id": "wrong-pastor",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>642299</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>642300</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>642301</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>642302</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>642303</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>642304 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        action\n",
              "0            1\n",
              "1            0\n",
              "2            1\n",
              "3            0\n",
              "4            1\n",
              "...        ...\n",
              "642299       0\n",
              "642300       1\n",
              "642301       0\n",
              "642302       1\n",
              "642303       0\n",
              "\n",
              "[642304 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.027968,
          "end_time": "2021-05-12T03:03:15.557122",
          "exception": false,
          "start_time": "2021-05-12T03:03:15.529154",
          "status": "completed"
        },
        "tags": [],
        "id": "touched-coordinate"
      },
      "source": [
        "## CV Split"
      ],
      "id": "touched-coordinate"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:15.619838Z",
          "iopub.status.busy": "2021-05-12T03:03:15.617632Z",
          "iopub.status.idle": "2021-05-12T03:03:15.787410Z",
          "shell.execute_reply": "2021-05-12T03:03:15.786989Z"
        },
        "papermill": {
          "duration": 0.202337,
          "end_time": "2021-05-12T03:03:15.787529",
          "exception": false,
          "start_time": "2021-05-12T03:03:15.585192",
          "status": "completed"
        },
        "tags": [],
        "id": "moving-skill",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7542c4b4-f7d3-444c-8450-50bffddb1892"
      },
      "source": [
        "folds = y_df.copy()\n",
        "Fold = StratifiedKFold(n_splits=Config.n_fold, shuffle=True, random_state=Config.seed)\n",
        "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[\"action\"])):\n",
        "    folds.loc[val_index, \"fold\"] = int(n)\n",
        "folds[\"fold\"] = folds[\"fold\"].astype(int)\n",
        "print(folds.groupby([\"fold\", \"action\"]).size())"
      ],
      "id": "moving-skill",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold  action\n",
            "0     0         30728\n",
            "      1         30729\n",
            "      2         33502\n",
            "      3         33502\n",
            "1     0         30728\n",
            "      1         30729\n",
            "      2         33502\n",
            "      3         33502\n",
            "2     0         30729\n",
            "      1         30728\n",
            "      2         33502\n",
            "      3         33502\n",
            "3     0         30729\n",
            "      1         30728\n",
            "      2         33502\n",
            "      3         33502\n",
            "4     0         30728\n",
            "      1         30728\n",
            "      2         33502\n",
            "      3         33502\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.029031,
          "end_time": "2021-05-12T03:03:15.845114",
          "exception": false,
          "start_time": "2021-05-12T03:03:15.816083",
          "status": "completed"
        },
        "tags": [],
        "id": "creative-football"
      },
      "source": [
        "## Dataset"
      ],
      "id": "creative-football"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:15.908966Z",
          "iopub.status.busy": "2021-05-12T03:03:15.908282Z",
          "iopub.status.idle": "2021-05-12T03:03:15.911117Z",
          "shell.execute_reply": "2021-05-12T03:03:15.910685Z"
        },
        "papermill": {
          "duration": 0.037264,
          "end_time": "2021-05-12T03:03:15.911219",
          "exception": false,
          "start_time": "2021-05-12T03:03:15.873955",
          "status": "completed"
        },
        "tags": [],
        "id": "other-murder"
      },
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, array, label):\n",
        "        self.array = array\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.array.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.array[idx], torch.tensor(self.label[idx]).long()\n",
        "\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, array):\n",
        "        self.array = array\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.array.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.array[idx]"
      ],
      "id": "other-murder",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:15.976092Z",
          "iopub.status.busy": "2021-05-12T03:03:15.975444Z",
          "iopub.status.idle": "2021-05-12T03:03:16.003593Z",
          "shell.execute_reply": "2021-05-12T03:03:16.003099Z"
        },
        "papermill": {
          "duration": 0.063691,
          "end_time": "2021-05-12T03:03:16.003693",
          "exception": false,
          "start_time": "2021-05-12T03:03:15.940002",
          "status": "completed"
        },
        "tags": [],
        "id": "adjusted-delhi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39504950-84bc-4692-8b90-8a5b64f741e0"
      },
      "source": [
        "# Test\n",
        "\n",
        "train_ds = TrainDataset(X_train, y_train)\n",
        "\n",
        "for i in range(1):\n",
        "    obs, action = train_ds[i]\n",
        "    print(obs.shape, action)"
      ],
      "id": "adjusted-delhi",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17, 7, 11) tensor(1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.02876,
          "end_time": "2021-05-12T03:03:16.061575",
          "exception": false,
          "start_time": "2021-05-12T03:03:16.032815",
          "status": "completed"
        },
        "tags": [],
        "id": "ceramic-startup"
      },
      "source": [
        "## Model"
      ],
      "id": "ceramic-startup"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:16.128034Z",
          "iopub.status.busy": "2021-05-12T03:03:16.127367Z",
          "iopub.status.idle": "2021-05-12T03:03:16.130137Z",
          "shell.execute_reply": "2021-05-12T03:03:16.129621Z"
        },
        "papermill": {
          "duration": 0.039055,
          "end_time": "2021-05-12T03:03:16.130239",
          "exception": false,
          "start_time": "2021-05-12T03:03:16.091184",
          "status": "completed"
        },
        "tags": [],
        "id": "unique-trick"
      },
      "source": [
        "class TorusConv2d(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
        "        super().__init__()\n",
        "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
        "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
        "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = torch.cat([x[:, :, :, -self.edge_size[1] :], x, x[:, :, :, : self.edge_size[1]]], dim=3)\n",
        "        h = torch.cat([h[:, :, -self.edge_size[0] :], h, h[:, :, : self.edge_size[0]]], dim=2)\n",
        "        h = self.conv(h)\n",
        "        h = self.bn(h) if self.bn is not None else h\n",
        "        return h"
      ],
      "id": "unique-trick",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:16.199989Z",
          "iopub.status.busy": "2021-05-12T03:03:16.199254Z",
          "iopub.status.idle": "2021-05-12T03:03:16.201923Z",
          "shell.execute_reply": "2021-05-12T03:03:16.201414Z"
        },
        "papermill": {
          "duration": 0.042421,
          "end_time": "2021-05-12T03:03:16.202024",
          "exception": false,
          "start_time": "2021-05-12T03:03:16.159603",
          "status": "completed"
        },
        "tags": [],
        "id": "extra-bradford"
      },
      "source": [
        "class GeeseNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        layers, filters = 12, 32\n",
        "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
        "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
        "\n",
        "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
        "        self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
        "\n",
        "        self.head_p = nn.Linear(filters, 4, bias=False)\n",
        "        self.head_v1 = nn.Linear(filters * 2, filters, bias=False)\n",
        "        self.head_v2 = nn.Linear(filters, 1, bias=False)\n",
        "\n",
        "    def forward(self, x, _=None):\n",
        "        h = F.relu_(self.conv0(x))\n",
        "        for block in self.blocks:\n",
        "            h = F.relu_(h + block(h))\n",
        "\n",
        "        h_p = F.relu_(self.conv_p(h))\n",
        "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
        "        p = self.head_p(h_head_p)\n",
        "\n",
        "        h_v = F.relu_(self.conv_v(h))\n",
        "        h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
        "        h_avg_v = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
        "\n",
        "        h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_avg_v], 1)))\n",
        "        v = torch.tanh(self.head_v2(h_v))\n",
        "\n",
        "        return {\"policy\": p, \"value\": v}"
      ],
      "id": "extra-bradford",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jspEE71c2Yma"
      },
      "source": [
        "class GeeseNetAlpha(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        layers, filters = 12, 64\n",
        "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
        "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
        "\n",
        "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
        "        # self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
        "\n",
        "        self.head_p1 = nn.Linear(filters * 2 + 77, filters, bias=False)\n",
        "        self.head_p2 = nn.Linear(filters, 4, bias=False)\n",
        "        # self.head_v1 = nn.Linear(filters * 2, filters, bias=False)\n",
        "        # self.head_v2 = nn.Linear(filters, 1, bias=False)\n",
        "\n",
        "    def forward(self, x, _=None):\n",
        "        # x = x[:, :-1]\n",
        "        # num_step = x[:, -1, 0, 0].view(x.size(0), 1)\n",
        "\n",
        "        h = F.relu_(self.conv0(x))\n",
        "        for block in self.blocks:\n",
        "            h = F.relu_(h + block(h))\n",
        "\n",
        "        h_p = F.relu_(self.conv_p(h))\n",
        "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
        "        h_avg_p1 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(-1)\n",
        "        h_avg_p2 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(1)\n",
        "\n",
        "        h_p = F.relu_(self.head_p1(torch.cat([h_head_p, h_avg_p1, h_avg_p2], 1)))\n",
        "        p = self.head_p2(h_p)\n",
        "\n",
        "        # h_v = F.relu_(self.conv_v(h))\n",
        "        # h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
        "        # h_avg_v = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
        "\n",
        "        # h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_avg_v], 1)))\n",
        "        # v = torch.tanh(self.head_v2(h_v))\n",
        "\n",
        "        return {\"policy\": p}  # \"value\": v"
      ],
      "id": "jspEE71c2Yma",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:16.271521Z",
          "iopub.status.busy": "2021-05-12T03:03:16.270975Z",
          "iopub.status.idle": "2021-05-12T03:03:21.187210Z",
          "shell.execute_reply": "2021-05-12T03:03:21.186277Z"
        },
        "papermill": {
          "duration": 4.955868,
          "end_time": "2021-05-12T03:03:21.187355",
          "exception": false,
          "start_time": "2021-05-12T03:03:16.231487",
          "status": "completed"
        },
        "tags": [],
        "id": "objective-victoria",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ab137a5-e26e-4b9c-ff85-95fef713b755"
      },
      "source": [
        "# Test\n",
        "\n",
        "model = GeeseNetAlpha()\n",
        "# print(model)\n",
        "\n",
        "params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"params: {params:,}\")\n",
        "\n",
        "train_ds = TrainDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
        "\n",
        "for obs, action in train_loader:\n",
        "    output = model(obs)\n",
        "    print(output)\n",
        "    print(f\"{torch.argmax(output['policy'], dim=1)}\")\n",
        "    break"
      ],
      "id": "objective-victoria",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "params: 505,088\n",
            "{'policy': tensor([[-0.0482,  0.0622,  0.0121,  0.0654],\n",
            "        [ 0.0047, -0.1130, -0.0873,  0.1382],\n",
            "        [-0.0846,  0.0202,  0.1040, -0.0044],\n",
            "        [-0.0422, -0.0436,  0.0040,  0.0635]], grad_fn=<MmBackward>)}\n",
            "tensor([3, 3, 2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.033001,
          "end_time": "2021-05-12T03:03:21.255277",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.222276",
          "status": "completed"
        },
        "tags": [],
        "id": "military-fiction"
      },
      "source": [
        "## Loss"
      ],
      "id": "military-fiction"
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.031759,
          "end_time": "2021-05-12T03:03:21.319849",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.288090",
          "status": "completed"
        },
        "tags": [],
        "id": "sophisticated-hearts"
      },
      "source": [
        ""
      ],
      "id": "sophisticated-hearts",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.03139,
          "end_time": "2021-05-12T03:03:21.383038",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.351648",
          "status": "completed"
        },
        "tags": [],
        "id": "designing-detective"
      },
      "source": [
        "## Scoring"
      ],
      "id": "designing-detective"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:21.451759Z",
          "iopub.status.busy": "2021-05-12T03:03:21.450940Z",
          "iopub.status.idle": "2021-05-12T03:03:21.453955Z",
          "shell.execute_reply": "2021-05-12T03:03:21.453477Z"
        },
        "papermill": {
          "duration": 0.038846,
          "end_time": "2021-05-12T03:03:21.454085",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.415239",
          "status": "completed"
        },
        "tags": [],
        "id": "passive-cooper"
      },
      "source": [
        "def get_score(y_true, y_pred):\n",
        "    return accuracy_score(y_true, y_pred)"
      ],
      "id": "passive-cooper",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.0293,
          "end_time": "2021-05-12T03:03:21.514179",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.484879",
          "status": "completed"
        },
        "tags": [],
        "id": "thirty-tracy"
      },
      "source": [
        "## Helper functions"
      ],
      "id": "thirty-tracy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:21.580683Z",
          "iopub.status.busy": "2021-05-12T03:03:21.580046Z",
          "iopub.status.idle": "2021-05-12T03:03:21.582848Z",
          "shell.execute_reply": "2021-05-12T03:03:21.582463Z"
        },
        "papermill": {
          "duration": 0.039424,
          "end_time": "2021-05-12T03:03:21.582969",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.543545",
          "status": "completed"
        },
        "tags": [],
        "id": "introductory-brooklyn"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return \"%dm %ds\" % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
      ],
      "id": "introductory-brooklyn",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:21.652644Z",
          "iopub.status.busy": "2021-05-12T03:03:21.651807Z",
          "iopub.status.idle": "2021-05-12T03:03:21.654450Z",
          "shell.execute_reply": "2021-05-12T03:03:21.654030Z"
        },
        "papermill": {
          "duration": 0.042063,
          "end_time": "2021-05-12T03:03:21.654559",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.612496",
          "status": "completed"
        },
        "tags": [],
        "id": "raising-laugh"
      },
      "source": [
        "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    scores = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    start = end = time.time()\n",
        "    global_step = 0\n",
        "\n",
        "    for step, (obs, action) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "        obs = obs.to(device)\n",
        "        action = action.to(device)\n",
        "        batch_size = action.size(0)\n",
        "\n",
        "        y_preds = model(obs.float())[\"policy\"]\n",
        "\n",
        "        loss = criterion(y_preds, action)\n",
        "\n",
        "        # record loss\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        if Config.gradient_accumulation_steps > 1:\n",
        "            loss = loss / Config.gradient_accumulation_steps\n",
        "        if Config.apex:\n",
        "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                scaled_loss.backward()\n",
        "        else:\n",
        "            loss.backward()\n",
        "\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), Config.max_grad_norm)\n",
        "\n",
        "        if (step + 1) % Config.gradient_accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            global_step += 1\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
        "            print(\n",
        "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
        "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
        "                f\"Loss: {losses.val:.4f}({losses.avg:.4f}) \"\n",
        "                f\"Grad: {grad_norm:.4f} \"\n",
        "                f\"LR: {scheduler.get_last_lr()[0]:.6f}  \"\n",
        "            )\n",
        "\n",
        "    return losses.avg"
      ],
      "id": "raising-laugh",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:21.724634Z",
          "iopub.status.busy": "2021-05-12T03:03:21.723879Z",
          "iopub.status.idle": "2021-05-12T03:03:21.726483Z",
          "shell.execute_reply": "2021-05-12T03:03:21.726090Z"
        },
        "papermill": {
          "duration": 0.041056,
          "end_time": "2021-05-12T03:03:21.726585",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.685529",
          "status": "completed"
        },
        "tags": [],
        "id": "plain-neighbor"
      },
      "source": [
        "def valid_fn(valid_loader, model, criterion, device):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    scores = AverageMeter()\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    start = end = time.time()\n",
        "\n",
        "    for step, (obs, action) in enumerate(valid_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "        obs = obs.to(device)\n",
        "        action = action.to(device)\n",
        "        batch_size = action.size(0)\n",
        "\n",
        "        # compute loss\n",
        "        with torch.no_grad():\n",
        "            y_preds = model(obs)[\"policy\"]\n",
        "\n",
        "        loss = criterion(y_preds, action)\n",
        "        losses.update(loss.item(), batch_size)\n",
        "\n",
        "        # record accuracy\n",
        "        preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
        "        if Config.gradient_accumulation_steps > 1:\n",
        "            loss = loss / Config.gradient_accumulation_steps\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
        "            print(\n",
        "                f\"EVAL: [{step}/{len(valid_loader)}] \"\n",
        "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
        "                f\"Loss: {losses.val:.4f}({losses.avg:.4f}) \"\n",
        "            )\n",
        "    predictions = np.concatenate(preds)\n",
        "    return losses.avg, predictions"
      ],
      "id": "plain-neighbor",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.029832,
          "end_time": "2021-05-12T03:03:21.786427",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.756595",
          "status": "completed"
        },
        "tags": [],
        "id": "integrated-classification"
      },
      "source": [
        "## Train loop"
      ],
      "id": "integrated-classification"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:21.867202Z",
          "iopub.status.busy": "2021-05-12T03:03:21.865599Z",
          "iopub.status.idle": "2021-05-12T03:03:21.867975Z",
          "shell.execute_reply": "2021-05-12T03:03:21.868446Z"
        },
        "papermill": {
          "duration": 0.05136,
          "end_time": "2021-05-12T03:03:21.868561",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.817201",
          "status": "completed"
        },
        "tags": [],
        "id": "harmful-explanation"
      },
      "source": [
        "def train_loop(folds, fold):\n",
        "\n",
        "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
        "\n",
        "    # ====================================================\n",
        "    # Data Loader\n",
        "    # ====================================================\n",
        "    X_train_folds = X_train[folds[\"fold\"] != fold]\n",
        "    X_valid_folds = X_train[folds[\"fold\"] == fold]\n",
        "\n",
        "    y_train_folds = y_train[folds[\"fold\"] != fold]\n",
        "    y_valid_folds = y_train[folds[\"fold\"] == fold]\n",
        "\n",
        "    y_df_train_folds = y_df[folds[\"fold\"] != fold]\n",
        "    y_df_valid_folds = y_df[folds[\"fold\"] == fold]\n",
        "\n",
        "    train_dataset = TrainDataset(X_train_folds, y_train_folds)\n",
        "    valid_dataset = TrainDataset(X_valid_folds, y_valid_folds)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=Config.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=Config.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=Config.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=Config.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=False,\n",
        "    )\n",
        "\n",
        "    # ====================================================\n",
        "    # Scheduler\n",
        "    # ====================================================\n",
        "    def get_scheduler(optimizer):\n",
        "        if Config.scheduler == \"ReduceLROnPlateau\":\n",
        "            scheduler = ReduceLROnPlateau(\n",
        "                optimizer, mode=\"min\", factor=Config.factor, patience=Config.patience, verbose=True, eps=Config.eps\n",
        "            )\n",
        "        elif Config.scheduler == \"CosineAnnealingLR\":\n",
        "            scheduler = CosineAnnealingLR(optimizer, T_max=Config.T_max, eta_min=Config.min_lr, last_epoch=-1)\n",
        "        elif Config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
        "            scheduler = CosineAnnealingWarmRestarts(\n",
        "                optimizer, T_0=Config.T_0, T_mult=1, eta_min=Config.min_lr, last_epoch=-1\n",
        "            )\n",
        "        return scheduler\n",
        "\n",
        "    # ====================================================\n",
        "    # model & optimizer\n",
        "    # ====================================================\n",
        "    model = GeeseNetAlpha()\n",
        "    model.to(device)\n",
        "\n",
        "    # Use multi GPU\n",
        "    if device == torch.device(\"cuda\") and not Config.apex:\n",
        "        model = torch.nn.DataParallel(model)  # make parallel\n",
        "        # torch.backends.cudnn.benchmark=True\n",
        "\n",
        "    optimizer = Adam(model.parameters(), lr=Config.lr, weight_decay=Config.weight_decay, amsgrad=False)\n",
        "    scheduler = get_scheduler(optimizer)\n",
        "\n",
        "    # ====================================================\n",
        "    # apex\n",
        "    # ====================================================\n",
        "    if Config.apex:\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
        "\n",
        "    # ====================================================\n",
        "    # Criterion\n",
        "    # ====================================================\n",
        "    def get_criterion():\n",
        "        if Config.criterion == \"CrossEntropyLoss\":\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "        return criterion\n",
        "\n",
        "    criterion = get_criterion()\n",
        "\n",
        "    # ====================================================\n",
        "    # loop\n",
        "    # ====================================================\n",
        "    best_score = 0.0\n",
        "    best_loss = np.inf\n",
        "\n",
        "    for epoch in range(Config.epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # train\n",
        "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
        "\n",
        "        # eval\n",
        "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
        "\n",
        "        if isinstance(scheduler, ReduceLROnPlateau):\n",
        "            scheduler.step(avg_val_loss)\n",
        "        elif isinstance(scheduler, CosineAnnealingLR):\n",
        "            scheduler.step()\n",
        "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
        "            scheduler.step()\n",
        "\n",
        "        # scoring\n",
        "        score = get_score(y_valid_folds, preds.argmax(1))\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        LOGGER.info(\n",
        "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
        "        )\n",
        "        LOGGER.info(f\"Epoch {epoch+1} - Accuracy: {score}\")\n",
        "\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n",
        "            torch.save(\n",
        "                {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_best.pth\"\n",
        "            )\n",
        "\n",
        "        if epoch == Config.epochs - 1:\n",
        "            LOGGER.info(f\"Epoch {epoch+1} - Save final model\")\n",
        "            torch.save(\n",
        "                {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_final.pth\"\n",
        "            )\n",
        "\n",
        "    check_point = torch.load(OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_best.pth\")\n",
        "\n",
        "    y_df_valid_folds[[str(c) for c in range(Config.n_class)]] = check_point[\"preds\"]\n",
        "    y_df_valid_folds[\"preds\"] = check_point[\"preds\"].argmax(1)\n",
        "\n",
        "    return y_df_valid_folds"
      ],
      "id": "harmful-explanation",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.030218,
          "end_time": "2021-05-12T03:03:21.928896",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.898678",
          "status": "completed"
        },
        "tags": [],
        "id": "complimentary-wright"
      },
      "source": [
        "## Main\n"
      ],
      "id": "complimentary-wright"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:21.998085Z",
          "iopub.status.busy": "2021-05-12T03:03:21.997385Z",
          "iopub.status.idle": "2021-05-12T03:03:22.000039Z",
          "shell.execute_reply": "2021-05-12T03:03:21.999634Z"
        },
        "papermill": {
          "duration": 0.04089,
          "end_time": "2021-05-12T03:03:22.000150",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.959260",
          "status": "completed"
        },
        "tags": [],
        "id": "particular-adaptation"
      },
      "source": [
        "def main():\n",
        "    def get_result(result_df):\n",
        "        preds = result_df[\"preds\"].values\n",
        "        labels = result_df[\"action\"].values\n",
        "        score = get_score(labels, preds)\n",
        "        LOGGER.info(f\"Score: {score:<.5f}\")\n",
        "\n",
        "    if Config.train:\n",
        "        # train\n",
        "        oof_df = pd.DataFrame()\n",
        "        for fold in range(Config.n_fold):\n",
        "            _oof_df = train_loop(folds, fold)\n",
        "            oof_df = pd.concat([oof_df, _oof_df])\n",
        "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
        "            get_result(_oof_df)\n",
        "        # CV result\n",
        "        LOGGER.info(f\"========== CV ==========\")\n",
        "        get_result(oof_df)\n",
        "        # save result\n",
        "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)"
      ],
      "id": "particular-adaptation",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:22.069767Z",
          "iopub.status.busy": "2021-05-12T03:03:22.068862Z",
          "iopub.status.idle": "2021-05-12T03:49:59.678255Z",
          "shell.execute_reply": "2021-05-12T03:49:59.677710Z"
        },
        "papermill": {
          "duration": 2797.64711,
          "end_time": "2021-05-12T03:49:59.678400",
          "exception": false,
          "start_time": "2021-05-12T03:03:22.031290",
          "status": "completed"
        },
        "tags": [],
        "id": "backed-journal",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c9f0ff3d-795e-466b-e22e-9ba21d08c874"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "id": "backed-journal",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========== fold: 0 training ==========\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [1][0/642] Elapsed 0m 0s (remain 5m 37s) Loss: 1.3819(1.3819) Grad: 0.4928 LR: 0.001000  \n",
            "Epoch: [1][100/642] Elapsed 0m 14s (remain 1m 19s) Loss: 0.6012(0.7205) Grad: 0.7432 LR: 0.001000  \n",
            "Epoch: [1][200/642] Elapsed 0m 29s (remain 1m 3s) Loss: 0.5813(0.6668) Grad: 0.7146 LR: 0.001000  \n",
            "Epoch: [1][300/642] Elapsed 0m 43s (remain 0m 49s) Loss: 0.5728(0.6383) Grad: 1.0060 LR: 0.001000  \n",
            "Epoch: [1][400/642] Elapsed 0m 57s (remain 0m 34s) Loss: 0.5191(0.6216) Grad: 0.6914 LR: 0.001000  \n",
            "Epoch: [1][500/642] Elapsed 1m 12s (remain 0m 20s) Loss: 0.5174(0.6073) Grad: 0.4872 LR: 0.001000  \n",
            "Epoch: [1][600/642] Elapsed 1m 26s (remain 0m 5s) Loss: 0.5729(0.5964) Grad: 0.8798 LR: 0.001000  \n",
            "Epoch: [1][641/642] Elapsed 1m 32s (remain 0m 0s) Loss: 0.5589(0.5926) Grad: 0.6233 LR: 0.001000  \n",
            "EVAL: [0/161] Elapsed 0m 0s (remain 1m 32s) Loss: 0.4899(0.4899) \n",
            "EVAL: [100/161] Elapsed 0m 4s (remain 0m 2s) Loss: 0.5256(0.5318) \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 - avg_train_loss: 0.5926  avg_val_loss: 0.5312  time: 99s\n",
            "Epoch 1 - Accuracy: 0.7617019951580636\n",
            "Epoch 1 - Save Best Score: 0.7617 Model\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVAL: [160/161] Elapsed 0m 6s (remain 0m 0s) Loss: 0.5655(0.5312) \n",
            "Epoch: [2][0/642] Elapsed 0m 0s (remain 7m 6s) Loss: 0.5176(0.5176) Grad: 0.7985 LR: 0.000976  \n",
            "Epoch: [2][100/642] Elapsed 0m 14s (remain 1m 20s) Loss: 0.5187(0.5179) Grad: 0.8288 LR: 0.000976  \n",
            "Epoch: [2][200/642] Elapsed 0m 29s (remain 1m 4s) Loss: 0.5030(0.5193) Grad: 0.5762 LR: 0.000976  \n",
            "Epoch: [2][300/642] Elapsed 0m 43s (remain 0m 49s) Loss: 0.5133(0.5180) Grad: 0.4613 LR: 0.000976  \n",
            "Epoch: [2][400/642] Elapsed 0m 57s (remain 0m 34s) Loss: 0.4793(0.5176) Grad: 0.4534 LR: 0.000976  \n",
            "Epoch: [2][500/642] Elapsed 1m 12s (remain 0m 20s) Loss: 0.4810(0.5165) Grad: 0.3822 LR: 0.000976  \n",
            "Epoch: [2][600/642] Elapsed 1m 26s (remain 0m 5s) Loss: 0.5026(0.5161) Grad: 0.9104 LR: 0.000976  \n",
            "Epoch: [2][641/642] Elapsed 1m 32s (remain 0m 0s) Loss: 0.5636(0.5160) Grad: 0.9159 LR: 0.000976  \n",
            "EVAL: [0/161] Elapsed 0m 0s (remain 1m 27s) Loss: 0.4650(0.4650) \n",
            "EVAL: [100/161] Elapsed 0m 4s (remain 0m 2s) Loss: 0.5111(0.5103) \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2 - avg_train_loss: 0.5160  avg_val_loss: 0.5107  time: 99s\n",
            "Epoch 2 - Accuracy: 0.7714092214757786\n",
            "Epoch 2 - Save Best Score: 0.7714 Model\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVAL: [160/161] Elapsed 0m 6s (remain 0m 0s) Loss: 0.5318(0.5107) \n",
            "Epoch: [3][0/642] Elapsed 0m 0s (remain 4m 25s) Loss: 0.5402(0.5402) Grad: 0.6498 LR: 0.000905  \n",
            "Epoch: [3][100/642] Elapsed 0m 14s (remain 1m 18s) Loss: 0.4709(0.4968) Grad: 0.5107 LR: 0.000905  \n",
            "Epoch: [3][200/642] Elapsed 0m 28s (remain 1m 3s) Loss: 0.4721(0.4969) Grad: 0.7209 LR: 0.000905  \n",
            "Epoch: [3][300/642] Elapsed 0m 43s (remain 0m 48s) Loss: 0.4533(0.4960) Grad: 0.6256 LR: 0.000905  \n",
            "Epoch: [3][400/642] Elapsed 0m 57s (remain 0m 34s) Loss: 0.4876(0.4956) Grad: 0.4901 LR: 0.000905  \n",
            "Epoch: [3][500/642] Elapsed 1m 11s (remain 0m 20s) Loss: 0.4811(0.4945) Grad: 0.4185 LR: 0.000905  \n",
            "Epoch: [3][600/642] Elapsed 1m 25s (remain 0m 5s) Loss: 0.5087(0.4938) Grad: 0.5529 LR: 0.000905  \n",
            "Epoch: [3][641/642] Elapsed 1m 31s (remain 0m 0s) Loss: 0.5331(0.4933) Grad: 0.5467 LR: 0.000905  \n",
            "EVAL: [0/161] Elapsed 0m 0s (remain 0m 40s) Loss: 0.4530(0.4530) \n",
            "EVAL: [100/161] Elapsed 0m 4s (remain 0m 2s) Loss: 0.4946(0.5016) \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3 - avg_train_loss: 0.4933  avg_val_loss: 0.5014  time: 99s\n",
            "Epoch 3 - Accuracy: 0.7774499653591362\n",
            "Epoch 3 - Save Best Score: 0.7774 Model\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVAL: [160/161] Elapsed 0m 6s (remain 0m 0s) Loss: 0.5316(0.5014) \n",
            "Epoch: [4][0/642] Elapsed 0m 0s (remain 4m 25s) Loss: 0.4604(0.4604) Grad: 0.4722 LR: 0.000796  \n",
            "Epoch: [4][100/642] Elapsed 0m 14s (remain 1m 18s) Loss: 0.4881(0.4733) Grad: 0.7677 LR: 0.000796  \n",
            "Epoch: [4][200/642] Elapsed 0m 28s (remain 1m 3s) Loss: 0.4921(0.4745) Grad: 0.5668 LR: 0.000796  \n",
            "Epoch: [4][300/642] Elapsed 0m 43s (remain 0m 48s) Loss: 0.4743(0.4753) Grad: 0.6255 LR: 0.000796  \n",
            "Epoch: [4][400/642] Elapsed 0m 57s (remain 0m 34s) Loss: 0.4978(0.4772) Grad: 0.6329 LR: 0.000796  \n",
            "Epoch: [4][500/642] Elapsed 1m 11s (remain 0m 20s) Loss: 0.4815(0.4777) Grad: 0.6839 LR: 0.000796  \n",
            "Epoch: [4][600/642] Elapsed 1m 25s (remain 0m 5s) Loss: 0.4788(0.4779) Grad: 0.6970 LR: 0.000796  \n",
            "Epoch: [4][641/642] Elapsed 1m 31s (remain 0m 0s) Loss: 0.4859(0.4778) Grad: 0.6054 LR: 0.000796  \n",
            "EVAL: [0/161] Elapsed 0m 0s (remain 0m 38s) Loss: 0.4354(0.4354) \n",
            "EVAL: [100/161] Elapsed 0m 4s (remain 0m 2s) Loss: 0.5036(0.4944) \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4 - avg_train_loss: 0.4778  avg_val_loss: 0.4940  time: 99s\n",
            "Epoch 4 - Accuracy: 0.7811553701123298\n",
            "Epoch 4 - Save Best Score: 0.7812 Model\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVAL: [160/161] Elapsed 0m 6s (remain 0m 0s) Loss: 0.5155(0.4940) \n",
            "Epoch: [5][0/642] Elapsed 0m 0s (remain 4m 31s) Loss: 0.5291(0.5291) Grad: 0.5399 LR: 0.000658  \n",
            "Epoch: [5][100/642] Elapsed 0m 14s (remain 1m 18s) Loss: 0.4669(0.4577) Grad: 0.4763 LR: 0.000658  \n",
            "Epoch: [5][200/642] Elapsed 0m 28s (remain 1m 3s) Loss: 0.4136(0.4585) Grad: 0.5038 LR: 0.000658  \n",
            "Epoch: [5][300/642] Elapsed 0m 43s (remain 0m 48s) Loss: 0.4398(0.4601) Grad: 0.6748 LR: 0.000658  \n",
            "Epoch: [5][400/642] Elapsed 0m 57s (remain 0m 34s) Loss: 0.4777(0.4614) Grad: 0.5371 LR: 0.000658  \n",
            "Epoch: [5][500/642] Elapsed 1m 11s (remain 0m 20s) Loss: 0.4833(0.4624) Grad: 0.6902 LR: 0.000658  \n",
            "Epoch: [5][600/642] Elapsed 1m 25s (remain 0m 5s) Loss: 0.5015(0.4630) Grad: 0.6358 LR: 0.000658  \n",
            "Epoch: [5][641/642] Elapsed 1m 31s (remain 0m 0s) Loss: 0.4575(0.4628) Grad: 0.5479 LR: 0.000658  \n",
            "EVAL: [0/161] Elapsed 0m 0s (remain 0m 42s) Loss: 0.4556(0.4556) \n",
            "EVAL: [100/161] Elapsed 0m 4s (remain 0m 2s) Loss: 0.4894(0.4983) \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5 - avg_train_loss: 0.4628  avg_val_loss: 0.4969  time: 98s\n",
            "Epoch 5 - Accuracy: 0.779559555040051\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVAL: [160/161] Elapsed 0m 6s (remain 0m 0s) Loss: 0.5255(0.4969) \n",
            "Epoch: [6][0/642] Elapsed 0m 0s (remain 4m 25s) Loss: 0.4501(0.4501) Grad: 0.4605 LR: 0.000505  \n",
            "Epoch: [6][100/642] Elapsed 0m 14s (remain 1m 18s) Loss: 0.4338(0.4415) Grad: 0.5732 LR: 0.000505  \n",
            "Epoch: [6][200/642] Elapsed 0m 28s (remain 1m 3s) Loss: 0.4304(0.4435) Grad: 0.6631 LR: 0.000505  \n",
            "Epoch: [6][300/642] Elapsed 0m 43s (remain 0m 48s) Loss: 0.4798(0.4452) Grad: 0.5773 LR: 0.000505  \n",
            "Epoch: [6][400/642] Elapsed 0m 57s (remain 0m 34s) Loss: 0.4460(0.4459) Grad: 0.4852 LR: 0.000505  \n",
            "Epoch: [6][500/642] Elapsed 1m 11s (remain 0m 20s) Loss: 0.4390(0.4476) Grad: 0.4549 LR: 0.000505  \n",
            "Epoch: [6][600/642] Elapsed 1m 25s (remain 0m 5s) Loss: 0.4722(0.4485) Grad: 0.6065 LR: 0.000505  \n",
            "Epoch: [6][641/642] Elapsed 1m 31s (remain 0m 0s) Loss: 0.3932(0.4486) Grad: 0.5307 LR: 0.000505  \n",
            "EVAL: [0/161] Elapsed 0m 0s (remain 0m 44s) Loss: 0.4381(0.4381) \n",
            "EVAL: [100/161] Elapsed 0m 4s (remain 0m 2s) Loss: 0.5030(0.4912) \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6 - avg_train_loss: 0.4486  avg_val_loss: 0.4892  time: 98s\n",
            "Epoch 6 - Accuracy: 0.7838020877931824\n",
            "Epoch 6 - Save Best Score: 0.7838 Model\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVAL: [160/161] Elapsed 0m 6s (remain 0m 0s) Loss: 0.5159(0.4892) \n",
            "Epoch: [7][0/642] Elapsed 0m 0s (remain 4m 22s) Loss: 0.4543(0.4543) Grad: 0.6314 LR: 0.000352  \n",
            "Epoch: [7][100/642] Elapsed 0m 14s (remain 1m 18s) Loss: 0.4030(0.4277) Grad: 0.6388 LR: 0.000352  \n",
            "Epoch: [7][200/642] Elapsed 0m 28s (remain 1m 3s) Loss: 0.4400(0.4300) Grad: 0.5665 LR: 0.000352  \n",
            "Epoch: [7][300/642] Elapsed 0m 43s (remain 0m 48s) Loss: 0.3845(0.4305) Grad: 0.6325 LR: 0.000352  \n",
            "Epoch: [7][400/642] Elapsed 0m 57s (remain 0m 34s) Loss: 0.4015(0.4316) Grad: 0.5311 LR: 0.000352  \n",
            "Epoch: [7][500/642] Elapsed 1m 11s (remain 0m 20s) Loss: 0.4494(0.4318) Grad: 0.5965 LR: 0.000352  \n",
            "Epoch: [7][600/642] Elapsed 1m 26s (remain 0m 5s) Loss: 0.4618(0.4321) Grad: 0.6593 LR: 0.000352  \n",
            "Epoch: [7][641/642] Elapsed 1m 31s (remain 0m 0s) Loss: 0.3993(0.4320) Grad: 0.5216 LR: 0.000352  \n",
            "EVAL: [0/161] Elapsed 0m 0s (remain 0m 44s) Loss: 0.4358(0.4358) \n",
            "EVAL: [100/161] Elapsed 0m 4s (remain 0m 2s) Loss: 0.5064(0.4940) \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7 - avg_train_loss: 0.4320  avg_val_loss: 0.4917  time: 99s\n",
            "Epoch 7 - Accuracy: 0.7836152606627692\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVAL: [160/161] Elapsed 0m 6s (remain 0m 0s) Loss: 0.5000(0.4917) \n",
            "Epoch: [8][0/642] Elapsed 0m 0s (remain 4m 40s) Loss: 0.3882(0.3882) Grad: 0.4602 LR: 0.000214  \n",
            "Epoch: [8][100/642] Elapsed 0m 14s (remain 1m 18s) Loss: 0.4224(0.4147) Grad: 0.6838 LR: 0.000214  \n",
            "Epoch: [8][200/642] Elapsed 0m 28s (remain 1m 3s) Loss: 0.4258(0.4143) Grad: 0.6292 LR: 0.000214  \n",
            "Epoch: [8][300/642] Elapsed 0m 43s (remain 0m 48s) Loss: 0.4262(0.4143) Grad: 0.6082 LR: 0.000214  \n",
            "Epoch: [8][400/642] Elapsed 0m 57s (remain 0m 34s) Loss: 0.4083(0.4145) Grad: 0.7034 LR: 0.000214  \n",
            "Epoch: [8][500/642] Elapsed 1m 11s (remain 0m 20s) Loss: 0.3976(0.4138) Grad: 0.6181 LR: 0.000214  \n",
            "Epoch: [8][600/642] Elapsed 1m 25s (remain 0m 5s) Loss: 0.3918(0.4146) Grad: 0.7292 LR: 0.000214  \n",
            "Epoch: [8][641/642] Elapsed 1m 31s (remain 0m 0s) Loss: 0.4327(0.4148) Grad: 0.7962 LR: 0.000214  \n",
            "EVAL: [0/161] Elapsed 0m 0s (remain 0m 39s) Loss: 0.4397(0.4397) \n",
            "EVAL: [100/161] Elapsed 0m 4s (remain 0m 2s) Loss: 0.4985(0.4984) \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8 - avg_train_loss: 0.4148  avg_val_loss: 0.4966  time: 98s\n",
            "Epoch 8 - Accuracy: 0.7833972956772872\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVAL: [160/161] Elapsed 0m 6s (remain 0m 0s) Loss: 0.4935(0.4966) \n",
            "Epoch: [9][0/642] Elapsed 0m 0s (remain 4m 29s) Loss: 0.3909(0.3909) Grad: 0.5720 LR: 0.000105  \n",
            "Epoch: [9][100/642] Elapsed 0m 14s (remain 1m 18s) Loss: 0.3927(0.3952) Grad: 0.6553 LR: 0.000105  \n",
            "Epoch: [9][200/642] Elapsed 0m 28s (remain 1m 3s) Loss: 0.4109(0.3962) Grad: 0.7140 LR: 0.000105  \n",
            "Epoch: [9][300/642] Elapsed 0m 43s (remain 0m 48s) Loss: 0.4048(0.3967) Grad: 0.6898 LR: 0.000105  \n",
            "Epoch: [9][400/642] Elapsed 0m 57s (remain 0m 34s) Loss: 0.3811(0.3966) Grad: 0.6805 LR: 0.000105  \n",
            "Epoch: [9][500/642] Elapsed 1m 11s (remain 0m 20s) Loss: 0.3738(0.3975) Grad: 0.6208 LR: 0.000105  \n",
            "Epoch: [9][600/642] Elapsed 1m 25s (remain 0m 5s) Loss: 0.4046(0.3986) Grad: 0.6814 LR: 0.000105  \n",
            "Epoch: [9][641/642] Elapsed 1m 31s (remain 0m 0s) Loss: 0.4482(0.3989) Grad: 0.7963 LR: 0.000105  \n",
            "EVAL: [0/161] Elapsed 0m 0s (remain 0m 48s) Loss: 0.4445(0.4445) \n",
            "EVAL: [100/161] Elapsed 0m 4s (remain 0m 2s) Loss: 0.5128(0.5019) \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9 - avg_train_loss: 0.3989  avg_val_loss: 0.5004  time: 98s\n",
            "Epoch 9 - Accuracy: 0.783350588894684\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVAL: [160/161] Elapsed 0m 6s (remain 0m 0s) Loss: 0.4949(0.5004) \n",
            "Epoch: [10][0/642] Elapsed 0m 0s (remain 4m 28s) Loss: 0.4380(0.4380) Grad: 0.7612 LR: 0.000034  \n",
            "Epoch: [10][100/642] Elapsed 0m 14s (remain 1m 18s) Loss: 0.3728(0.3872) Grad: 0.5851 LR: 0.000034  \n",
            "Epoch: [10][200/642] Elapsed 0m 28s (remain 1m 3s) Loss: 0.4209(0.3870) Grad: 0.7678 LR: 0.000034  \n",
            "Epoch: [10][300/642] Elapsed 0m 43s (remain 0m 48s) Loss: 0.3956(0.3877) Grad: 0.6339 LR: 0.000034  \n",
            "Epoch: [10][400/642] Elapsed 0m 57s (remain 0m 34s) Loss: 0.3845(0.3874) Grad: 0.6586 LR: 0.000034  \n",
            "Epoch: [10][500/642] Elapsed 1m 11s (remain 0m 20s) Loss: 0.3940(0.3876) Grad: 0.7304 LR: 0.000034  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-972361fa1b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-bf7c3c1dd7ea>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moof_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0m_oof_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0moof_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_oof_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"========== fold: {fold} result ==========\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-0cab51cbb1ea>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(folds, fold)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-ac347ec147ee>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, scheduler, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.209774,
          "end_time": "2021-05-12T03:50:00.096860",
          "exception": false,
          "start_time": "2021-05-12T03:49:59.887086",
          "status": "completed"
        },
        "tags": [],
        "id": "human-arena"
      },
      "source": [
        ""
      ],
      "id": "human-arena",
      "execution_count": null,
      "outputs": []
    }
  ]
}
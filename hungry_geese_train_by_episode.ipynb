{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abroad-piece",
    "papermill": {
     "duration": 0.025714,
     "end_time": "2021-05-12T03:01:02.640708",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.614994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About this notebook ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pressing-commercial",
    "papermill": {
     "duration": 0.024272,
     "end_time": "2021-05-12T03:01:02.689850",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.665578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "german-ethics",
    "papermill": {
     "duration": 1.852306,
     "end_time": "2021-05-12T03:01:04.566362",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.714056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "apparent-fiction",
    "papermill": {
     "duration": 0.030961,
     "end_time": "2021-05-12T03:01:04.622818",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.591857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robust-humanity",
    "papermill": {
     "duration": 0.024539,
     "end_time": "2021-05-12T03:01:04.672270",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.647731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "designed-effect",
    "papermill": {
     "duration": 0.031167,
     "end_time": "2021-05-12T03:01:04.728079",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.696912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"../input/hungrygeeseepisode/hungry-geese-episode/\"\n",
    "OUTPUT_DIR = \"pre-models/\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "special-broadcast",
    "outputId": "c440e1e9-5651-42ee-eb0f-08c822d7471a",
    "papermill": {
     "duration": 0.31211,
     "end_time": "2021-05-12T03:01:05.064722",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.752612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16521\n"
     ]
    }
   ],
   "source": [
    "paths = [path for path in glob.glob(BASE_DIR + \"*.json\") if \"info\" not in path]\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "editorial-haiti",
    "papermill": {
     "duration": 0.024908,
     "end_time": "2021-05-12T03:01:05.115280",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.090372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "opened-python",
    "papermill": {
     "duration": 0.035637,
     "end_time": "2021-05-12T03:01:05.176119",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.140482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 440\n",
    "\n",
    "    n_class = 4\n",
    "    n_fold = 10\n",
    "\n",
    "    geese_net_layers = 12\n",
    "    geese_net_filters = 128\n",
    "\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "\n",
    "    num_workers = 4\n",
    "    batch_size = 3200\n",
    "\n",
    "    scheduler = \"CosineAnnealingWarmRestarts\"\n",
    "    # factor = 0.2  # ReduceLROnPlateau\n",
    "    # patience = 4  # ReduceLROnPlateau\n",
    "    # eps = 1e-6  # ReduceLROnPlateau\n",
    "    # T_max = 10  # CosineAnnealingLR\n",
    "    T_0 = 12  # CosineAnnealingWarmRestarts\n",
    "\n",
    "    criterion = \"CrossEntropyLoss\"\n",
    "    lr = 1e-3\n",
    "    min_lr = 1e-4\n",
    "    weight_decay = 0\n",
    "\n",
    "    epochs = 12\n",
    "    model_name = \"geese_net\"\n",
    "\n",
    "    print_freq = 100\n",
    "\n",
    "    train = True\n",
    "    tuning = False\n",
    "    debug = False\n",
    "    apex = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "contained-singles",
    "papermill": {
     "duration": 0.031266,
     "end_time": "2021-05-12T03:01:05.235456",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.204190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.tuning:\n",
    "    Config.epochs = 2\n",
    "\n",
    "if Config.debug:\n",
    "    Config.epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dietary-track",
    "papermill": {
     "duration": 0.031421,
     "end_time": "2021-05-12T03:01:05.292382",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.260961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.apex:\n",
    "    from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "invalid-dispute",
    "papermill": {
     "duration": 0.169531,
     "end_time": "2021-05-12T03:01:05.488665",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.319134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "treated-serum",
    "papermill": {
     "duration": 0.025219,
     "end_time": "2021-05-12T03:01:05.539482",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.514263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gothic-alloy",
    "papermill": {
     "duration": 0.070842,
     "end_time": "2021-05-12T03:01:05.642364",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.571522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=Config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "experienced-correspondence",
    "papermill": {
     "duration": 0.053842,
     "end_time": "2021-05-12T03:01:05.741858",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.688016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reverse_ns(y):\n",
    "    if y == 0:\n",
    "        return 1\n",
    "    if y == 1:\n",
    "        return 0\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_we(y):\n",
    "    if y == 2:\n",
    "        return 3\n",
    "    if y == 3:\n",
    "        return 2\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_nswe(y):\n",
    "    return reverse_ns(reverse_we(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "further-transaction",
    "papermill": {
     "duration": 0.042365,
     "end_time": "2021-05-12T03:01:05.826807",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.784442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "naughty-clause",
    "papermill": {
     "duration": 0.058537,
     "end_time": "2021-05-12T03:01:05.928292",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.869755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_input(obses):\n",
    "    b = np.zeros((17, 7 * 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "        pid = (p - obs[\"index\"]) % 4\n",
    "\n",
    "        # head position\n",
    "        for pos in pos_list[:1]:\n",
    "            b[0 + pid, pos] = 1\n",
    "        # tip position\n",
    "        for pos in pos_list[-1:]:\n",
    "            b[4 + pid, pos] = 1\n",
    "        # whole position\n",
    "        for pos in pos_list:\n",
    "            b[8 + pid, pos] = 1\n",
    "\n",
    "    # previous head position\n",
    "    if len(obses) > 1:\n",
    "        obs_prev = obses[-2]\n",
    "        for p, pos_list in enumerate(obs_prev[\"geese\"]):\n",
    "            for pos in pos_list[:1]:\n",
    "                b[12 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    # food\n",
    "    for pos in obs[\"food\"]:\n",
    "        b[16, pos] = 1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "i6lOS7itC0da"
   },
   "outputs": [],
   "source": [
    "def observation_num_step(obses):\n",
    "    b = np.zeros((7, 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    b[0, 0] = obs[\"step\"]  # 0-198\n",
    "\n",
    "    return b.reshape(1, 7, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pretty-aaron",
    "papermill": {
     "duration": 0.042985,
     "end_time": "2021-05-12T03:01:06.014038",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.971053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "international-secret",
    "papermill": {
     "duration": 0.064855,
     "end_time": "2021-05-12T03:01:06.121648",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.056793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset_from_json(filepath, json_object=None, standing=0):\n",
    "    if json_object is None:\n",
    "        json_open = open(path, \"r\")\n",
    "        json_load = json.load(json_open)\n",
    "    else:\n",
    "        json_load = json_object\n",
    "\n",
    "    try:\n",
    "        winner_index = np.argmax(np.argsort(json_load[\"rewards\"]) == 3 - standing)\n",
    "\n",
    "        obses = []\n",
    "        X = []\n",
    "        y = []\n",
    "        actions = {\"NORTH\": 0, \"SOUTH\": 1, \"WEST\": 2, \"EAST\": 3}\n",
    "\n",
    "        for i in range(len(json_load[\"steps\"]) - 1):\n",
    "            if json_load[\"steps\"][i][winner_index][\"status\"] == \"ACTIVE\":\n",
    "                y_ = json_load[\"steps\"][i + 1][winner_index][\"action\"]\n",
    "                if y_ is not None:\n",
    "                    step = json_load[\"steps\"][i]\n",
    "                    step[winner_index][\"observation\"][\"geese\"] = step[0][\"observation\"][\"geese\"]\n",
    "                    step[winner_index][\"observation\"][\"food\"] = step[0][\"observation\"][\"food\"]\n",
    "                    step[winner_index][\"observation\"][\"step\"] = step[0][\"observation\"][\"step\"]\n",
    "                    obses.append(step[winner_index][\"observation\"])\n",
    "                    y.append(actions[y_])\n",
    "\n",
    "                    y.append(reverse_ns(actions[y_]))  # 上下反転\n",
    "                    y.append(reverse_we(actions[y_]))  # 左右反転\n",
    "                    y.append(reverse_nswe(actions[y_]))  # 上下左右反転\n",
    "\n",
    "        for j in range(len(obses)):\n",
    "            # X_ = make_input(obses[: j + 1])\n",
    "\n",
    "            X_ = []\n",
    "            X_.append(make_input(obses[: j + 1]))\n",
    "            # X_.append(observation_num_step(obses[: j + 1]))\n",
    "            X_ = np.concatenate(X_)\n",
    "\n",
    "            X.append(X_)\n",
    "\n",
    "            X.append(X_[:, ::-1, :])  # 上下反転\n",
    "            X.append(X_[:, :, ::-1])  # 左右反転\n",
    "            X.append(X_[:, ::-1, ::-1])  # 上下左右反転\n",
    "\n",
    "        X = np.array(X, dtype=np.uint8)  # [starting_step:]\n",
    "        y = np.array(y, dtype=np.uint8)  # [starting_step:]\n",
    "\n",
    "        return X, y\n",
    "    except:\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "4134662bdbe04a918d9809632e268ef8",
      "8ddb49ac3c91409f99a569a061a70b3d",
      "0857c0fa22b544488d65bb2c7dad18ee",
      "e33e4f894b424988b316c468bc9225ce",
      "c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "f905db5005be40b194ea150c8b0deb9f",
      "04a486aa6f454d8f92e388dba1b9ee21",
      "507d2b6a02bb43d0bb4c8c2734f19cbb"
     ]
    },
    "id": "handled-pleasure",
    "outputId": "955c1c6b-36bc-4b30-dc44-b72b05398f8c",
    "papermill": {
     "duration": 15.320591,
     "end_time": "2021-05-12T03:01:21.474816",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.154225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012fea68ab794bc0952c28a23012f5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=16521.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num episode: 10343040\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for path in tqdm(paths[: int(len(paths))]):\n",
    "    X, y = create_dataset_from_json(path, standing=0)  # use only winners' moves\n",
    "    if X is not 0:\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "persistent-loading",
    "papermill": {
     "duration": 112.92618,
     "end_time": "2021-05-12T03:03:14.428162",
     "exception": false,
     "start_time": "2021-05-12T03:01:21.501982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# X_train, unique_index = np.unique(X_train, axis=0, return_index=True)  # remove duplicate\n",
    "# y_train = y_train[unique_index]\n",
    "\n",
    "# y_train = np.eye(4, dtype=\"uint8\")[y_train]  # to categorical\n",
    "\n",
    "# print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sum_obs = X_train.reshape(X_train.shape[0], -1).sum(1)\n",
    "X_train_group = np.unique(X_train_sum_obs)\n",
    "X_train_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc2112b866c473a8ece69dda6803504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=75.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num episode: 10341154\n"
     ]
    }
   ],
   "source": [
    "X_train_unique = []\n",
    "y_train_unique = []\n",
    "for group in tqdm(X_train_group):\n",
    "    group_index = np.where(X_train_sum_obs == group)\n",
    "\n",
    "    X_train_ = X_train[group_index]\n",
    "    y_train_ = y_train[group_index]\n",
    "\n",
    "    X_train_, unique_index = np.unique(X_train_, axis=0, return_index=True)  # remove duplicate\n",
    "    y_train_ = y_train_[unique_index]\n",
    "\n",
    "    X_train_unique.append(X_train_)\n",
    "    y_train_unique.append(y_train_)\n",
    "\n",
    "X_train = np.concatenate(X_train_unique)\n",
    "y_train = np.concatenate(y_train_unique)\n",
    "\n",
    "print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_sum_obs\n",
    "del X_train_group\n",
    "del X_train_unique\n",
    "del y_train_unique\n",
    "del X_train_\n",
    "del y_train_\n",
    "del group_index\n",
    "del unique_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "micro-french",
    "papermill": {
     "duration": 0.033413,
     "end_time": "2021-05-12T03:03:15.360395",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.326982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    X_train = X_train[:1000]\n",
    "    y_train = y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "wrong-pastor",
    "outputId": "406a2f1d-0b8a-46bf-ca01-546f3110c301",
    "papermill": {
     "duration": 0.036161,
     "end_time": "2021-05-12T03:03:15.425149",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.388988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10341149</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10341150</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10341151</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10341152</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10341153</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10341154 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          action\n",
       "0              2\n",
       "1              3\n",
       "2              1\n",
       "3              2\n",
       "4              0\n",
       "...          ...\n",
       "10341149       3\n",
       "10341150       3\n",
       "10341151       2\n",
       "10341152       2\n",
       "10341153       3\n",
       "\n",
       "[10341154 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(y_train, dtype=np.uint8)\n",
    "y_df.columns = [\"action\"]\n",
    "y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "touched-coordinate",
    "papermill": {
     "duration": 0.027968,
     "end_time": "2021-05-12T03:03:15.557122",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.529154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "moving-skill",
    "outputId": "7542c4b4-f7d3-444c-8450-50bffddb1892",
    "papermill": {
     "duration": 0.202337,
     "end_time": "2021-05-12T03:03:15.787529",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.585192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  action\n",
      "0     0         246342\n",
      "      1         246342\n",
      "      2         270716\n",
      "      3         270716\n",
      "1     0         246342\n",
      "      1         246342\n",
      "      2         270716\n",
      "      3         270716\n",
      "2     0         246342\n",
      "      1         246342\n",
      "      2         270716\n",
      "      3         270716\n",
      "3     0         246342\n",
      "      1         246342\n",
      "      2         270716\n",
      "      3         270716\n",
      "4     0         246342\n",
      "      1         246342\n",
      "      2         270716\n",
      "      3         270715\n",
      "5     0         246342\n",
      "      1         246342\n",
      "      2         270716\n",
      "      3         270715\n",
      "6     0         246342\n",
      "      1         246342\n",
      "      2         270716\n",
      "      3         270715\n",
      "7     0         246342\n",
      "      1         246342\n",
      "      2         270716\n",
      "      3         270715\n",
      "8     0         246342\n",
      "      1         246342\n",
      "      2         270715\n",
      "      3         270716\n",
      "9     0         246342\n",
      "      1         246342\n",
      "      2         270715\n",
      "      3         270716\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "folds = y_df.copy()\n",
    "Fold = StratifiedKFold(n_splits=Config.n_fold, shuffle=True, random_state=Config.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[\"action\"])):\n",
    "    folds.loc[val_index, \"fold\"] = int(n)\n",
    "folds[\"fold\"] = folds[\"fold\"].astype(np.uint8)\n",
    "print(folds.groupby([\"fold\", \"action\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "creative-football",
    "papermill": {
     "duration": 0.029031,
     "end_time": "2021-05-12T03:03:15.845114",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.816083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "other-murder",
    "papermill": {
     "duration": 0.037264,
     "end_time": "2021-05-12T03:03:15.911219",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.873955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, array, label):\n",
    "        self.array = array\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx], torch.tensor(self.label[idx]).long()\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, array):\n",
    "        self.array = array\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adjusted-delhi",
    "outputId": "39504950-84bc-4692-8b90-8a5b64f741e0",
    "papermill": {
     "duration": 0.063691,
     "end_time": "2021-05-12T03:03:16.003693",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.940002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "if Config.debug or False:\n",
    "    train_ds = TrainDataset(X_train, y_train)\n",
    "\n",
    "    for i in range(1):\n",
    "        obs, action = train_ds[i]\n",
    "        print(obs.shape, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceramic-startup",
    "papermill": {
     "duration": 0.02876,
     "end_time": "2021-05-12T03:03:16.061575",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.032815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "unique-trick",
    "papermill": {
     "duration": 0.039055,
     "end_time": "2021-05-12T03:03:16.130239",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.091184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TorusConv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
    "        super().__init__()\n",
    "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([x[:, :, :, -self.edge_size[1] :], x, x[:, :, :, : self.edge_size[1]]], dim=3)\n",
    "        h = torch.cat([h[:, :, -self.edge_size[0] :], h, h[:, :, : self.edge_size[0]]], dim=2)\n",
    "        h = self.conv(h)\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "extra-bradford",
    "papermill": {
     "duration": 0.042421,
     "end_time": "2021-05-12T03:03:16.202024",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.159603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GeeseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers, filters = 12, 32\n",
    "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p = nn.Linear(filters, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(filters * 2, filters, bias=False)\n",
    "        self.head_v2 = nn.Linear(filters, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h_p = F.relu_(self.conv_p(h))\n",
    "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        p = self.head_p(h_head_p)\n",
    "\n",
    "        h_v = F.relu_(self.conv_v(h))\n",
    "        h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_avg_v = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
    "\n",
    "        h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_avg_v], 1)))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p, \"value\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "jspEE71c2Yma"
   },
   "outputs": [],
   "source": [
    "class GeeseNetAlpha(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = Config.geese_net_layers\n",
    "        filters = Config.geese_net_filters\n",
    "\n",
    "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p1 = nn.Linear(filters * 5 + 77, filters * 3, bias=False)\n",
    "        self.head_p2 = nn.Linear(filters * 3, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(filters * 5 + 77, filters * 3, bias=False)\n",
    "        self.head_v2 = nn.Linear(filters * 3, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h_p = F.relu_(self.conv_p(h))\n",
    "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p2 = (h_p * x[:, 1:2]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p3 = (h_p * x[:, 2:3]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p4 = (h_p * x[:, 3:4]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_avg_p1 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(-1)\n",
    "        h_avg_p2 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(1)\n",
    "\n",
    "        h_p = F.relu_(self.head_p1(torch.cat([h_head_p, h_head_p2, h_head_p3, h_head_p4, h_avg_p1, h_avg_p2], 1)))\n",
    "        p = self.head_p2(h_p)\n",
    "\n",
    "        h_v = F.relu_(self.conv_v(h))\n",
    "        h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_head_v2 = (h_v * x[:, 1:2]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_head_v3 = (h_v * x[:, 2:3]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_head_v4 = (h_v * x[:, 3:4]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_avg_v1 = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
    "        h_avg_v2 = h_v.view(h_v.size(0), h_v.size(1), -1).mean(1)\n",
    "\n",
    "        h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_head_v2, h_head_v3, h_head_v4, h_avg_v1, h_avg_v2], 1)))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p, \"value\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "objective-victoria",
    "outputId": "1ab137a5-e26e-4b9c-ff85-95fef713b755",
    "papermill": {
     "duration": 4.955868,
     "end_time": "2021-05-12T03:03:21.187355",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.231487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "if Config.debug or False:\n",
    "    model = GeeseNetAlpha()\n",
    "    # print(model)\n",
    "\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"params: {params:,}\")\n",
    "\n",
    "    train_ds = TrainDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "    for obs, action in train_loader:\n",
    "        output = model(obs)\n",
    "        print(output)\n",
    "        print(f\"{torch.argmax(output['policy'], dim=1)}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "military-fiction",
    "papermill": {
     "duration": 0.033001,
     "end_time": "2021-05-12T03:03:21.255277",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.222276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sophisticated-hearts",
    "papermill": {
     "duration": 0.031759,
     "end_time": "2021-05-12T03:03:21.319849",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.288090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "designing-detective",
    "papermill": {
     "duration": 0.03139,
     "end_time": "2021-05-12T03:03:21.383038",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.351648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "passive-cooper",
    "papermill": {
     "duration": 0.038846,
     "end_time": "2021-05-12T03:03:21.454085",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.415239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(result_df):\n",
    "    preds = result_df[\"preds\"].values\n",
    "    labels = result_df[\"action\"].values\n",
    "    score = get_score(labels, preds)\n",
    "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thirty-tracy",
    "papermill": {
     "duration": 0.0293,
     "end_time": "2021-05-12T03:03:21.514179",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.484879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "introductory-brooklyn",
    "papermill": {
     "duration": 0.039424,
     "end_time": "2021-05-12T03:03:21.582969",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.543545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "raising-laugh",
    "papermill": {
     "duration": 0.042063,
     "end_time": "2021-05-12T03:03:21.654559",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.612496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "\n",
    "    for step, (obs, action) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        y_preds = model(obs.float())[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "\n",
    "        # record loss\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "        if Config.apex:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), Config.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % Config.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print(\n",
    "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
    "                f\"Loss: {losses.val:.4f}({losses.avg:.4f}) \"\n",
    "                f\"Grad: {grad_norm:.4f} \"\n",
    "                f\"LR: {scheduler.get_last_lr()[0]:.6f}  \"\n",
    "            )\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "plain-neighbor",
    "papermill": {
     "duration": 0.041056,
     "end_time": "2021-05-12T03:03:21.726585",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.685529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "\n",
    "    for step, (obs, action) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(obs)[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print(\n",
    "                f\"EVAL: [{step}/{len(valid_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
    "                f\"Loss: {losses.val:.4f}({losses.avg:.4f}) \"\n",
    "            )\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "integrated-classification",
    "papermill": {
     "duration": 0.029832,
     "end_time": "2021-05-12T03:03:21.786427",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.756595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "harmful-explanation",
    "papermill": {
     "duration": 0.05136,
     "end_time": "2021-05-12T03:03:21.868561",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.817201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(folds, fold):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    # X_train_folds = X_train[folds[\"fold\"] != fold]\n",
    "    # X_valid_folds = X_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    # y_train_folds = y_train[folds[\"fold\"] != fold]\n",
    "    y_valid_folds = y_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    # y_df_train_folds = y_df[folds[\"fold\"] != fold]\n",
    "    y_df_valid_folds = y_df[folds[\"fold\"] == fold]\n",
    "\n",
    "    # train_dataset = TrainDataset(X_train[folds[\"fold\"] != fold], y_train[folds[\"fold\"] != fold])\n",
    "    # valid_dataset = TrainDataset(X_train[folds[\"fold\"] == fold], y_valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        TrainDataset(X_train[folds[\"fold\"] != fold], y_train[folds[\"fold\"] != fold]),\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        TrainDataset(X_train[folds[\"fold\"] == fold], y_valid_folds),\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if Config.scheduler == \"ReduceLROnPlateau\":\n",
    "            scheduler = ReduceLROnPlateau(\n",
    "                optimizer, mode=\"min\", factor=Config.factor, patience=Config.patience, verbose=True, eps=Config.eps\n",
    "            )\n",
    "        elif Config.scheduler == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=Config.T_max, eta_min=Config.min_lr, last_epoch=-1)\n",
    "        elif Config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "            scheduler = CosineAnnealingWarmRestarts(\n",
    "                optimizer, T_0=Config.T_0, T_mult=1, eta_min=Config.min_lr, last_epoch=-1\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = GeeseNetAlpha()\n",
    "\n",
    "    # Disable training for value network\n",
    "    for param in model.conv_v.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.head_v1.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.head_v2.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Use multi GPU\n",
    "    if device == torch.device(\"cuda\") and not Config.apex:\n",
    "        model = torch.nn.DataParallel(model)  # make parallel\n",
    "        # torch.backends.cudnn.benchmark=True\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=Config.lr, weight_decay=Config.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # apex\n",
    "    # ====================================================\n",
    "    if Config.apex:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
    "\n",
    "    # ====================================================\n",
    "    # Criterion\n",
    "    # ====================================================\n",
    "    def get_criterion():\n",
    "        if Config.criterion == \"CrossEntropyLoss\":\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        return criterion\n",
    "\n",
    "    criterion = get_criterion()\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    best_score = 0.0\n",
    "    best_loss = np.inf\n",
    "    best_preds = None\n",
    "\n",
    "    for epoch in range(Config.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "\n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(y_valid_folds, preds.argmax(1))\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Accuracy: {score}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_best.pth\")\n",
    "            best_preds = preds\n",
    "\n",
    "        if epoch == Config.epochs - 1:\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save final model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_final.pth\")\n",
    "\n",
    "    if Config.train:\n",
    "        y_df_valid_folds[[str(c) for c in range(Config.n_class)]] = best_preds\n",
    "        y_df_valid_folds[\"preds\"] = best_preds.argmax(1)\n",
    "\n",
    "        return y_df_valid_folds\n",
    "\n",
    "    if Config.tuning:\n",
    "        score = get_score(y_df_valid_folds[\"action\"].values, best_preds.argmax(1))\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    Config.geese_net_layers = trial.suggest_int(\"layers\", 6, 18)\n",
    "    Config.geese_net_filters = trial.suggest_int(\"filters\", 32, 128)\n",
    "\n",
    "    score = train_loop(folds, 0)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "complimentary-wright",
    "papermill": {
     "duration": 0.030218,
     "end_time": "2021-05-12T03:03:21.928896",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.898678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "particular-adaptation",
    "papermill": {
     "duration": 0.04089,
     "end_time": "2021-05-12T03:03:22.000150",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.959260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if Config.train:\n",
    "        # train\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(Config.n_fold):\n",
    "            _oof_df = train_loop(folds, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df)\n",
    "            break  # fold 1つだけ\n",
    "        # CV result\n",
    "        # LOGGER.info(f\"========== CV ==========\")\n",
    "        # get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
    "\n",
    "    if Config.tuning:\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=10)\n",
    "\n",
    "        trial = study.best_trial\n",
    "        print(\"Best trial:\")\n",
    "        print(\"  Value: \", trial.value)\n",
    "        print(\"  Params: \")\n",
    "        for key, value in trial.params.items():\n",
    "            print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "backed-journal",
    "outputId": "c9f0ff3d-795e-466b-e22e-9ba21d08c874",
    "papermill": {
     "duration": 2797.64711,
     "end_time": "2021-05-12T03:49:59.678400",
     "exception": false,
     "start_time": "2021-05-12T03:03:22.031290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2908] Elapsed 0m 6s (remain 298m 45s) Loss: 1.3930(1.3930) Grad: 0.5802 LR: 0.001000  \n",
      "Epoch: [1][100/2908] Elapsed 2m 53s (remain 80m 35s) Loss: 0.5810(0.6809) Grad: 0.5089 LR: 0.001000  \n",
      "Epoch: [1][200/2908] Elapsed 5m 41s (remain 76m 39s) Loss: 0.5348(0.6211) Grad: 0.5582 LR: 0.001000  \n",
      "Epoch: [1][300/2908] Elapsed 8m 29s (remain 73m 31s) Loss: 0.5341(0.5915) Grad: 0.4694 LR: 0.001000  \n",
      "Epoch: [1][400/2908] Elapsed 11m 16s (remain 70m 31s) Loss: 0.5097(0.5728) Grad: 0.3969 LR: 0.001000  \n",
      "Epoch: [1][500/2908] Elapsed 14m 4s (remain 67m 36s) Loss: 0.4956(0.5597) Grad: 0.5190 LR: 0.001000  \n",
      "Epoch: [1][600/2908] Elapsed 16m 51s (remain 64m 44s) Loss: 0.5061(0.5502) Grad: 0.4199 LR: 0.001000  \n",
      "Epoch: [1][700/2908] Elapsed 19m 39s (remain 61m 53s) Loss: 0.5155(0.5423) Grad: 0.4302 LR: 0.001000  \n",
      "Epoch: [1][800/2908] Elapsed 22m 27s (remain 59m 3s) Loss: 0.4812(0.5363) Grad: 0.2754 LR: 0.001000  \n",
      "Epoch: [1][900/2908] Elapsed 25m 14s (remain 56m 13s) Loss: 0.4938(0.5313) Grad: 0.3828 LR: 0.001000  \n",
      "Epoch: [1][1000/2908] Elapsed 28m 2s (remain 53m 24s) Loss: 0.4839(0.5270) Grad: 0.3197 LR: 0.001000  \n",
      "Epoch: [1][1100/2908] Elapsed 30m 50s (remain 50m 36s) Loss: 0.4675(0.5233) Grad: 0.5316 LR: 0.001000  \n",
      "Epoch: [1][1200/2908] Elapsed 33m 37s (remain 47m 47s) Loss: 0.4609(0.5200) Grad: 0.3413 LR: 0.001000  \n",
      "Epoch: [1][1300/2908] Elapsed 36m 25s (remain 44m 59s) Loss: 0.4845(0.5171) Grad: 0.1856 LR: 0.001000  \n",
      "Epoch: [1][1400/2908] Elapsed 39m 12s (remain 42m 10s) Loss: 0.4818(0.5146) Grad: 0.2519 LR: 0.001000  \n",
      "Epoch: [1][1500/2908] Elapsed 42m 0s (remain 39m 22s) Loss: 0.5018(0.5122) Grad: 0.2576 LR: 0.001000  \n",
      "Epoch: [1][1600/2908] Elapsed 44m 47s (remain 36m 34s) Loss: 0.4862(0.5100) Grad: 0.2110 LR: 0.001000  \n",
      "Epoch: [1][1700/2908] Elapsed 47m 35s (remain 33m 46s) Loss: 0.4596(0.5081) Grad: 0.2746 LR: 0.001000  \n",
      "Epoch: [1][1800/2908] Elapsed 50m 23s (remain 30m 58s) Loss: 0.4769(0.5064) Grad: 0.3405 LR: 0.001000  \n",
      "Epoch: [1][1900/2908] Elapsed 53m 11s (remain 28m 10s) Loss: 0.4569(0.5047) Grad: 0.2431 LR: 0.001000  \n",
      "Epoch: [1][2000/2908] Elapsed 55m 58s (remain 25m 22s) Loss: 0.4801(0.5031) Grad: 0.3035 LR: 0.001000  \n",
      "Epoch: [1][2100/2908] Elapsed 58m 46s (remain 22m 34s) Loss: 0.4844(0.5016) Grad: 0.2552 LR: 0.001000  \n",
      "Epoch: [1][2200/2908] Elapsed 61m 33s (remain 19m 46s) Loss: 0.4921(0.5004) Grad: 0.3603 LR: 0.001000  \n",
      "Epoch: [1][2300/2908] Elapsed 64m 21s (remain 16m 58s) Loss: 0.4708(0.4991) Grad: 0.2343 LR: 0.001000  \n",
      "Epoch: [1][2400/2908] Elapsed 67m 8s (remain 14m 10s) Loss: 0.4668(0.4979) Grad: 0.2486 LR: 0.001000  \n",
      "Epoch: [1][2500/2908] Elapsed 69m 56s (remain 11m 22s) Loss: 0.4658(0.4967) Grad: 0.1809 LR: 0.001000  \n",
      "Epoch: [1][2600/2908] Elapsed 72m 44s (remain 8m 35s) Loss: 0.4776(0.4957) Grad: 0.3847 LR: 0.001000  \n",
      "Epoch: [1][2700/2908] Elapsed 75m 31s (remain 5m 47s) Loss: 0.4735(0.4947) Grad: 0.2646 LR: 0.001000  \n",
      "Epoch: [1][2800/2908] Elapsed 78m 19s (remain 2m 59s) Loss: 0.4600(0.4938) Grad: 0.3301 LR: 0.001000  \n",
      "Epoch: [1][2900/2908] Elapsed 81m 7s (remain 0m 11s) Loss: 0.4722(0.4931) Grad: 0.2477 LR: 0.001000  \n",
      "Epoch: [1][2907/2908] Elapsed 81m 18s (remain 0m 0s) Loss: 0.4799(0.4930) Grad: 0.3139 LR: 0.001000  \n",
      "EVAL: [0/324] Elapsed 0m 1s (remain 9m 0s) Loss: 0.7941(0.7941) \n",
      "EVAL: [100/324] Elapsed 0m 50s (remain 1m 51s) Loss: 0.4898(0.5379) \n",
      "EVAL: [200/324] Elapsed 1m 39s (remain 1m 0s) Loss: 0.4512(0.5017) \n",
      "EVAL: [300/324] Elapsed 2m 28s (remain 0m 11s) Loss: 0.3854(0.4775) \n",
      "EVAL: [323/324] Elapsed 2m 39s (remain 0m 0s) Loss: 0.2669(0.4699) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4930  avg_val_loss: 0.4699  time: 5039s\n",
      "Epoch 1 - Accuracy: 0.7957443845758116\n",
      "Epoch 1 - Save Best Score: 0.7957 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2908] Elapsed 0m 3s (remain 176m 48s) Loss: 0.4781(0.4781) Grad: 0.2365 LR: 0.000985  \n",
      "Epoch: [2][100/2908] Elapsed 2m 51s (remain 79m 19s) Loss: 0.4480(0.4652) Grad: 0.2247 LR: 0.000985  \n",
      "Epoch: [2][200/2908] Elapsed 5m 39s (remain 76m 5s) Loss: 0.4491(0.4650) Grad: 0.2159 LR: 0.000985  \n",
      "Epoch: [2][300/2908] Elapsed 8m 26s (remain 73m 7s) Loss: 0.4490(0.4649) Grad: 0.3877 LR: 0.000985  \n",
      "Epoch: [2][400/2908] Elapsed 11m 14s (remain 70m 14s) Loss: 0.4588(0.4644) Grad: 0.1666 LR: 0.000985  \n",
      "Epoch: [2][500/2908] Elapsed 14m 1s (remain 67m 23s) Loss: 0.4525(0.4642) Grad: 0.2712 LR: 0.000985  \n",
      "Epoch: [2][600/2908] Elapsed 16m 49s (remain 64m 33s) Loss: 0.4603(0.4638) Grad: 0.1757 LR: 0.000985  \n",
      "Epoch: [2][700/2908] Elapsed 19m 36s (remain 61m 44s) Loss: 0.4456(0.4640) Grad: 0.3363 LR: 0.000985  \n",
      "Epoch: [2][800/2908] Elapsed 22m 24s (remain 58m 55s) Loss: 0.4527(0.4638) Grad: 0.2447 LR: 0.000985  \n",
      "Epoch: [2][900/2908] Elapsed 25m 11s (remain 56m 7s) Loss: 0.4637(0.4635) Grad: 0.1608 LR: 0.000985  \n",
      "Epoch: [2][1000/2908] Elapsed 27m 59s (remain 53m 19s) Loss: 0.4613(0.4634) Grad: 0.2221 LR: 0.000985  \n",
      "Epoch: [2][1100/2908] Elapsed 30m 47s (remain 50m 31s) Loss: 0.4288(0.4633) Grad: 0.1608 LR: 0.000985  \n",
      "Epoch: [2][1200/2908] Elapsed 33m 34s (remain 47m 43s) Loss: 0.4371(0.4630) Grad: 0.2339 LR: 0.000985  \n",
      "Epoch: [2][1300/2908] Elapsed 36m 22s (remain 44m 55s) Loss: 0.4450(0.4629) Grad: 0.2742 LR: 0.000985  \n",
      "Epoch: [2][1400/2908] Elapsed 39m 9s (remain 42m 7s) Loss: 0.4674(0.4629) Grad: 0.1692 LR: 0.000985  \n",
      "Epoch: [2][1500/2908] Elapsed 41m 57s (remain 39m 19s) Loss: 0.4611(0.4627) Grad: 0.2660 LR: 0.000985  \n",
      "Epoch: [2][1600/2908] Elapsed 44m 44s (remain 36m 31s) Loss: 0.4595(0.4625) Grad: 0.1431 LR: 0.000985  \n",
      "Epoch: [2][1700/2908] Elapsed 47m 32s (remain 33m 43s) Loss: 0.4607(0.4624) Grad: 0.1395 LR: 0.000985  \n",
      "Epoch: [2][1800/2908] Elapsed 50m 20s (remain 30m 56s) Loss: 0.4656(0.4622) Grad: 0.2629 LR: 0.000985  \n",
      "Epoch: [2][1900/2908] Elapsed 53m 7s (remain 28m 8s) Loss: 0.4579(0.4621) Grad: 0.2550 LR: 0.000985  \n",
      "Epoch: [2][2000/2908] Elapsed 55m 55s (remain 25m 20s) Loss: 0.4617(0.4620) Grad: 0.2143 LR: 0.000985  \n",
      "Epoch: [2][2100/2908] Elapsed 58m 42s (remain 22m 33s) Loss: 0.4670(0.4619) Grad: 0.1778 LR: 0.000985  \n",
      "Epoch: [2][2200/2908] Elapsed 61m 30s (remain 19m 45s) Loss: 0.4759(0.4619) Grad: 0.3289 LR: 0.000985  \n",
      "Epoch: [2][2300/2908] Elapsed 64m 17s (remain 16m 57s) Loss: 0.4444(0.4618) Grad: 0.1309 LR: 0.000985  \n",
      "Epoch: [2][2400/2908] Elapsed 67m 5s (remain 14m 10s) Loss: 0.4688(0.4617) Grad: 0.1531 LR: 0.000985  \n",
      "Epoch: [2][2500/2908] Elapsed 69m 52s (remain 11m 22s) Loss: 0.4598(0.4616) Grad: 0.2305 LR: 0.000985  \n",
      "Epoch: [2][2600/2908] Elapsed 72m 40s (remain 8m 34s) Loss: 0.4569(0.4615) Grad: 0.3032 LR: 0.000985  \n",
      "Epoch: [2][2700/2908] Elapsed 75m 28s (remain 5m 47s) Loss: 0.4629(0.4614) Grad: 0.2247 LR: 0.000985  \n",
      "Epoch: [2][2800/2908] Elapsed 78m 15s (remain 2m 59s) Loss: 0.4673(0.4612) Grad: 0.2530 LR: 0.000985  \n",
      "Epoch: [2][2900/2908] Elapsed 81m 3s (remain 0m 11s) Loss: 0.4762(0.4612) Grad: 0.2519 LR: 0.000985  \n",
      "Epoch: [2][2907/2908] Elapsed 81m 15s (remain 0m 0s) Loss: 0.4660(0.4611) Grad: 0.1910 LR: 0.000985  \n",
      "EVAL: [0/324] Elapsed 0m 1s (remain 8m 54s) Loss: 0.7912(0.7912) \n",
      "EVAL: [100/324] Elapsed 0m 50s (remain 1m 51s) Loss: 0.4794(0.5290) \n",
      "EVAL: [200/324] Elapsed 1m 39s (remain 1m 0s) Loss: 0.4382(0.4917) \n",
      "EVAL: [300/324] Elapsed 2m 28s (remain 0m 11s) Loss: 0.3702(0.4667) \n",
      "EVAL: [323/324] Elapsed 2m 39s (remain 0m 0s) Loss: 0.2421(0.4590) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4611  avg_val_loss: 0.4590  time: 5035s\n",
      "Epoch 2 - Accuracy: 0.8006519578074414\n",
      "Epoch 2 - Save Best Score: 0.8007 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/2908] Elapsed 0m 3s (remain 180m 57s) Loss: 0.4742(0.4742) Grad: 0.1856 LR: 0.000940  \n",
      "Epoch: [3][100/2908] Elapsed 2m 51s (remain 79m 31s) Loss: 0.4521(0.4541) Grad: 0.2946 LR: 0.000940  \n",
      "Epoch: [3][200/2908] Elapsed 5m 39s (remain 76m 8s) Loss: 0.4646(0.4537) Grad: 0.1640 LR: 0.000940  \n",
      "Epoch: [3][300/2908] Elapsed 8m 26s (remain 73m 9s) Loss: 0.4371(0.4536) Grad: 0.1947 LR: 0.000940  \n",
      "Epoch: [3][400/2908] Elapsed 11m 14s (remain 70m 15s) Loss: 0.4567(0.4535) Grad: 0.2017 LR: 0.000940  \n",
      "Epoch: [3][500/2908] Elapsed 14m 1s (remain 67m 24s) Loss: 0.4401(0.4536) Grad: 0.1618 LR: 0.000940  \n",
      "Epoch: [3][600/2908] Elapsed 16m 49s (remain 64m 34s) Loss: 0.4565(0.4537) Grad: 0.2678 LR: 0.000940  \n",
      "Epoch: [3][700/2908] Elapsed 19m 36s (remain 61m 45s) Loss: 0.4492(0.4536) Grad: 0.2726 LR: 0.000940  \n",
      "Epoch: [3][800/2908] Elapsed 22m 24s (remain 58m 56s) Loss: 0.4713(0.4536) Grad: 0.2350 LR: 0.000940  \n",
      "Epoch: [3][900/2908] Elapsed 25m 12s (remain 56m 8s) Loss: 0.4210(0.4536) Grad: 0.2871 LR: 0.000940  \n",
      "Epoch: [3][1000/2908] Elapsed 27m 59s (remain 53m 20s) Loss: 0.4638(0.4538) Grad: 0.2340 LR: 0.000940  \n",
      "Epoch: [3][1100/2908] Elapsed 30m 47s (remain 50m 31s) Loss: 0.4705(0.4536) Grad: 0.2718 LR: 0.000940  \n",
      "Epoch: [3][1200/2908] Elapsed 33m 34s (remain 47m 43s) Loss: 0.4575(0.4537) Grad: 0.2243 LR: 0.000940  \n",
      "Epoch: [3][1300/2908] Elapsed 36m 22s (remain 44m 55s) Loss: 0.4485(0.4537) Grad: 0.2801 LR: 0.000940  \n",
      "Epoch: [3][1400/2908] Elapsed 39m 10s (remain 42m 7s) Loss: 0.4568(0.4537) Grad: 0.1930 LR: 0.000940  \n",
      "Epoch: [3][1500/2908] Elapsed 41m 57s (remain 39m 19s) Loss: 0.4334(0.4537) Grad: 0.1316 LR: 0.000940  \n",
      "Epoch: [3][1600/2908] Elapsed 44m 45s (remain 36m 32s) Loss: 0.4352(0.4534) Grad: 0.2442 LR: 0.000940  \n",
      "Epoch: [3][1700/2908] Elapsed 47m 33s (remain 33m 44s) Loss: 0.4652(0.4533) Grad: 0.1847 LR: 0.000940  \n",
      "Epoch: [3][1800/2908] Elapsed 50m 20s (remain 30m 56s) Loss: 0.4607(0.4532) Grad: 0.1984 LR: 0.000940  \n",
      "Epoch: [3][1900/2908] Elapsed 53m 8s (remain 28m 8s) Loss: 0.4757(0.4533) Grad: 0.2484 LR: 0.000940  \n",
      "Epoch: [3][2000/2908] Elapsed 55m 55s (remain 25m 21s) Loss: 0.4581(0.4533) Grad: 0.1781 LR: 0.000940  \n",
      "Epoch: [3][2100/2908] Elapsed 58m 43s (remain 22m 33s) Loss: 0.4536(0.4531) Grad: 0.1911 LR: 0.000940  \n",
      "Epoch: [3][2200/2908] Elapsed 61m 30s (remain 19m 45s) Loss: 0.4598(0.4530) Grad: 0.2448 LR: 0.000940  \n",
      "Epoch: [3][2300/2908] Elapsed 64m 18s (remain 16m 57s) Loss: 0.4512(0.4529) Grad: 0.2841 LR: 0.000940  \n",
      "Epoch: [3][2400/2908] Elapsed 67m 6s (remain 14m 10s) Loss: 0.4467(0.4529) Grad: 0.1277 LR: 0.000940  \n",
      "Epoch: [3][2500/2908] Elapsed 69m 53s (remain 11m 22s) Loss: 0.4702(0.4528) Grad: 0.2002 LR: 0.000940  \n",
      "Epoch: [3][2600/2908] Elapsed 72m 41s (remain 8m 34s) Loss: 0.4484(0.4528) Grad: 0.1553 LR: 0.000940  \n",
      "Epoch: [3][2700/2908] Elapsed 75m 29s (remain 5m 47s) Loss: 0.4472(0.4528) Grad: 0.1752 LR: 0.000940  \n",
      "Epoch: [3][2800/2908] Elapsed 78m 16s (remain 2m 59s) Loss: 0.4334(0.4528) Grad: 0.3614 LR: 0.000940  \n",
      "Epoch: [3][2900/2908] Elapsed 81m 4s (remain 0m 11s) Loss: 0.4321(0.4528) Grad: 0.1651 LR: 0.000940  \n",
      "Epoch: [3][2907/2908] Elapsed 81m 16s (remain 0m 0s) Loss: 0.4407(0.4528) Grad: 0.2262 LR: 0.000940  \n",
      "EVAL: [0/324] Elapsed 0m 1s (remain 9m 2s) Loss: 0.7861(0.7861) \n",
      "EVAL: [100/324] Elapsed 0m 50s (remain 1m 51s) Loss: 0.4760(0.5272) \n",
      "EVAL: [200/324] Elapsed 1m 39s (remain 1m 0s) Loss: 0.4379(0.4889) \n",
      "EVAL: [300/324] Elapsed 2m 28s (remain 0m 11s) Loss: 0.3634(0.4632) \n",
      "EVAL: [323/324] Elapsed 2m 39s (remain 0m 0s) Loss: 0.2498(0.4554) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.4528  avg_val_loss: 0.4554  time: 5037s\n",
      "Epoch 3 - Accuracy: 0.8015744848740374\n",
      "Epoch 3 - Save Best Score: 0.8016 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/2908] Elapsed 0m 3s (remain 177m 30s) Loss: 0.4517(0.4517) Grad: 0.1358 LR: 0.000868  \n",
      "Epoch: [4][100/2908] Elapsed 2m 51s (remain 79m 19s) Loss: 0.4472(0.4442) Grad: 0.1345 LR: 0.000868  \n",
      "Epoch: [4][200/2908] Elapsed 5m 38s (remain 76m 2s) Loss: 0.4298(0.4468) Grad: 0.1686 LR: 0.000868  \n",
      "Epoch: [4][300/2908] Elapsed 8m 26s (remain 73m 5s) Loss: 0.4448(0.4472) Grad: 0.1939 LR: 0.000868  \n",
      "Epoch: [4][400/2908] Elapsed 11m 13s (remain 70m 13s) Loss: 0.4487(0.4470) Grad: 0.1702 LR: 0.000868  \n",
      "Epoch: [4][500/2908] Elapsed 14m 1s (remain 67m 22s) Loss: 0.4374(0.4468) Grad: 0.3306 LR: 0.000868  \n",
      "Epoch: [4][600/2908] Elapsed 16m 48s (remain 64m 33s) Loss: 0.4467(0.4467) Grad: 0.2947 LR: 0.000868  \n",
      "Epoch: [4][700/2908] Elapsed 19m 36s (remain 61m 44s) Loss: 0.4545(0.4466) Grad: 0.1358 LR: 0.000868  \n",
      "Epoch: [4][800/2908] Elapsed 22m 24s (remain 58m 56s) Loss: 0.4576(0.4466) Grad: 0.1334 LR: 0.000868  \n",
      "Epoch: [4][900/2908] Elapsed 25m 11s (remain 56m 7s) Loss: 0.4491(0.4470) Grad: 0.2047 LR: 0.000868  \n",
      "Epoch: [4][1000/2908] Elapsed 27m 59s (remain 53m 19s) Loss: 0.4522(0.4470) Grad: 0.1888 LR: 0.000868  \n",
      "Epoch: [4][1100/2908] Elapsed 30m 46s (remain 50m 31s) Loss: 0.4427(0.4472) Grad: 0.1449 LR: 0.000868  \n",
      "Epoch: [4][1200/2908] Elapsed 33m 34s (remain 47m 43s) Loss: 0.4476(0.4471) Grad: 0.1218 LR: 0.000868  \n",
      "Epoch: [4][1300/2908] Elapsed 36m 22s (remain 44m 55s) Loss: 0.4466(0.4471) Grad: 0.1855 LR: 0.000868  \n",
      "Epoch: [4][1400/2908] Elapsed 39m 9s (remain 42m 7s) Loss: 0.4471(0.4470) Grad: 0.1955 LR: 0.000868  \n",
      "Epoch: [4][1500/2908] Elapsed 41m 57s (remain 39m 19s) Loss: 0.4635(0.4470) Grad: 0.1680 LR: 0.000868  \n",
      "Epoch: [4][1600/2908] Elapsed 44m 45s (remain 36m 31s) Loss: 0.4496(0.4471) Grad: 0.1965 LR: 0.000868  \n",
      "Epoch: [4][1700/2908] Elapsed 47m 32s (remain 33m 44s) Loss: 0.4408(0.4470) Grad: 0.1294 LR: 0.000868  \n",
      "Epoch: [4][1800/2908] Elapsed 50m 20s (remain 30m 56s) Loss: 0.4398(0.4470) Grad: 0.1549 LR: 0.000868  \n",
      "Epoch: [4][1900/2908] Elapsed 53m 7s (remain 28m 8s) Loss: 0.4551(0.4470) Grad: 0.1782 LR: 0.000868  \n",
      "Epoch: [4][2000/2908] Elapsed 55m 55s (remain 25m 20s) Loss: 0.4664(0.4470) Grad: 0.2181 LR: 0.000868  \n",
      "Epoch: [4][2100/2908] Elapsed 58m 42s (remain 22m 33s) Loss: 0.4491(0.4470) Grad: 0.2402 LR: 0.000868  \n",
      "Epoch: [4][2200/2908] Elapsed 61m 30s (remain 19m 45s) Loss: 0.4673(0.4470) Grad: 0.1769 LR: 0.000868  \n",
      "Epoch: [4][2300/2908] Elapsed 64m 17s (remain 16m 57s) Loss: 0.4528(0.4470) Grad: 0.2611 LR: 0.000868  \n",
      "Epoch: [4][2400/2908] Elapsed 67m 5s (remain 14m 10s) Loss: 0.4402(0.4469) Grad: 0.1611 LR: 0.000868  \n",
      "Epoch: [4][2500/2908] Elapsed 69m 53s (remain 11m 22s) Loss: 0.4480(0.4469) Grad: 0.1578 LR: 0.000868  \n",
      "Epoch: [4][2600/2908] Elapsed 72m 40s (remain 8m 34s) Loss: 0.4385(0.4469) Grad: 0.1811 LR: 0.000868  \n",
      "Epoch: [4][2700/2908] Elapsed 75m 28s (remain 5m 47s) Loss: 0.4549(0.4469) Grad: 0.1847 LR: 0.000868  \n",
      "Epoch: [4][2800/2908] Elapsed 78m 15s (remain 2m 59s) Loss: 0.4377(0.4468) Grad: 0.1469 LR: 0.000868  \n",
      "Epoch: [4][2900/2908] Elapsed 81m 3s (remain 0m 11s) Loss: 0.4426(0.4469) Grad: 0.1962 LR: 0.000868  \n",
      "Epoch: [4][2907/2908] Elapsed 81m 15s (remain 0m 0s) Loss: 0.4234(0.4469) Grad: 0.1733 LR: 0.000868  \n",
      "EVAL: [0/324] Elapsed 0m 1s (remain 9m 5s) Loss: 0.7835(0.7835) \n",
      "EVAL: [100/324] Elapsed 0m 50s (remain 1m 51s) Loss: 0.4786(0.5258) \n",
      "EVAL: [200/324] Elapsed 1m 39s (remain 1m 0s) Loss: 0.4342(0.4872) \n",
      "EVAL: [300/324] Elapsed 2m 28s (remain 0m 11s) Loss: 0.3582(0.4611) \n",
      "EVAL: [323/324] Elapsed 2m 39s (remain 0m 0s) Loss: 0.2486(0.4532) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.4469  avg_val_loss: 0.4532  time: 5036s\n",
      "Epoch 4 - Accuracy: 0.8032377412205207\n",
      "Epoch 4 - Save Best Score: 0.8032 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/2908] Elapsed 0m 3s (remain 175m 45s) Loss: 0.4438(0.4438) Grad: 0.1522 LR: 0.000775  \n",
      "Epoch: [5][100/2908] Elapsed 2m 51s (remain 79m 19s) Loss: 0.4329(0.4394) Grad: 0.2363 LR: 0.000775  \n",
      "Epoch: [5][200/2908] Elapsed 5m 38s (remain 76m 3s) Loss: 0.4320(0.4402) Grad: 0.1275 LR: 0.000775  \n",
      "Epoch: [5][300/2908] Elapsed 8m 26s (remain 73m 6s) Loss: 0.4455(0.4407) Grad: 0.2512 LR: 0.000775  \n",
      "Epoch: [5][400/2908] Elapsed 11m 14s (remain 70m 13s) Loss: 0.4688(0.4409) Grad: 0.1064 LR: 0.000775  \n",
      "Epoch: [5][500/2908] Elapsed 14m 1s (remain 67m 23s) Loss: 0.4470(0.4414) Grad: 0.1684 LR: 0.000775  \n",
      "Epoch: [5][600/2908] Elapsed 16m 49s (remain 64m 33s) Loss: 0.4422(0.4416) Grad: 0.1316 LR: 0.000775  \n",
      "Epoch: [5][700/2908] Elapsed 19m 36s (remain 61m 45s) Loss: 0.4667(0.4415) Grad: 0.1505 LR: 0.000775  \n",
      "Epoch: [5][800/2908] Elapsed 22m 24s (remain 58m 56s) Loss: 0.4385(0.4414) Grad: 0.1258 LR: 0.000775  \n",
      "Epoch: [5][900/2908] Elapsed 25m 11s (remain 56m 7s) Loss: 0.4517(0.4414) Grad: 0.2256 LR: 0.000775  \n",
      "Epoch: [5][1000/2908] Elapsed 27m 59s (remain 53m 19s) Loss: 0.4459(0.4416) Grad: 0.1995 LR: 0.000775  \n",
      "Epoch: [5][1100/2908] Elapsed 30m 46s (remain 50m 31s) Loss: 0.4460(0.4417) Grad: 0.1888 LR: 0.000775  \n",
      "Epoch: [5][1200/2908] Elapsed 33m 34s (remain 47m 43s) Loss: 0.4555(0.4418) Grad: 0.1088 LR: 0.000775  \n",
      "Epoch: [5][1300/2908] Elapsed 36m 22s (remain 44m 55s) Loss: 0.4185(0.4418) Grad: 0.1959 LR: 0.000775  \n",
      "Epoch: [5][1400/2908] Elapsed 39m 9s (remain 42m 7s) Loss: 0.4263(0.4418) Grad: 0.1495 LR: 0.000775  \n",
      "Epoch: [5][1500/2908] Elapsed 41m 57s (remain 39m 19s) Loss: 0.4403(0.4418) Grad: 0.1899 LR: 0.000775  \n",
      "Epoch: [5][1600/2908] Elapsed 44m 45s (remain 36m 31s) Loss: 0.4392(0.4416) Grad: 0.1138 LR: 0.000775  \n",
      "Epoch: [5][1700/2908] Elapsed 47m 32s (remain 33m 44s) Loss: 0.4439(0.4417) Grad: 0.1242 LR: 0.000775  \n",
      "Epoch: [5][1800/2908] Elapsed 50m 20s (remain 30m 56s) Loss: 0.4509(0.4417) Grad: 0.1748 LR: 0.000775  \n",
      "Epoch: [5][1900/2908] Elapsed 53m 7s (remain 28m 8s) Loss: 0.4280(0.4417) Grad: 0.1068 LR: 0.000775  \n",
      "Epoch: [5][2000/2908] Elapsed 55m 55s (remain 25m 20s) Loss: 0.4464(0.4418) Grad: 0.1718 LR: 0.000775  \n",
      "Epoch: [5][2100/2908] Elapsed 58m 42s (remain 22m 33s) Loss: 0.4311(0.4417) Grad: 0.1456 LR: 0.000775  \n",
      "Epoch: [5][2200/2908] Elapsed 61m 30s (remain 19m 45s) Loss: 0.4424(0.4417) Grad: 0.1547 LR: 0.000775  \n",
      "Epoch: [5][2300/2908] Elapsed 64m 18s (remain 16m 57s) Loss: 0.4370(0.4417) Grad: 0.1306 LR: 0.000775  \n",
      "Epoch: [5][2400/2908] Elapsed 67m 6s (remain 14m 10s) Loss: 0.4476(0.4418) Grad: 0.2000 LR: 0.000775  \n",
      "Epoch: [5][2500/2908] Elapsed 69m 53s (remain 11m 22s) Loss: 0.4676(0.4418) Grad: 0.1457 LR: 0.000775  \n",
      "Epoch: [5][2600/2908] Elapsed 72m 41s (remain 8m 34s) Loss: 0.4342(0.4417) Grad: 0.1223 LR: 0.000775  \n",
      "Epoch: [5][2700/2908] Elapsed 75m 28s (remain 5m 47s) Loss: 0.4509(0.4417) Grad: 0.1456 LR: 0.000775  \n",
      "Epoch: [5][2800/2908] Elapsed 78m 16s (remain 2m 59s) Loss: 0.4403(0.4418) Grad: 0.1536 LR: 0.000775  \n",
      "Epoch: [5][2900/2908] Elapsed 81m 4s (remain 0m 11s) Loss: 0.4513(0.4417) Grad: 0.1909 LR: 0.000775  \n",
      "Epoch: [5][2907/2908] Elapsed 81m 15s (remain 0m 0s) Loss: 0.4590(0.4417) Grad: 0.1506 LR: 0.000775  \n",
      "EVAL: [0/324] Elapsed 0m 1s (remain 9m 48s) Loss: 0.7810(0.7810) \n",
      "EVAL: [100/324] Elapsed 0m 50s (remain 1m 51s) Loss: 0.4718(0.5235) \n",
      "EVAL: [200/324] Elapsed 1m 39s (remain 1m 1s) Loss: 0.4299(0.4849) \n",
      "EVAL: [300/324] Elapsed 2m 28s (remain 0m 11s) Loss: 0.3621(0.4589) \n",
      "EVAL: [323/324] Elapsed 2m 39s (remain 0m 0s) Loss: 0.2479(0.4511) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.4417  avg_val_loss: 0.4511  time: 5036s\n",
      "Epoch 5 - Accuracy: 0.8044745463758418\n",
      "Epoch 5 - Save Best Score: 0.8045 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/2908] Elapsed 0m 3s (remain 177m 10s) Loss: 0.4252(0.4252) Grad: 0.2099 LR: 0.000666  \n",
      "Epoch: [6][100/2908] Elapsed 2m 51s (remain 79m 20s) Loss: 0.4247(0.4373) Grad: 0.1841 LR: 0.000666  \n",
      "Epoch: [6][200/2908] Elapsed 5m 38s (remain 76m 4s) Loss: 0.4326(0.4373) Grad: 0.1102 LR: 0.000666  \n",
      "Epoch: [6][300/2908] Elapsed 8m 26s (remain 73m 6s) Loss: 0.4287(0.4375) Grad: 0.1602 LR: 0.000666  \n",
      "Epoch: [6][400/2908] Elapsed 11m 14s (remain 70m 14s) Loss: 0.4405(0.4370) Grad: 0.1265 LR: 0.000666  \n",
      "Epoch: [6][500/2908] Elapsed 14m 1s (remain 67m 23s) Loss: 0.4375(0.4365) Grad: 0.1981 LR: 0.000666  \n",
      "Epoch: [6][600/2908] Elapsed 16m 49s (remain 64m 34s) Loss: 0.4368(0.4365) Grad: 0.1952 LR: 0.000666  \n",
      "Epoch: [6][700/2908] Elapsed 19m 37s (remain 61m 45s) Loss: 0.4227(0.4369) Grad: 0.1789 LR: 0.000666  \n",
      "Epoch: [6][800/2908] Elapsed 22m 24s (remain 58m 57s) Loss: 0.4282(0.4368) Grad: 0.1428 LR: 0.000666  \n",
      "Epoch: [6][900/2908] Elapsed 25m 12s (remain 56m 8s) Loss: 0.4413(0.4369) Grad: 0.1354 LR: 0.000666  \n",
      "Epoch: [6][1000/2908] Elapsed 27m 59s (remain 53m 20s) Loss: 0.4441(0.4369) Grad: 0.1261 LR: 0.000666  \n",
      "Epoch: [6][1100/2908] Elapsed 30m 47s (remain 50m 31s) Loss: 0.4362(0.4369) Grad: 0.1379 LR: 0.000666  \n",
      "Epoch: [6][1200/2908] Elapsed 33m 34s (remain 47m 43s) Loss: 0.4272(0.4369) Grad: 0.1558 LR: 0.000666  \n",
      "Epoch: [6][1300/2908] Elapsed 36m 22s (remain 44m 55s) Loss: 0.4449(0.4368) Grad: 0.1979 LR: 0.000666  \n",
      "Epoch: [6][1400/2908] Elapsed 39m 9s (remain 42m 7s) Loss: 0.4604(0.4368) Grad: 0.1721 LR: 0.000666  \n",
      "Epoch: [6][1500/2908] Elapsed 41m 57s (remain 39m 20s) Loss: 0.4312(0.4368) Grad: 0.2118 LR: 0.000666  \n",
      "Epoch: [6][1600/2908] Elapsed 44m 45s (remain 36m 32s) Loss: 0.4444(0.4368) Grad: 0.2327 LR: 0.000666  \n",
      "Epoch: [6][1700/2908] Elapsed 47m 32s (remain 33m 44s) Loss: 0.4265(0.4368) Grad: 0.1394 LR: 0.000666  \n",
      "Epoch: [6][1800/2908] Elapsed 50m 20s (remain 30m 56s) Loss: 0.4355(0.4368) Grad: 0.1471 LR: 0.000666  \n",
      "Epoch: [6][1900/2908] Elapsed 53m 8s (remain 28m 8s) Loss: 0.4258(0.4367) Grad: 0.1398 LR: 0.000666  \n",
      "Epoch: [6][2000/2908] Elapsed 55m 55s (remain 25m 21s) Loss: 0.4296(0.4367) Grad: 0.2274 LR: 0.000666  \n",
      "Epoch: [6][2100/2908] Elapsed 58m 43s (remain 22m 33s) Loss: 0.4125(0.4367) Grad: 0.1224 LR: 0.000666  \n",
      "Epoch: [6][2200/2908] Elapsed 61m 30s (remain 19m 45s) Loss: 0.4440(0.4367) Grad: 0.1685 LR: 0.000666  \n",
      "Epoch: [6][2300/2908] Elapsed 64m 18s (remain 16m 57s) Loss: 0.4353(0.4367) Grad: 0.1142 LR: 0.000666  \n",
      "Epoch: [6][2400/2908] Elapsed 67m 6s (remain 14m 10s) Loss: 0.4359(0.4367) Grad: 0.1810 LR: 0.000666  \n",
      "Epoch: [6][2500/2908] Elapsed 69m 53s (remain 11m 22s) Loss: 0.4636(0.4367) Grad: 0.1372 LR: 0.000666  \n",
      "Epoch: [6][2600/2908] Elapsed 72m 41s (remain 8m 34s) Loss: 0.4460(0.4367) Grad: 0.1200 LR: 0.000666  \n",
      "Epoch: [6][2700/2908] Elapsed 75m 28s (remain 5m 47s) Loss: 0.4387(0.4367) Grad: 0.1510 LR: 0.000666  \n",
      "Epoch: [6][2800/2908] Elapsed 78m 16s (remain 2m 59s) Loss: 0.4273(0.4367) Grad: 0.1491 LR: 0.000666  \n",
      "Epoch: [6][2900/2908] Elapsed 81m 4s (remain 0m 11s) Loss: 0.4420(0.4368) Grad: 0.1677 LR: 0.000666  \n",
      "Epoch: [6][2907/2908] Elapsed 81m 15s (remain 0m 0s) Loss: 0.4358(0.4368) Grad: 0.1721 LR: 0.000666  \n",
      "EVAL: [0/324] Elapsed 0m 1s (remain 9m 45s) Loss: 0.7777(0.7777) \n",
      "EVAL: [100/324] Elapsed 0m 50s (remain 1m 52s) Loss: 0.4749(0.5220) \n",
      "EVAL: [200/324] Elapsed 1m 39s (remain 1m 0s) Loss: 0.4301(0.4842) \n",
      "EVAL: [300/324] Elapsed 2m 28s (remain 0m 11s) Loss: 0.3596(0.4582) \n",
      "EVAL: [323/324] Elapsed 2m 39s (remain 0m 0s) Loss: 0.2432(0.4504) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.4368  avg_val_loss: 0.4504  time: 5036s\n",
      "Epoch 6 - Accuracy: 0.8044822824518719\n",
      "Epoch 6 - Save Best Score: 0.8045 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/2908] Elapsed 0m 3s (remain 185m 20s) Loss: 0.4205(0.4205) Grad: 0.1158 LR: 0.000550  \n",
      "Epoch: [7][100/2908] Elapsed 2m 51s (remain 79m 27s) Loss: 0.4457(0.4317) Grad: 0.1216 LR: 0.000550  \n",
      "Epoch: [7][200/2908] Elapsed 5m 39s (remain 76m 6s) Loss: 0.4363(0.4310) Grad: 0.1287 LR: 0.000550  \n",
      "Epoch: [7][300/2908] Elapsed 8m 26s (remain 73m 8s) Loss: 0.4324(0.4303) Grad: 0.1392 LR: 0.000550  \n",
      "Epoch: [7][400/2908] Elapsed 11m 14s (remain 70m 14s) Loss: 0.4182(0.4300) Grad: 0.1497 LR: 0.000550  \n",
      "Epoch: [7][500/2908] Elapsed 14m 1s (remain 67m 23s) Loss: 0.4298(0.4300) Grad: 0.1406 LR: 0.000550  \n",
      "Epoch: [7][600/2908] Elapsed 16m 49s (remain 64m 34s) Loss: 0.4401(0.4302) Grad: 0.1806 LR: 0.000550  \n",
      "Epoch: [7][700/2908] Elapsed 19m 36s (remain 61m 45s) Loss: 0.4407(0.4302) Grad: 0.1456 LR: 0.000550  \n",
      "Epoch: [7][800/2908] Elapsed 22m 24s (remain 58m 56s) Loss: 0.4233(0.4303) Grad: 0.1690 LR: 0.000550  \n",
      "Epoch: [7][900/2908] Elapsed 25m 12s (remain 56m 8s) Loss: 0.4166(0.4302) Grad: 0.1691 LR: 0.000550  \n",
      "Epoch: [7][1000/2908] Elapsed 27m 59s (remain 53m 19s) Loss: 0.4102(0.4302) Grad: 0.1814 LR: 0.000550  \n",
      "Epoch: [7][1100/2908] Elapsed 30m 47s (remain 50m 31s) Loss: 0.4587(0.4304) Grad: 0.1520 LR: 0.000550  \n",
      "Epoch: [7][1200/2908] Elapsed 33m 34s (remain 47m 43s) Loss: 0.4446(0.4306) Grad: 0.2337 LR: 0.000550  \n",
      "Epoch: [7][1300/2908] Elapsed 36m 22s (remain 44m 55s) Loss: 0.4408(0.4310) Grad: 0.1192 LR: 0.000550  \n",
      "Epoch: [7][1400/2908] Elapsed 39m 9s (remain 42m 7s) Loss: 0.4282(0.4311) Grad: 0.1804 LR: 0.000550  \n",
      "Epoch: [7][1500/2908] Elapsed 41m 57s (remain 39m 19s) Loss: 0.4258(0.4312) Grad: 0.1814 LR: 0.000550  \n",
      "Epoch: [7][1600/2908] Elapsed 44m 44s (remain 36m 31s) Loss: 0.4188(0.4311) Grad: 0.1089 LR: 0.000550  \n",
      "Epoch: [7][1700/2908] Elapsed 47m 32s (remain 33m 44s) Loss: 0.4432(0.4312) Grad: 0.1419 LR: 0.000550  \n",
      "Epoch: [7][1800/2908] Elapsed 50m 19s (remain 30m 56s) Loss: 0.4129(0.4313) Grad: 0.2003 LR: 0.000550  \n",
      "Epoch: [7][1900/2908] Elapsed 53m 7s (remain 28m 8s) Loss: 0.4329(0.4314) Grad: 0.1639 LR: 0.000550  \n",
      "Epoch: [7][2000/2908] Elapsed 55m 55s (remain 25m 20s) Loss: 0.4356(0.4315) Grad: 0.1497 LR: 0.000550  \n",
      "Epoch: [7][2100/2908] Elapsed 58m 42s (remain 22m 33s) Loss: 0.4425(0.4316) Grad: 0.1471 LR: 0.000550  \n",
      "Epoch: [7][2200/2908] Elapsed 61m 30s (remain 19m 45s) Loss: 0.4300(0.4316) Grad: 0.1432 LR: 0.000550  \n",
      "Epoch: [7][2300/2908] Elapsed 64m 17s (remain 16m 57s) Loss: 0.4113(0.4316) Grad: 0.1785 LR: 0.000550  \n",
      "Epoch: [7][2400/2908] Elapsed 67m 5s (remain 14m 10s) Loss: 0.4309(0.4316) Grad: 0.1165 LR: 0.000550  \n",
      "Epoch: [7][2500/2908] Elapsed 69m 52s (remain 11m 22s) Loss: 0.4363(0.4317) Grad: 0.1365 LR: 0.000550  \n",
      "Epoch: [7][2600/2908] Elapsed 72m 40s (remain 8m 34s) Loss: 0.4051(0.4317) Grad: 0.1496 LR: 0.000550  \n",
      "Epoch: [7][2700/2908] Elapsed 75m 27s (remain 5m 47s) Loss: 0.4423(0.4318) Grad: 0.1571 LR: 0.000550  \n",
      "Epoch: [7][2800/2908] Elapsed 78m 15s (remain 2m 59s) Loss: 0.4359(0.4318) Grad: 0.1227 LR: 0.000550  \n",
      "Epoch: [7][2900/2908] Elapsed 81m 3s (remain 0m 11s) Loss: 0.4265(0.4318) Grad: 0.1958 LR: 0.000550  \n",
      "Epoch: [7][2907/2908] Elapsed 81m 14s (remain 0m 0s) Loss: 0.4348(0.4318) Grad: 0.1226 LR: 0.000550  \n",
      "EVAL: [0/324] Elapsed 0m 1s (remain 9m 54s) Loss: 0.7786(0.7786) \n",
      "EVAL: [100/324] Elapsed 0m 50s (remain 1m 52s) Loss: 0.4753(0.5220) \n",
      "EVAL: [200/324] Elapsed 1m 39s (remain 1m 0s) Loss: 0.4293(0.4848) \n",
      "EVAL: [300/324] Elapsed 2m 28s (remain 0m 11s) Loss: 0.3612(0.4593) \n",
      "EVAL: [323/324] Elapsed 2m 39s (remain 0m 0s) Loss: 0.2558(0.4515) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.4318  avg_val_loss: 0.4515  time: 5035s\n",
      "Epoch 7 - Accuracy: 0.8043710763589385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/2908] Elapsed 0m 3s (remain 177m 30s) Loss: 0.4107(0.4107) Grad: 0.1389 LR: 0.000434  \n",
      "Epoch: [8][100/2908] Elapsed 2m 51s (remain 79m 21s) Loss: 0.4215(0.4250) Grad: 0.1251 LR: 0.000434  \n",
      "Epoch: [8][200/2908] Elapsed 5m 38s (remain 76m 2s) Loss: 0.4305(0.4239) Grad: 0.1656 LR: 0.000434  \n",
      "Epoch: [8][300/2908] Elapsed 8m 26s (remain 73m 5s) Loss: 0.4321(0.4241) Grad: 0.1428 LR: 0.000434  \n",
      "Epoch: [8][400/2908] Elapsed 11m 13s (remain 70m 12s) Loss: 0.4214(0.4246) Grad: 0.1572 LR: 0.000434  \n",
      "Epoch: [8][500/2908] Elapsed 14m 1s (remain 67m 23s) Loss: 0.4177(0.4249) Grad: 0.2735 LR: 0.000434  \n",
      "Epoch: [8][600/2908] Elapsed 16m 49s (remain 64m 33s) Loss: 0.4443(0.4251) Grad: 0.1975 LR: 0.000434  \n",
      "Epoch: [8][700/2908] Elapsed 19m 36s (remain 61m 44s) Loss: 0.4109(0.4252) Grad: 0.1813 LR: 0.000434  \n",
      "Epoch: [8][800/2908] Elapsed 22m 24s (remain 58m 56s) Loss: 0.4329(0.4252) Grad: 0.1371 LR: 0.000434  \n",
      "Epoch: [8][900/2908] Elapsed 25m 11s (remain 56m 7s) Loss: 0.4244(0.4255) Grad: 0.1854 LR: 0.000434  \n",
      "Epoch: [8][1000/2908] Elapsed 27m 59s (remain 53m 19s) Loss: 0.4298(0.4257) Grad: 0.1164 LR: 0.000434  \n",
      "Epoch: [8][1100/2908] Elapsed 30m 46s (remain 50m 31s) Loss: 0.4176(0.4258) Grad: 0.2046 LR: 0.000434  \n",
      "Epoch: [8][1200/2908] Elapsed 33m 34s (remain 47m 43s) Loss: 0.4126(0.4257) Grad: 0.1326 LR: 0.000434  \n",
      "Epoch: [8][1300/2908] Elapsed 36m 22s (remain 44m 55s) Loss: 0.4301(0.4258) Grad: 0.1211 LR: 0.000434  \n",
      "Epoch: [8][1400/2908] Elapsed 39m 9s (remain 42m 7s) Loss: 0.4366(0.4259) Grad: 0.1646 LR: 0.000434  \n",
      "Epoch: [8][1500/2908] Elapsed 41m 57s (remain 39m 19s) Loss: 0.4156(0.4260) Grad: 0.1753 LR: 0.000434  \n",
      "Epoch: [8][1600/2908] Elapsed 44m 44s (remain 36m 31s) Loss: 0.4274(0.4260) Grad: 0.1321 LR: 0.000434  \n",
      "Epoch: [8][1700/2908] Elapsed 47m 32s (remain 33m 43s) Loss: 0.4172(0.4260) Grad: 0.1317 LR: 0.000434  \n",
      "Epoch: [8][1800/2908] Elapsed 50m 19s (remain 30m 56s) Loss: 0.4316(0.4260) Grad: 0.1510 LR: 0.000434  \n",
      "Epoch: [8][1900/2908] Elapsed 53m 7s (remain 28m 8s) Loss: 0.4421(0.4261) Grad: 0.1260 LR: 0.000434  \n",
      "Epoch: [8][2000/2908] Elapsed 55m 54s (remain 25m 20s) Loss: 0.4244(0.4262) Grad: 0.1368 LR: 0.000434  \n",
      "Epoch: [8][2100/2908] Elapsed 58m 42s (remain 22m 33s) Loss: 0.4221(0.4263) Grad: 0.1697 LR: 0.000434  \n",
      "Epoch: [8][2200/2908] Elapsed 61m 30s (remain 19m 45s) Loss: 0.4272(0.4263) Grad: 0.1852 LR: 0.000434  \n",
      "Epoch: [8][2300/2908] Elapsed 64m 17s (remain 16m 57s) Loss: 0.4296(0.4264) Grad: 0.1476 LR: 0.000434  \n",
      "Epoch: [8][2400/2908] Elapsed 67m 5s (remain 14m 10s) Loss: 0.4401(0.4265) Grad: 0.1411 LR: 0.000434  \n",
      "Epoch: [8][2500/2908] Elapsed 69m 53s (remain 11m 22s) Loss: 0.4279(0.4265) Grad: 0.1208 LR: 0.000434  \n",
      "Epoch: [8][2600/2908] Elapsed 72m 40s (remain 8m 34s) Loss: 0.4277(0.4266) Grad: 0.1408 LR: 0.000434  \n",
      "Epoch: [8][2700/2908] Elapsed 75m 28s (remain 5m 47s) Loss: 0.4192(0.4266) Grad: 0.1274 LR: 0.000434  \n",
      "Epoch: [8][2800/2908] Elapsed 78m 15s (remain 2m 59s) Loss: 0.4258(0.4266) Grad: 0.1343 LR: 0.000434  \n",
      "Epoch: [8][2900/2908] Elapsed 81m 3s (remain 0m 11s) Loss: 0.4180(0.4267) Grad: 0.1452 LR: 0.000434  \n",
      "Epoch: [8][2907/2908] Elapsed 81m 15s (remain 0m 0s) Loss: 0.4236(0.4267) Grad: 0.1703 LR: 0.000434  \n",
      "EVAL: [0/324] Elapsed 0m 1s (remain 9m 2s) Loss: 0.7781(0.7781) \n",
      "EVAL: [100/324] Elapsed 0m 50s (remain 1m 51s) Loss: 0.4759(0.5218) \n",
      "EVAL: [200/324] Elapsed 1m 39s (remain 1m 0s) Loss: 0.4294(0.4839) \n",
      "EVAL: [300/324] Elapsed 2m 28s (remain 0m 11s) Loss: 0.3615(0.4582) \n",
      "EVAL: [323/324] Elapsed 2m 39s (remain 0m 0s) Loss: 0.2561(0.4504) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.4267  avg_val_loss: 0.4504  time: 5035s\n",
      "Epoch 8 - Accuracy: 0.8047607811889576\n",
      "Epoch 8 - Save Best Score: 0.8048 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/2908] Elapsed 0m 3s (remain 179m 42s) Loss: 0.4220(0.4220) Grad: 0.1183 LR: 0.000325  \n",
      "Epoch: [9][100/2908] Elapsed 2m 51s (remain 79m 20s) Loss: 0.4129(0.4206) Grad: 0.1548 LR: 0.000325  \n",
      "Epoch: [9][200/2908] Elapsed 5m 38s (remain 76m 3s) Loss: 0.4434(0.4192) Grad: 0.1990 LR: 0.000325  \n",
      "Epoch: [9][300/2908] Elapsed 8m 26s (remain 73m 5s) Loss: 0.4229(0.4193) Grad: 0.1592 LR: 0.000325  \n",
      "Epoch: [9][400/2908] Elapsed 11m 14s (remain 70m 14s) Loss: 0.3963(0.4194) Grad: 0.1371 LR: 0.000325  \n",
      "Epoch: [9][500/2908] Elapsed 14m 1s (remain 67m 23s) Loss: 0.4304(0.4194) Grad: 0.1580 LR: 0.000325  \n",
      "Epoch: [9][600/2908] Elapsed 16m 49s (remain 64m 33s) Loss: 0.4208(0.4195) Grad: 0.2049 LR: 0.000325  \n",
      "Epoch: [9][700/2908] Elapsed 19m 36s (remain 61m 44s) Loss: 0.4201(0.4198) Grad: 0.1196 LR: 0.000325  \n",
      "Epoch: [9][800/2908] Elapsed 22m 24s (remain 58m 56s) Loss: 0.4256(0.4198) Grad: 0.2152 LR: 0.000325  \n",
      "Epoch: [9][900/2908] Elapsed 25m 11s (remain 56m 7s) Loss: 0.4139(0.4200) Grad: 0.1316 LR: 0.000325  \n",
      "Epoch: [9][1000/2908] Elapsed 27m 59s (remain 53m 19s) Loss: 0.4421(0.4201) Grad: 0.1202 LR: 0.000325  \n",
      "Epoch: [9][1100/2908] Elapsed 30m 46s (remain 50m 30s) Loss: 0.4274(0.4201) Grad: 0.1474 LR: 0.000325  \n",
      "Epoch: [9][1200/2908] Elapsed 33m 34s (remain 47m 43s) Loss: 0.3962(0.4203) Grad: 0.1671 LR: 0.000325  \n",
      "Epoch: [9][1300/2908] Elapsed 36m 22s (remain 44m 55s) Loss: 0.4229(0.4203) Grad: 0.1241 LR: 0.000325  \n",
      "Epoch: [9][1400/2908] Elapsed 39m 9s (remain 42m 7s) Loss: 0.4103(0.4205) Grad: 0.1531 LR: 0.000325  \n",
      "Epoch: [9][1500/2908] Elapsed 41m 57s (remain 39m 19s) Loss: 0.4265(0.4206) Grad: 0.1679 LR: 0.000325  \n",
      "Epoch: [9][1600/2908] Elapsed 44m 44s (remain 36m 31s) Loss: 0.4232(0.4206) Grad: 0.1408 LR: 0.000325  \n",
      "Epoch: [9][1700/2908] Elapsed 47m 32s (remain 33m 44s) Loss: 0.4226(0.4206) Grad: 0.1284 LR: 0.000325  \n",
      "Epoch: [9][1800/2908] Elapsed 50m 20s (remain 30m 56s) Loss: 0.4299(0.4208) Grad: 0.1726 LR: 0.000325  \n",
      "Epoch: [9][1900/2908] Elapsed 53m 7s (remain 28m 8s) Loss: 0.4310(0.4209) Grad: 0.2023 LR: 0.000325  \n",
      "Epoch: [9][2000/2908] Elapsed 55m 55s (remain 25m 20s) Loss: 0.4040(0.4209) Grad: 0.1533 LR: 0.000325  \n",
      "Epoch: [9][2100/2908] Elapsed 58m 43s (remain 22m 33s) Loss: 0.4271(0.4209) Grad: 0.1360 LR: 0.000325  \n",
      "Epoch: [9][2200/2908] Elapsed 61m 30s (remain 19m 45s) Loss: 0.4448(0.4210) Grad: 0.2070 LR: 0.000325  \n",
      "Epoch: [9][2300/2908] Elapsed 64m 18s (remain 16m 57s) Loss: 0.4304(0.4210) Grad: 0.1181 LR: 0.000325  \n",
      "Epoch: [9][2400/2908] Elapsed 67m 5s (remain 14m 10s) Loss: 0.4314(0.4211) Grad: 0.1231 LR: 0.000325  \n",
      "Epoch: [9][2500/2908] Elapsed 69m 53s (remain 11m 22s) Loss: 0.4269(0.4213) Grad: 0.1412 LR: 0.000325  \n",
      "Epoch: [9][2600/2908] Elapsed 72m 41s (remain 8m 34s) Loss: 0.4424(0.4213) Grad: 0.1416 LR: 0.000325  \n",
      "Epoch: [9][2700/2908] Elapsed 75m 28s (remain 5m 47s) Loss: 0.4228(0.4213) Grad: 0.1264 LR: 0.000325  \n",
      "Epoch: [9][2800/2908] Elapsed 78m 16s (remain 2m 59s) Loss: 0.4169(0.4215) Grad: 0.1930 LR: 0.000325  \n",
      "Epoch: [9][2900/2908] Elapsed 81m 4s (remain 0m 11s) Loss: 0.4421(0.4214) Grad: 0.1612 LR: 0.000325  \n",
      "Epoch: [9][2907/2908] Elapsed 81m 15s (remain 0m 0s) Loss: 0.4331(0.4214) Grad: 0.1398 LR: 0.000325  \n",
      "EVAL: [0/324] Elapsed 0m 1s (remain 9m 9s) Loss: 0.7853(0.7853) \n",
      "EVAL: [100/324] Elapsed 0m 50s (remain 1m 51s) Loss: 0.4764(0.5233) \n",
      "EVAL: [200/324] Elapsed 1m 39s (remain 1m 0s) Loss: 0.4301(0.4853) \n",
      "EVAL: [300/324] Elapsed 2m 28s (remain 0m 11s) Loss: 0.3592(0.4595) \n",
      "EVAL: [323/324] Elapsed 2m 39s (remain 0m 0s) Loss: 0.2550(0.4517) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.4214  avg_val_loss: 0.4517  time: 5036s\n",
      "Epoch 9 - Accuracy: 0.8046234658394222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/2908] Elapsed 0m 3s (remain 176m 36s) Loss: 0.4058(0.4058) Grad: 0.1673 LR: 0.000232  \n",
      "Epoch: [10][100/2908] Elapsed 2m 51s (remain 79m 17s) Loss: 0.4145(0.4165) Grad: 0.1871 LR: 0.000232  \n",
      "Epoch: [10][200/2908] Elapsed 5m 38s (remain 76m 1s) Loss: 0.4232(0.4162) Grad: 0.1911 LR: 0.000232  \n",
      "Epoch: [10][300/2908] Elapsed 8m 26s (remain 73m 4s) Loss: 0.4065(0.4155) Grad: 0.1481 LR: 0.000232  \n",
      "Epoch: [10][400/2908] Elapsed 11m 13s (remain 70m 13s) Loss: 0.4170(0.4155) Grad: 0.1714 LR: 0.000232  \n",
      "Epoch: [10][500/2908] Elapsed 14m 1s (remain 67m 22s) Loss: 0.4256(0.4156) Grad: 0.2005 LR: 0.000232  \n",
      "Epoch: [10][600/2908] Elapsed 16m 48s (remain 64m 33s) Loss: 0.4065(0.4155) Grad: 0.1643 LR: 0.000232  \n",
      "Epoch: [10][700/2908] Elapsed 19m 36s (remain 61m 44s) Loss: 0.4106(0.4154) Grad: 0.1070 LR: 0.000232  \n",
      "Epoch: [10][800/2908] Elapsed 22m 24s (remain 58m 55s) Loss: 0.4288(0.4155) Grad: 0.1455 LR: 0.000232  \n",
      "Epoch: [10][900/2908] Elapsed 25m 11s (remain 56m 7s) Loss: 0.3938(0.4154) Grad: 0.1353 LR: 0.000232  \n",
      "Epoch: [10][1000/2908] Elapsed 27m 59s (remain 53m 19s) Loss: 0.4138(0.4154) Grad: 0.1366 LR: 0.000232  \n",
      "Epoch: [10][1100/2908] Elapsed 30m 47s (remain 50m 31s) Loss: 0.4359(0.4154) Grad: 0.1250 LR: 0.000232  \n",
      "Epoch: [10][1200/2908] Elapsed 33m 34s (remain 47m 43s) Loss: 0.4232(0.4155) Grad: 0.1696 LR: 0.000232  \n",
      "Epoch: [10][1300/2908] Elapsed 36m 22s (remain 44m 55s) Loss: 0.4269(0.4155) Grad: 0.1705 LR: 0.000232  \n",
      "Epoch: [10][1400/2908] Elapsed 39m 9s (remain 42m 7s) Loss: 0.4215(0.4157) Grad: 0.1367 LR: 0.000232  \n",
      "Epoch: [10][1500/2908] Elapsed 41m 57s (remain 39m 19s) Loss: 0.4094(0.4159) Grad: 0.1581 LR: 0.000232  \n",
      "Epoch: [10][1600/2908] Elapsed 44m 44s (remain 36m 31s) Loss: 0.3941(0.4161) Grad: 0.1421 LR: 0.000232  \n",
      "Epoch: [10][1700/2908] Elapsed 47m 32s (remain 33m 43s) Loss: 0.4222(0.4161) Grad: 0.1347 LR: 0.000232  \n",
      "Epoch: [10][1800/2908] Elapsed 50m 19s (remain 30m 56s) Loss: 0.4080(0.4162) Grad: 0.1273 LR: 0.000232  \n",
      "Epoch: [10][1900/2908] Elapsed 53m 7s (remain 28m 8s) Loss: 0.4121(0.4162) Grad: 0.1687 LR: 0.000232  \n",
      "Epoch: [10][2000/2908] Elapsed 55m 54s (remain 25m 20s) Loss: 0.4077(0.4162) Grad: 0.1380 LR: 0.000232  \n",
      "Epoch: [10][2100/2908] Elapsed 58m 42s (remain 22m 32s) Loss: 0.4065(0.4163) Grad: 0.1249 LR: 0.000232  \n",
      "Epoch: [10][2200/2908] Elapsed 61m 30s (remain 19m 45s) Loss: 0.4194(0.4162) Grad: 0.1747 LR: 0.000232  \n",
      "Epoch: [10][2300/2908] Elapsed 64m 17s (remain 16m 57s) Loss: 0.4176(0.4163) Grad: 0.1488 LR: 0.000232  \n",
      "Epoch: [10][2400/2908] Elapsed 67m 5s (remain 14m 9s) Loss: 0.4094(0.4164) Grad: 0.1621 LR: 0.000232  \n",
      "Epoch: [10][2500/2908] Elapsed 69m 52s (remain 11m 22s) Loss: 0.4289(0.4164) Grad: 0.1541 LR: 0.000232  \n",
      "Epoch: [10][2600/2908] Elapsed 72m 40s (remain 8m 34s) Loss: 0.3991(0.4165) Grad: 0.1360 LR: 0.000232  \n",
      "Epoch: [10][2700/2908] Elapsed 75m 27s (remain 5m 47s) Loss: 0.4013(0.4164) Grad: 0.2025 LR: 0.000232  \n",
      "Epoch: [10][2800/2908] Elapsed 78m 15s (remain 2m 59s) Loss: 0.3951(0.4164) Grad: 0.2053 LR: 0.000232  \n",
      "Epoch: [10][2900/2908] Elapsed 81m 3s (remain 0m 11s) Loss: 0.4013(0.4165) Grad: 0.1132 LR: 0.000232  \n",
      "Epoch: [10][2907/2908] Elapsed 81m 14s (remain 0m 0s) Loss: 0.4251(0.4165) Grad: 0.1486 LR: 0.000232  \n",
      "EVAL: [0/324] Elapsed 0m 1s (remain 9m 12s) Loss: 0.7840(0.7840) \n",
      "EVAL: [100/324] Elapsed 0m 50s (remain 1m 51s) Loss: 0.4781(0.5234) \n",
      "EVAL: [200/324] Elapsed 1m 39s (remain 1m 0s) Loss: 0.4284(0.4861) \n",
      "EVAL: [300/324] Elapsed 2m 28s (remain 0m 11s) Loss: 0.3646(0.4609) \n",
      "EVAL: [323/324] Elapsed 2m 39s (remain 0m 0s) Loss: 0.2680(0.4533) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.4165  avg_val_loss: 0.4533  time: 5035s\n",
      "Epoch 10 - Accuracy: 0.8040790394888001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [11][0/2908] Elapsed 0m 3s (remain 177m 44s) Loss: 0.4025(0.4025) Grad: 0.1382 LR: 0.000160  \n",
      "Epoch: [11][100/2908] Elapsed 2m 51s (remain 79m 18s) Loss: 0.4450(0.4099) Grad: 0.1577 LR: 0.000160  \n",
      "Epoch: [11][200/2908] Elapsed 5m 38s (remain 76m 2s) Loss: 0.4104(0.4103) Grad: 0.1339 LR: 0.000160  \n",
      "Epoch: [11][300/2908] Elapsed 8m 26s (remain 73m 7s) Loss: 0.4130(0.4100) Grad: 0.1592 LR: 0.000160  \n",
      "Epoch: [11][400/2908] Elapsed 11m 14s (remain 70m 14s) Loss: 0.3907(0.4103) Grad: 0.1857 LR: 0.000160  \n",
      "Epoch: [11][500/2908] Elapsed 14m 1s (remain 67m 23s) Loss: 0.4076(0.4104) Grad: 0.1405 LR: 0.000160  \n",
      "Epoch: [11][600/2908] Elapsed 16m 49s (remain 64m 33s) Loss: 0.4148(0.4105) Grad: 0.1446 LR: 0.000160  \n",
      "Epoch: [11][700/2908] Elapsed 19m 36s (remain 61m 44s) Loss: 0.4196(0.4105) Grad: 0.1503 LR: 0.000160  \n",
      "Epoch: [11][800/2908] Elapsed 22m 24s (remain 58m 56s) Loss: 0.4081(0.4107) Grad: 0.1743 LR: 0.000160  \n",
      "Epoch: [11][900/2908] Elapsed 25m 11s (remain 56m 7s) Loss: 0.4099(0.4106) Grad: 0.1729 LR: 0.000160  \n",
      "Epoch: [11][1000/2908] Elapsed 27m 59s (remain 53m 19s) Loss: 0.4085(0.4107) Grad: 0.1531 LR: 0.000160  \n",
      "Epoch: [11][1100/2908] Elapsed 30m 47s (remain 50m 31s) Loss: 0.4243(0.4109) Grad: 0.1313 LR: 0.000160  \n",
      "Epoch: [11][1200/2908] Elapsed 33m 34s (remain 47m 43s) Loss: 0.4254(0.4110) Grad: 0.1245 LR: 0.000160  \n",
      "Epoch: [11][1300/2908] Elapsed 36m 22s (remain 44m 55s) Loss: 0.4090(0.4111) Grad: 0.1572 LR: 0.000160  \n",
      "Epoch: [11][1400/2908] Elapsed 39m 10s (remain 42m 7s) Loss: 0.4173(0.4113) Grad: 0.1348 LR: 0.000160  \n",
      "Epoch: [11][1500/2908] Elapsed 41m 57s (remain 39m 20s) Loss: 0.4074(0.4113) Grad: 0.1361 LR: 0.000160  \n",
      "Epoch: [11][1600/2908] Elapsed 44m 45s (remain 36m 32s) Loss: 0.4180(0.4115) Grad: 0.1671 LR: 0.000160  \n",
      "Epoch: [11][1700/2908] Elapsed 47m 32s (remain 33m 44s) Loss: 0.4141(0.4116) Grad: 0.1519 LR: 0.000160  \n",
      "Epoch: [11][1800/2908] Elapsed 50m 20s (remain 30m 56s) Loss: 0.4143(0.4117) Grad: 0.2060 LR: 0.000160  \n",
      "Epoch: [11][1900/2908] Elapsed 53m 8s (remain 28m 8s) Loss: 0.4066(0.4118) Grad: 0.1479 LR: 0.000160  \n",
      "Epoch: [11][2000/2908] Elapsed 55m 55s (remain 25m 21s) Loss: 0.4192(0.4119) Grad: 0.1952 LR: 0.000160  \n",
      "Epoch: [11][2100/2908] Elapsed 58m 43s (remain 22m 33s) Loss: 0.4142(0.4119) Grad: 0.1291 LR: 0.000160  \n",
      "Epoch: [11][2200/2908] Elapsed 61m 31s (remain 19m 45s) Loss: 0.4121(0.4120) Grad: 0.1186 LR: 0.000160  \n",
      "Epoch: [11][2300/2908] Elapsed 64m 18s (remain 16m 57s) Loss: 0.4047(0.4120) Grad: 0.1410 LR: 0.000160  \n",
      "Epoch: [11][2400/2908] Elapsed 67m 6s (remain 14m 10s) Loss: 0.4368(0.4119) Grad: 0.1494 LR: 0.000160  \n",
      "Epoch: [11][2500/2908] Elapsed 69m 53s (remain 11m 22s) Loss: 0.4147(0.4120) Grad: 0.1423 LR: 0.000160  \n",
      "Epoch: [11][2600/2908] Elapsed 72m 41s (remain 8m 34s) Loss: 0.3992(0.4121) Grad: 0.1413 LR: 0.000160  \n",
      "Epoch: [11][2700/2908] Elapsed 75m 29s (remain 5m 47s) Loss: 0.4234(0.4121) Grad: 0.1754 LR: 0.000160  \n",
      "Epoch: [11][2800/2908] Elapsed 78m 16s (remain 2m 59s) Loss: 0.4366(0.4122) Grad: 0.1780 LR: 0.000160  \n",
      "Epoch: [11][2900/2908] Elapsed 81m 4s (remain 0m 11s) Loss: 0.4161(0.4122) Grad: 0.1828 LR: 0.000160  \n",
      "Epoch: [11][2907/2908] Elapsed 81m 16s (remain 0m 0s) Loss: 0.3892(0.4122) Grad: 0.1708 LR: 0.000160  \n",
      "EVAL: [0/324] Elapsed 0m 1s (remain 9m 12s) Loss: 0.7874(0.7874) \n",
      "EVAL: [100/324] Elapsed 0m 50s (remain 1m 51s) Loss: 0.4795(0.5250) \n",
      "EVAL: [200/324] Elapsed 1m 39s (remain 1m 0s) Loss: 0.4305(0.4880) \n",
      "EVAL: [300/324] Elapsed 2m 28s (remain 0m 11s) Loss: 0.3673(0.4630) \n",
      "EVAL: [323/324] Elapsed 2m 39s (remain 0m 0s) Loss: 0.2624(0.4553) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - avg_train_loss: 0.4122  avg_val_loss: 0.4553  time: 5036s\n",
      "Epoch 11 - Accuracy: 0.8036255120315322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [12][0/2908] Elapsed 0m 3s (remain 182m 40s) Loss: 0.4069(0.4069) Grad: 0.1325 LR: 0.000115  \n",
      "Epoch: [12][100/2908] Elapsed 2m 51s (remain 79m 23s) Loss: 0.4141(0.4074) Grad: 0.1412 LR: 0.000115  \n",
      "Epoch: [12][200/2908] Elapsed 5m 39s (remain 76m 8s) Loss: 0.4091(0.4075) Grad: 0.1473 LR: 0.000115  \n",
      "Epoch: [12][300/2908] Elapsed 8m 26s (remain 73m 9s) Loss: 0.4302(0.4075) Grad: 0.1593 LR: 0.000115  \n",
      "Epoch: [12][400/2908] Elapsed 11m 14s (remain 70m 15s) Loss: 0.3893(0.4073) Grad: 0.1588 LR: 0.000115  \n",
      "Epoch: [12][500/2908] Elapsed 14m 1s (remain 67m 24s) Loss: 0.4144(0.4074) Grad: 0.1530 LR: 0.000115  \n",
      "Epoch: [12][600/2908] Elapsed 16m 49s (remain 64m 34s) Loss: 0.4159(0.4075) Grad: 0.1591 LR: 0.000115  \n",
      "Epoch: [12][700/2908] Elapsed 19m 37s (remain 61m 45s) Loss: 0.3877(0.4077) Grad: 0.1866 LR: 0.000115  \n",
      "Epoch: [12][800/2908] Elapsed 22m 24s (remain 58m 56s) Loss: 0.4124(0.4077) Grad: 0.1622 LR: 0.000115  \n",
      "Epoch: [12][900/2908] Elapsed 25m 12s (remain 56m 8s) Loss: 0.4063(0.4078) Grad: 0.1468 LR: 0.000115  \n",
      "Epoch: [12][1000/2908] Elapsed 28m 0s (remain 53m 20s) Loss: 0.3896(0.4078) Grad: 0.1778 LR: 0.000115  \n",
      "Epoch: [12][1100/2908] Elapsed 30m 47s (remain 50m 32s) Loss: 0.4219(0.4080) Grad: 0.1366 LR: 0.000115  \n",
      "Epoch: [12][1200/2908] Elapsed 33m 35s (remain 47m 44s) Loss: 0.4070(0.4081) Grad: 0.1513 LR: 0.000115  \n",
      "Epoch: [12][1300/2908] Elapsed 36m 22s (remain 44m 56s) Loss: 0.3975(0.4083) Grad: 0.1561 LR: 0.000115  \n",
      "Epoch: [12][1400/2908] Elapsed 39m 10s (remain 42m 8s) Loss: 0.4055(0.4084) Grad: 0.1705 LR: 0.000115  \n",
      "Epoch: [12][1500/2908] Elapsed 41m 57s (remain 39m 20s) Loss: 0.3946(0.4083) Grad: 0.1530 LR: 0.000115  \n",
      "Epoch: [12][1600/2908] Elapsed 44m 45s (remain 36m 32s) Loss: 0.4141(0.4084) Grad: 0.1887 LR: 0.000115  \n",
      "Epoch: [12][1700/2908] Elapsed 47m 33s (remain 33m 44s) Loss: 0.4016(0.4084) Grad: 0.1539 LR: 0.000115  \n",
      "Epoch: [12][1800/2908] Elapsed 50m 20s (remain 30m 56s) Loss: 0.4151(0.4085) Grad: 0.1771 LR: 0.000115  \n",
      "Epoch: [12][1900/2908] Elapsed 53m 8s (remain 28m 8s) Loss: 0.4345(0.4085) Grad: 0.1838 LR: 0.000115  \n",
      "Epoch: [12][2000/2908] Elapsed 55m 55s (remain 25m 21s) Loss: 0.4263(0.4086) Grad: 0.1442 LR: 0.000115  \n",
      "Epoch: [12][2100/2908] Elapsed 58m 43s (remain 22m 33s) Loss: 0.4228(0.4087) Grad: 0.1507 LR: 0.000115  \n",
      "Epoch: [12][2200/2908] Elapsed 61m 30s (remain 19m 45s) Loss: 0.4052(0.4087) Grad: 0.1450 LR: 0.000115  \n",
      "Epoch: [12][2300/2908] Elapsed 64m 18s (remain 16m 57s) Loss: 0.3924(0.4088) Grad: 0.1441 LR: 0.000115  \n",
      "Epoch: [12][2400/2908] Elapsed 67m 6s (remain 14m 10s) Loss: 0.4211(0.4088) Grad: 0.1669 LR: 0.000115  \n",
      "Epoch: [12][2500/2908] Elapsed 69m 53s (remain 11m 22s) Loss: 0.3978(0.4088) Grad: 0.1260 LR: 0.000115  \n",
      "Epoch: [12][2600/2908] Elapsed 72m 41s (remain 8m 34s) Loss: 0.4340(0.4089) Grad: 0.1512 LR: 0.000115  \n",
      "Epoch: [12][2700/2908] Elapsed 75m 28s (remain 5m 47s) Loss: 0.3875(0.4088) Grad: 0.1247 LR: 0.000115  \n",
      "Epoch: [12][2800/2908] Elapsed 78m 16s (remain 2m 59s) Loss: 0.4124(0.4088) Grad: 0.1640 LR: 0.000115  \n",
      "Epoch: [12][2900/2908] Elapsed 81m 4s (remain 0m 11s) Loss: 0.4120(0.4088) Grad: 0.1335 LR: 0.000115  \n",
      "Epoch: [12][2907/2908] Elapsed 81m 15s (remain 0m 0s) Loss: 0.4200(0.4088) Grad: 0.1504 LR: 0.000115  \n",
      "EVAL: [0/324] Elapsed 0m 1s (remain 9m 6s) Loss: 0.7883(0.7883) \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "human-arena",
    "papermill": {
     "duration": 0.209774,
     "end_time": "2021-05-12T03:50:00.096860",
     "exception": false,
     "start_time": "2021-05-12T03:49:59.887086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "hungry-geese-train-by-episode.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2945.71762,
   "end_time": "2021-05-12T03:50:02.012348",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-12T03:00:56.294728",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04a486aa6f454d8f92e388dba1b9ee21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0857c0fa22b544488d65bb2c7dad18ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f905db5005be40b194ea150c8b0deb9f",
      "max": 1001,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "value": 1001
     }
    },
    "4134662bdbe04a918d9809632e268ef8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0857c0fa22b544488d65bb2c7dad18ee",
       "IPY_MODEL_e33e4f894b424988b316c468bc9225ce"
      ],
      "layout": "IPY_MODEL_8ddb49ac3c91409f99a569a061a70b3d"
     }
    },
    "507d2b6a02bb43d0bb4c8c2734f19cbb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ddb49ac3c91409f99a569a061a70b3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c96b7bfbdf0243a8ae1dbb3d9aedf123": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e33e4f894b424988b316c468bc9225ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_507d2b6a02bb43d0bb4c8c2734f19cbb",
      "placeholder": "​",
      "style": "IPY_MODEL_04a486aa6f454d8f92e388dba1b9ee21",
      "value": " 1001/1001 [03:35&lt;00:00,  4.64it/s]"
     }
    },
    "f905db5005be40b194ea150c8b0deb9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

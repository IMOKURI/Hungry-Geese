{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abroad-piece",
    "papermill": {
     "duration": 0.025714,
     "end_time": "2021-05-12T03:01:02.640708",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.614994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About this notebook ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pressing-commercial",
    "papermill": {
     "duration": 0.024272,
     "end_time": "2021-05-12T03:01:02.689850",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.665578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "german-ethics",
    "papermill": {
     "duration": 1.852306,
     "end_time": "2021-05-12T03:01:04.566362",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.714056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "apparent-fiction",
    "papermill": {
     "duration": 0.030961,
     "end_time": "2021-05-12T03:01:04.622818",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.591857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robust-humanity",
    "papermill": {
     "duration": 0.024539,
     "end_time": "2021-05-12T03:01:04.672270",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.647731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "designed-effect",
    "papermill": {
     "duration": 0.031167,
     "end_time": "2021-05-12T03:01:04.728079",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.696912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"../input/hungrygeeseepisode/hungry-geese-episode/\"\n",
    "OUTPUT_DIR = \"pre-models/\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "special-broadcast",
    "outputId": "c440e1e9-5651-42ee-eb0f-08c822d7471a",
    "papermill": {
     "duration": 0.31211,
     "end_time": "2021-05-12T03:01:05.064722",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.752612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16521\n"
     ]
    }
   ],
   "source": [
    "paths = [path for path in glob.glob(BASE_DIR + \"*.json\") if \"info\" not in path]\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "editorial-haiti",
    "papermill": {
     "duration": 0.024908,
     "end_time": "2021-05-12T03:01:05.115280",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.090372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "opened-python",
    "papermill": {
     "duration": 0.035637,
     "end_time": "2021-05-12T03:01:05.176119",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.140482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 440\n",
    "\n",
    "    n_class = 4\n",
    "    n_fold = 5\n",
    "\n",
    "    geese_net_layers = 12\n",
    "    geese_net_filters = 64\n",
    "\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "\n",
    "    num_workers = 4\n",
    "    batch_size = 3200\n",
    "\n",
    "    scheduler = \"CosineAnnealingWarmRestarts\"\n",
    "    # factor = 0.2  # ReduceLROnPlateau\n",
    "    # patience = 4  # ReduceLROnPlateau\n",
    "    # eps = 1e-6  # ReduceLROnPlateau\n",
    "    # T_max = 10  # CosineAnnealingLR\n",
    "    T_0 = 10  # CosineAnnealingWarmRestarts\n",
    "\n",
    "    criterion = \"CrossEntropyLoss\"\n",
    "    lr = 1e-3\n",
    "    min_lr = 1e-4\n",
    "    weight_decay = 0\n",
    "\n",
    "    epochs = 10\n",
    "    model_name = \"geese_net\"\n",
    "\n",
    "    print_freq = 100\n",
    "\n",
    "    train = False\n",
    "    tuning = True\n",
    "    debug = False\n",
    "    apex = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "contained-singles",
    "papermill": {
     "duration": 0.031266,
     "end_time": "2021-05-12T03:01:05.235456",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.204190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.tuning:\n",
    "    Config.epochs = 2\n",
    "\n",
    "if Config.debug:\n",
    "    Config.epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dietary-track",
    "papermill": {
     "duration": 0.031421,
     "end_time": "2021-05-12T03:01:05.292382",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.260961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.apex:\n",
    "    from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "invalid-dispute",
    "papermill": {
     "duration": 0.169531,
     "end_time": "2021-05-12T03:01:05.488665",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.319134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "treated-serum",
    "papermill": {
     "duration": 0.025219,
     "end_time": "2021-05-12T03:01:05.539482",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.514263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gothic-alloy",
    "papermill": {
     "duration": 0.070842,
     "end_time": "2021-05-12T03:01:05.642364",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.571522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=Config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "experienced-correspondence",
    "papermill": {
     "duration": 0.053842,
     "end_time": "2021-05-12T03:01:05.741858",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.688016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reverse_ns(y):\n",
    "    if y == 0:\n",
    "        return 1\n",
    "    if y == 1:\n",
    "        return 0\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_we(y):\n",
    "    if y == 2:\n",
    "        return 3\n",
    "    if y == 3:\n",
    "        return 2\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_nswe(y):\n",
    "    return reverse_ns(reverse_we(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "further-transaction",
    "papermill": {
     "duration": 0.042365,
     "end_time": "2021-05-12T03:01:05.826807",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.784442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "naughty-clause",
    "papermill": {
     "duration": 0.058537,
     "end_time": "2021-05-12T03:01:05.928292",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.869755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_input(obses):\n",
    "    b = np.zeros((17, 7 * 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "        pid = (p - obs[\"index\"]) % 4\n",
    "\n",
    "        # head position\n",
    "        for pos in pos_list[:1]:\n",
    "            b[0 + pid, pos] = 1\n",
    "        # tip position\n",
    "        for pos in pos_list[-1:]:\n",
    "            b[4 + pid, pos] = 1\n",
    "        # whole position\n",
    "        for pos in pos_list:\n",
    "            b[8 + pid, pos] = 1\n",
    "\n",
    "    # previous head position\n",
    "    if len(obses) > 1:\n",
    "        obs_prev = obses[-2]\n",
    "        for p, pos_list in enumerate(obs_prev[\"geese\"]):\n",
    "            for pos in pos_list[:1]:\n",
    "                b[12 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    # food\n",
    "    for pos in obs[\"food\"]:\n",
    "        b[16, pos] = 1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "i6lOS7itC0da"
   },
   "outputs": [],
   "source": [
    "def observation_num_step(obses):\n",
    "    b = np.zeros((7, 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    b[0, 0] = obs[\"step\"]  # 0-198\n",
    "\n",
    "    return b.reshape(1, 7, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pretty-aaron",
    "papermill": {
     "duration": 0.042985,
     "end_time": "2021-05-12T03:01:06.014038",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.971053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "international-secret",
    "papermill": {
     "duration": 0.064855,
     "end_time": "2021-05-12T03:01:06.121648",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.056793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset_from_json(filepath, json_object=None, standing=0):\n",
    "    if json_object is None:\n",
    "        json_open = open(path, \"r\")\n",
    "        json_load = json.load(json_open)\n",
    "    else:\n",
    "        json_load = json_object\n",
    "\n",
    "    try:\n",
    "        winner_index = np.argmax(np.argsort(json_load[\"rewards\"]) == 3 - standing)\n",
    "\n",
    "        obses = []\n",
    "        X = []\n",
    "        y = []\n",
    "        actions = {\"NORTH\": 0, \"SOUTH\": 1, \"WEST\": 2, \"EAST\": 3}\n",
    "\n",
    "        for i in range(len(json_load[\"steps\"]) - 1):\n",
    "            if json_load[\"steps\"][i][winner_index][\"status\"] == \"ACTIVE\":\n",
    "                y_ = json_load[\"steps\"][i + 1][winner_index][\"action\"]\n",
    "                if y_ is not None:\n",
    "                    step = json_load[\"steps\"][i]\n",
    "                    step[winner_index][\"observation\"][\"geese\"] = step[0][\"observation\"][\"geese\"]\n",
    "                    step[winner_index][\"observation\"][\"food\"] = step[0][\"observation\"][\"food\"]\n",
    "                    step[winner_index][\"observation\"][\"step\"] = step[0][\"observation\"][\"step\"]\n",
    "                    obses.append(step[winner_index][\"observation\"])\n",
    "                    y.append(actions[y_])\n",
    "\n",
    "                    y.append(reverse_ns(actions[y_]))  # 上下反転\n",
    "                    y.append(reverse_we(actions[y_]))  # 左右反転\n",
    "                    y.append(reverse_nswe(actions[y_]))  # 上下左右反転\n",
    "\n",
    "        for j in range(len(obses)):\n",
    "            # X_ = make_input(obses[: j + 1])\n",
    "\n",
    "            X_ = []\n",
    "            X_.append(make_input(obses[: j + 1]))\n",
    "            # X_.append(observation_num_step(obses[: j + 1]))\n",
    "            X_ = np.concatenate(X_)\n",
    "\n",
    "            X.append(X_)\n",
    "\n",
    "            X.append(X_[:, ::-1, :])  # 上下反転\n",
    "            X.append(X_[:, :, ::-1])  # 左右反転\n",
    "            X.append(X_[:, ::-1, ::-1])  # 上下左右反転\n",
    "\n",
    "        X = np.array(X, dtype=np.uint8)  # [starting_step:]\n",
    "        y = np.array(y, dtype=np.uint8)  # [starting_step:]\n",
    "\n",
    "        return X, y\n",
    "    except:\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "4134662bdbe04a918d9809632e268ef8",
      "8ddb49ac3c91409f99a569a061a70b3d",
      "0857c0fa22b544488d65bb2c7dad18ee",
      "e33e4f894b424988b316c468bc9225ce",
      "c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "f905db5005be40b194ea150c8b0deb9f",
      "04a486aa6f454d8f92e388dba1b9ee21",
      "507d2b6a02bb43d0bb4c8c2734f19cbb"
     ]
    },
    "id": "handled-pleasure",
    "outputId": "955c1c6b-36bc-4b30-dc44-b72b05398f8c",
    "papermill": {
     "duration": 15.320591,
     "end_time": "2021-05-12T03:01:21.474816",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.154225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1272e31b613e41c48fa780a28e7d635e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=16521.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num episode: 10343040\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for path in tqdm(paths[: int(len(paths))]):\n",
    "    X, y = create_dataset_from_json(path, standing=0)  # use only winners' moves\n",
    "    if X is not 0:\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "persistent-loading",
    "papermill": {
     "duration": 112.92618,
     "end_time": "2021-05-12T03:03:14.428162",
     "exception": false,
     "start_time": "2021-05-12T03:01:21.501982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# X_train, unique_index = np.unique(X_train, axis=0, return_index=True)  # remove duplicate\n",
    "# y_train = y_train[unique_index]\n",
    "\n",
    "# y_train = np.eye(4, dtype=\"uint8\")[y_train]  # to categorical\n",
    "\n",
    "# print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sum_obs = X_train.reshape(X_train.shape[0], -1).sum(1)\n",
    "X_train_group = np.unique(X_train_sum_obs)\n",
    "X_train_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d64fbb512244dabfe23011578d4bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=75.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num episode: 10341154\n"
     ]
    }
   ],
   "source": [
    "X_train_unique = []\n",
    "y_train_unique = []\n",
    "for group in tqdm(X_train_group):\n",
    "    group_index = np.where(X_train_sum_obs == group)\n",
    "\n",
    "    X_train_ = X_train[group_index]\n",
    "    y_train_ = y_train[group_index]\n",
    "\n",
    "    X_train_, unique_index = np.unique(X_train_, axis=0, return_index=True)  # remove duplicate\n",
    "    y_train_ = y_train_[unique_index]\n",
    "\n",
    "    X_train_unique.append(X_train_)\n",
    "    y_train_unique.append(y_train_)\n",
    "\n",
    "X_train = np.concatenate(X_train_unique)\n",
    "y_train = np.concatenate(y_train_unique)\n",
    "\n",
    "print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_sum_obs\n",
    "del X_train_group\n",
    "del X_train_unique\n",
    "del y_train_unique\n",
    "del X_train_\n",
    "del y_train_\n",
    "del group_index\n",
    "del unique_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "micro-french",
    "papermill": {
     "duration": 0.033413,
     "end_time": "2021-05-12T03:03:15.360395",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.326982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    X_train = X_train[:1000]\n",
    "    y_train = y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "wrong-pastor",
    "outputId": "406a2f1d-0b8a-46bf-ca01-546f3110c301",
    "papermill": {
     "duration": 0.036161,
     "end_time": "2021-05-12T03:03:15.425149",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.388988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10341149</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10341150</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10341151</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10341152</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10341153</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10341154 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          action\n",
       "0              2\n",
       "1              3\n",
       "2              1\n",
       "3              2\n",
       "4              0\n",
       "...          ...\n",
       "10341149       3\n",
       "10341150       3\n",
       "10341151       2\n",
       "10341152       2\n",
       "10341153       3\n",
       "\n",
       "[10341154 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(y_train, dtype=np.uint8)\n",
    "y_df.columns = [\"action\"]\n",
    "y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "touched-coordinate",
    "papermill": {
     "duration": 0.027968,
     "end_time": "2021-05-12T03:03:15.557122",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.529154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "moving-skill",
    "outputId": "7542c4b4-f7d3-444c-8450-50bffddb1892",
    "papermill": {
     "duration": 0.202337,
     "end_time": "2021-05-12T03:03:15.787529",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.585192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  action\n",
      "0     0         492684\n",
      "      1         492684\n",
      "      2         541432\n",
      "      3         541431\n",
      "1     0         492684\n",
      "      1         492684\n",
      "      2         541432\n",
      "      3         541431\n",
      "2     0         492684\n",
      "      1         492684\n",
      "      2         541432\n",
      "      3         541431\n",
      "3     0         492684\n",
      "      1         492684\n",
      "      2         541431\n",
      "      3         541432\n",
      "4     0         492684\n",
      "      1         492684\n",
      "      2         541431\n",
      "      3         541431\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "folds = y_df.copy()\n",
    "Fold = StratifiedKFold(n_splits=Config.n_fold, shuffle=True, random_state=Config.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[\"action\"])):\n",
    "    folds.loc[val_index, \"fold\"] = int(n)\n",
    "folds[\"fold\"] = folds[\"fold\"].astype(np.uint8)\n",
    "print(folds.groupby([\"fold\", \"action\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "creative-football",
    "papermill": {
     "duration": 0.029031,
     "end_time": "2021-05-12T03:03:15.845114",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.816083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "other-murder",
    "papermill": {
     "duration": 0.037264,
     "end_time": "2021-05-12T03:03:15.911219",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.873955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, array, label):\n",
    "        self.array = array\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx], torch.tensor(self.label[idx]).long()\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, array):\n",
    "        self.array = array\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adjusted-delhi",
    "outputId": "39504950-84bc-4692-8b90-8a5b64f741e0",
    "papermill": {
     "duration": 0.063691,
     "end_time": "2021-05-12T03:03:16.003693",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.940002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "if Config.debug or False:\n",
    "    train_ds = TrainDataset(X_train, y_train)\n",
    "\n",
    "    for i in range(1):\n",
    "        obs, action = train_ds[i]\n",
    "        print(obs.shape, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceramic-startup",
    "papermill": {
     "duration": 0.02876,
     "end_time": "2021-05-12T03:03:16.061575",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.032815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "unique-trick",
    "papermill": {
     "duration": 0.039055,
     "end_time": "2021-05-12T03:03:16.130239",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.091184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TorusConv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
    "        super().__init__()\n",
    "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([x[:, :, :, -self.edge_size[1] :], x, x[:, :, :, : self.edge_size[1]]], dim=3)\n",
    "        h = torch.cat([h[:, :, -self.edge_size[0] :], h, h[:, :, : self.edge_size[0]]], dim=2)\n",
    "        h = self.conv(h)\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "extra-bradford",
    "papermill": {
     "duration": 0.042421,
     "end_time": "2021-05-12T03:03:16.202024",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.159603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GeeseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers, filters = 12, 32\n",
    "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p = nn.Linear(filters, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(filters * 2, filters, bias=False)\n",
    "        self.head_v2 = nn.Linear(filters, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h_p = F.relu_(self.conv_p(h))\n",
    "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        p = self.head_p(h_head_p)\n",
    "\n",
    "        h_v = F.relu_(self.conv_v(h))\n",
    "        h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_avg_v = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
    "\n",
    "        h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_avg_v], 1)))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p, \"value\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "jspEE71c2Yma"
   },
   "outputs": [],
   "source": [
    "class GeeseNetAlpha(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = Config.geese_net_layers\n",
    "        filters = Config.geese_net_filters\n",
    "\n",
    "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p1 = nn.Linear(filters * 5 + 77, filters * 3, bias=False)\n",
    "        self.head_p2 = nn.Linear(filters * 3, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(filters * 5 + 77, filters * 3, bias=False)\n",
    "        self.head_v2 = nn.Linear(filters * 3, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h_p = F.relu_(self.conv_p(h))\n",
    "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p2 = (h_p * x[:, 1:2]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p3 = (h_p * x[:, 2:3]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p4 = (h_p * x[:, 3:4]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_avg_p1 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(-1)\n",
    "        h_avg_p2 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(1)\n",
    "\n",
    "        h_p = F.relu_(self.head_p1(torch.cat([h_head_p, h_head_p2, h_head_p3, h_head_p4, h_avg_p1, h_avg_p2], 1)))\n",
    "        p = self.head_p2(h_p)\n",
    "\n",
    "        h_v = F.relu_(self.conv_v(h))\n",
    "        h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_head_v2 = (h_v * x[:, 1:2]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_head_v3 = (h_v * x[:, 2:3]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_head_v4 = (h_v * x[:, 3:4]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_avg_v1 = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
    "        h_avg_v2 = h_v.view(h_v.size(0), h_v.size(1), -1).mean(1)\n",
    "\n",
    "        h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_head_v2, h_head_v3, h_head_v4, h_avg_v1, h_avg_v2], 1)))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p, \"value\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "objective-victoria",
    "outputId": "1ab137a5-e26e-4b9c-ff85-95fef713b755",
    "papermill": {
     "duration": 4.955868,
     "end_time": "2021-05-12T03:03:21.187355",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.231487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "if Config.debug or False:\n",
    "    model = GeeseNetAlpha()\n",
    "    # print(model)\n",
    "\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"params: {params:,}\")\n",
    "\n",
    "    train_ds = TrainDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "    for obs, action in train_loader:\n",
    "        output = model(obs)\n",
    "        print(output)\n",
    "        print(f\"{torch.argmax(output['policy'], dim=1)}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "military-fiction",
    "papermill": {
     "duration": 0.033001,
     "end_time": "2021-05-12T03:03:21.255277",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.222276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sophisticated-hearts",
    "papermill": {
     "duration": 0.031759,
     "end_time": "2021-05-12T03:03:21.319849",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.288090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "designing-detective",
    "papermill": {
     "duration": 0.03139,
     "end_time": "2021-05-12T03:03:21.383038",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.351648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "passive-cooper",
    "papermill": {
     "duration": 0.038846,
     "end_time": "2021-05-12T03:03:21.454085",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.415239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(result_df):\n",
    "    preds = result_df[\"preds\"].values\n",
    "    labels = result_df[\"action\"].values\n",
    "    score = get_score(labels, preds)\n",
    "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thirty-tracy",
    "papermill": {
     "duration": 0.0293,
     "end_time": "2021-05-12T03:03:21.514179",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.484879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "introductory-brooklyn",
    "papermill": {
     "duration": 0.039424,
     "end_time": "2021-05-12T03:03:21.582969",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.543545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "raising-laugh",
    "papermill": {
     "duration": 0.042063,
     "end_time": "2021-05-12T03:03:21.654559",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.612496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "\n",
    "    for step, (obs, action) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        y_preds = model(obs.float())[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "\n",
    "        # record loss\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "        if Config.apex:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), Config.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % Config.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print(\n",
    "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
    "                f\"Loss: {losses.val:.4f}({losses.avg:.4f}) \"\n",
    "                f\"Grad: {grad_norm:.4f} \"\n",
    "                f\"LR: {scheduler.get_last_lr()[0]:.6f}  \"\n",
    "            )\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "plain-neighbor",
    "papermill": {
     "duration": 0.041056,
     "end_time": "2021-05-12T03:03:21.726585",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.685529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "\n",
    "    for step, (obs, action) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(obs)[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print(\n",
    "                f\"EVAL: [{step}/{len(valid_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
    "                f\"Loss: {losses.val:.4f}({losses.avg:.4f}) \"\n",
    "            )\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "integrated-classification",
    "papermill": {
     "duration": 0.029832,
     "end_time": "2021-05-12T03:03:21.786427",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.756595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "harmful-explanation",
    "papermill": {
     "duration": 0.05136,
     "end_time": "2021-05-12T03:03:21.868561",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.817201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(folds, fold):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    # X_train_folds = X_train[folds[\"fold\"] != fold]\n",
    "    # X_valid_folds = X_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    # y_train_folds = y_train[folds[\"fold\"] != fold]\n",
    "    y_valid_folds = y_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    # y_df_train_folds = y_df[folds[\"fold\"] != fold]\n",
    "    y_df_valid_folds = y_df[folds[\"fold\"] == fold]\n",
    "\n",
    "    # train_dataset = TrainDataset(X_train[folds[\"fold\"] != fold], y_train[folds[\"fold\"] != fold])\n",
    "    # valid_dataset = TrainDataset(X_train[folds[\"fold\"] == fold], y_valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        TrainDataset(X_train[folds[\"fold\"] != fold], y_train[folds[\"fold\"] != fold]),\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        TrainDataset(X_train[folds[\"fold\"] == fold], y_valid_folds),\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if Config.scheduler == \"ReduceLROnPlateau\":\n",
    "            scheduler = ReduceLROnPlateau(\n",
    "                optimizer, mode=\"min\", factor=Config.factor, patience=Config.patience, verbose=True, eps=Config.eps\n",
    "            )\n",
    "        elif Config.scheduler == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=Config.T_max, eta_min=Config.min_lr, last_epoch=-1)\n",
    "        elif Config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "            scheduler = CosineAnnealingWarmRestarts(\n",
    "                optimizer, T_0=Config.T_0, T_mult=1, eta_min=Config.min_lr, last_epoch=-1\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = GeeseNetAlpha()\n",
    "\n",
    "    # Disable training for value network\n",
    "    for param in model.conv_v.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.head_v1.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.head_v2.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Use multi GPU\n",
    "    if device == torch.device(\"cuda\") and not Config.apex:\n",
    "        model = torch.nn.DataParallel(model)  # make parallel\n",
    "        # torch.backends.cudnn.benchmark=True\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=Config.lr, weight_decay=Config.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # apex\n",
    "    # ====================================================\n",
    "    if Config.apex:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
    "\n",
    "    # ====================================================\n",
    "    # Criterion\n",
    "    # ====================================================\n",
    "    def get_criterion():\n",
    "        if Config.criterion == \"CrossEntropyLoss\":\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        return criterion\n",
    "\n",
    "    criterion = get_criterion()\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    best_score = 0.0\n",
    "    best_loss = np.inf\n",
    "    best_preds = None\n",
    "\n",
    "    for epoch in range(Config.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "\n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(y_valid_folds, preds.argmax(1))\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Accuracy: {score}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_best.pth\")\n",
    "            best_preds = preds\n",
    "\n",
    "        if epoch == Config.epochs - 1:\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save final model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_final.pth\")\n",
    "\n",
    "    if Config.train:\n",
    "        y_df_valid_folds[[str(c) for c in range(Config.n_class)]] = best_preds\n",
    "        y_df_valid_folds[\"preds\"] = best_preds.argmax(1)\n",
    "\n",
    "        return y_df_valid_folds\n",
    "\n",
    "    if Config.tuning:\n",
    "        score = get_score(y_df_valid_folds[\"action\"].values, best_preds.argmax(1))\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    Config.geese_net_layers = trial.suggest_int(\"layers\", 6, 18)\n",
    "    Config.geese_net_filters = trial.suggest_int(\"filters\", 32, 128)\n",
    "\n",
    "    score = train_loop(folds, 0)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "complimentary-wright",
    "papermill": {
     "duration": 0.030218,
     "end_time": "2021-05-12T03:03:21.928896",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.898678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "particular-adaptation",
    "papermill": {
     "duration": 0.04089,
     "end_time": "2021-05-12T03:03:22.000150",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.959260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if Config.train:\n",
    "        # train\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(Config.n_fold):\n",
    "            _oof_df = train_loop(folds, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df)\n",
    "            break  # fold 1つだけ\n",
    "        # CV result\n",
    "        # LOGGER.info(f\"========== CV ==========\")\n",
    "        # get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
    "\n",
    "    if Config.tuning:\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=10)\n",
    "\n",
    "        trial = study.best_trial\n",
    "        print(\"Best trial:\")\n",
    "        print(\"  Value: \", trial.value)\n",
    "        print(\"  Params: \")\n",
    "        for key, value in trial.params.items():\n",
    "            print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "backed-journal",
    "outputId": "c9f0ff3d-795e-466b-e22e-9ba21d08c874",
    "papermill": {
     "duration": 2797.64711,
     "end_time": "2021-05-12T03:49:59.678400",
     "exception": false,
     "start_time": "2021-05-12T03:03:22.031290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-17 21:45:36,145]\u001b[0m A new study created in memory with name: no-name-a2e6656d-2383-40bf-8855-aa11f6fc7d2c\u001b[0m\n",
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2585] Elapsed 0m 5s (remain 240m 13s) Loss: 1.4050(1.4050) Grad: 0.6862 LR: 0.001000  \n",
      "Epoch: [1][100/2585] Elapsed 2m 8s (remain 52m 37s) Loss: 0.5839(0.6841) Grad: 0.6368 LR: 0.001000  \n",
      "Epoch: [1][200/2585] Elapsed 4m 11s (remain 49m 40s) Loss: 0.5427(0.6258) Grad: 0.5462 LR: 0.001000  \n",
      "Epoch: [1][300/2585] Elapsed 6m 14s (remain 47m 18s) Loss: 0.5437(0.5959) Grad: 0.7162 LR: 0.001000  \n",
      "Epoch: [1][400/2585] Elapsed 8m 16s (remain 45m 5s) Loss: 0.5083(0.5765) Grad: 0.4606 LR: 0.001000  \n",
      "Epoch: [1][500/2585] Elapsed 10m 19s (remain 42m 57s) Loss: 0.5013(0.5633) Grad: 0.3756 LR: 0.001000  \n",
      "Epoch: [1][600/2585] Elapsed 12m 22s (remain 40m 50s) Loss: 0.4942(0.5535) Grad: 0.6405 LR: 0.001000  \n",
      "Epoch: [1][700/2585] Elapsed 14m 25s (remain 38m 44s) Loss: 0.4819(0.5461) Grad: 0.3531 LR: 0.001000  \n",
      "Epoch: [1][800/2585] Elapsed 16m 27s (remain 36m 40s) Loss: 0.5078(0.5398) Grad: 0.5177 LR: 0.001000  \n",
      "Epoch: [1][900/2585] Elapsed 18m 30s (remain 34m 35s) Loss: 0.4903(0.5346) Grad: 0.4360 LR: 0.001000  \n",
      "Epoch: [1][1000/2585] Elapsed 20m 33s (remain 32m 31s) Loss: 0.5073(0.5301) Grad: 0.5503 LR: 0.001000  \n",
      "Epoch: [1][1100/2585] Elapsed 22m 36s (remain 30m 27s) Loss: 0.4896(0.5264) Grad: 0.3600 LR: 0.001000  \n",
      "Epoch: [1][1200/2585] Elapsed 24m 38s (remain 28m 24s) Loss: 0.4794(0.5230) Grad: 0.2898 LR: 0.001000  \n",
      "Epoch: [1][1300/2585] Elapsed 26m 41s (remain 26m 20s) Loss: 0.4833(0.5200) Grad: 0.2603 LR: 0.001000  \n",
      "Epoch: [1][1400/2585] Elapsed 28m 44s (remain 24m 17s) Loss: 0.4815(0.5174) Grad: 0.4237 LR: 0.001000  \n",
      "Epoch: [1][1500/2585] Elapsed 30m 47s (remain 22m 14s) Loss: 0.4779(0.5150) Grad: 0.2137 LR: 0.001000  \n",
      "Epoch: [1][1600/2585] Elapsed 32m 50s (remain 20m 10s) Loss: 0.4978(0.5128) Grad: 0.2769 LR: 0.001000  \n",
      "Epoch: [1][1700/2585] Elapsed 34m 52s (remain 18m 7s) Loss: 0.4512(0.5108) Grad: 0.3624 LR: 0.001000  \n",
      "Epoch: [1][1800/2585] Elapsed 36m 55s (remain 16m 4s) Loss: 0.4711(0.5090) Grad: 0.1878 LR: 0.001000  \n",
      "Epoch: [1][1900/2585] Elapsed 38m 58s (remain 14m 1s) Loss: 0.4951(0.5073) Grad: 0.3424 LR: 0.001000  \n",
      "Epoch: [1][2000/2585] Elapsed 41m 1s (remain 11m 58s) Loss: 0.4720(0.5058) Grad: 0.2968 LR: 0.001000  \n",
      "Epoch: [1][2100/2585] Elapsed 43m 4s (remain 9m 55s) Loss: 0.4694(0.5043) Grad: 0.2994 LR: 0.001000  \n",
      "Epoch: [1][2200/2585] Elapsed 45m 6s (remain 7m 52s) Loss: 0.4665(0.5030) Grad: 0.3166 LR: 0.001000  \n",
      "Epoch: [1][2300/2585] Elapsed 47m 9s (remain 5m 49s) Loss: 0.4539(0.5016) Grad: 0.2494 LR: 0.001000  \n",
      "Epoch: [1][2400/2585] Elapsed 49m 12s (remain 3m 46s) Loss: 0.4753(0.5004) Grad: 0.2549 LR: 0.001000  \n",
      "Epoch: [1][2500/2585] Elapsed 51m 15s (remain 1m 43s) Loss: 0.5056(0.4992) Grad: 0.3847 LR: 0.001000  \n",
      "Epoch: [1][2584/2585] Elapsed 52m 58s (remain 0m 0s) Loss: 0.4602(0.4983) Grad: 0.2081 LR: 0.001000  \n",
      "EVAL: [0/647] Elapsed 0m 1s (remain 16m 45s) Loss: 0.7536(0.7536) \n",
      "EVAL: [100/647] Elapsed 0m 37s (remain 3m 23s) Loss: 0.5380(0.5889) \n",
      "EVAL: [200/647] Elapsed 1m 13s (remain 2m 43s) Loss: 0.4702(0.5432) \n",
      "EVAL: [300/647] Elapsed 1m 49s (remain 2m 6s) Loss: 0.4594(0.5213) \n",
      "EVAL: [400/647] Elapsed 2m 25s (remain 1m 29s) Loss: 0.4610(0.5069) \n",
      "EVAL: [500/647] Elapsed 3m 2s (remain 0m 53s) Loss: 0.4433(0.4950) \n",
      "EVAL: [600/647] Elapsed 3m 38s (remain 0m 16s) Loss: 0.3842(0.4829) \n",
      "EVAL: [646/647] Elapsed 3m 54s (remain 0m 0s) Loss: 0.2500(0.4750) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4983  avg_val_loss: 0.4750  time: 3414s\n",
      "Epoch 1 - Accuracy: 0.7930057135784155\n",
      "Epoch 1 - Save Best Score: 0.7930 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2585] Elapsed 0m 3s (remain 133m 19s) Loss: 0.4928(0.4928) Grad: 0.5023 LR: 0.000978  \n",
      "Epoch: [2][100/2585] Elapsed 2m 5s (remain 51m 37s) Loss: 0.4748(0.4670) Grad: 0.5098 LR: 0.000978  \n",
      "Epoch: [2][200/2585] Elapsed 4m 8s (remain 49m 10s) Loss: 0.4718(0.4673) Grad: 0.1784 LR: 0.000978  \n",
      "Epoch: [2][300/2585] Elapsed 6m 11s (remain 46m 59s) Loss: 0.4725(0.4678) Grad: 0.2053 LR: 0.000978  \n",
      "Epoch: [2][400/2585] Elapsed 8m 14s (remain 44m 52s) Loss: 0.4666(0.4668) Grad: 0.2734 LR: 0.000978  \n",
      "Epoch: [2][500/2585] Elapsed 10m 17s (remain 42m 47s) Loss: 0.4633(0.4668) Grad: 0.3577 LR: 0.000978  \n",
      "Epoch: [2][600/2585] Elapsed 12m 19s (remain 40m 42s) Loss: 0.4605(0.4665) Grad: 0.2601 LR: 0.000978  \n",
      "Epoch: [2][700/2585] Elapsed 14m 22s (remain 38m 38s) Loss: 0.4514(0.4666) Grad: 0.2528 LR: 0.000978  \n",
      "Epoch: [2][800/2585] Elapsed 16m 25s (remain 36m 34s) Loss: 0.4616(0.4664) Grad: 0.3776 LR: 0.000978  \n",
      "Epoch: [2][900/2585] Elapsed 18m 28s (remain 34m 31s) Loss: 0.4902(0.4661) Grad: 0.2910 LR: 0.000978  \n",
      "Epoch: [2][1000/2585] Elapsed 20m 31s (remain 32m 27s) Loss: 0.4664(0.4658) Grad: 0.2552 LR: 0.000978  \n",
      "Epoch: [2][1100/2585] Elapsed 22m 33s (remain 30m 24s) Loss: 0.4663(0.4656) Grad: 0.2537 LR: 0.000978  \n",
      "Epoch: [2][1200/2585] Elapsed 24m 36s (remain 28m 21s) Loss: 0.4715(0.4655) Grad: 0.2230 LR: 0.000978  \n",
      "Epoch: [2][1300/2585] Elapsed 26m 39s (remain 26m 18s) Loss: 0.4454(0.4654) Grad: 0.2799 LR: 0.000978  \n",
      "Epoch: [2][1400/2585] Elapsed 28m 41s (remain 24m 15s) Loss: 0.4695(0.4654) Grad: 0.3186 LR: 0.000978  \n",
      "Epoch: [2][1500/2585] Elapsed 30m 44s (remain 22m 12s) Loss: 0.4772(0.4652) Grad: 0.2980 LR: 0.000978  \n",
      "Epoch: [2][1600/2585] Elapsed 32m 47s (remain 20m 9s) Loss: 0.4656(0.4652) Grad: 0.2224 LR: 0.000978  \n",
      "Epoch: [2][1700/2585] Elapsed 34m 50s (remain 18m 6s) Loss: 0.4597(0.4651) Grad: 0.1929 LR: 0.000978  \n",
      "Epoch: [2][1800/2585] Elapsed 36m 53s (remain 16m 3s) Loss: 0.4690(0.4650) Grad: 0.3320 LR: 0.000978  \n",
      "Epoch: [2][1900/2585] Elapsed 38m 55s (remain 14m 0s) Loss: 0.4945(0.4649) Grad: 0.2963 LR: 0.000978  \n",
      "Epoch: [2][2000/2585] Elapsed 40m 58s (remain 11m 57s) Loss: 0.4488(0.4648) Grad: 0.2617 LR: 0.000978  \n",
      "Epoch: [2][2100/2585] Elapsed 43m 1s (remain 9m 54s) Loss: 0.4458(0.4647) Grad: 0.1557 LR: 0.000978  \n",
      "Epoch: [2][2200/2585] Elapsed 45m 4s (remain 7m 51s) Loss: 0.4588(0.4646) Grad: 0.3104 LR: 0.000978  \n",
      "Epoch: [2][2300/2585] Elapsed 47m 6s (remain 5m 48s) Loss: 0.4510(0.4645) Grad: 0.1789 LR: 0.000978  \n",
      "Epoch: [2][2400/2585] Elapsed 49m 9s (remain 3m 46s) Loss: 0.4506(0.4643) Grad: 0.1653 LR: 0.000978  \n",
      "Epoch: [2][2500/2585] Elapsed 51m 12s (remain 1m 43s) Loss: 0.4761(0.4642) Grad: 0.2413 LR: 0.000978  \n",
      "Epoch: [2][2584/2585] Elapsed 52m 55s (remain 0m 0s) Loss: 0.4581(0.4641) Grad: 0.3088 LR: 0.000978  \n",
      "EVAL: [0/647] Elapsed 0m 1s (remain 16m 53s) Loss: 0.7476(0.7476) \n",
      "EVAL: [100/647] Elapsed 0m 37s (remain 3m 23s) Loss: 0.5309(0.5794) \n",
      "EVAL: [200/647] Elapsed 1m 13s (remain 2m 43s) Loss: 0.4577(0.5332) \n",
      "EVAL: [300/647] Elapsed 1m 50s (remain 2m 6s) Loss: 0.4477(0.5106) \n",
      "EVAL: [400/647] Elapsed 2m 26s (remain 1m 29s) Loss: 0.4421(0.4955) \n",
      "EVAL: [500/647] Elapsed 3m 2s (remain 0m 53s) Loss: 0.4318(0.4832) \n",
      "EVAL: [600/647] Elapsed 3m 38s (remain 0m 16s) Loss: 0.3651(0.4709) \n",
      "EVAL: [646/647] Elapsed 3m 54s (remain 0m 0s) Loss: 0.2368(0.4628) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4641  avg_val_loss: 0.4628  time: 3411s\n",
      "Epoch 2 - Accuracy: 0.7986245250167897\n",
      "Epoch 2 - Save Best Score: 0.7986 Model\n",
      "Epoch 2 - Save final model\n",
      "\u001b[32m[I 2021-05-17 23:39:49,041]\u001b[0m Trial 0 finished with value: 0.7986245250167897 and parameters: {'layers': 9, 'filters': 117}. Best is trial 0 with value: 0.7986245250167897.\u001b[0m\n",
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2585] Elapsed 0m 3s (remain 149m 13s) Loss: 1.3931(1.3931) Grad: 0.4987 LR: 0.001000  \n",
      "Epoch: [1][100/2585] Elapsed 2m 49s (remain 69m 30s) Loss: 0.5742(0.6817) Grad: 0.7576 LR: 0.001000  \n",
      "Epoch: [1][200/2585] Elapsed 5m 35s (remain 66m 21s) Loss: 0.5523(0.6208) Grad: 0.7124 LR: 0.001000  \n",
      "Epoch: [1][300/2585] Elapsed 8m 21s (remain 63m 27s) Loss: 0.5320(0.5904) Grad: 0.5868 LR: 0.001000  \n",
      "Epoch: [1][400/2585] Elapsed 11m 8s (remain 60m 38s) Loss: 0.5222(0.5723) Grad: 0.7441 LR: 0.001000  \n",
      "Epoch: [1][500/2585] Elapsed 13m 53s (remain 57m 48s) Loss: 0.5075(0.5595) Grad: 0.3945 LR: 0.001000  \n",
      "Epoch: [1][600/2585] Elapsed 16m 39s (remain 55m 0s) Loss: 0.5195(0.5502) Grad: 0.5779 LR: 0.001000  \n",
      "Epoch: [1][700/2585] Elapsed 19m 25s (remain 52m 13s) Loss: 0.5030(0.5429) Grad: 0.7195 LR: 0.001000  \n",
      "Epoch: [1][800/2585] Elapsed 22m 11s (remain 49m 25s) Loss: 0.4929(0.5367) Grad: 0.4778 LR: 0.001000  \n",
      "Epoch: [1][900/2585] Elapsed 24m 57s (remain 46m 39s) Loss: 0.4785(0.5317) Grad: 0.6353 LR: 0.001000  \n",
      "Epoch: [1][1000/2585] Elapsed 27m 43s (remain 43m 52s) Loss: 0.5102(0.5274) Grad: 0.5255 LR: 0.001000  \n",
      "Epoch: [1][1100/2585] Elapsed 30m 29s (remain 41m 5s) Loss: 0.4835(0.5235) Grad: 0.2207 LR: 0.001000  \n",
      "Epoch: [1][1200/2585] Elapsed 33m 15s (remain 38m 19s) Loss: 0.4971(0.5203) Grad: 0.4308 LR: 0.001000  \n",
      "Epoch: [1][1300/2585] Elapsed 36m 1s (remain 35m 33s) Loss: 0.4791(0.5175) Grad: 0.2405 LR: 0.001000  \n",
      "Epoch: [1][1400/2585] Elapsed 38m 47s (remain 32m 47s) Loss: 0.4683(0.5149) Grad: 0.5248 LR: 0.001000  \n",
      "Epoch: [1][1500/2585] Elapsed 41m 33s (remain 30m 0s) Loss: 0.4962(0.5126) Grad: 0.4774 LR: 0.001000  \n",
      "Epoch: [1][1600/2585] Elapsed 44m 19s (remain 27m 14s) Loss: 0.4575(0.5105) Grad: 0.3975 LR: 0.001000  \n",
      "Epoch: [1][1700/2585] Elapsed 47m 5s (remain 24m 28s) Loss: 0.4752(0.5086) Grad: 0.2469 LR: 0.001000  \n",
      "Epoch: [1][1800/2585] Elapsed 49m 51s (remain 21m 42s) Loss: 0.4795(0.5068) Grad: 0.2461 LR: 0.001000  \n",
      "Epoch: [1][1900/2585] Elapsed 52m 37s (remain 18m 56s) Loss: 0.4748(0.5051) Grad: 0.2412 LR: 0.001000  \n",
      "Epoch: [1][2000/2585] Elapsed 55m 23s (remain 16m 10s) Loss: 0.4718(0.5036) Grad: 0.4033 LR: 0.001000  \n",
      "Epoch: [1][2100/2585] Elapsed 58m 9s (remain 13m 23s) Loss: 0.4956(0.5022) Grad: 0.4109 LR: 0.001000  \n",
      "Epoch: [1][2200/2585] Elapsed 60m 55s (remain 10m 37s) Loss: 0.4884(0.5009) Grad: 0.3322 LR: 0.001000  \n",
      "Epoch: [1][2300/2585] Elapsed 63m 41s (remain 7m 51s) Loss: 0.4728(0.4997) Grad: 0.2383 LR: 0.001000  \n",
      "Epoch: [1][2400/2585] Elapsed 66m 27s (remain 5m 5s) Loss: 0.4606(0.4985) Grad: 0.3524 LR: 0.001000  \n",
      "Epoch: [1][2500/2585] Elapsed 69m 13s (remain 2m 19s) Loss: 0.4573(0.4974) Grad: 0.3147 LR: 0.001000  \n",
      "Epoch: [1][2584/2585] Elapsed 71m 32s (remain 0m 0s) Loss: 0.4634(0.4966) Grad: 0.2576 LR: 0.001000  \n",
      "EVAL: [0/647] Elapsed 0m 1s (remain 19m 26s) Loss: 0.7569(0.7569) \n",
      "EVAL: [100/647] Elapsed 0m 49s (remain 4m 25s) Loss: 0.5386(0.5867) \n",
      "EVAL: [200/647] Elapsed 1m 36s (remain 3m 33s) Loss: 0.4686(0.5411) \n",
      "EVAL: [300/647] Elapsed 2m 23s (remain 2m 45s) Loss: 0.4613(0.5191) \n",
      "EVAL: [400/647] Elapsed 3m 10s (remain 1m 57s) Loss: 0.4564(0.5046) \n",
      "EVAL: [500/647] Elapsed 3m 57s (remain 1m 9s) Loss: 0.4395(0.4926) \n",
      "EVAL: [600/647] Elapsed 4m 45s (remain 0m 21s) Loss: 0.3729(0.4803) \n",
      "EVAL: [646/647] Elapsed 5m 6s (remain 0m 0s) Loss: 0.2425(0.4723) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4966  avg_val_loss: 0.4723  time: 4600s\n",
      "Epoch 1 - Accuracy: 0.7942961883851465\n",
      "Epoch 1 - Save Best Score: 0.7943 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2585] Elapsed 0m 3s (remain 156m 20s) Loss: 0.4634(0.4634) Grad: 0.3431 LR: 0.000978  \n",
      "Epoch: [2][100/2585] Elapsed 2m 49s (remain 69m 34s) Loss: 0.4652(0.4668) Grad: 0.2788 LR: 0.000978  \n",
      "Epoch: [2][200/2585] Elapsed 5m 35s (remain 66m 23s) Loss: 0.4586(0.4663) Grad: 0.2182 LR: 0.000978  \n",
      "Epoch: [2][300/2585] Elapsed 8m 21s (remain 63m 27s) Loss: 0.4383(0.4663) Grad: 0.2354 LR: 0.000978  \n",
      "Epoch: [2][400/2585] Elapsed 11m 7s (remain 60m 36s) Loss: 0.4691(0.4660) Grad: 0.1934 LR: 0.000978  \n",
      "Epoch: [2][500/2585] Elapsed 13m 53s (remain 57m 47s) Loss: 0.4688(0.4656) Grad: 0.2559 LR: 0.000978  \n",
      "Epoch: [2][600/2585] Elapsed 16m 39s (remain 54m 59s) Loss: 0.4698(0.4654) Grad: 0.1531 LR: 0.000978  \n",
      "Epoch: [2][700/2585] Elapsed 19m 25s (remain 52m 12s) Loss: 0.4768(0.4650) Grad: 0.3319 LR: 0.000978  \n",
      "Epoch: [2][800/2585] Elapsed 22m 11s (remain 49m 25s) Loss: 0.4711(0.4649) Grad: 0.1866 LR: 0.000978  \n",
      "Epoch: [2][900/2585] Elapsed 24m 57s (remain 46m 38s) Loss: 0.4505(0.4649) Grad: 0.1508 LR: 0.000978  \n",
      "Epoch: [2][1000/2585] Elapsed 27m 43s (remain 43m 52s) Loss: 0.4791(0.4649) Grad: 0.2013 LR: 0.000978  \n",
      "Epoch: [2][1100/2585] Elapsed 30m 29s (remain 41m 5s) Loss: 0.4668(0.4648) Grad: 0.2872 LR: 0.000978  \n",
      "Epoch: [2][1200/2585] Elapsed 33m 15s (remain 38m 19s) Loss: 0.4636(0.4646) Grad: 0.2917 LR: 0.000978  \n",
      "Epoch: [2][1300/2585] Elapsed 36m 1s (remain 35m 32s) Loss: 0.4568(0.4644) Grad: 0.2253 LR: 0.000978  \n",
      "Epoch: [2][1400/2585] Elapsed 38m 46s (remain 32m 46s) Loss: 0.4613(0.4642) Grad: 0.1803 LR: 0.000978  \n",
      "Epoch: [2][1500/2585] Elapsed 41m 32s (remain 30m 0s) Loss: 0.4560(0.4642) Grad: 0.1941 LR: 0.000978  \n",
      "Epoch: [2][1600/2585] Elapsed 44m 18s (remain 27m 14s) Loss: 0.4699(0.4641) Grad: 0.1715 LR: 0.000978  \n",
      "Epoch: [2][1700/2585] Elapsed 47m 4s (remain 24m 28s) Loss: 0.4562(0.4639) Grad: 0.1867 LR: 0.000978  \n",
      "Epoch: [2][1800/2585] Elapsed 49m 50s (remain 21m 41s) Loss: 0.4666(0.4638) Grad: 0.3680 LR: 0.000978  \n",
      "Epoch: [2][1900/2585] Elapsed 52m 36s (remain 18m 55s) Loss: 0.4772(0.4637) Grad: 0.2941 LR: 0.000978  \n",
      "Epoch: [2][2000/2585] Elapsed 55m 22s (remain 16m 9s) Loss: 0.4734(0.4636) Grad: 0.2823 LR: 0.000978  \n",
      "Epoch: [2][2100/2585] Elapsed 58m 8s (remain 13m 23s) Loss: 0.4691(0.4635) Grad: 0.2373 LR: 0.000978  \n",
      "Epoch: [2][2200/2585] Elapsed 60m 54s (remain 10m 37s) Loss: 0.4701(0.4634) Grad: 0.2080 LR: 0.000978  \n",
      "Epoch: [2][2300/2585] Elapsed 63m 40s (remain 7m 51s) Loss: 0.4608(0.4634) Grad: 0.2195 LR: 0.000978  \n",
      "Epoch: [2][2400/2585] Elapsed 66m 26s (remain 5m 5s) Loss: 0.4616(0.4633) Grad: 0.3782 LR: 0.000978  \n",
      "Epoch: [2][2500/2585] Elapsed 69m 12s (remain 2m 19s) Loss: 0.4531(0.4631) Grad: 0.2241 LR: 0.000978  \n",
      "Epoch: [2][2584/2585] Elapsed 71m 31s (remain 0m 0s) Loss: 0.4779(0.4631) Grad: 0.2036 LR: 0.000978  \n",
      "EVAL: [0/647] Elapsed 0m 1s (remain 15m 56s) Loss: 0.7448(0.7448) \n",
      "EVAL: [100/647] Elapsed 0m 48s (remain 4m 23s) Loss: 0.5287(0.5792) \n",
      "EVAL: [200/647] Elapsed 1m 35s (remain 3m 32s) Loss: 0.4599(0.5324) \n",
      "EVAL: [300/647] Elapsed 2m 23s (remain 2m 44s) Loss: 0.4528(0.5094) \n",
      "EVAL: [400/647] Elapsed 3m 10s (remain 1m 56s) Loss: 0.4428(0.4941) \n",
      "EVAL: [500/647] Elapsed 3m 57s (remain 1m 9s) Loss: 0.4256(0.4816) \n",
      "EVAL: [600/647] Elapsed 4m 44s (remain 0m 21s) Loss: 0.3629(0.4689) \n",
      "EVAL: [646/647] Elapsed 5m 6s (remain 0m 0s) Loss: 0.2309(0.4607) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4631  avg_val_loss: 0.4607  time: 4599s\n",
      "Epoch 2 - Accuracy: 0.8000682709039755\n",
      "Epoch 2 - Save Best Score: 0.8001 Model\n",
      "Epoch 2 - Save final model\n",
      "\u001b[32m[I 2021-05-18 02:13:30,649]\u001b[0m Trial 1 finished with value: 0.8000682709039755 and parameters: {'layers': 13, 'filters': 115}. Best is trial 1 with value: 0.8000682709039755.\u001b[0m\n",
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2585] Elapsed 0m 3s (remain 162m 46s) Loss: 1.3884(1.3884) Grad: 0.5084 LR: 0.001000  \n",
      "Epoch: [1][100/2585] Elapsed 3m 25s (remain 84m 19s) Loss: 0.5848(0.6763) Grad: 1.1381 LR: 0.001000  \n",
      "Epoch: [1][200/2585] Elapsed 6m 47s (remain 80m 34s) Loss: 0.5443(0.6198) Grad: 0.7290 LR: 0.001000  \n",
      "Epoch: [1][300/2585] Elapsed 10m 9s (remain 77m 5s) Loss: 0.5000(0.5906) Grad: 0.5190 LR: 0.001000  \n",
      "Epoch: [1][400/2585] Elapsed 13m 31s (remain 73m 39s) Loss: 0.5104(0.5723) Grad: 0.5240 LR: 0.001000  \n",
      "Epoch: [1][500/2585] Elapsed 16m 53s (remain 70m 15s) Loss: 0.4938(0.5599) Grad: 0.4043 LR: 0.001000  \n",
      "Epoch: [1][600/2585] Elapsed 20m 15s (remain 66m 52s) Loss: 0.5050(0.5504) Grad: 0.4823 LR: 0.001000  \n",
      "Epoch: [1][700/2585] Elapsed 23m 37s (remain 63m 30s) Loss: 0.5046(0.5432) Grad: 0.4636 LR: 0.001000  \n",
      "Epoch: [1][800/2585] Elapsed 26m 59s (remain 60m 7s) Loss: 0.4820(0.5373) Grad: 0.4990 LR: 0.001000  \n",
      "Epoch: [1][900/2585] Elapsed 30m 21s (remain 56m 44s) Loss: 0.5047(0.5323) Grad: 0.4607 LR: 0.001000  \n",
      "Epoch: [1][1000/2585] Elapsed 33m 43s (remain 53m 22s) Loss: 0.4789(0.5279) Grad: 0.3837 LR: 0.001000  \n",
      "Epoch: [1][1100/2585] Elapsed 37m 5s (remain 49m 59s) Loss: 0.4732(0.5241) Grad: 0.2960 LR: 0.001000  \n",
      "Epoch: [1][1200/2585] Elapsed 40m 27s (remain 46m 37s) Loss: 0.4676(0.5209) Grad: 0.3099 LR: 0.001000  \n",
      "Epoch: [1][1300/2585] Elapsed 43m 49s (remain 43m 14s) Loss: 0.4677(0.5180) Grad: 0.2739 LR: 0.001000  \n",
      "Epoch: [1][1400/2585] Elapsed 47m 11s (remain 39m 52s) Loss: 0.4878(0.5155) Grad: 0.3327 LR: 0.001000  \n",
      "Epoch: [1][1500/2585] Elapsed 50m 33s (remain 36m 30s) Loss: 0.4691(0.5132) Grad: 0.2903 LR: 0.001000  \n",
      "Epoch: [1][1600/2585] Elapsed 53m 55s (remain 33m 8s) Loss: 0.4855(0.5110) Grad: 0.2190 LR: 0.001000  \n",
      "Epoch: [1][1700/2585] Elapsed 57m 17s (remain 29m 46s) Loss: 0.4674(0.5091) Grad: 0.2723 LR: 0.001000  \n",
      "Epoch: [1][1800/2585] Elapsed 60m 38s (remain 26m 24s) Loss: 0.4756(0.5073) Grad: 0.1842 LR: 0.001000  \n",
      "Epoch: [1][1900/2585] Elapsed 64m 0s (remain 23m 1s) Loss: 0.4787(0.5057) Grad: 0.2620 LR: 0.001000  \n",
      "Epoch: [1][2000/2585] Elapsed 67m 22s (remain 19m 39s) Loss: 0.4667(0.5041) Grad: 0.2330 LR: 0.001000  \n",
      "Epoch: [1][2100/2585] Elapsed 70m 44s (remain 16m 17s) Loss: 0.4767(0.5027) Grad: 0.3274 LR: 0.001000  \n",
      "Epoch: [1][2200/2585] Elapsed 74m 6s (remain 12m 55s) Loss: 0.4553(0.5013) Grad: 0.2316 LR: 0.001000  \n",
      "Epoch: [1][2300/2585] Elapsed 77m 28s (remain 9m 33s) Loss: 0.4784(0.5001) Grad: 0.2272 LR: 0.001000  \n",
      "Epoch: [1][2400/2585] Elapsed 80m 50s (remain 6m 11s) Loss: 0.4750(0.4990) Grad: 0.4017 LR: 0.001000  \n",
      "Epoch: [1][2500/2585] Elapsed 84m 12s (remain 2m 49s) Loss: 0.4658(0.4978) Grad: 0.2752 LR: 0.001000  \n",
      "Epoch: [1][2584/2585] Elapsed 87m 2s (remain 0m 0s) Loss: 0.4499(0.4969) Grad: 0.1990 LR: 0.001000  \n",
      "EVAL: [0/647] Elapsed 0m 1s (remain 18m 54s) Loss: 0.7573(0.7573) \n",
      "EVAL: [100/647] Elapsed 0m 58s (remain 5m 18s) Loss: 0.5399(0.5871) \n",
      "EVAL: [200/647] Elapsed 1m 55s (remain 4m 17s) Loss: 0.4709(0.5405) \n",
      "EVAL: [300/647] Elapsed 2m 52s (remain 3m 18s) Loss: 0.4535(0.5182) \n",
      "EVAL: [400/647] Elapsed 3m 50s (remain 2m 21s) Loss: 0.4503(0.5037) \n",
      "EVAL: [500/647] Elapsed 4m 47s (remain 1m 23s) Loss: 0.4401(0.4915) \n",
      "EVAL: [600/647] Elapsed 5m 44s (remain 0m 26s) Loss: 0.3727(0.4792) \n",
      "EVAL: [646/647] Elapsed 6m 10s (remain 0m 0s) Loss: 0.2364(0.4711) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4969  avg_val_loss: 0.4711  time: 5593s\n",
      "Epoch 1 - Accuracy: 0.7953449106990467\n",
      "Epoch 1 - Save Best Score: 0.7953 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2585] Elapsed 0m 3s (remain 167m 52s) Loss: 0.4676(0.4676) Grad: 0.2128 LR: 0.000978  \n",
      "Epoch: [2][100/2585] Elapsed 3m 25s (remain 84m 21s) Loss: 0.4700(0.4652) Grad: 0.3543 LR: 0.000978  \n",
      "Epoch: [2][200/2585] Elapsed 6m 47s (remain 80m 34s) Loss: 0.4739(0.4664) Grad: 0.2195 LR: 0.000978  \n",
      "Epoch: [2][300/2585] Elapsed 10m 9s (remain 77m 4s) Loss: 0.4599(0.4669) Grad: 0.1827 LR: 0.000978  \n",
      "Epoch: [2][400/2585] Elapsed 13m 31s (remain 73m 38s) Loss: 0.4512(0.4667) Grad: 0.1757 LR: 0.000978  \n",
      "Epoch: [2][500/2585] Elapsed 16m 53s (remain 70m 14s) Loss: 0.4560(0.4664) Grad: 0.1621 LR: 0.000978  \n",
      "Epoch: [2][600/2585] Elapsed 20m 15s (remain 66m 51s) Loss: 0.4628(0.4669) Grad: 0.3022 LR: 0.000978  \n",
      "Epoch: [2][700/2585] Elapsed 23m 36s (remain 63m 27s) Loss: 0.4613(0.4667) Grad: 0.1443 LR: 0.000978  \n",
      "Epoch: [2][800/2585] Elapsed 26m 58s (remain 60m 5s) Loss: 0.4480(0.4662) Grad: 0.1803 LR: 0.000978  \n",
      "Epoch: [2][900/2585] Elapsed 30m 20s (remain 56m 42s) Loss: 0.4536(0.4660) Grad: 0.2345 LR: 0.000978  \n",
      "Epoch: [2][1000/2585] Elapsed 33m 42s (remain 53m 20s) Loss: 0.4338(0.4658) Grad: 0.2037 LR: 0.000978  \n",
      "Epoch: [2][1100/2585] Elapsed 37m 4s (remain 49m 57s) Loss: 0.4666(0.4657) Grad: 0.1634 LR: 0.000978  \n",
      "Epoch: [2][1200/2585] Elapsed 40m 25s (remain 46m 35s) Loss: 0.4648(0.4655) Grad: 0.4073 LR: 0.000978  \n",
      "Epoch: [2][1300/2585] Elapsed 43m 47s (remain 43m 13s) Loss: 0.4638(0.4655) Grad: 0.3839 LR: 0.000978  \n",
      "Epoch: [2][1400/2585] Elapsed 47m 9s (remain 39m 51s) Loss: 0.4537(0.4654) Grad: 0.3024 LR: 0.000978  \n",
      "Epoch: [2][1500/2585] Elapsed 50m 31s (remain 36m 29s) Loss: 0.4629(0.4650) Grad: 0.2594 LR: 0.000978  \n",
      "Epoch: [2][1600/2585] Elapsed 53m 53s (remain 33m 7s) Loss: 0.4686(0.4650) Grad: 0.1943 LR: 0.000978  \n",
      "Epoch: [2][1700/2585] Elapsed 57m 15s (remain 29m 45s) Loss: 0.4548(0.4649) Grad: 0.1824 LR: 0.000978  \n",
      "Epoch: [2][1800/2585] Elapsed 60m 37s (remain 26m 23s) Loss: 0.4554(0.4648) Grad: 0.2601 LR: 0.000978  \n",
      "Epoch: [2][1900/2585] Elapsed 63m 59s (remain 23m 1s) Loss: 0.4699(0.4647) Grad: 0.1844 LR: 0.000978  \n",
      "Epoch: [2][2000/2585] Elapsed 67m 21s (remain 19m 39s) Loss: 0.4761(0.4645) Grad: 0.1453 LR: 0.000978  \n",
      "Epoch: [2][2100/2585] Elapsed 70m 43s (remain 16m 17s) Loss: 0.4661(0.4644) Grad: 0.1867 LR: 0.000978  \n",
      "Epoch: [2][2200/2585] Elapsed 74m 4s (remain 12m 55s) Loss: 0.4282(0.4643) Grad: 0.2277 LR: 0.000978  \n",
      "Epoch: [2][2300/2585] Elapsed 77m 26s (remain 9m 33s) Loss: 0.4581(0.4642) Grad: 0.1829 LR: 0.000978  \n",
      "Epoch: [2][2400/2585] Elapsed 80m 48s (remain 6m 11s) Loss: 0.4480(0.4640) Grad: 0.1866 LR: 0.000978  \n",
      "Epoch: [2][2500/2585] Elapsed 84m 10s (remain 2m 49s) Loss: 0.4549(0.4639) Grad: 0.1692 LR: 0.000978  \n",
      "Epoch: [2][2584/2585] Elapsed 86m 59s (remain 0m 0s) Loss: 0.4657(0.4638) Grad: 0.2558 LR: 0.000978  \n",
      "EVAL: [0/647] Elapsed 0m 1s (remain 18m 49s) Loss: 0.7474(0.7474) \n",
      "EVAL: [100/647] Elapsed 0m 58s (remain 5m 18s) Loss: 0.5279(0.5785) \n",
      "EVAL: [200/647] Elapsed 1m 56s (remain 4m 17s) Loss: 0.4592(0.5321) \n",
      "EVAL: [300/647] Elapsed 2m 53s (remain 3m 19s) Loss: 0.4453(0.5092) \n",
      "EVAL: [400/647] Elapsed 3m 50s (remain 2m 21s) Loss: 0.4402(0.4939) \n",
      "EVAL: [500/647] Elapsed 4m 47s (remain 1m 23s) Loss: 0.4294(0.4815) \n",
      "EVAL: [600/647] Elapsed 5m 44s (remain 0m 26s) Loss: 0.3654(0.4691) \n",
      "EVAL: [646/647] Elapsed 6m 10s (remain 0m 0s) Loss: 0.2349(0.4610) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4638  avg_val_loss: 0.4610  time: 5592s\n",
      "Epoch 2 - Accuracy: 0.7998671328299402\n",
      "Epoch 2 - Save Best Score: 0.7999 Model\n",
      "Epoch 2 - Save final model\n",
      "\u001b[32m[I 2021-05-18 05:20:20,618]\u001b[0m Trial 2 finished with value: 0.7998671328299402 and parameters: {'layers': 18, 'filters': 106}. Best is trial 1 with value: 0.8000682709039755.\u001b[0m\n",
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2585] Elapsed 0m 2s (remain 118m 31s) Loss: 1.3969(1.3969) Grad: 0.4876 LR: 0.001000  \n",
      "Epoch: [1][100/2585] Elapsed 1m 33s (remain 38m 13s) Loss: 0.5741(0.6939) Grad: 0.6342 LR: 0.001000  \n",
      "Epoch: [1][200/2585] Elapsed 3m 3s (remain 36m 21s) Loss: 0.5561(0.6335) Grad: 0.8800 LR: 0.001000  \n",
      "Epoch: [1][300/2585] Elapsed 4m 34s (remain 34m 44s) Loss: 0.5194(0.6033) Grad: 0.6011 LR: 0.001000  \n",
      "Epoch: [1][400/2585] Elapsed 6m 5s (remain 33m 9s) Loss: 0.5141(0.5832) Grad: 0.5230 LR: 0.001000  \n",
      "Epoch: [1][500/2585] Elapsed 7m 35s (remain 31m 36s) Loss: 0.5263(0.5694) Grad: 0.3600 LR: 0.001000  \n",
      "Epoch: [1][600/2585] Elapsed 9m 6s (remain 30m 4s) Loss: 0.5064(0.5593) Grad: 0.3620 LR: 0.001000  \n",
      "Epoch: [1][700/2585] Elapsed 10m 37s (remain 28m 32s) Loss: 0.4945(0.5512) Grad: 0.4882 LR: 0.001000  \n",
      "Epoch: [1][800/2585] Elapsed 12m 7s (remain 27m 1s) Loss: 0.5133(0.5448) Grad: 0.2691 LR: 0.001000  \n",
      "Epoch: [1][900/2585] Elapsed 13m 38s (remain 25m 30s) Loss: 0.4961(0.5395) Grad: 0.3778 LR: 0.001000  \n",
      "Epoch: [1][1000/2585] Elapsed 15m 9s (remain 23m 58s) Loss: 0.4817(0.5346) Grad: 0.4262 LR: 0.001000  \n",
      "Epoch: [1][1100/2585] Elapsed 16m 39s (remain 22m 27s) Loss: 0.4806(0.5308) Grad: 0.3736 LR: 0.001000  \n",
      "Epoch: [1][1200/2585] Elapsed 18m 10s (remain 20m 56s) Loss: 0.4863(0.5273) Grad: 0.4399 LR: 0.001000  \n",
      "Epoch: [1][1300/2585] Elapsed 19m 41s (remain 19m 25s) Loss: 0.4755(0.5242) Grad: 0.4785 LR: 0.001000  \n",
      "Epoch: [1][1400/2585] Elapsed 21m 11s (remain 17m 54s) Loss: 0.4945(0.5215) Grad: 0.3514 LR: 0.001000  \n",
      "Epoch: [1][1500/2585] Elapsed 22m 42s (remain 16m 23s) Loss: 0.4844(0.5189) Grad: 0.6899 LR: 0.001000  \n",
      "Epoch: [1][1600/2585] Elapsed 24m 12s (remain 14m 52s) Loss: 0.4836(0.5166) Grad: 0.3872 LR: 0.001000  \n",
      "Epoch: [1][1700/2585] Elapsed 25m 43s (remain 13m 22s) Loss: 0.4874(0.5147) Grad: 0.3138 LR: 0.001000  \n",
      "Epoch: [1][1800/2585] Elapsed 27m 14s (remain 11m 51s) Loss: 0.4818(0.5128) Grad: 0.3185 LR: 0.001000  \n",
      "Epoch: [1][1900/2585] Elapsed 28m 44s (remain 10m 20s) Loss: 0.4690(0.5110) Grad: 0.2423 LR: 0.001000  \n",
      "Epoch: [1][2000/2585] Elapsed 30m 15s (remain 8m 49s) Loss: 0.4670(0.5094) Grad: 0.2119 LR: 0.001000  \n",
      "Epoch: [1][2100/2585] Elapsed 31m 45s (remain 7m 19s) Loss: 0.4696(0.5079) Grad: 0.2601 LR: 0.001000  \n",
      "Epoch: [1][2200/2585] Elapsed 33m 16s (remain 5m 48s) Loss: 0.4917(0.5065) Grad: 0.2546 LR: 0.001000  \n",
      "Epoch: [1][2300/2585] Elapsed 34m 47s (remain 4m 17s) Loss: 0.4897(0.5051) Grad: 0.2646 LR: 0.001000  \n",
      "Epoch: [1][2400/2585] Elapsed 36m 17s (remain 2m 46s) Loss: 0.4869(0.5039) Grad: 0.3508 LR: 0.001000  \n",
      "Epoch: [1][2500/2585] Elapsed 37m 48s (remain 1m 16s) Loss: 0.4749(0.5027) Grad: 0.2674 LR: 0.001000  \n",
      "Epoch: [1][2584/2585] Elapsed 39m 4s (remain 0m 0s) Loss: 0.4883(0.5017) Grad: 0.3216 LR: 0.001000  \n",
      "EVAL: [0/647] Elapsed 0m 1s (remain 14m 50s) Loss: 0.7579(0.7579) \n",
      "EVAL: [100/647] Elapsed 0m 28s (remain 2m 36s) Loss: 0.5366(0.5856) \n",
      "EVAL: [200/647] Elapsed 0m 56s (remain 2m 5s) Loss: 0.4697(0.5402) \n",
      "EVAL: [300/647] Elapsed 1m 24s (remain 1m 36s) Loss: 0.4545(0.5185) \n",
      "EVAL: [400/647] Elapsed 1m 51s (remain 1m 8s) Loss: 0.4532(0.5043) \n",
      "EVAL: [500/647] Elapsed 2m 19s (remain 0m 40s) Loss: 0.4435(0.4926) \n",
      "EVAL: [600/647] Elapsed 2m 47s (remain 0m 12s) Loss: 0.3747(0.4807) \n",
      "EVAL: [646/647] Elapsed 2m 59s (remain 0m 0s) Loss: 0.2333(0.4727) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.5017  avg_val_loss: 0.4727  time: 2526s\n",
      "Epoch 1 - Accuracy: 0.7942976389001035\n",
      "Epoch 1 - Save Best Score: 0.7943 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2585] Elapsed 0m 2s (remain 110m 26s) Loss: 0.4612(0.4612) Grad: 0.3098 LR: 0.000978  \n",
      "Epoch: [2][100/2585] Elapsed 1m 32s (remain 38m 6s) Loss: 0.4544(0.4705) Grad: 0.3551 LR: 0.000978  \n",
      "Epoch: [2][200/2585] Elapsed 3m 3s (remain 36m 15s) Loss: 0.4979(0.4701) Grad: 0.2145 LR: 0.000978  \n",
      "Epoch: [2][300/2585] Elapsed 4m 33s (remain 34m 37s) Loss: 0.4824(0.4698) Grad: 0.2939 LR: 0.000978  \n",
      "Epoch: [2][400/2585] Elapsed 6m 4s (remain 33m 3s) Loss: 0.4583(0.4694) Grad: 0.2377 LR: 0.000978  \n",
      "Epoch: [2][500/2585] Elapsed 7m 34s (remain 31m 30s) Loss: 0.4533(0.4695) Grad: 0.4056 LR: 0.000978  \n",
      "Epoch: [2][600/2585] Elapsed 9m 4s (remain 29m 58s) Loss: 0.4639(0.4691) Grad: 0.2640 LR: 0.000978  \n",
      "Epoch: [2][700/2585] Elapsed 10m 35s (remain 28m 27s) Loss: 0.4684(0.4690) Grad: 0.3592 LR: 0.000978  \n",
      "Epoch: [2][800/2585] Elapsed 12m 5s (remain 26m 55s) Loss: 0.4595(0.4688) Grad: 0.2057 LR: 0.000978  \n",
      "Epoch: [2][900/2585] Elapsed 13m 35s (remain 25m 24s) Loss: 0.4461(0.4686) Grad: 0.1939 LR: 0.000978  \n",
      "Epoch: [2][1000/2585] Elapsed 15m 6s (remain 23m 54s) Loss: 0.4530(0.4685) Grad: 0.2043 LR: 0.000978  \n",
      "Epoch: [2][1100/2585] Elapsed 16m 36s (remain 22m 23s) Loss: 0.4632(0.4684) Grad: 0.2483 LR: 0.000978  \n",
      "Epoch: [2][1200/2585] Elapsed 18m 6s (remain 20m 52s) Loss: 0.4658(0.4683) Grad: 0.2829 LR: 0.000978  \n",
      "Epoch: [2][1300/2585] Elapsed 19m 37s (remain 19m 21s) Loss: 0.4635(0.4682) Grad: 0.3856 LR: 0.000978  \n",
      "Epoch: [2][1400/2585] Elapsed 21m 7s (remain 17m 51s) Loss: 0.4726(0.4680) Grad: 0.2233 LR: 0.000978  \n",
      "Epoch: [2][1500/2585] Elapsed 22m 38s (remain 16m 20s) Loss: 0.4655(0.4679) Grad: 0.1953 LR: 0.000978  \n",
      "Epoch: [2][1600/2585] Elapsed 24m 8s (remain 14m 50s) Loss: 0.4682(0.4678) Grad: 0.1968 LR: 0.000978  \n",
      "Epoch: [2][1700/2585] Elapsed 25m 38s (remain 13m 19s) Loss: 0.4651(0.4677) Grad: 0.2465 LR: 0.000978  \n",
      "Epoch: [2][1800/2585] Elapsed 27m 9s (remain 11m 49s) Loss: 0.4624(0.4676) Grad: 0.2165 LR: 0.000978  \n",
      "Epoch: [2][1900/2585] Elapsed 28m 39s (remain 10m 18s) Loss: 0.4663(0.4674) Grad: 0.2503 LR: 0.000978  \n",
      "Epoch: [2][2000/2585] Elapsed 30m 9s (remain 8m 48s) Loss: 0.4607(0.4673) Grad: 0.2990 LR: 0.000978  \n",
      "Epoch: [2][2100/2585] Elapsed 31m 40s (remain 7m 17s) Loss: 0.4735(0.4672) Grad: 0.2206 LR: 0.000978  \n",
      "Epoch: [2][2200/2585] Elapsed 33m 10s (remain 5m 47s) Loss: 0.4782(0.4671) Grad: 0.3626 LR: 0.000978  \n",
      "Epoch: [2][2300/2585] Elapsed 34m 40s (remain 4m 16s) Loss: 0.4472(0.4670) Grad: 0.1737 LR: 0.000978  \n",
      "Epoch: [2][2400/2585] Elapsed 36m 11s (remain 2m 46s) Loss: 0.4582(0.4668) Grad: 0.2382 LR: 0.000978  \n",
      "Epoch: [2][2500/2585] Elapsed 37m 41s (remain 1m 15s) Loss: 0.4624(0.4668) Grad: 0.2328 LR: 0.000978  \n",
      "Epoch: [2][2584/2585] Elapsed 38m 57s (remain 0m 0s) Loss: 0.4480(0.4666) Grad: 0.2596 LR: 0.000978  \n",
      "EVAL: [0/647] Elapsed 0m 1s (remain 13m 46s) Loss: 0.7434(0.7434) \n",
      "EVAL: [100/647] Elapsed 0m 28s (remain 2m 36s) Loss: 0.5355(0.5823) \n",
      "EVAL: [200/647] Elapsed 0m 56s (remain 2m 5s) Loss: 0.4647(0.5359) \n",
      "EVAL: [300/647] Elapsed 1m 24s (remain 1m 36s) Loss: 0.4470(0.5131) \n",
      "EVAL: [400/647] Elapsed 1m 51s (remain 1m 8s) Loss: 0.4412(0.4979) \n",
      "EVAL: [500/647] Elapsed 2m 19s (remain 0m 40s) Loss: 0.4300(0.4854) \n",
      "EVAL: [600/647] Elapsed 2m 47s (remain 0m 12s) Loss: 0.3653(0.4730) \n",
      "EVAL: [646/647] Elapsed 2m 59s (remain 0m 0s) Loss: 0.2342(0.4648) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4666  avg_val_loss: 0.4648  time: 2518s\n",
      "Epoch 2 - Accuracy: 0.7978663891992722\n",
      "Epoch 2 - Save Best Score: 0.7979 Model\n",
      "Epoch 2 - Save final model\n",
      "\u001b[32m[I 2021-05-18 06:44:45,622]\u001b[0m Trial 3 finished with value: 0.7978663891992722 and parameters: {'layers': 8, 'filters': 94}. Best is trial 1 with value: 0.8000682709039755.\u001b[0m\n",
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2585] Elapsed 0m 2s (remain 109m 26s) Loss: 1.3955(1.3955) Grad: 0.4174 LR: 0.001000  \n",
      "Epoch: [1][100/2585] Elapsed 1m 24s (remain 34m 43s) Loss: 0.5797(0.6848) Grad: 0.9614 LR: 0.001000  \n",
      "Epoch: [1][200/2585] Elapsed 2m 46s (remain 32m 58s) Loss: 0.5798(0.6287) Grad: 0.6165 LR: 0.001000  \n",
      "Epoch: [1][300/2585] Elapsed 4m 8s (remain 31m 28s) Loss: 0.5326(0.6003) Grad: 0.4294 LR: 0.001000  \n",
      "Epoch: [1][400/2585] Elapsed 5m 30s (remain 30m 2s) Loss: 0.5349(0.5817) Grad: 0.6643 LR: 0.001000  \n",
      "Epoch: [1][500/2585] Elapsed 6m 52s (remain 28m 37s) Loss: 0.5010(0.5686) Grad: 0.4155 LR: 0.001000  \n",
      "Epoch: [1][600/2585] Elapsed 8m 14s (remain 27m 14s) Loss: 0.5151(0.5587) Grad: 0.5180 LR: 0.001000  \n",
      "Epoch: [1][700/2585] Elapsed 9m 37s (remain 25m 50s) Loss: 0.4987(0.5512) Grad: 0.3074 LR: 0.001000  \n",
      "Epoch: [1][800/2585] Elapsed 10m 59s (remain 24m 27s) Loss: 0.4685(0.5450) Grad: 0.3601 LR: 0.001000  \n",
      "Epoch: [1][900/2585] Elapsed 12m 21s (remain 23m 5s) Loss: 0.4888(0.5398) Grad: 0.2516 LR: 0.001000  \n",
      "Epoch: [1][1000/2585] Elapsed 13m 43s (remain 21m 42s) Loss: 0.4932(0.5353) Grad: 0.5853 LR: 0.001000  \n",
      "Epoch: [1][1100/2585] Elapsed 15m 5s (remain 20m 20s) Loss: 0.4817(0.5314) Grad: 0.3676 LR: 0.001000  \n",
      "Epoch: [1][1200/2585] Elapsed 16m 27s (remain 18m 57s) Loss: 0.5013(0.5280) Grad: 0.4487 LR: 0.001000  \n",
      "Epoch: [1][1300/2585] Elapsed 17m 49s (remain 17m 35s) Loss: 0.4858(0.5248) Grad: 0.3874 LR: 0.001000  \n",
      "Epoch: [1][1400/2585] Elapsed 19m 11s (remain 16m 13s) Loss: 0.5048(0.5221) Grad: 0.4749 LR: 0.001000  \n",
      "Epoch: [1][1500/2585] Elapsed 20m 33s (remain 14m 50s) Loss: 0.4700(0.5195) Grad: 0.3170 LR: 0.001000  \n",
      "Epoch: [1][1600/2585] Elapsed 21m 55s (remain 13m 28s) Loss: 0.4787(0.5174) Grad: 0.2992 LR: 0.001000  \n",
      "Epoch: [1][1700/2585] Elapsed 23m 17s (remain 12m 6s) Loss: 0.4736(0.5154) Grad: 0.3969 LR: 0.001000  \n",
      "Epoch: [1][1800/2585] Elapsed 24m 39s (remain 10m 44s) Loss: 0.4747(0.5135) Grad: 0.4085 LR: 0.001000  \n",
      "Epoch: [1][1900/2585] Elapsed 26m 1s (remain 9m 21s) Loss: 0.4931(0.5117) Grad: 0.3647 LR: 0.001000  \n",
      "Epoch: [1][2000/2585] Elapsed 27m 23s (remain 7m 59s) Loss: 0.4994(0.5101) Grad: 0.5437 LR: 0.001000  \n",
      "Epoch: [1][2100/2585] Elapsed 28m 45s (remain 6m 37s) Loss: 0.4623(0.5086) Grad: 0.2986 LR: 0.001000  \n",
      "Epoch: [1][2200/2585] Elapsed 30m 7s (remain 5m 15s) Loss: 0.4658(0.5071) Grad: 0.2406 LR: 0.001000  \n",
      "Epoch: [1][2300/2585] Elapsed 31m 29s (remain 3m 53s) Loss: 0.4721(0.5058) Grad: 0.3822 LR: 0.001000  \n",
      "Epoch: [1][2400/2585] Elapsed 32m 51s (remain 2m 31s) Loss: 0.4575(0.5045) Grad: 0.3061 LR: 0.001000  \n",
      "Epoch: [1][2500/2585] Elapsed 34m 13s (remain 1m 8s) Loss: 0.4602(0.5034) Grad: 0.2964 LR: 0.001000  \n",
      "Epoch: [1][2584/2585] Elapsed 35m 22s (remain 0m 0s) Loss: 0.4768(0.5025) Grad: 0.2809 LR: 0.001000  \n",
      "EVAL: [0/647] Elapsed 0m 1s (remain 14m 23s) Loss: 0.7499(0.7499) \n",
      "EVAL: [100/647] Elapsed 0m 26s (remain 2m 23s) Loss: 0.5407(0.5887) \n",
      "EVAL: [200/647] Elapsed 0m 51s (remain 1m 54s) Loss: 0.4695(0.5434) \n",
      "EVAL: [300/647] Elapsed 1m 16s (remain 1m 28s) Loss: 0.4559(0.5221) \n",
      "EVAL: [400/647] Elapsed 1m 41s (remain 1m 2s) Loss: 0.4611(0.5079) \n",
      "EVAL: [500/647] Elapsed 2m 6s (remain 0m 36s) Loss: 0.4372(0.4962) \n",
      "EVAL: [600/647] Elapsed 2m 32s (remain 0m 11s) Loss: 0.3840(0.4839) \n",
      "EVAL: [646/647] Elapsed 2m 43s (remain 0m 0s) Loss: 0.2487(0.4758) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.5025  avg_val_loss: 0.4758  time: 2287s\n",
      "Epoch 1 - Accuracy: 0.7923259055685753\n",
      "Epoch 1 - Save Best Score: 0.7923 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2585] Elapsed 0m 2s (remain 108m 44s) Loss: 0.4576(0.4576) Grad: 0.3434 LR: 0.000978  \n",
      "Epoch: [2][100/2585] Elapsed 1m 24s (remain 34m 36s) Loss: 0.4660(0.4705) Grad: 0.2676 LR: 0.000978  \n",
      "Epoch: [2][200/2585] Elapsed 2m 46s (remain 32m 53s) Loss: 0.4635(0.4706) Grad: 0.2155 LR: 0.000978  \n",
      "Epoch: [2][300/2585] Elapsed 4m 8s (remain 31m 24s) Loss: 0.4745(0.4708) Grad: 0.3035 LR: 0.000978  \n",
      "Epoch: [2][400/2585] Elapsed 5m 30s (remain 29m 58s) Loss: 0.4874(0.4702) Grad: 0.2955 LR: 0.000978  \n",
      "Epoch: [2][500/2585] Elapsed 6m 52s (remain 28m 34s) Loss: 0.4681(0.4701) Grad: 0.2946 LR: 0.000978  \n",
      "Epoch: [2][600/2585] Elapsed 8m 14s (remain 27m 11s) Loss: 0.4692(0.4701) Grad: 0.2870 LR: 0.000978  \n",
      "Epoch: [2][700/2585] Elapsed 9m 36s (remain 25m 48s) Loss: 0.4713(0.4698) Grad: 0.3658 LR: 0.000978  \n",
      "Epoch: [2][800/2585] Elapsed 10m 58s (remain 24m 25s) Loss: 0.4474(0.4697) Grad: 0.2197 LR: 0.000978  \n",
      "Epoch: [2][900/2585] Elapsed 12m 19s (remain 23m 2s) Loss: 0.4492(0.4695) Grad: 0.2028 LR: 0.000978  \n",
      "Epoch: [2][1000/2585] Elapsed 13m 41s (remain 21m 40s) Loss: 0.4708(0.4693) Grad: 0.2384 LR: 0.000978  \n",
      "Epoch: [2][1100/2585] Elapsed 15m 3s (remain 20m 18s) Loss: 0.4818(0.4694) Grad: 0.2428 LR: 0.000978  \n",
      "Epoch: [2][1200/2585] Elapsed 16m 25s (remain 18m 55s) Loss: 0.4652(0.4693) Grad: 0.3019 LR: 0.000978  \n",
      "Epoch: [2][1300/2585] Elapsed 17m 47s (remain 17m 33s) Loss: 0.4693(0.4693) Grad: 0.1873 LR: 0.000978  \n",
      "Epoch: [2][1400/2585] Elapsed 19m 9s (remain 16m 11s) Loss: 0.4533(0.4692) Grad: 0.2736 LR: 0.000978  \n",
      "Epoch: [2][1500/2585] Elapsed 20m 31s (remain 14m 49s) Loss: 0.4654(0.4689) Grad: 0.3353 LR: 0.000978  \n",
      "Epoch: [2][1600/2585] Elapsed 21m 53s (remain 13m 27s) Loss: 0.4820(0.4688) Grad: 0.2287 LR: 0.000978  \n",
      "Epoch: [2][1700/2585] Elapsed 23m 15s (remain 12m 5s) Loss: 0.4550(0.4685) Grad: 0.2788 LR: 0.000978  \n",
      "Epoch: [2][1800/2585] Elapsed 24m 37s (remain 10m 43s) Loss: 0.4785(0.4683) Grad: 0.2722 LR: 0.000978  \n",
      "Epoch: [2][1900/2585] Elapsed 25m 59s (remain 9m 21s) Loss: 0.4850(0.4682) Grad: 0.1994 LR: 0.000978  \n",
      "Epoch: [2][2000/2585] Elapsed 27m 21s (remain 7m 59s) Loss: 0.4613(0.4682) Grad: 0.3091 LR: 0.000978  \n",
      "Epoch: [2][2100/2585] Elapsed 28m 43s (remain 6m 36s) Loss: 0.4789(0.4680) Grad: 0.4152 LR: 0.000978  \n",
      "Epoch: [2][2200/2585] Elapsed 30m 5s (remain 5m 14s) Loss: 0.4688(0.4679) Grad: 0.3227 LR: 0.000978  \n",
      "Epoch: [2][2300/2585] Elapsed 31m 27s (remain 3m 52s) Loss: 0.4608(0.4678) Grad: 0.2018 LR: 0.000978  \n",
      "Epoch: [2][2400/2585] Elapsed 32m 48s (remain 2m 30s) Loss: 0.4542(0.4676) Grad: 0.1663 LR: 0.000978  \n",
      "Epoch: [2][2500/2585] Elapsed 34m 10s (remain 1m 8s) Loss: 0.4683(0.4675) Grad: 0.3274 LR: 0.000978  \n",
      "Epoch: [2][2584/2585] Elapsed 35m 19s (remain 0m 0s) Loss: 0.4628(0.4674) Grad: 0.2574 LR: 0.000978  \n",
      "EVAL: [0/647] Elapsed 0m 1s (remain 15m 12s) Loss: 0.7529(0.7529) \n",
      "EVAL: [100/647] Elapsed 0m 26s (remain 2m 24s) Loss: 0.5286(0.5810) \n",
      "EVAL: [200/647] Elapsed 0m 51s (remain 1m 55s) Loss: 0.4635(0.5354) \n",
      "EVAL: [300/647] Elapsed 1m 17s (remain 1m 28s) Loss: 0.4510(0.5134) \n",
      "EVAL: [400/647] Elapsed 1m 42s (remain 1m 2s) Loss: 0.4491(0.4984) \n",
      "EVAL: [500/647] Elapsed 2m 7s (remain 0m 37s) Loss: 0.4366(0.4861) \n",
      "EVAL: [600/647] Elapsed 2m 32s (remain 0m 11s) Loss: 0.3749(0.4737) \n",
      "EVAL: [646/647] Elapsed 2m 44s (remain 0m 0s) Loss: 0.2354(0.4656) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4674  avg_val_loss: 0.4656  time: 2285s\n",
      "Epoch 2 - Accuracy: 0.797216558498543\n",
      "Epoch 2 - Save Best Score: 0.7972 Model\n",
      "Epoch 2 - Save final model\n",
      "\u001b[32m[I 2021-05-18 08:01:23,609]\u001b[0m Trial 4 finished with value: 0.797216558498543 and parameters: {'layers': 8, 'filters': 85}. Best is trial 1 with value: 0.8000682709039755.\u001b[0m\n",
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2585] Elapsed 0m 3s (remain 156m 6s) Loss: 1.3966(1.3966) Grad: 0.5167 LR: 0.001000  \n",
      "Epoch: [1][100/2585] Elapsed 2m 59s (remain 73m 31s) Loss: 0.5818(0.6888) Grad: 0.8461 LR: 0.001000  \n",
      "Epoch: [1][200/2585] Elapsed 5m 55s (remain 70m 13s) Loss: 0.5407(0.6276) Grad: 0.7269 LR: 0.001000  \n",
      "Epoch: [1][300/2585] Elapsed 8m 50s (remain 67m 7s) Loss: 0.5463(0.5964) Grad: 0.3950 LR: 0.001000  \n",
      "Epoch: [1][400/2585] Elapsed 11m 46s (remain 64m 6s) Loss: 0.5147(0.5768) Grad: 0.4300 LR: 0.001000  \n",
      "Epoch: [1][500/2585] Elapsed 14m 41s (remain 61m 8s) Loss: 0.5245(0.5638) Grad: 0.4617 LR: 0.001000  \n",
      "Epoch: [1][600/2585] Elapsed 17m 37s (remain 58m 10s) Loss: 0.5080(0.5539) Grad: 0.5082 LR: 0.001000  \n",
      "Epoch: [1][700/2585] Elapsed 20m 32s (remain 55m 13s) Loss: 0.5106(0.5460) Grad: 0.3342 LR: 0.001000  \n",
      "Epoch: [1][800/2585] Elapsed 23m 28s (remain 52m 16s) Loss: 0.5118(0.5396) Grad: 0.3259 LR: 0.001000  \n",
      "Epoch: [1][900/2585] Elapsed 26m 24s (remain 49m 20s) Loss: 0.4987(0.5348) Grad: 0.4234 LR: 0.001000  \n",
      "Epoch: [1][1000/2585] Elapsed 29m 19s (remain 46m 24s) Loss: 0.4735(0.5305) Grad: 0.3062 LR: 0.001000  \n",
      "Epoch: [1][1100/2585] Elapsed 32m 15s (remain 43m 28s) Loss: 0.4886(0.5268) Grad: 0.3312 LR: 0.001000  \n",
      "Epoch: [1][1200/2585] Elapsed 35m 11s (remain 40m 32s) Loss: 0.4865(0.5234) Grad: 0.2917 LR: 0.001000  \n",
      "Epoch: [1][1300/2585] Elapsed 38m 6s (remain 37m 36s) Loss: 0.5046(0.5205) Grad: 0.3687 LR: 0.001000  \n",
      "Epoch: [1][1400/2585] Elapsed 41m 2s (remain 34m 40s) Loss: 0.4765(0.5178) Grad: 0.3150 LR: 0.001000  \n",
      "Epoch: [1][1500/2585] Elapsed 43m 57s (remain 31m 44s) Loss: 0.4652(0.5154) Grad: 0.2346 LR: 0.001000  \n",
      "Epoch: [1][1600/2585] Elapsed 46m 53s (remain 28m 49s) Loss: 0.4900(0.5132) Grad: 0.2795 LR: 0.001000  \n",
      "Epoch: [1][1700/2585] Elapsed 49m 49s (remain 25m 53s) Loss: 0.4751(0.5112) Grad: 0.2951 LR: 0.001000  \n",
      "Epoch: [1][1800/2585] Elapsed 52m 44s (remain 22m 57s) Loss: 0.4890(0.5093) Grad: 0.2818 LR: 0.001000  \n",
      "Epoch: [1][1900/2585] Elapsed 55m 40s (remain 20m 1s) Loss: 0.4742(0.5076) Grad: 0.3408 LR: 0.001000  \n",
      "Epoch: [1][2000/2585] Elapsed 58m 35s (remain 17m 6s) Loss: 0.4859(0.5061) Grad: 0.2882 LR: 0.001000  \n",
      "Epoch: [1][2100/2585] Elapsed 61m 31s (remain 14m 10s) Loss: 0.4684(0.5047) Grad: 0.2454 LR: 0.001000  \n",
      "Epoch: [1][2200/2585] Elapsed 64m 27s (remain 11m 14s) Loss: 0.4780(0.5033) Grad: 0.2169 LR: 0.001000  \n",
      "Epoch: [1][2300/2585] Elapsed 67m 22s (remain 8m 18s) Loss: 0.4588(0.5020) Grad: 0.3533 LR: 0.001000  \n",
      "Epoch: [1][2400/2585] Elapsed 70m 18s (remain 5m 23s) Loss: 0.4781(0.5008) Grad: 0.2627 LR: 0.001000  \n",
      "Epoch: [1][2500/2585] Elapsed 73m 14s (remain 2m 27s) Loss: 0.4673(0.4997) Grad: 0.3131 LR: 0.001000  \n",
      "Epoch: [1][2584/2585] Elapsed 75m 41s (remain 0m 0s) Loss: 0.4929(0.4988) Grad: 0.2767 LR: 0.001000  \n",
      "EVAL: [0/647] Elapsed 0m 1s (remain 17m 50s) Loss: 0.7615(0.7615) \n",
      "EVAL: [100/647] Elapsed 0m 51s (remain 4m 39s) Loss: 0.5372(0.5878) \n",
      "EVAL: [200/647] Elapsed 1m 41s (remain 3m 45s) Loss: 0.4703(0.5413) \n",
      "EVAL: [300/647] Elapsed 2m 31s (remain 2m 54s) Loss: 0.4609(0.5191) \n",
      "EVAL: [400/647] Elapsed 3m 21s (remain 2m 3s) Loss: 0.4505(0.5045) \n",
      "EVAL: [500/647] Elapsed 4m 11s (remain 1m 13s) Loss: 0.4372(0.4924) \n",
      "EVAL: [600/647] Elapsed 5m 1s (remain 0m 23s) Loss: 0.3791(0.4802) \n",
      "EVAL: [646/647] Elapsed 5m 24s (remain 0m 0s) Loss: 0.2388(0.4722) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4988  avg_val_loss: 0.4722  time: 4868s\n",
      "Epoch 1 - Accuracy: 0.7943372863089277\n",
      "Epoch 1 - Save Best Score: 0.7943 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2585] Elapsed 0m 3s (remain 149m 16s) Loss: 0.4737(0.4737) Grad: 0.1835 LR: 0.000978  \n",
      "Epoch: [2][100/2585] Elapsed 2m 58s (remain 73m 21s) Loss: 0.4905(0.4676) Grad: 0.3920 LR: 0.000978  \n",
      "Epoch: [2][200/2585] Elapsed 5m 54s (remain 70m 3s) Loss: 0.4732(0.4677) Grad: 0.3793 LR: 0.000978  \n",
      "Epoch: [2][300/2585] Elapsed 8m 49s (remain 67m 1s) Loss: 0.4751(0.4679) Grad: 0.2732 LR: 0.000978  \n",
      "Epoch: [2][400/2585] Elapsed 11m 45s (remain 64m 2s) Loss: 0.4689(0.4679) Grad: 0.2878 LR: 0.000978  \n",
      "Epoch: [2][500/2585] Elapsed 14m 40s (remain 61m 4s) Loss: 0.4579(0.4681) Grad: 0.1950 LR: 0.000978  \n",
      "Epoch: [2][600/2585] Elapsed 17m 36s (remain 58m 7s) Loss: 0.4672(0.4677) Grad: 0.1972 LR: 0.000978  \n",
      "Epoch: [2][700/2585] Elapsed 20m 31s (remain 55m 10s) Loss: 0.4532(0.4674) Grad: 0.3145 LR: 0.000978  \n",
      "Epoch: [2][800/2585] Elapsed 23m 27s (remain 52m 15s) Loss: 0.4612(0.4674) Grad: 0.2188 LR: 0.000978  \n",
      "Epoch: [2][900/2585] Elapsed 26m 23s (remain 49m 19s) Loss: 0.4635(0.4673) Grad: 0.2760 LR: 0.000978  \n",
      "Epoch: [2][1000/2585] Elapsed 29m 18s (remain 46m 23s) Loss: 0.4577(0.4671) Grad: 0.1916 LR: 0.000978  \n",
      "Epoch: [2][1100/2585] Elapsed 32m 14s (remain 43m 27s) Loss: 0.4743(0.4670) Grad: 0.2339 LR: 0.000978  \n",
      "Epoch: [2][1200/2585] Elapsed 35m 9s (remain 40m 31s) Loss: 0.4600(0.4668) Grad: 0.3134 LR: 0.000978  \n",
      "Epoch: [2][1300/2585] Elapsed 38m 5s (remain 37m 35s) Loss: 0.4745(0.4666) Grad: 0.2170 LR: 0.000978  \n",
      "Epoch: [2][1400/2585] Elapsed 41m 1s (remain 34m 39s) Loss: 0.4545(0.4665) Grad: 0.3158 LR: 0.000978  \n",
      "Epoch: [2][1500/2585] Elapsed 43m 56s (remain 31m 44s) Loss: 0.4851(0.4664) Grad: 0.2469 LR: 0.000978  \n",
      "Epoch: [2][1600/2585] Elapsed 46m 52s (remain 28m 48s) Loss: 0.4707(0.4663) Grad: 0.1626 LR: 0.000978  \n",
      "Epoch: [2][1700/2585] Elapsed 49m 48s (remain 25m 52s) Loss: 0.4582(0.4662) Grad: 0.2323 LR: 0.000978  \n",
      "Epoch: [2][1800/2585] Elapsed 52m 43s (remain 22m 57s) Loss: 0.4658(0.4660) Grad: 0.1527 LR: 0.000978  \n",
      "Epoch: [2][1900/2585] Elapsed 55m 39s (remain 20m 1s) Loss: 0.4717(0.4659) Grad: 0.1680 LR: 0.000978  \n",
      "Epoch: [2][2000/2585] Elapsed 58m 34s (remain 17m 5s) Loss: 0.4651(0.4658) Grad: 0.2223 LR: 0.000978  \n",
      "Epoch: [2][2100/2585] Elapsed 61m 30s (remain 14m 10s) Loss: 0.4718(0.4657) Grad: 0.2789 LR: 0.000978  \n",
      "Epoch: [2][2200/2585] Elapsed 64m 25s (remain 11m 14s) Loss: 0.4648(0.4656) Grad: 0.2122 LR: 0.000978  \n",
      "Epoch: [2][2300/2585] Elapsed 67m 21s (remain 8m 18s) Loss: 0.4448(0.4654) Grad: 0.2495 LR: 0.000978  \n",
      "Epoch: [2][2400/2585] Elapsed 70m 17s (remain 5m 23s) Loss: 0.4568(0.4653) Grad: 0.2403 LR: 0.000978  \n",
      "Epoch: [2][2500/2585] Elapsed 73m 12s (remain 2m 27s) Loss: 0.4609(0.4651) Grad: 0.2632 LR: 0.000978  \n",
      "Epoch: [2][2584/2585] Elapsed 75m 40s (remain 0m 0s) Loss: 0.4666(0.4650) Grad: 0.2742 LR: 0.000978  \n",
      "EVAL: [0/647] Elapsed 0m 1s (remain 18m 10s) Loss: 0.7464(0.7464) \n",
      "EVAL: [100/647] Elapsed 0m 51s (remain 4m 39s) Loss: 0.5264(0.5805) \n",
      "EVAL: [200/647] Elapsed 1m 41s (remain 3m 46s) Loss: 0.4658(0.5353) \n",
      "EVAL: [300/647] Elapsed 2m 31s (remain 2m 54s) Loss: 0.4549(0.5131) \n",
      "EVAL: [400/647] Elapsed 3m 21s (remain 2m 3s) Loss: 0.4516(0.4982) \n",
      "EVAL: [500/647] Elapsed 4m 12s (remain 1m 13s) Loss: 0.4332(0.4860) \n",
      "EVAL: [600/647] Elapsed 5m 2s (remain 0m 23s) Loss: 0.3767(0.4736) \n",
      "EVAL: [646/647] Elapsed 5m 25s (remain 0m 0s) Loss: 0.2323(0.4655) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4650  avg_val_loss: 0.4655  time: 4867s\n",
      "Epoch 2 - Accuracy: 0.7974027079180227\n",
      "Epoch 2 - Save Best Score: 0.7974 Model\n",
      "Epoch 2 - Save final model\n",
      "\u001b[32m[I 2021-05-18 10:43:59,798]\u001b[0m Trial 5 finished with value: 0.7974027079180227 and parameters: {'layers': 18, 'filters': 90}. Best is trial 1 with value: 0.8000682709039755.\u001b[0m\n",
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2585] Elapsed 0m 3s (remain 135m 33s) Loss: 1.3955(1.3955) Grad: 0.5572 LR: 0.001000  \n",
      "Epoch: [1][100/2585] Elapsed 2m 6s (remain 51m 57s) Loss: 0.5920(0.6793) Grad: 0.6077 LR: 0.001000  \n",
      "Epoch: [1][200/2585] Elapsed 4m 10s (remain 49m 29s) Loss: 0.5361(0.6220) Grad: 0.6570 LR: 0.001000  \n",
      "Epoch: [1][300/2585] Elapsed 6m 13s (remain 47m 17s) Loss: 0.5300(0.5920) Grad: 0.3823 LR: 0.001000  \n",
      "Epoch: [1][400/2585] Elapsed 8m 17s (remain 45m 9s) Loss: 0.5093(0.5736) Grad: 0.4870 LR: 0.001000  \n",
      "Epoch: [1][500/2585] Elapsed 10m 21s (remain 43m 3s) Loss: 0.5125(0.5611) Grad: 0.4945 LR: 0.001000  \n",
      "Epoch: [1][600/2585] Elapsed 12m 24s (remain 40m 57s) Loss: 0.5038(0.5517) Grad: 0.5214 LR: 0.001000  \n",
      "Epoch: [1][700/2585] Elapsed 14m 28s (remain 38m 53s) Loss: 0.4926(0.5442) Grad: 0.4893 LR: 0.001000  \n",
      "Epoch: [1][800/2585] Elapsed 16m 31s (remain 36m 48s) Loss: 0.4799(0.5379) Grad: 0.3401 LR: 0.001000  \n",
      "Epoch: [1][900/2585] Elapsed 18m 35s (remain 34m 44s) Loss: 0.4822(0.5328) Grad: 0.3540 LR: 0.001000  \n",
      "Epoch: [1][1000/2585] Elapsed 20m 38s (remain 32m 40s) Loss: 0.4830(0.5287) Grad: 0.4202 LR: 0.001000  \n",
      "Epoch: [1][1100/2585] Elapsed 22m 42s (remain 30m 36s) Loss: 0.4942(0.5248) Grad: 0.3503 LR: 0.001000  \n",
      "Epoch: [1][1200/2585] Elapsed 24m 45s (remain 28m 32s) Loss: 0.4809(0.5214) Grad: 0.4147 LR: 0.001000  \n",
      "Epoch: [1][1300/2585] Elapsed 26m 49s (remain 26m 28s) Loss: 0.4857(0.5185) Grad: 0.2404 LR: 0.001000  \n",
      "Epoch: [1][1400/2585] Elapsed 28m 52s (remain 24m 24s) Loss: 0.4799(0.5160) Grad: 0.3206 LR: 0.001000  \n",
      "Epoch: [1][1500/2585] Elapsed 30m 56s (remain 22m 20s) Loss: 0.4825(0.5136) Grad: 0.2771 LR: 0.001000  \n",
      "Epoch: [1][1600/2585] Elapsed 32m 59s (remain 20m 16s) Loss: 0.4739(0.5116) Grad: 0.3702 LR: 0.001000  \n",
      "Epoch: [1][1700/2585] Elapsed 35m 3s (remain 18m 13s) Loss: 0.4711(0.5096) Grad: 0.4096 LR: 0.001000  \n",
      "Epoch: [1][1800/2585] Elapsed 37m 7s (remain 16m 9s) Loss: 0.4587(0.5077) Grad: 0.2911 LR: 0.001000  \n",
      "Epoch: [1][1900/2585] Elapsed 39m 10s (remain 14m 5s) Loss: 0.4715(0.5061) Grad: 0.2837 LR: 0.001000  \n",
      "Epoch: [1][2000/2585] Elapsed 41m 14s (remain 12m 2s) Loss: 0.4684(0.5046) Grad: 0.3329 LR: 0.001000  \n",
      "Epoch: [1][2100/2585] Elapsed 43m 17s (remain 9m 58s) Loss: 0.4628(0.5031) Grad: 0.4748 LR: 0.001000  \n",
      "Epoch: [1][2200/2585] Elapsed 45m 21s (remain 7m 54s) Loss: 0.4671(0.5018) Grad: 0.1939 LR: 0.001000  \n",
      "Epoch: [1][2300/2585] Elapsed 47m 24s (remain 5m 51s) Loss: 0.4809(0.5006) Grad: 0.2995 LR: 0.001000  \n",
      "Epoch: [1][2400/2585] Elapsed 49m 28s (remain 3m 47s) Loss: 0.4708(0.4994) Grad: 0.2125 LR: 0.001000  \n",
      "Epoch: [1][2500/2585] Elapsed 51m 31s (remain 1m 43s) Loss: 0.4721(0.4984) Grad: 0.2510 LR: 0.001000  \n",
      "Epoch: [1][2584/2585] Elapsed 53m 15s (remain 0m 0s) Loss: 0.4744(0.4976) Grad: 0.2473 LR: 0.001000  \n",
      "EVAL: [0/647] Elapsed 0m 1s (remain 14m 50s) Loss: 0.7569(0.7569) \n",
      "EVAL: [100/647] Elapsed 0m 37s (remain 3m 24s) Loss: 0.5321(0.5849) \n",
      "EVAL: [200/647] Elapsed 1m 14s (remain 2m 44s) Loss: 0.4709(0.5395) \n",
      "EVAL: [300/647] Elapsed 1m 50s (remain 2m 7s) Loss: 0.4548(0.5172) \n",
      "EVAL: [400/647] Elapsed 2m 27s (remain 1m 30s) Loss: 0.4515(0.5025) \n",
      "EVAL: [500/647] Elapsed 3m 3s (remain 0m 53s) Loss: 0.4396(0.4905) \n",
      "EVAL: [600/647] Elapsed 3m 39s (remain 0m 16s) Loss: 0.3743(0.4783) \n",
      "EVAL: [646/647] Elapsed 3m 56s (remain 0m 0s) Loss: 0.2405(0.4703) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4976  avg_val_loss: 0.4703  time: 3433s\n",
      "Epoch 1 - Accuracy: 0.7956263106007018\n",
      "Epoch 1 - Save Best Score: 0.7956 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2585] Elapsed 0m 3s (remain 129m 53s) Loss: 0.4980(0.4980) Grad: 0.3224 LR: 0.000978  \n",
      "Epoch: [2][100/2585] Elapsed 2m 6s (remain 51m 53s) Loss: 0.4811(0.4682) Grad: 0.2749 LR: 0.000978  \n",
      "Epoch: [2][200/2585] Elapsed 4m 10s (remain 49m 26s) Loss: 0.4752(0.4669) Grad: 0.2633 LR: 0.000978  \n",
      "Epoch: [2][300/2585] Elapsed 6m 13s (remain 47m 14s) Loss: 0.4589(0.4666) Grad: 0.2230 LR: 0.000978  \n",
      "Epoch: [2][400/2585] Elapsed 8m 17s (remain 45m 7s) Loss: 0.4721(0.4666) Grad: 0.3617 LR: 0.000978  \n",
      "Epoch: [2][500/2585] Elapsed 10m 20s (remain 43m 1s) Loss: 0.4579(0.4669) Grad: 0.3424 LR: 0.000978  \n",
      "Epoch: [2][600/2585] Elapsed 12m 24s (remain 40m 56s) Loss: 0.4685(0.4668) Grad: 0.2137 LR: 0.000978  \n",
      "Epoch: [2][700/2585] Elapsed 14m 27s (remain 38m 51s) Loss: 0.4426(0.4668) Grad: 0.2808 LR: 0.000978  \n",
      "Epoch: [2][800/2585] Elapsed 16m 31s (remain 36m 47s) Loss: 0.4587(0.4665) Grad: 0.2691 LR: 0.000978  \n",
      "Epoch: [2][900/2585] Elapsed 18m 34s (remain 34m 43s) Loss: 0.4673(0.4663) Grad: 0.1894 LR: 0.000978  \n",
      "Epoch: [2][1000/2585] Elapsed 20m 38s (remain 32m 39s) Loss: 0.4921(0.4662) Grad: 0.4577 LR: 0.000978  \n",
      "Epoch: [2][1100/2585] Elapsed 22m 41s (remain 30m 35s) Loss: 0.4669(0.4660) Grad: 0.2432 LR: 0.000978  \n",
      "Epoch: [2][1200/2585] Elapsed 24m 45s (remain 28m 31s) Loss: 0.4676(0.4657) Grad: 0.1712 LR: 0.000978  \n",
      "Epoch: [2][1300/2585] Elapsed 26m 48s (remain 26m 27s) Loss: 0.4775(0.4656) Grad: 0.3010 LR: 0.000978  \n",
      "Epoch: [2][1400/2585] Elapsed 28m 52s (remain 24m 23s) Loss: 0.4518(0.4655) Grad: 0.2629 LR: 0.000978  \n",
      "Epoch: [2][1500/2585] Elapsed 30m 55s (remain 22m 20s) Loss: 0.4652(0.4653) Grad: 0.2026 LR: 0.000978  \n",
      "Epoch: [2][1600/2585] Elapsed 32m 59s (remain 20m 16s) Loss: 0.4754(0.4651) Grad: 0.3245 LR: 0.000978  \n",
      "Epoch: [2][1700/2585] Elapsed 35m 2s (remain 18m 12s) Loss: 0.4625(0.4650) Grad: 0.1937 LR: 0.000978  \n",
      "Epoch: [2][1800/2585] Elapsed 37m 6s (remain 16m 9s) Loss: 0.4583(0.4650) Grad: 0.3382 LR: 0.000978  \n",
      "Epoch: [2][1900/2585] Elapsed 39m 9s (remain 14m 5s) Loss: 0.4536(0.4647) Grad: 0.3124 LR: 0.000978  \n",
      "Epoch: [2][2000/2585] Elapsed 41m 13s (remain 12m 1s) Loss: 0.4468(0.4646) Grad: 0.2505 LR: 0.000978  \n",
      "Epoch: [2][2100/2585] Elapsed 43m 16s (remain 9m 58s) Loss: 0.4578(0.4645) Grad: 0.1706 LR: 0.000978  \n",
      "Epoch: [2][2200/2585] Elapsed 45m 20s (remain 7m 54s) Loss: 0.4545(0.4644) Grad: 0.2768 LR: 0.000978  \n",
      "Epoch: [2][2300/2585] Elapsed 47m 23s (remain 5m 50s) Loss: 0.4533(0.4643) Grad: 0.2993 LR: 0.000978  \n",
      "Epoch: [2][2400/2585] Elapsed 49m 27s (remain 3m 47s) Loss: 0.4685(0.4643) Grad: 0.1903 LR: 0.000978  \n",
      "Epoch: [2][2500/2585] Elapsed 51m 30s (remain 1m 43s) Loss: 0.4600(0.4641) Grad: 0.2502 LR: 0.000978  \n",
      "Epoch: [2][2584/2585] Elapsed 53m 14s (remain 0m 0s) Loss: 0.4474(0.4640) Grad: 0.1873 LR: 0.000978  \n",
      "EVAL: [0/647] Elapsed 0m 1s (remain 16m 46s) Loss: 0.7538(0.7538) \n",
      "EVAL: [100/647] Elapsed 0m 37s (remain 3m 25s) Loss: 0.5301(0.5796) \n",
      "EVAL: [200/647] Elapsed 1m 14s (remain 2m 44s) Loss: 0.4625(0.5331) \n",
      "EVAL: [300/647] Elapsed 1m 50s (remain 2m 7s) Loss: 0.4451(0.5105) \n",
      "EVAL: [400/647] Elapsed 2m 27s (remain 1m 30s) Loss: 0.4501(0.4955) \n",
      "EVAL: [500/647] Elapsed 3m 3s (remain 0m 53s) Loss: 0.4228(0.4832) \n",
      "EVAL: [600/647] Elapsed 3m 39s (remain 0m 16s) Loss: 0.3616(0.4708) \n",
      "EVAL: [646/647] Elapsed 3m 56s (remain 0m 0s) Loss: 0.2386(0.4627) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4640  avg_val_loss: 0.4627  time: 3432s\n",
      "Epoch 2 - Accuracy: 0.7991167330921933\n",
      "Epoch 2 - Save Best Score: 0.7991 Model\n",
      "Epoch 2 - Save final model\n",
      "\u001b[32m[I 2021-05-18 12:38:48,972]\u001b[0m Trial 6 finished with value: 0.7991167330921933 and parameters: {'layers': 9, 'filters': 118}. Best is trial 1 with value: 0.8000682709039755.\u001b[0m\n",
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2585] Elapsed 0m 3s (remain 130m 40s) Loss: 1.3876(1.3876) Grad: 0.4272 LR: 0.001000  \n",
      "Epoch: [1][100/2585] Elapsed 2m 3s (remain 50m 26s) Loss: 0.5691(0.6718) Grad: 0.7916 LR: 0.001000  \n",
      "Epoch: [1][200/2585] Elapsed 4m 3s (remain 48m 3s) Loss: 0.5474(0.6162) Grad: 0.4461 LR: 0.001000  \n",
      "Epoch: [1][300/2585] Elapsed 6m 2s (remain 45m 54s) Loss: 0.5295(0.5890) Grad: 0.3367 LR: 0.001000  \n",
      "Epoch: [1][400/2585] Elapsed 8m 2s (remain 43m 49s) Loss: 0.5023(0.5711) Grad: 0.4730 LR: 0.001000  \n",
      "Epoch: [1][500/2585] Elapsed 10m 2s (remain 41m 46s) Loss: 0.5064(0.5588) Grad: 0.3641 LR: 0.001000  \n",
      "Epoch: [1][600/2585] Elapsed 12m 2s (remain 39m 44s) Loss: 0.4975(0.5495) Grad: 0.3514 LR: 0.001000  \n",
      "Epoch: [1][700/2585] Elapsed 14m 2s (remain 37m 43s) Loss: 0.4856(0.5425) Grad: 0.4844 LR: 0.001000  \n",
      "Epoch: [1][800/2585] Elapsed 16m 2s (remain 35m 42s) Loss: 0.4797(0.5366) Grad: 0.3621 LR: 0.001000  \n",
      "Epoch: [1][900/2585] Elapsed 18m 2s (remain 33m 42s) Loss: 0.5039(0.5318) Grad: 0.3740 LR: 0.001000  \n",
      "Epoch: [1][1000/2585] Elapsed 20m 1s (remain 31m 42s) Loss: 0.4931(0.5277) Grad: 0.5086 LR: 0.001000  \n",
      "Epoch: [1][1100/2585] Elapsed 22m 1s (remain 29m 41s) Loss: 0.4702(0.5242) Grad: 0.2701 LR: 0.001000  \n",
      "Epoch: [1][1200/2585] Elapsed 24m 1s (remain 27m 41s) Loss: 0.4824(0.5210) Grad: 0.3325 LR: 0.001000  \n",
      "Epoch: [1][1300/2585] Elapsed 26m 1s (remain 25m 41s) Loss: 0.4804(0.5183) Grad: 0.3235 LR: 0.001000  \n",
      "Epoch: [1][1400/2585] Elapsed 28m 1s (remain 23m 40s) Loss: 0.4943(0.5157) Grad: 0.4325 LR: 0.001000  \n",
      "Epoch: [1][1500/2585] Elapsed 30m 1s (remain 21m 40s) Loss: 0.4876(0.5134) Grad: 0.3381 LR: 0.001000  \n",
      "Epoch: [1][1600/2585] Elapsed 32m 0s (remain 19m 40s) Loss: 0.4927(0.5114) Grad: 0.3098 LR: 0.001000  \n",
      "Epoch: [1][1700/2585] Elapsed 34m 0s (remain 17m 40s) Loss: 0.4803(0.5096) Grad: 0.2217 LR: 0.001000  \n",
      "Epoch: [1][1800/2585] Elapsed 36m 0s (remain 15m 40s) Loss: 0.4717(0.5077) Grad: 0.2681 LR: 0.001000  \n",
      "Epoch: [1][1900/2585] Elapsed 38m 0s (remain 13m 40s) Loss: 0.4613(0.5062) Grad: 0.2449 LR: 0.001000  \n",
      "Epoch: [1][2000/2585] Elapsed 40m 0s (remain 11m 40s) Loss: 0.4780(0.5046) Grad: 0.2923 LR: 0.001000  \n",
      "Epoch: [1][2100/2585] Elapsed 42m 0s (remain 9m 40s) Loss: 0.4735(0.5031) Grad: 0.4032 LR: 0.001000  \n",
      "Epoch: [1][2200/2585] Elapsed 44m 0s (remain 7m 40s) Loss: 0.4645(0.5018) Grad: 0.2316 LR: 0.001000  \n",
      "Epoch: [1][2300/2585] Elapsed 45m 59s (remain 5m 40s) Loss: 0.4765(0.5006) Grad: 0.2107 LR: 0.001000  \n",
      "Epoch: [1][2400/2585] Elapsed 47m 59s (remain 3m 40s) Loss: 0.4748(0.4996) Grad: 0.3692 LR: 0.001000  \n",
      "Epoch: [1][2500/2585] Elapsed 49m 59s (remain 1m 40s) Loss: 0.4753(0.4985) Grad: 0.2273 LR: 0.001000  \n",
      "Epoch: [1][2584/2585] Elapsed 51m 40s (remain 0m 0s) Loss: 0.4718(0.4976) Grad: 0.1923 LR: 0.001000  \n",
      "EVAL: [0/647] Elapsed 0m 1s (remain 14m 31s) Loss: 0.7470(0.7470) \n",
      "EVAL: [100/647] Elapsed 0m 36s (remain 3m 18s) Loss: 0.5424(0.5857) \n",
      "EVAL: [200/647] Elapsed 1m 11s (remain 2m 39s) Loss: 0.4672(0.5401) \n",
      "EVAL: [300/647] Elapsed 1m 47s (remain 2m 3s) Loss: 0.4543(0.5186) \n",
      "EVAL: [400/647] Elapsed 2m 22s (remain 1m 27s) Loss: 0.4513(0.5043) \n",
      "EVAL: [500/647] Elapsed 2m 57s (remain 0m 51s) Loss: 0.4404(0.4923) \n",
      "EVAL: [600/647] Elapsed 3m 33s (remain 0m 16s) Loss: 0.3739(0.4801) \n",
      "EVAL: [646/647] Elapsed 3m 49s (remain 0m 0s) Loss: 0.2361(0.4720) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4976  avg_val_loss: 0.4720  time: 3331s\n",
      "Epoch 1 - Accuracy: 0.794675739798891\n",
      "Epoch 1 - Save Best Score: 0.7947 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2585] Elapsed 0m 3s (remain 132m 3s) Loss: 0.4579(0.4579) Grad: 0.2485 LR: 0.000978  \n",
      "Epoch: [2][100/2585] Elapsed 2m 2s (remain 50m 22s) Loss: 0.4648(0.4668) Grad: 0.2665 LR: 0.000978  \n",
      "Epoch: [2][200/2585] Elapsed 4m 2s (remain 47m 57s) Loss: 0.4636(0.4678) Grad: 0.3235 LR: 0.000978  \n",
      "Epoch: [2][300/2585] Elapsed 6m 2s (remain 45m 48s) Loss: 0.4697(0.4671) Grad: 0.2186 LR: 0.000978  \n",
      "Epoch: [2][400/2585] Elapsed 8m 1s (remain 43m 44s) Loss: 0.4465(0.4669) Grad: 0.3244 LR: 0.000978  \n",
      "Epoch: [2][500/2585] Elapsed 10m 1s (remain 41m 43s) Loss: 0.4672(0.4668) Grad: 0.2889 LR: 0.000978  \n",
      "Epoch: [2][600/2585] Elapsed 12m 1s (remain 39m 42s) Loss: 0.4760(0.4666) Grad: 0.1788 LR: 0.000978  \n",
      "Epoch: [2][700/2585] Elapsed 14m 1s (remain 37m 41s) Loss: 0.4650(0.4665) Grad: 0.2449 LR: 0.000978  \n",
      "Epoch: [2][800/2585] Elapsed 16m 1s (remain 35m 40s) Loss: 0.4556(0.4664) Grad: 0.2650 LR: 0.000978  \n",
      "Epoch: [2][900/2585] Elapsed 18m 0s (remain 33m 40s) Loss: 0.4546(0.4663) Grad: 0.2111 LR: 0.000978  \n",
      "Epoch: [2][1000/2585] Elapsed 20m 0s (remain 31m 39s) Loss: 0.4425(0.4661) Grad: 0.2874 LR: 0.000978  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "human-arena",
    "papermill": {
     "duration": 0.209774,
     "end_time": "2021-05-12T03:50:00.096860",
     "exception": false,
     "start_time": "2021-05-12T03:49:59.887086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "hungry-geese-train-by-episode.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2945.71762,
   "end_time": "2021-05-12T03:50:02.012348",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-12T03:00:56.294728",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04a486aa6f454d8f92e388dba1b9ee21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0857c0fa22b544488d65bb2c7dad18ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f905db5005be40b194ea150c8b0deb9f",
      "max": 1001,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "value": 1001
     }
    },
    "4134662bdbe04a918d9809632e268ef8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0857c0fa22b544488d65bb2c7dad18ee",
       "IPY_MODEL_e33e4f894b424988b316c468bc9225ce"
      ],
      "layout": "IPY_MODEL_8ddb49ac3c91409f99a569a061a70b3d"
     }
    },
    "507d2b6a02bb43d0bb4c8c2734f19cbb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ddb49ac3c91409f99a569a061a70b3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c96b7bfbdf0243a8ae1dbb3d9aedf123": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e33e4f894b424988b316c468bc9225ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_507d2b6a02bb43d0bb4c8c2734f19cbb",
      "placeholder": "​",
      "style": "IPY_MODEL_04a486aa6f454d8f92e388dba1b9ee21",
      "value": " 1001/1001 [03:35&lt;00:00,  4.64it/s]"
     }
    },
    "f905db5005be40b194ea150c8b0deb9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

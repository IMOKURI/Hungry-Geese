{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abroad-piece",
    "papermill": {
     "duration": 0.025714,
     "end_time": "2021-05-12T03:01:02.640708",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.614994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About this notebook ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pressing-commercial",
    "papermill": {
     "duration": 0.024272,
     "end_time": "2021-05-12T03:01:02.689850",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.665578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "german-ethics",
    "papermill": {
     "duration": 1.852306,
     "end_time": "2021-05-12T03:01:04.566362",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.714056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "apparent-fiction",
    "papermill": {
     "duration": 0.030961,
     "end_time": "2021-05-12T03:01:04.622818",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.591857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robust-humanity",
    "papermill": {
     "duration": 0.024539,
     "end_time": "2021-05-12T03:01:04.672270",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.647731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "designed-effect",
    "papermill": {
     "duration": 0.031167,
     "end_time": "2021-05-12T03:01:04.728079",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.696912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"../input/hungrygeeseepisode/hungry-geese-episode/\"\n",
    "OUTPUT_DIR = \"pre-models/\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "special-broadcast",
    "outputId": "c440e1e9-5651-42ee-eb0f-08c822d7471a",
    "papermill": {
     "duration": 0.31211,
     "end_time": "2021-05-12T03:01:05.064722",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.752612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6011\n"
     ]
    }
   ],
   "source": [
    "paths = [path for path in glob.glob(BASE_DIR + \"*.json\") if \"info\" not in path]\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "editorial-haiti",
    "papermill": {
     "duration": 0.024908,
     "end_time": "2021-05-12T03:01:05.115280",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.090372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "opened-python",
    "papermill": {
     "duration": 0.035637,
     "end_time": "2021-05-12T03:01:05.176119",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.140482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 440\n",
    "\n",
    "    n_class = 4\n",
    "    n_fold = 10\n",
    "\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "\n",
    "    num_workers = 4\n",
    "    batch_size = 3200\n",
    "\n",
    "    scheduler = \"CosineAnnealingWarmRestarts\"\n",
    "    # factor = 0.2  # ReduceLROnPlateau\n",
    "    # patience = 4  # ReduceLROnPlateau\n",
    "    # eps = 1e-6  # ReduceLROnPlateau\n",
    "    # T_max = 10  # CosineAnnealingLR\n",
    "    T_0 = 10  # CosineAnnealingWarmRestarts\n",
    "\n",
    "    criterion = \"CrossEntropyLoss\"\n",
    "    lr = 1e-3\n",
    "    min_lr = 1e-4\n",
    "    weight_decay = 0\n",
    "\n",
    "    epochs = 10\n",
    "    model_name = \"geese_net\"\n",
    "\n",
    "    print_freq = 100\n",
    "\n",
    "    train = True\n",
    "    debug = False\n",
    "    apex = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "contained-singles",
    "papermill": {
     "duration": 0.031266,
     "end_time": "2021-05-12T03:01:05.235456",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.204190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    Config.epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dietary-track",
    "papermill": {
     "duration": 0.031421,
     "end_time": "2021-05-12T03:01:05.292382",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.260961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.apex:\n",
    "    from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "invalid-dispute",
    "papermill": {
     "duration": 0.169531,
     "end_time": "2021-05-12T03:01:05.488665",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.319134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "treated-serum",
    "papermill": {
     "duration": 0.025219,
     "end_time": "2021-05-12T03:01:05.539482",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.514263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gothic-alloy",
    "papermill": {
     "duration": 0.070842,
     "end_time": "2021-05-12T03:01:05.642364",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.571522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=Config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "experienced-correspondence",
    "papermill": {
     "duration": 0.053842,
     "end_time": "2021-05-12T03:01:05.741858",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.688016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reverse_ns(y):\n",
    "    if y == 0:\n",
    "        return 1\n",
    "    if y == 1:\n",
    "        return 0\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_we(y):\n",
    "    if y == 2:\n",
    "        return 3\n",
    "    if y == 3:\n",
    "        return 2\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_nswe(y):\n",
    "    return reverse_ns(reverse_we(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "further-transaction",
    "papermill": {
     "duration": 0.042365,
     "end_time": "2021-05-12T03:01:05.826807",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.784442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "naughty-clause",
    "papermill": {
     "duration": 0.058537,
     "end_time": "2021-05-12T03:01:05.928292",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.869755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_input(obses):\n",
    "    b = np.zeros((17, 7 * 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "        pid = (p - obs[\"index\"]) % 4\n",
    "\n",
    "        # head position\n",
    "        for pos in pos_list[:1]:\n",
    "            b[0 + pid, pos] = 1\n",
    "        # tip position\n",
    "        for pos in pos_list[-1:]:\n",
    "            b[4 + pid, pos] = 1\n",
    "        # whole position\n",
    "        for pos in pos_list:\n",
    "            b[8 + pid, pos] = 1\n",
    "\n",
    "    # previous head position\n",
    "    if len(obses) > 1:\n",
    "        obs_prev = obses[-2]\n",
    "        for p, pos_list in enumerate(obs_prev[\"geese\"]):\n",
    "            for pos in pos_list[:1]:\n",
    "                b[12 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    # food\n",
    "    for pos in obs[\"food\"]:\n",
    "        b[16, pos] = 1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "i6lOS7itC0da"
   },
   "outputs": [],
   "source": [
    "def observation_num_step(obses):\n",
    "    b = np.zeros((7, 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    num_step = obs[\"step\"]  # 0-198\n",
    "    b[0, 0] = num_step / 198\n",
    "\n",
    "    return b.reshape(1, 7, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pretty-aaron",
    "papermill": {
     "duration": 0.042985,
     "end_time": "2021-05-12T03:01:06.014038",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.971053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "international-secret",
    "papermill": {
     "duration": 0.064855,
     "end_time": "2021-05-12T03:01:06.121648",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.056793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset_from_json(filepath, json_object=None, standing=0):\n",
    "    if json_object is None:\n",
    "        json_open = open(path, \"r\")\n",
    "        json_load = json.load(json_open)\n",
    "    else:\n",
    "        json_load = json_object\n",
    "\n",
    "    try:\n",
    "        winner_index = np.argmax(np.argsort(json_load[\"rewards\"]) == 3 - standing)\n",
    "\n",
    "        obses = []\n",
    "        X = []\n",
    "        y = []\n",
    "        actions = {\"NORTH\": 0, \"SOUTH\": 1, \"WEST\": 2, \"EAST\": 3}\n",
    "\n",
    "        for i in range(len(json_load[\"steps\"]) - 1):\n",
    "            if json_load[\"steps\"][i][winner_index][\"status\"] == \"ACTIVE\":\n",
    "                y_ = json_load[\"steps\"][i + 1][winner_index][\"action\"]\n",
    "                if y_ is not None:\n",
    "                    step = json_load[\"steps\"][i]\n",
    "                    step[winner_index][\"observation\"][\"geese\"] = step[0][\"observation\"][\"geese\"]\n",
    "                    step[winner_index][\"observation\"][\"food\"] = step[0][\"observation\"][\"food\"]\n",
    "                    step[winner_index][\"observation\"][\"step\"] = step[0][\"observation\"][\"step\"]\n",
    "                    obses.append(step[winner_index][\"observation\"])\n",
    "                    y.append(actions[y_])\n",
    "\n",
    "                    y.append(reverse_ns(actions[y_]))  # 上下反転\n",
    "                    y.append(reverse_we(actions[y_]))  # 左右反転\n",
    "                    y.append(reverse_nswe(actions[y_]))  # 上下左右反転\n",
    "\n",
    "        for j in range(len(obses)):\n",
    "            # X_ = make_input(obses[: j + 1])\n",
    "\n",
    "            X_ = []\n",
    "            X_.append(make_input(obses[: j + 1]))\n",
    "            # X_.append(observation_num_step(obses[: j + 1]))\n",
    "            X_ = np.concatenate(X_)\n",
    "\n",
    "            X.append(X_)\n",
    "\n",
    "            X.append(X_[:, ::-1, :])  # 上下反転\n",
    "            X.append(X_[:, :, ::-1])  # 左右反転\n",
    "            X.append(X_[:, ::-1, ::-1])  # 上下左右反転\n",
    "\n",
    "        X = np.array(X, dtype=np.float32)  # [starting_step:]\n",
    "        y = np.array(y, dtype=np.uint8)  # [starting_step:]\n",
    "\n",
    "        return X, y\n",
    "    except:\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "4134662bdbe04a918d9809632e268ef8",
      "8ddb49ac3c91409f99a569a061a70b3d",
      "0857c0fa22b544488d65bb2c7dad18ee",
      "e33e4f894b424988b316c468bc9225ce",
      "c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "f905db5005be40b194ea150c8b0deb9f",
      "04a486aa6f454d8f92e388dba1b9ee21",
      "507d2b6a02bb43d0bb4c8c2734f19cbb"
     ]
    },
    "id": "handled-pleasure",
    "outputId": "955c1c6b-36bc-4b30-dc44-b72b05398f8c",
    "papermill": {
     "duration": 15.320591,
     "end_time": "2021-05-12T03:01:21.474816",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.154225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b139f5dfd94ae5835be57250775af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6011.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num episode: 3800040\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for path in tqdm(paths[: int(len(paths))]):\n",
    "    X, y = create_dataset_from_json(path, standing=0)  # use only winners' moves\n",
    "    if X is not 0:\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "persistent-loading",
    "papermill": {
     "duration": 112.92618,
     "end_time": "2021-05-12T03:03:14.428162",
     "exception": false,
     "start_time": "2021-05-12T03:01:21.501982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: データをuniqueにしたいがメモリエラーになってしまう。\n",
    "\n",
    "# X_train, unique_index = np.unique(X_train, axis=0, return_index=True)  # remove duplicate\n",
    "# y_train = y_train[unique_index]\n",
    "\n",
    "# y_train = np.eye(4, dtype=\"uint8\")[y_train]  # to categorical\n",
    "\n",
    "# print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# まとめてuniqueかけるとメモリ量が足りないので、いくつかのグループに分けてuniqueにする\n",
    "\n",
    "X_train_sum_obs = X_train.reshape(X_train.shape[0], -1).sum(1)\n",
    "X_train_group = np.unique(X_train_sum_obs)\n",
    "X_train_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e617e0889b6d47f691889a5ffd74f873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=75.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num episode: 3799476\n"
     ]
    }
   ],
   "source": [
    "X_train_unique = []\n",
    "y_train_unique = []\n",
    "for group in tqdm(X_train_group):\n",
    "    group_index = np.where(X_train_sum_obs == group)\n",
    "\n",
    "    X_train_ = X_train[group_index]\n",
    "    y_train_ = y_train[group_index]\n",
    "\n",
    "    X_train_, unique_index = np.unique(X_train_, axis=0, return_index=True)  # remove duplicate\n",
    "    y_train_ = y_train_[unique_index]\n",
    "\n",
    "    X_train_unique.append(X_train_)\n",
    "    y_train_unique.append(y_train_)\n",
    "\n",
    "X_train = np.concatenate(X_train_unique)\n",
    "y_train = np.concatenate(y_train_unique)\n",
    "\n",
    "print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "micro-french",
    "papermill": {
     "duration": 0.033413,
     "end_time": "2021-05-12T03:03:15.360395",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.326982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    X_train = X_train[:1000]\n",
    "    y_train = y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "wrong-pastor",
    "outputId": "406a2f1d-0b8a-46bf-ca01-546f3110c301",
    "papermill": {
     "duration": 0.036161,
     "end_time": "2021-05-12T03:03:15.425149",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.388988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799471</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799472</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799473</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799474</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799475</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3799476 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         action\n",
       "0             2\n",
       "1             0\n",
       "2             2\n",
       "3             3\n",
       "4             2\n",
       "...         ...\n",
       "3799471       1\n",
       "3799472       2\n",
       "3799473       3\n",
       "3799474       2\n",
       "3799475       3\n",
       "\n",
       "[3799476 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(y_train)\n",
    "y_df.columns = [\"action\"]\n",
    "y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "touched-coordinate",
    "papermill": {
     "duration": 0.027968,
     "end_time": "2021-05-12T03:03:15.557122",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.529154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "moving-skill",
    "outputId": "7542c4b4-f7d3-444c-8450-50bffddb1892",
    "papermill": {
     "duration": 0.202337,
     "end_time": "2021-05-12T03:03:15.787529",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.585192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  action\n",
      "0     0         90530\n",
      "      1         90531\n",
      "      2         99444\n",
      "      3         99443\n",
      "1     0         90530\n",
      "      1         90531\n",
      "      2         99444\n",
      "      3         99443\n",
      "2     0         90531\n",
      "      1         90531\n",
      "      2         99443\n",
      "      3         99443\n",
      "3     0         90531\n",
      "      1         90531\n",
      "      2         99443\n",
      "      3         99443\n",
      "4     0         90531\n",
      "      1         90531\n",
      "      2         99443\n",
      "      3         99443\n",
      "5     0         90531\n",
      "      1         90531\n",
      "      2         99443\n",
      "      3         99443\n",
      "6     0         90531\n",
      "      1         90530\n",
      "      2         99443\n",
      "      3         99443\n",
      "7     0         90531\n",
      "      1         90530\n",
      "      2         99443\n",
      "      3         99443\n",
      "8     0         90530\n",
      "      1         90530\n",
      "      2         99443\n",
      "      3         99444\n",
      "9     0         90530\n",
      "      1         90530\n",
      "      2         99443\n",
      "      3         99444\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "folds = y_df.copy()\n",
    "Fold = StratifiedKFold(n_splits=Config.n_fold, shuffle=True, random_state=Config.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[\"action\"])):\n",
    "    folds.loc[val_index, \"fold\"] = int(n)\n",
    "folds[\"fold\"] = folds[\"fold\"].astype(int)\n",
    "print(folds.groupby([\"fold\", \"action\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "creative-football",
    "papermill": {
     "duration": 0.029031,
     "end_time": "2021-05-12T03:03:15.845114",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.816083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "other-murder",
    "papermill": {
     "duration": 0.037264,
     "end_time": "2021-05-12T03:03:15.911219",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.873955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, array, label):\n",
    "        self.array = array\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx], torch.tensor(self.label[idx]).long()\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, array):\n",
    "        self.array = array\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adjusted-delhi",
    "outputId": "39504950-84bc-4692-8b90-8a5b64f741e0",
    "papermill": {
     "duration": 0.063691,
     "end_time": "2021-05-12T03:03:16.003693",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.940002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 7, 11) tensor(2)\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "train_ds = TrainDataset(X_train, y_train)\n",
    "\n",
    "for i in range(1):\n",
    "    obs, action = train_ds[i]\n",
    "    print(obs.shape, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceramic-startup",
    "papermill": {
     "duration": 0.02876,
     "end_time": "2021-05-12T03:03:16.061575",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.032815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "unique-trick",
    "papermill": {
     "duration": 0.039055,
     "end_time": "2021-05-12T03:03:16.130239",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.091184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TorusConv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
    "        super().__init__()\n",
    "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([x[:, :, :, -self.edge_size[1] :], x, x[:, :, :, : self.edge_size[1]]], dim=3)\n",
    "        h = torch.cat([h[:, :, -self.edge_size[0] :], h, h[:, :, : self.edge_size[0]]], dim=2)\n",
    "        h = self.conv(h)\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "extra-bradford",
    "papermill": {
     "duration": 0.042421,
     "end_time": "2021-05-12T03:03:16.202024",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.159603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GeeseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers, filters = 12, 32\n",
    "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p = nn.Linear(filters, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(filters * 2, filters, bias=False)\n",
    "        self.head_v2 = nn.Linear(filters, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h_p = F.relu_(self.conv_p(h))\n",
    "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        p = self.head_p(h_head_p)\n",
    "\n",
    "        h_v = F.relu_(self.conv_v(h))\n",
    "        h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_avg_v = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
    "\n",
    "        h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_avg_v], 1)))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p, \"value\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "jspEE71c2Yma"
   },
   "outputs": [],
   "source": [
    "class GeeseNetAlpha(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers, filters = 12, 64\n",
    "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        # self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p1 = nn.Linear(filters * 7 + 77, filters * 4, bias=False)\n",
    "        self.head_p2 = nn.Linear(filters * 4, 4, bias=False)\n",
    "        # self.head_v1 = nn.Linear(filters * 2, filters, bias=False)\n",
    "        # self.head_v2 = nn.Linear(filters, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h_p = F.relu_(self.conv_p(h))\n",
    "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p2 = (h_p * x[:, 1:2]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p3 = (h_p * x[:, 2:3]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_head_p4 = (h_p * x[:, 3:4]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_avg_p1 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(-1)\n",
    "        h_avg_p2 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(1)\n",
    "        \n",
    "        food_index = torch.where(x[:, 16] == 1)\n",
    "        h_food = h_p[food_index[0], :, food_index[1], food_index[2]].view(h_p.size(0), -1)\n",
    "\n",
    "        h_p = F.relu_(self.head_p1(torch.cat([h_head_p, h_head_p2, h_head_p3, h_head_p4, h_food, h_avg_p1, h_avg_p2], 1)))\n",
    "        p = self.head_p2(h_p)\n",
    "\n",
    "        # h_v = F.relu_(self.conv_v(h))\n",
    "        # h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        # h_avg_v = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
    "\n",
    "        # h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_avg_v], 1)))\n",
    "        # v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p}  # \"value\": v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "objective-victoria",
    "outputId": "1ab137a5-e26e-4b9c-ff85-95fef713b755",
    "papermill": {
     "duration": 4.955868,
     "end_time": "2021-05-12T03:03:21.187355",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.231487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: 627,136\n",
      "{'policy': tensor([[-0.0653,  0.1081, -0.0956, -0.0748],\n",
      "        [-0.0650,  0.1073, -0.0054, -0.0658],\n",
      "        [ 0.0768,  0.2302, -0.0417, -0.0833],\n",
      "        [-0.0347,  0.1204,  0.0647,  0.0948]], grad_fn=<MmBackward>)}\n",
      "tensor([1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "model = GeeseNetAlpha()\n",
    "# print(model)\n",
    "\n",
    "params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"params: {params:,}\")\n",
    "\n",
    "train_ds = TrainDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "for obs, action in train_loader:\n",
    "    output = model(obs)\n",
    "    print(output)\n",
    "    print(f\"{torch.argmax(output['policy'], dim=1)}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "military-fiction",
    "papermill": {
     "duration": 0.033001,
     "end_time": "2021-05-12T03:03:21.255277",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.222276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sophisticated-hearts",
    "papermill": {
     "duration": 0.031759,
     "end_time": "2021-05-12T03:03:21.319849",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.288090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "designing-detective",
    "papermill": {
     "duration": 0.03139,
     "end_time": "2021-05-12T03:03:21.383038",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.351648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "passive-cooper",
    "papermill": {
     "duration": 0.038846,
     "end_time": "2021-05-12T03:03:21.454085",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.415239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thirty-tracy",
    "papermill": {
     "duration": 0.0293,
     "end_time": "2021-05-12T03:03:21.514179",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.484879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "introductory-brooklyn",
    "papermill": {
     "duration": 0.039424,
     "end_time": "2021-05-12T03:03:21.582969",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.543545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "raising-laugh",
    "papermill": {
     "duration": 0.042063,
     "end_time": "2021-05-12T03:03:21.654559",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.612496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "\n",
    "    for step, (obs, action) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        y_preds = model(obs.float())[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "\n",
    "        # record loss\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "        if Config.apex:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), Config.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % Config.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print(\n",
    "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
    "                f\"Loss: {losses.val:.4f}({losses.avg:.4f}) \"\n",
    "                f\"Grad: {grad_norm:.4f} \"\n",
    "                f\"LR: {scheduler.get_last_lr()[0]:.6f}  \"\n",
    "            )\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "plain-neighbor",
    "papermill": {
     "duration": 0.041056,
     "end_time": "2021-05-12T03:03:21.726585",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.685529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "\n",
    "    for step, (obs, action) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(obs)[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print(\n",
    "                f\"EVAL: [{step}/{len(valid_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
    "                f\"Loss: {losses.val:.4f}({losses.avg:.4f}) \"\n",
    "            )\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "integrated-classification",
    "papermill": {
     "duration": 0.029832,
     "end_time": "2021-05-12T03:03:21.786427",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.756595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "harmful-explanation",
    "papermill": {
     "duration": 0.05136,
     "end_time": "2021-05-12T03:03:21.868561",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.817201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(folds, fold):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    X_train_folds = X_train[folds[\"fold\"] != fold]\n",
    "    X_valid_folds = X_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    y_train_folds = y_train[folds[\"fold\"] != fold]\n",
    "    y_valid_folds = y_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    y_df_train_folds = y_df[folds[\"fold\"] != fold]\n",
    "    y_df_valid_folds = y_df[folds[\"fold\"] == fold]\n",
    "\n",
    "    train_dataset = TrainDataset(X_train_folds, y_train_folds)\n",
    "    valid_dataset = TrainDataset(X_valid_folds, y_valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if Config.scheduler == \"ReduceLROnPlateau\":\n",
    "            scheduler = ReduceLROnPlateau(\n",
    "                optimizer, mode=\"min\", factor=Config.factor, patience=Config.patience, verbose=True, eps=Config.eps\n",
    "            )\n",
    "        elif Config.scheduler == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=Config.T_max, eta_min=Config.min_lr, last_epoch=-1)\n",
    "        elif Config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "            scheduler = CosineAnnealingWarmRestarts(\n",
    "                optimizer, T_0=Config.T_0, T_mult=1, eta_min=Config.min_lr, last_epoch=-1\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = GeeseNetAlpha()\n",
    "    model.to(device)\n",
    "\n",
    "    # Use multi GPU\n",
    "    if device == torch.device(\"cuda\") and not Config.apex:\n",
    "        model = torch.nn.DataParallel(model)  # make parallel\n",
    "        # torch.backends.cudnn.benchmark=True\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=Config.lr, weight_decay=Config.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # apex\n",
    "    # ====================================================\n",
    "    if Config.apex:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
    "\n",
    "    # ====================================================\n",
    "    # Criterion\n",
    "    # ====================================================\n",
    "    def get_criterion():\n",
    "        if Config.criterion == \"CrossEntropyLoss\":\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        return criterion\n",
    "\n",
    "    criterion = get_criterion()\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    best_score = 0.0\n",
    "    best_loss = np.inf\n",
    "    best_preds = None\n",
    "\n",
    "    for epoch in range(Config.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "\n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(y_valid_folds, preds.argmax(1))\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Accuracy: {score}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_best.pth\")\n",
    "            best_preds = preds\n",
    "\n",
    "        if epoch == Config.epochs - 1:\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save final model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_final.pth\")\n",
    "\n",
    "    y_df_valid_folds[[str(c) for c in range(Config.n_class)]] = best_preds\n",
    "    y_df_valid_folds[\"preds\"] = best_preds.argmax(1)\n",
    "\n",
    "    return y_df_valid_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "complimentary-wright",
    "papermill": {
     "duration": 0.030218,
     "end_time": "2021-05-12T03:03:21.928896",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.898678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "particular-adaptation",
    "papermill": {
     "duration": 0.04089,
     "end_time": "2021-05-12T03:03:22.000150",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.959260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    def get_result(result_df):\n",
    "        preds = result_df[\"preds\"].values\n",
    "        labels = result_df[\"action\"].values\n",
    "        score = get_score(labels, preds)\n",
    "        LOGGER.info(f\"Score: {score:<.5f}\")\n",
    "\n",
    "    if Config.train:\n",
    "        # train\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(Config.n_fold):\n",
    "            _oof_df = train_loop(folds, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df)\n",
    "            break  # fold 1つだけ実行する\n",
    "        # CV result\n",
    "        # LOGGER.info(f\"========== CV ==========\")\n",
    "        # get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "backed-journal",
    "outputId": "c9f0ff3d-795e-466b-e22e-9ba21d08c874",
    "papermill": {
     "duration": 2797.64711,
     "end_time": "2021-05-12T03:49:59.678400",
     "exception": false,
     "start_time": "2021-05-12T03:03:22.031290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/1068] Elapsed 0m 3s (remain 62m 1s) Loss: 1.3899(1.3899) Grad: 0.4199 LR: 0.001000  \n",
      "Epoch: [1][100/1068] Elapsed 1m 13s (remain 11m 41s) Loss: 0.5903(0.7045) Grad: 0.9669 LR: 0.001000  \n",
      "Epoch: [1][200/1068] Elapsed 2m 23s (remain 10m 17s) Loss: 0.5483(0.6393) Grad: 0.6481 LR: 0.001000  \n",
      "Epoch: [1][300/1068] Elapsed 3m 33s (remain 9m 2s) Loss: 0.5332(0.6070) Grad: 0.5839 LR: 0.001000  \n",
      "Epoch: [1][400/1068] Elapsed 4m 42s (remain 7m 50s) Loss: 0.5134(0.5873) Grad: 0.5861 LR: 0.001000  \n",
      "Epoch: [1][500/1068] Elapsed 5m 52s (remain 6m 39s) Loss: 0.4998(0.5728) Grad: 0.5943 LR: 0.001000  \n",
      "Epoch: [1][600/1068] Elapsed 7m 2s (remain 5m 28s) Loss: 0.5133(0.5626) Grad: 0.4512 LR: 0.001000  \n",
      "Epoch: [1][700/1068] Elapsed 8m 12s (remain 4m 17s) Loss: 0.5134(0.5543) Grad: 0.4478 LR: 0.001000  \n",
      "Epoch: [1][800/1068] Elapsed 9m 22s (remain 3m 7s) Loss: 0.5000(0.5476) Grad: 0.3119 LR: 0.001000  \n",
      "Epoch: [1][900/1068] Elapsed 10m 32s (remain 1m 57s) Loss: 0.5037(0.5419) Grad: 0.6239 LR: 0.001000  \n",
      "Epoch: [1][1000/1068] Elapsed 11m 42s (remain 0m 47s) Loss: 0.4972(0.5373) Grad: 0.3678 LR: 0.001000  \n",
      "Epoch: [1][1067/1068] Elapsed 12m 29s (remain 0m 0s) Loss: 0.5107(0.5346) Grad: 0.3655 LR: 0.001000  \n",
      "EVAL: [0/119] Elapsed 0m 0s (remain 1m 16s) Loss: 0.7757(0.7757) \n",
      "EVAL: [100/119] Elapsed 0m 19s (remain 0m 3s) Loss: 0.4442(0.5093) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.5346  avg_val_loss: 0.4946  time: 772s\n",
      "Epoch 1 - Accuracy: 0.7821570320149073\n",
      "Epoch 1 - Save Best Score: 0.7822 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [118/119] Elapsed 0m 22s (remain 0m 0s) Loss: 0.3292(0.4946) \n",
      "Epoch: [2][0/1068] Elapsed 0m 1s (remain 26m 13s) Loss: 0.4790(0.4790) Grad: 0.4522 LR: 0.000978  \n",
      "Epoch: [2][100/1068] Elapsed 1m 11s (remain 11m 24s) Loss: 0.4745(0.4871) Grad: 0.3775 LR: 0.000978  \n",
      "Epoch: [2][200/1068] Elapsed 2m 21s (remain 10m 9s) Loss: 0.4998(0.4858) Grad: 0.3555 LR: 0.000978  \n",
      "Epoch: [2][300/1068] Elapsed 3m 31s (remain 8m 58s) Loss: 0.4964(0.4855) Grad: 0.3650 LR: 0.000978  \n",
      "Epoch: [2][400/1068] Elapsed 4m 41s (remain 7m 47s) Loss: 0.4815(0.4847) Grad: 0.3305 LR: 0.000978  \n",
      "Epoch: [2][500/1068] Elapsed 5m 50s (remain 6m 37s) Loss: 0.4776(0.4841) Grad: 0.3648 LR: 0.000978  \n",
      "Epoch: [2][600/1068] Elapsed 7m 0s (remain 5m 26s) Loss: 0.4789(0.4834) Grad: 0.3012 LR: 0.000978  \n",
      "Epoch: [2][700/1068] Elapsed 8m 10s (remain 4m 16s) Loss: 0.4800(0.4830) Grad: 0.3757 LR: 0.000978  \n",
      "Epoch: [2][800/1068] Elapsed 9m 20s (remain 3m 6s) Loss: 0.4668(0.4824) Grad: 0.5542 LR: 0.000978  \n",
      "Epoch: [2][900/1068] Elapsed 10m 30s (remain 1m 56s) Loss: 0.4996(0.4820) Grad: 0.3609 LR: 0.000978  \n",
      "Epoch: [2][1000/1068] Elapsed 11m 40s (remain 0m 46s) Loss: 0.4706(0.4814) Grad: 0.3205 LR: 0.000978  \n",
      "Epoch: [2][1067/1068] Elapsed 12m 27s (remain 0m 0s) Loss: 0.4862(0.4811) Grad: 0.4147 LR: 0.000978  \n",
      "EVAL: [0/119] Elapsed 0m 0s (remain 1m 18s) Loss: 0.7586(0.7586) \n",
      "EVAL: [100/119] Elapsed 0m 19s (remain 0m 3s) Loss: 0.4333(0.4965) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4811  avg_val_loss: 0.4817  time: 770s\n",
      "Epoch 2 - Accuracy: 0.7890842957457336\n",
      "Epoch 2 - Save Best Score: 0.7891 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [118/119] Elapsed 0m 22s (remain 0m 0s) Loss: 0.3167(0.4817) \n",
      "Epoch: [3][0/1068] Elapsed 0m 1s (remain 25m 13s) Loss: 0.4585(0.4585) Grad: 0.3845 LR: 0.000914  \n",
      "Epoch: [3][100/1068] Elapsed 1m 11s (remain 11m 22s) Loss: 0.4635(0.4704) Grad: 0.3222 LR: 0.000914  \n",
      "Epoch: [3][200/1068] Elapsed 2m 21s (remain 10m 9s) Loss: 0.4479(0.4709) Grad: 0.2664 LR: 0.000914  \n",
      "Epoch: [3][300/1068] Elapsed 3m 31s (remain 8m 57s) Loss: 0.4422(0.4703) Grad: 0.2663 LR: 0.000914  \n",
      "Epoch: [3][400/1068] Elapsed 4m 40s (remain 7m 47s) Loss: 0.4539(0.4706) Grad: 0.3164 LR: 0.000914  \n",
      "Epoch: [3][500/1068] Elapsed 5m 50s (remain 6m 37s) Loss: 0.4847(0.4702) Grad: 0.2980 LR: 0.000914  \n",
      "Epoch: [3][600/1068] Elapsed 7m 0s (remain 5m 26s) Loss: 0.4531(0.4696) Grad: 0.2990 LR: 0.000914  \n",
      "Epoch: [3][700/1068] Elapsed 8m 10s (remain 4m 16s) Loss: 0.4610(0.4694) Grad: 0.2636 LR: 0.000914  \n",
      "Epoch: [3][800/1068] Elapsed 9m 20s (remain 3m 6s) Loss: 0.4938(0.4694) Grad: 0.3120 LR: 0.000914  \n",
      "Epoch: [3][900/1068] Elapsed 10m 30s (remain 1m 56s) Loss: 0.4675(0.4692) Grad: 0.3086 LR: 0.000914  \n",
      "Epoch: [3][1000/1068] Elapsed 11m 40s (remain 0m 46s) Loss: 0.4810(0.4690) Grad: 0.3868 LR: 0.000914  \n",
      "Epoch: [3][1067/1068] Elapsed 12m 27s (remain 0m 0s) Loss: 0.4605(0.4688) Grad: 0.2379 LR: 0.000914  \n",
      "EVAL: [0/119] Elapsed 0m 0s (remain 1m 17s) Loss: 0.7529(0.7529) \n",
      "EVAL: [100/119] Elapsed 0m 19s (remain 0m 3s) Loss: 0.4280(0.4901) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.4688  avg_val_loss: 0.4752  time: 770s\n",
      "Epoch 3 - Accuracy: 0.791863623443208\n",
      "Epoch 3 - Save Best Score: 0.7919 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [118/119] Elapsed 0m 22s (remain 0m 0s) Loss: 0.3116(0.4752) \n",
      "Epoch: [4][0/1068] Elapsed 0m 1s (remain 25m 12s) Loss: 0.4510(0.4510) Grad: 0.3710 LR: 0.000815  \n",
      "Epoch: [4][100/1068] Elapsed 1m 11s (remain 11m 22s) Loss: 0.4581(0.4596) Grad: 0.2526 LR: 0.000815  \n",
      "Epoch: [4][200/1068] Elapsed 2m 21s (remain 10m 8s) Loss: 0.4509(0.4594) Grad: 0.3156 LR: 0.000815  \n",
      "Epoch: [4][300/1068] Elapsed 3m 30s (remain 8m 57s) Loss: 0.4412(0.4604) Grad: 0.3498 LR: 0.000815  \n",
      "Epoch: [4][400/1068] Elapsed 4m 40s (remain 7m 47s) Loss: 0.4831(0.4610) Grad: 0.3746 LR: 0.000815  \n",
      "Epoch: [4][500/1068] Elapsed 5m 50s (remain 6m 37s) Loss: 0.4651(0.4612) Grad: 0.3159 LR: 0.000815  \n",
      "Epoch: [4][600/1068] Elapsed 7m 0s (remain 5m 26s) Loss: 0.4888(0.4612) Grad: 0.2971 LR: 0.000815  \n",
      "Epoch: [4][700/1068] Elapsed 8m 10s (remain 4m 16s) Loss: 0.4387(0.4609) Grad: 0.2172 LR: 0.000815  \n",
      "Epoch: [4][800/1068] Elapsed 9m 20s (remain 3m 6s) Loss: 0.4429(0.4608) Grad: 0.1996 LR: 0.000815  \n",
      "Epoch: [4][900/1068] Elapsed 10m 30s (remain 1m 56s) Loss: 0.4490(0.4609) Grad: 0.2394 LR: 0.000815  \n",
      "Epoch: [4][1000/1068] Elapsed 11m 40s (remain 0m 46s) Loss: 0.4714(0.4608) Grad: 0.2218 LR: 0.000815  \n",
      "Epoch: [4][1067/1068] Elapsed 12m 27s (remain 0m 0s) Loss: 0.4359(0.4610) Grad: 0.2112 LR: 0.000815  \n",
      "EVAL: [0/119] Elapsed 0m 0s (remain 1m 19s) Loss: 0.7493(0.7493) \n",
      "EVAL: [100/119] Elapsed 0m 19s (remain 0m 3s) Loss: 0.4232(0.4848) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.4610  avg_val_loss: 0.4696  time: 770s\n",
      "Epoch 4 - Accuracy: 0.7952825123437944\n",
      "Epoch 4 - Save Best Score: 0.7953 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [118/119] Elapsed 0m 22s (remain 0m 0s) Loss: 0.3096(0.4696) \n",
      "Epoch: [5][0/1068] Elapsed 0m 1s (remain 25m 2s) Loss: 0.4556(0.4556) Grad: 0.2484 LR: 0.000689  \n",
      "Epoch: [5][100/1068] Elapsed 1m 11s (remain 11m 22s) Loss: 0.4658(0.4547) Grad: 0.2496 LR: 0.000689  \n",
      "Epoch: [5][200/1068] Elapsed 2m 21s (remain 10m 8s) Loss: 0.4439(0.4548) Grad: 0.3011 LR: 0.000689  \n",
      "Epoch: [5][300/1068] Elapsed 3m 31s (remain 8m 57s) Loss: 0.4633(0.4541) Grad: 0.3120 LR: 0.000689  \n",
      "Epoch: [5][400/1068] Elapsed 4m 41s (remain 7m 47s) Loss: 0.4638(0.4544) Grad: 0.3010 LR: 0.000689  \n",
      "Epoch: [5][500/1068] Elapsed 5m 50s (remain 6m 37s) Loss: 0.4475(0.4543) Grad: 0.2323 LR: 0.000689  \n",
      "Epoch: [5][600/1068] Elapsed 7m 0s (remain 5m 26s) Loss: 0.4543(0.4545) Grad: 0.2492 LR: 0.000689  \n",
      "Epoch: [5][700/1068] Elapsed 8m 10s (remain 4m 16s) Loss: 0.4442(0.4542) Grad: 0.3615 LR: 0.000689  \n",
      "Epoch: [5][800/1068] Elapsed 9m 20s (remain 3m 6s) Loss: 0.4449(0.4541) Grad: 0.2571 LR: 0.000689  \n",
      "Epoch: [5][900/1068] Elapsed 10m 30s (remain 1m 56s) Loss: 0.4508(0.4542) Grad: 0.2450 LR: 0.000689  \n",
      "Epoch: [5][1000/1068] Elapsed 11m 40s (remain 0m 46s) Loss: 0.4529(0.4544) Grad: 0.4663 LR: 0.000689  \n",
      "Epoch: [5][1067/1068] Elapsed 12m 27s (remain 0m 0s) Loss: 0.4661(0.4546) Grad: 0.2476 LR: 0.000689  \n",
      "EVAL: [0/119] Elapsed 0m 0s (remain 1m 17s) Loss: 0.7448(0.7448) \n",
      "EVAL: [100/119] Elapsed 0m 19s (remain 0m 3s) Loss: 0.4209(0.4843) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.4546  avg_val_loss: 0.4694  time: 770s\n",
      "Epoch 5 - Accuracy: 0.7946850621664017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [118/119] Elapsed 0m 22s (remain 0m 0s) Loss: 0.3080(0.4694) \n",
      "Epoch: [6][0/1068] Elapsed 0m 1s (remain 25m 10s) Loss: 0.4452(0.4452) Grad: 0.3053 LR: 0.000550  \n",
      "Epoch: [6][100/1068] Elapsed 1m 11s (remain 11m 22s) Loss: 0.4285(0.4456) Grad: 0.2735 LR: 0.000550  \n",
      "Epoch: [6][200/1068] Elapsed 2m 21s (remain 10m 8s) Loss: 0.4455(0.4474) Grad: 0.3530 LR: 0.000550  \n",
      "Epoch: [6][300/1068] Elapsed 3m 31s (remain 8m 57s) Loss: 0.4536(0.4474) Grad: 0.2201 LR: 0.000550  \n",
      "Epoch: [6][400/1068] Elapsed 4m 40s (remain 7m 47s) Loss: 0.4421(0.4476) Grad: 0.2630 LR: 0.000550  \n",
      "Epoch: [6][500/1068] Elapsed 5m 50s (remain 6m 36s) Loss: 0.4700(0.4478) Grad: 0.2753 LR: 0.000550  \n",
      "Epoch: [6][600/1068] Elapsed 7m 0s (remain 5m 26s) Loss: 0.4288(0.4479) Grad: 0.3126 LR: 0.000550  \n",
      "Epoch: [6][700/1068] Elapsed 8m 10s (remain 4m 16s) Loss: 0.4510(0.4478) Grad: 0.2621 LR: 0.000550  \n",
      "Epoch: [6][800/1068] Elapsed 9m 20s (remain 3m 6s) Loss: 0.4528(0.4479) Grad: 0.2582 LR: 0.000550  \n",
      "Epoch: [6][900/1068] Elapsed 10m 30s (remain 1m 56s) Loss: 0.4605(0.4481) Grad: 0.3423 LR: 0.000550  \n",
      "Epoch: [6][1000/1068] Elapsed 11m 40s (remain 0m 46s) Loss: 0.4550(0.4484) Grad: 0.2271 LR: 0.000550  \n",
      "Epoch: [6][1067/1068] Elapsed 12m 27s (remain 0m 0s) Loss: 0.4420(0.4485) Grad: 0.2293 LR: 0.000550  \n",
      "EVAL: [0/119] Elapsed 0m 0s (remain 1m 17s) Loss: 0.7444(0.7444) \n",
      "EVAL: [100/119] Elapsed 0m 19s (remain 0m 3s) Loss: 0.4142(0.4780) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.4485  avg_val_loss: 0.4631  time: 770s\n",
      "Epoch 6 - Accuracy: 0.7981065830060956\n",
      "Epoch 6 - Save Best Score: 0.7981 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [118/119] Elapsed 0m 22s (remain 0m 0s) Loss: 0.3091(0.4631) \n",
      "Epoch: [7][0/1068] Elapsed 0m 1s (remain 25m 16s) Loss: 0.4424(0.4424) Grad: 0.2055 LR: 0.000411  \n",
      "Epoch: [7][100/1068] Elapsed 1m 11s (remain 11m 23s) Loss: 0.4267(0.4406) Grad: 0.2449 LR: 0.000411  \n",
      "Epoch: [7][200/1068] Elapsed 2m 21s (remain 10m 10s) Loss: 0.4502(0.4401) Grad: 0.2229 LR: 0.000411  \n",
      "Epoch: [7][300/1068] Elapsed 3m 31s (remain 8m 58s) Loss: 0.4522(0.4413) Grad: 0.3149 LR: 0.000411  \n",
      "Epoch: [7][400/1068] Elapsed 4m 41s (remain 7m 47s) Loss: 0.4407(0.4416) Grad: 0.2963 LR: 0.000411  \n",
      "Epoch: [7][500/1068] Elapsed 5m 51s (remain 6m 37s) Loss: 0.4317(0.4422) Grad: 0.2416 LR: 0.000411  \n",
      "Epoch: [7][600/1068] Elapsed 7m 1s (remain 5m 27s) Loss: 0.4447(0.4425) Grad: 0.2793 LR: 0.000411  \n",
      "Epoch: [7][700/1068] Elapsed 8m 11s (remain 4m 17s) Loss: 0.4406(0.4424) Grad: 0.2950 LR: 0.000411  \n",
      "Epoch: [7][800/1068] Elapsed 9m 20s (remain 3m 6s) Loss: 0.4249(0.4426) Grad: 0.4436 LR: 0.000411  \n",
      "Epoch: [7][900/1068] Elapsed 10m 30s (remain 1m 56s) Loss: 0.4435(0.4426) Grad: 0.2747 LR: 0.000411  \n",
      "Epoch: [7][1000/1068] Elapsed 11m 40s (remain 0m 46s) Loss: 0.4392(0.4424) Grad: 0.2324 LR: 0.000411  \n",
      "Epoch: [7][1067/1068] Elapsed 12m 27s (remain 0m 0s) Loss: 0.4352(0.4426) Grad: 0.2025 LR: 0.000411  \n",
      "EVAL: [0/119] Elapsed 0m 0s (remain 1m 17s) Loss: 0.7414(0.7414) \n",
      "EVAL: [100/119] Elapsed 0m 19s (remain 0m 3s) Loss: 0.4133(0.4771) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.4426  avg_val_loss: 0.4621  time: 771s\n",
      "Epoch 7 - Accuracy: 0.7985487487761483\n",
      "Epoch 7 - Save Best Score: 0.7985 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [118/119] Elapsed 0m 22s (remain 0m 0s) Loss: 0.3050(0.4621) \n",
      "Epoch: [8][0/1068] Elapsed 0m 1s (remain 26m 26s) Loss: 0.4374(0.4374) Grad: 0.2482 LR: 0.000285  \n",
      "Epoch: [8][100/1068] Elapsed 1m 11s (remain 11m 24s) Loss: 0.4348(0.4370) Grad: 0.2395 LR: 0.000285  \n",
      "Epoch: [8][200/1068] Elapsed 2m 21s (remain 10m 9s) Loss: 0.4503(0.4367) Grad: 0.2551 LR: 0.000285  \n",
      "Epoch: [8][300/1068] Elapsed 3m 31s (remain 8m 58s) Loss: 0.4538(0.4365) Grad: 0.3554 LR: 0.000285  \n",
      "Epoch: [8][400/1068] Elapsed 4m 41s (remain 7m 47s) Loss: 0.4379(0.4368) Grad: 0.2203 LR: 0.000285  \n",
      "Epoch: [8][500/1068] Elapsed 5m 51s (remain 6m 37s) Loss: 0.4445(0.4367) Grad: 0.2282 LR: 0.000285  \n",
      "Epoch: [8][600/1068] Elapsed 7m 1s (remain 5m 27s) Loss: 0.4301(0.4369) Grad: 0.2562 LR: 0.000285  \n",
      "Epoch: [8][700/1068] Elapsed 8m 10s (remain 4m 16s) Loss: 0.4261(0.4371) Grad: 0.2384 LR: 0.000285  \n",
      "Epoch: [8][800/1068] Elapsed 9m 20s (remain 3m 6s) Loss: 0.4438(0.4370) Grad: 0.2207 LR: 0.000285  \n",
      "Epoch: [8][900/1068] Elapsed 10m 30s (remain 1m 56s) Loss: 0.4452(0.4369) Grad: 0.3028 LR: 0.000285  \n",
      "Epoch: [8][1000/1068] Elapsed 11m 40s (remain 0m 46s) Loss: 0.4205(0.4371) Grad: 0.2928 LR: 0.000285  \n",
      "Epoch: [8][1067/1068] Elapsed 12m 27s (remain 0m 0s) Loss: 0.4434(0.4370) Grad: 0.3164 LR: 0.000285  \n",
      "EVAL: [0/119] Elapsed 0m 0s (remain 1m 28s) Loss: 0.7456(0.7456) \n",
      "EVAL: [100/119] Elapsed 0m 19s (remain 0m 3s) Loss: 0.4170(0.4774) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.4370  avg_val_loss: 0.4625  time: 771s\n",
      "Epoch 8 - Accuracy: 0.7980065693200122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [118/119] Elapsed 0m 23s (remain 0m 0s) Loss: 0.3071(0.4625) \n",
      "Epoch: [9][0/1068] Elapsed 0m 1s (remain 25m 27s) Loss: 0.4305(0.4305) Grad: 0.2740 LR: 0.000186  \n",
      "Epoch: [9][100/1068] Elapsed 1m 11s (remain 11m 23s) Loss: 0.4262(0.4310) Grad: 0.2306 LR: 0.000186  \n",
      "Epoch: [9][200/1068] Elapsed 2m 21s (remain 10m 9s) Loss: 0.4381(0.4309) Grad: 0.2327 LR: 0.000186  \n",
      "Epoch: [9][300/1068] Elapsed 3m 31s (remain 8m 57s) Loss: 0.4079(0.4314) Grad: 0.2264 LR: 0.000186  \n",
      "Epoch: [9][400/1068] Elapsed 4m 40s (remain 7m 47s) Loss: 0.4243(0.4314) Grad: 0.2234 LR: 0.000186  \n",
      "Epoch: [9][500/1068] Elapsed 5m 50s (remain 6m 37s) Loss: 0.4343(0.4315) Grad: 0.2608 LR: 0.000186  \n",
      "Epoch: [9][600/1068] Elapsed 7m 0s (remain 5m 27s) Loss: 0.4614(0.4315) Grad: 0.2718 LR: 0.000186  \n",
      "Epoch: [9][700/1068] Elapsed 8m 10s (remain 4m 16s) Loss: 0.4355(0.4317) Grad: 0.2267 LR: 0.000186  \n",
      "Epoch: [9][800/1068] Elapsed 9m 20s (remain 3m 6s) Loss: 0.4507(0.4315) Grad: 0.2983 LR: 0.000186  \n",
      "Epoch: [9][900/1068] Elapsed 10m 30s (remain 1m 56s) Loss: 0.4349(0.4315) Grad: 0.2634 LR: 0.000186  \n",
      "Epoch: [9][1000/1068] Elapsed 11m 40s (remain 0m 46s) Loss: 0.4286(0.4317) Grad: 0.2602 LR: 0.000186  \n",
      "Epoch: [9][1067/1068] Elapsed 12m 27s (remain 0m 0s) Loss: 0.4465(0.4318) Grad: 0.2619 LR: 0.000186  \n",
      "EVAL: [0/119] Elapsed 0m 0s (remain 1m 18s) Loss: 0.7413(0.7413) \n",
      "EVAL: [100/119] Elapsed 0m 19s (remain 0m 3s) Loss: 0.4158(0.4758) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.4318  avg_val_loss: 0.4609  time: 770s\n",
      "Epoch 9 - Accuracy: 0.7994199206207165\n",
      "Epoch 9 - Save Best Score: 0.7994 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [118/119] Elapsed 0m 22s (remain 0m 0s) Loss: 0.3064(0.4609) \n",
      "Epoch: [10][0/1068] Elapsed 0m 1s (remain 25m 24s) Loss: 0.4315(0.4315) Grad: 0.2285 LR: 0.000122  \n",
      "Epoch: [10][100/1068] Elapsed 1m 11s (remain 11m 22s) Loss: 0.4070(0.4260) Grad: 0.2476 LR: 0.000122  \n",
      "Epoch: [10][200/1068] Elapsed 2m 21s (remain 10m 9s) Loss: 0.4250(0.4268) Grad: 0.2707 LR: 0.000122  \n",
      "Epoch: [10][300/1068] Elapsed 3m 31s (remain 8m 57s) Loss: 0.4073(0.4272) Grad: 0.2756 LR: 0.000122  \n",
      "Epoch: [10][400/1068] Elapsed 4m 40s (remain 7m 47s) Loss: 0.4223(0.4270) Grad: 0.2685 LR: 0.000122  \n",
      "Epoch: [10][500/1068] Elapsed 5m 50s (remain 6m 37s) Loss: 0.4256(0.4268) Grad: 0.2709 LR: 0.000122  \n",
      "Epoch: [10][600/1068] Elapsed 7m 0s (remain 5m 26s) Loss: 0.4177(0.4269) Grad: 0.2287 LR: 0.000122  \n",
      "Epoch: [10][700/1068] Elapsed 8m 10s (remain 4m 16s) Loss: 0.4206(0.4274) Grad: 0.2635 LR: 0.000122  \n",
      "Epoch: [10][800/1068] Elapsed 9m 20s (remain 3m 6s) Loss: 0.4200(0.4276) Grad: 0.2343 LR: 0.000122  \n",
      "Epoch: [10][900/1068] Elapsed 10m 30s (remain 1m 56s) Loss: 0.4262(0.4277) Grad: 0.2438 LR: 0.000122  \n",
      "Epoch: [10][1000/1068] Elapsed 11m 40s (remain 0m 46s) Loss: 0.4104(0.4278) Grad: 0.2721 LR: 0.000122  \n",
      "Epoch: [10][1067/1068] Elapsed 12m 27s (remain 0m 0s) Loss: 0.4315(0.4278) Grad: 0.2506 LR: 0.000122  \n",
      "EVAL: [0/119] Elapsed 0m 0s (remain 1m 19s) Loss: 0.7414(0.7414) \n",
      "EVAL: [100/119] Elapsed 0m 19s (remain 0m 3s) Loss: 0.4136(0.4771) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.4278  avg_val_loss: 0.4622  time: 770s\n",
      "Epoch 10 - Accuracy: 0.7989540673986967\n",
      "Epoch 10 - Save final model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [118/119] Elapsed 0m 22s (remain 0m 0s) Loss: 0.3053(0.4622) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 result ==========\n",
      "Score: 0.79942\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "human-arena",
    "papermill": {
     "duration": 0.209774,
     "end_time": "2021-05-12T03:50:00.096860",
     "exception": false,
     "start_time": "2021-05-12T03:49:59.887086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "hungry-geese-train-by-episode.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2945.71762,
   "end_time": "2021-05-12T03:50:02.012348",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-12T03:00:56.294728",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04a486aa6f454d8f92e388dba1b9ee21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0857c0fa22b544488d65bb2c7dad18ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f905db5005be40b194ea150c8b0deb9f",
      "max": 1001,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "value": 1001
     }
    },
    "4134662bdbe04a918d9809632e268ef8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0857c0fa22b544488d65bb2c7dad18ee",
       "IPY_MODEL_e33e4f894b424988b316c468bc9225ce"
      ],
      "layout": "IPY_MODEL_8ddb49ac3c91409f99a569a061a70b3d"
     }
    },
    "507d2b6a02bb43d0bb4c8c2734f19cbb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ddb49ac3c91409f99a569a061a70b3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c96b7bfbdf0243a8ae1dbb3d9aedf123": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e33e4f894b424988b316c468bc9225ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_507d2b6a02bb43d0bb4c8c2734f19cbb",
      "placeholder": "​",
      "style": "IPY_MODEL_04a486aa6f454d8f92e388dba1b9ee21",
      "value": " 1001/1001 [03:35&lt;00:00,  4.64it/s]"
     }
    },
    "f905db5005be40b194ea150c8b0deb9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

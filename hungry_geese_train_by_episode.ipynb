{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 2945.71762,
      "end_time": "2021-05-12T03:50:02.012348",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-05-12T03:00:56.294728",
      "version": "2.3.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aa44b46ab6364b85a8a40191f6445b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cdb28d008aaa483bbafa7ecb28275482",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_61a88b3301754e2bb0dfbecc95bdd16d",
              "IPY_MODEL_a6ab5cab64d1449cb0194b919737b800"
            ]
          }
        },
        "cdb28d008aaa483bbafa7ecb28275482": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61a88b3301754e2bb0dfbecc95bdd16d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fe36a4a151c7425e9b726a4553f96cfb",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1001,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1001,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d45cab53964426990253a3b4a6df1fe"
          }
        },
        "a6ab5cab64d1449cb0194b919737b800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2cbfa2ce2bdf4869b3320645b342f691",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1001/1001 [00:11&lt;00:00, 84.40it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a896644b50e44baba2a34b1510f3d80"
          }
        },
        "fe36a4a151c7425e9b726a4553f96cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d45cab53964426990253a3b4a6df1fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2cbfa2ce2bdf4869b3320645b342f691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a896644b50e44baba2a34b1510f3d80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "colab": {
      "name": "hungry-geese-train-by-episode.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IMOKURI/Hungry-Geese/blob/main/hungry_geese_train_by_episode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.025714,
          "end_time": "2021-05-12T03:01:02.640708",
          "exception": false,
          "start_time": "2021-05-12T03:01:02.614994",
          "status": "completed"
        },
        "tags": [],
        "id": "abroad-piece"
      },
      "source": [
        "# About this notebook ..."
      ],
      "id": "abroad-piece"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX0zm2Gdvr7u"
      },
      "source": [
        "## Prepare for Colab"
      ],
      "id": "GX0zm2Gdvr7u"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tFzcJBNvvJ5"
      },
      "source": [
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n"
      ],
      "id": "2tFzcJBNvvJ5",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKDVdCItvx_T"
      },
      "source": [
        "COMPETE = \"hungry-geese\"\n",
        "DATASETS = [\n",
        "    \"imokuri/hungrygeeseepisode\",\n",
        "]\n",
        "KERNEL_OUTPUTS = []\n",
        "PACKAGES = []\n"
      ],
      "id": "QKDVdCItvx_T",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRvzBjztxH02",
        "outputId": "2fecc0ba-ee36-4cbb-ff55-3891424c4b1f"
      },
      "source": [
        "if IN_COLAB:\n",
        "    # Work around for python2 exception.\n",
        "    !python2 -m pip uninstall kaggle -y\n",
        "    !python3 -m pip uninstall kaggle -y\n",
        "    !python3 -m pip install -U -q kaggle\n"
      ],
      "id": "cRvzBjztxH02",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping kaggle as it is not installed.\u001b[0m\n",
            "Uninstalling kaggle-1.5.12:\n",
            "  Successfully uninstalled kaggle-1.5.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8YygQsTv-a7",
        "outputId": "162c3abf-967c-4b2d-8d49-d4492eb59a4b"
      },
      "source": [
        "if IN_COLAB:\n",
        "    !pip install -q -U git+https://github.com/IMOKURI/kaggle_on_google_colab.git\n",
        "\n",
        "    from kaggle_on_google_colab import setup\n",
        "    kaggle = setup.Setup()\n",
        "    kaggle.dirs(COMPETE)\n",
        "\n",
        "    # !kaggle competitions download -p /content/zip {COMPETE}\n",
        "    # !unzip -q -n /content/zip/{COMPETE}.zip -d /content/{COMPETE}/input/{COMPETE}\n",
        "\n",
        "    for dataset in DATASETS:\n",
        "        dataset_name = dataset.split(\"/\")[-1]\n",
        "        !kaggle datasets download -p /content/zip {dataset}\n",
        "        !unzip -q -n /content/zip/{dataset_name}.zip -d /content/{COMPETE}/input/{dataset_name}\n",
        "\n",
        "    for kernel in KERNEL_OUTPUTS:\n",
        "        kernel_name = kernel.split(\"/\")[-1]\n",
        "        !kaggle kernels output -p /content/{COMPETE}/input/{kernel_name} {kernel}\n",
        "\n",
        "    for package in PACKAGES:\n",
        "        !pip install -q {package}\n",
        "\n",
        "    %cd /content/{COMPETE}/output\n"
      ],
      "id": "F8YygQsTv-a7",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for kaggle-on-google-colab (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Download 100%.\n",
            "hungrygeeseepisode.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "/content/hungry-geese/output\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.024272,
          "end_time": "2021-05-12T03:01:02.689850",
          "exception": false,
          "start_time": "2021-05-12T03:01:02.665578",
          "status": "completed"
        },
        "tags": [],
        "id": "pressing-commercial"
      },
      "source": [
        "## Library"
      ],
      "id": "pressing-commercial"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:02.750196Z",
          "iopub.status.busy": "2021-05-12T03:01:02.749580Z",
          "iopub.status.idle": "2021-05-12T03:01:04.566183Z",
          "shell.execute_reply": "2021-05-12T03:01:04.565458Z"
        },
        "papermill": {
          "duration": 1.852306,
          "end_time": "2021-05-12T03:01:04.566362",
          "exception": false,
          "start_time": "2021-05-12T03:01:02.714056",
          "status": "completed"
        },
        "tags": [],
        "id": "german-ethics"
      },
      "source": [
        "import glob\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import warnings\n",
        "from contextlib import contextmanager\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.optim import SGD, Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm.notebook import tqdm"
      ],
      "id": "german-ethics",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:04.621034Z",
          "iopub.status.busy": "2021-05-12T03:01:04.620187Z",
          "iopub.status.idle": "2021-05-12T03:01:04.622713Z",
          "shell.execute_reply": "2021-05-12T03:01:04.622327Z"
        },
        "papermill": {
          "duration": 0.030961,
          "end_time": "2021-05-12T03:01:04.622818",
          "exception": false,
          "start_time": "2021-05-12T03:01:04.591857",
          "status": "completed"
        },
        "tags": [],
        "id": "apparent-fiction"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "apparent-fiction",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.024539,
          "end_time": "2021-05-12T03:01:04.672270",
          "exception": false,
          "start_time": "2021-05-12T03:01:04.647731",
          "status": "completed"
        },
        "tags": [],
        "id": "robust-humanity"
      },
      "source": [
        "## Load Data"
      ],
      "id": "robust-humanity"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:04.725686Z",
          "iopub.status.busy": "2021-05-12T03:01:04.724981Z",
          "iopub.status.idle": "2021-05-12T03:01:04.727535Z",
          "shell.execute_reply": "2021-05-12T03:01:04.727956Z"
        },
        "papermill": {
          "duration": 0.031167,
          "end_time": "2021-05-12T03:01:04.728079",
          "exception": false,
          "start_time": "2021-05-12T03:01:04.696912",
          "status": "completed"
        },
        "tags": [],
        "id": "designed-effect"
      },
      "source": [
        "BASE_DIR = \"../input/hungrygeeseepisode/hungry-geese-episode/\"\n",
        "OUTPUT_DIR = \"pre-models/\"\n",
        "\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)"
      ],
      "id": "designed-effect",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:04.780710Z",
          "iopub.status.busy": "2021-05-12T03:01:04.780213Z",
          "iopub.status.idle": "2021-05-12T03:01:05.064607Z",
          "shell.execute_reply": "2021-05-12T03:01:05.064145Z"
        },
        "papermill": {
          "duration": 0.31211,
          "end_time": "2021-05-12T03:01:05.064722",
          "exception": false,
          "start_time": "2021-05-12T03:01:04.752612",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "special-broadcast",
        "outputId": "b38ef1c9-1db4-4d8e-fe40-c4e8262a5a32"
      },
      "source": [
        "paths = [path for path in glob.glob(BASE_DIR + \"*.json\") if \"info\" not in path]\n",
        "print(len(paths))"
      ],
      "id": "special-broadcast",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.024908,
          "end_time": "2021-05-12T03:01:05.115280",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.090372",
          "status": "completed"
        },
        "tags": [],
        "id": "editorial-haiti"
      },
      "source": [
        "## Config"
      ],
      "id": "editorial-haiti"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:05.173654Z",
          "iopub.status.busy": "2021-05-12T03:01:05.172793Z",
          "iopub.status.idle": "2021-05-12T03:01:05.175299Z",
          "shell.execute_reply": "2021-05-12T03:01:05.175845Z"
        },
        "papermill": {
          "duration": 0.035637,
          "end_time": "2021-05-12T03:01:05.176119",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.140482",
          "status": "completed"
        },
        "tags": [],
        "id": "opened-python"
      },
      "source": [
        "class Config:\n",
        "    seed = 440\n",
        "\n",
        "    n_class = 4\n",
        "    n_fold = 5\n",
        "\n",
        "    gradient_accumulation_steps = 1\n",
        "    max_grad_norm = 1000\n",
        "\n",
        "    num_workers = 4\n",
        "    batch_size = 800\n",
        "\n",
        "    scheduler = \"CosineAnnealingWarmRestarts\"\n",
        "    # factor = 0.2  # ReduceLROnPlateau\n",
        "    # patience = 4  # ReduceLROnPlateau\n",
        "    # eps = 1e-6  # ReduceLROnPlateau\n",
        "    # T_max = 10  # CosineAnnealingLR\n",
        "    T_0 = 10  # CosineAnnealingWarmRestarts\n",
        "\n",
        "    criterion = \"CrossEntropyLoss\"\n",
        "    lr = 2e-3\n",
        "    min_lr = 2e-5\n",
        "    weight_decay = 1e-6\n",
        "\n",
        "    epochs = 10\n",
        "    model_name = \"geese_net\"\n",
        "\n",
        "    print_freq = 100\n",
        "\n",
        "    train = True\n",
        "    debug = False\n",
        "    apex = False"
      ],
      "id": "opened-python",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:05.233296Z",
          "iopub.status.busy": "2021-05-12T03:01:05.232628Z",
          "iopub.status.idle": "2021-05-12T03:01:05.235351Z",
          "shell.execute_reply": "2021-05-12T03:01:05.234953Z"
        },
        "papermill": {
          "duration": 0.031266,
          "end_time": "2021-05-12T03:01:05.235456",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.204190",
          "status": "completed"
        },
        "tags": [],
        "id": "contained-singles"
      },
      "source": [
        "if Config.debug:\n",
        "    Config.epochs = 1"
      ],
      "id": "contained-singles",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:05.290450Z",
          "iopub.status.busy": "2021-05-12T03:01:05.289701Z",
          "iopub.status.idle": "2021-05-12T03:01:05.291811Z",
          "shell.execute_reply": "2021-05-12T03:01:05.292268Z"
        },
        "papermill": {
          "duration": 0.031421,
          "end_time": "2021-05-12T03:01:05.292382",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.260961",
          "status": "completed"
        },
        "tags": [],
        "id": "dietary-track"
      },
      "source": [
        "if Config.apex:\n",
        "    from apex import amp"
      ],
      "id": "dietary-track",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:05.485693Z",
          "iopub.status.busy": "2021-05-12T03:01:05.483279Z",
          "iopub.status.idle": "2021-05-12T03:01:05.488061Z",
          "shell.execute_reply": "2021-05-12T03:01:05.488530Z"
        },
        "papermill": {
          "duration": 0.169531,
          "end_time": "2021-05-12T03:01:05.488665",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.319134",
          "status": "completed"
        },
        "tags": [],
        "id": "invalid-dispute"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "id": "invalid-dispute",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.025219,
          "end_time": "2021-05-12T03:01:05.539482",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.514263",
          "status": "completed"
        },
        "tags": [],
        "id": "treated-serum"
      },
      "source": [
        "## Utils"
      ],
      "id": "treated-serum"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:05.622688Z",
          "iopub.status.busy": "2021-05-12T03:01:05.621871Z",
          "iopub.status.idle": "2021-05-12T03:01:05.642197Z",
          "shell.execute_reply": "2021-05-12T03:01:05.640797Z"
        },
        "papermill": {
          "duration": 0.070842,
          "end_time": "2021-05-12T03:01:05.642364",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.571522",
          "status": "completed"
        },
        "tags": [],
        "id": "gothic-alloy"
      },
      "source": [
        "@contextmanager\n",
        "def timer(name):\n",
        "    t0 = time.time()\n",
        "    LOGGER.info(f\"[{name}] start\")\n",
        "    yield\n",
        "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
        "\n",
        "\n",
        "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
        "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
        "\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler1 = StreamHandler()\n",
        "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
        "    handler2 = FileHandler(filename=log_file)\n",
        "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(handler1)\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "\n",
        "LOGGER = init_logger()\n",
        "\n",
        "\n",
        "def seed_torch(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "seed_torch(seed=Config.seed)"
      ],
      "id": "gothic-alloy",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:05.736939Z",
          "iopub.status.busy": "2021-05-12T03:01:05.736146Z",
          "iopub.status.idle": "2021-05-12T03:01:05.741693Z",
          "shell.execute_reply": "2021-05-12T03:01:05.741081Z"
        },
        "papermill": {
          "duration": 0.053842,
          "end_time": "2021-05-12T03:01:05.741858",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.688016",
          "status": "completed"
        },
        "tags": [],
        "id": "experienced-correspondence"
      },
      "source": [
        "def reverse_ns(y):\n",
        "    if y == 0:\n",
        "        return 1\n",
        "    if y == 1:\n",
        "        return 0\n",
        "    return y\n",
        "\n",
        "def reverse_we(y):\n",
        "    if y == 2:\n",
        "        return 3\n",
        "    if y == 3:\n",
        "        return 2\n",
        "    return y\n",
        "\n",
        "def reverse_nswe(y):\n",
        "    return reverse_ns(reverse_we(y))"
      ],
      "id": "experienced-correspondence",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.042365,
          "end_time": "2021-05-12T03:01:05.826807",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.784442",
          "status": "completed"
        },
        "tags": [],
        "id": "further-transaction"
      },
      "source": [
        "## Observation"
      ],
      "id": "further-transaction"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:05.923923Z",
          "iopub.status.busy": "2021-05-12T03:01:05.922723Z",
          "iopub.status.idle": "2021-05-12T03:01:05.927158Z",
          "shell.execute_reply": "2021-05-12T03:01:05.928120Z"
        },
        "papermill": {
          "duration": 0.058537,
          "end_time": "2021-05-12T03:01:05.928292",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.869755",
          "status": "completed"
        },
        "tags": [],
        "id": "naughty-clause"
      },
      "source": [
        "def make_input(obses):\n",
        "    b = np.zeros((17, 7 * 11), dtype=np.float32)\n",
        "    obs = obses[-1]\n",
        "\n",
        "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
        "        pid = (p - obs[\"index\"]) % 4\n",
        "\n",
        "        # head position\n",
        "        for pos in pos_list[:1]:\n",
        "            b[0 + pid, pos] = 1\n",
        "        # tip position\n",
        "        for pos in pos_list[-1:]:\n",
        "            b[4 + pid, pos] = 1\n",
        "        # whole position\n",
        "        for pos in pos_list:\n",
        "            b[8 + pid, pos] = 1\n",
        "\n",
        "    # previous head position\n",
        "    if len(obses) > 1:\n",
        "        obs_prev = obses[-2]\n",
        "        for p, pos_list in enumerate(obs_prev[\"geese\"]):\n",
        "            for pos in pos_list[:1]:\n",
        "                b[12 + (p - obs[\"index\"]) % 4, pos] = 1\n",
        "\n",
        "    # food\n",
        "    for pos in obs[\"food\"]:\n",
        "        b[16, pos] = 1\n",
        "\n",
        "    return b.reshape(-1, 7, 11)"
      ],
      "id": "naughty-clause",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6lOS7itC0da"
      },
      "source": [
        "def observation_num_step(obses):\n",
        "    b = np.zeros((7, 11), dtype=np.float32)\n",
        "    obs = obses[-1]\n",
        "\n",
        "    num_step = obs[\"step\"]  # 0-198\n",
        "    b[0, 0] = num_step / 198\n",
        "\n",
        "    return b.reshape(1, 7, 11)"
      ],
      "id": "i6lOS7itC0da",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.042985,
          "end_time": "2021-05-12T03:01:06.014038",
          "exception": false,
          "start_time": "2021-05-12T03:01:05.971053",
          "status": "completed"
        },
        "tags": [],
        "id": "pretty-aaron"
      },
      "source": [
        "## Data"
      ],
      "id": "pretty-aaron"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:06.111097Z",
          "iopub.status.busy": "2021-05-12T03:01:06.110359Z",
          "iopub.status.idle": "2021-05-12T03:01:06.120495Z",
          "shell.execute_reply": "2021-05-12T03:01:06.121470Z"
        },
        "papermill": {
          "duration": 0.064855,
          "end_time": "2021-05-12T03:01:06.121648",
          "exception": false,
          "start_time": "2021-05-12T03:01:06.056793",
          "status": "completed"
        },
        "tags": [],
        "id": "international-secret"
      },
      "source": [
        "def create_dataset_from_json(filepath, json_object=None, standing=0):\n",
        "    if json_object is None:\n",
        "        json_open = open(path, \"r\")\n",
        "        json_load = json.load(json_open)\n",
        "    else:\n",
        "        json_load = json_object\n",
        "\n",
        "    try:\n",
        "        winner_index = np.argmax(np.argsort(json_load[\"rewards\"]) == 3 - standing)\n",
        "\n",
        "        obses = []\n",
        "        X = []\n",
        "        y = []\n",
        "        actions = {\"NORTH\": 0, \"SOUTH\": 1, \"WEST\": 2, \"EAST\": 3}\n",
        "\n",
        "        for i in range(len(json_load[\"steps\"]) - 1):\n",
        "            if json_load[\"steps\"][i][winner_index][\"status\"] == \"ACTIVE\":\n",
        "                y_ = json_load[\"steps\"][i + 1][winner_index][\"action\"]\n",
        "                if y_ is not None:\n",
        "                    step = json_load[\"steps\"][i]\n",
        "                    step[winner_index][\"observation\"][\"geese\"] = step[0][\"observation\"][\"geese\"]\n",
        "                    step[winner_index][\"observation\"][\"food\"] = step[0][\"observation\"][\"food\"]\n",
        "                    step[winner_index][\"observation\"][\"step\"] = step[0][\"observation\"][\"step\"]\n",
        "                    obses.append(step[winner_index][\"observation\"])\n",
        "                    y.append(actions[y_])\n",
        "\n",
        "                    y.append(reverse_ns(actions[y_]))  # 上下反転\n",
        "                    y.append(reverse_we(actions[y_]))  # 左右反転\n",
        "                    y.append(reverse_nswe(actions[y_]))  # 上下左右反転\n",
        "\n",
        "        for j in range(len(obses)):\n",
        "            # X_ = make_input(obses[: j + 1])\n",
        "\n",
        "            X_ = []\n",
        "            X_.append(make_input(obses[: j + 1]))\n",
        "            X_.append(observation_num_step(obses[: j + 1]))\n",
        "            X_ = np.concatenate(X_)\n",
        "\n",
        "            X.append(X_)\n",
        "\n",
        "            X.append(X_[:, ::-1, :])  # 上下反転\n",
        "            X.append(X_[:, :, ::-1])  # 左右反転\n",
        "            X.append(X_[:, ::-1, ::-1])  # 上下左右反転\n",
        "\n",
        "        X = np.array(X, dtype=np.float32)  # [starting_step:]\n",
        "        y = np.array(y, dtype=np.uint8)  # [starting_step:]\n",
        "\n",
        "        return X, y\n",
        "    except:\n",
        "        return 0, 0"
      ],
      "id": "international-secret",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:01:06.210574Z",
          "iopub.status.busy": "2021-05-12T03:01:06.209744Z",
          "iopub.status.idle": "2021-05-12T03:01:21.474698Z",
          "shell.execute_reply": "2021-05-12T03:01:21.474263Z"
        },
        "papermill": {
          "duration": 15.320591,
          "end_time": "2021-05-12T03:01:21.474816",
          "exception": false,
          "start_time": "2021-05-12T03:01:06.154225",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "aa44b46ab6364b85a8a40191f6445b99",
            "cdb28d008aaa483bbafa7ecb28275482",
            "61a88b3301754e2bb0dfbecc95bdd16d",
            "a6ab5cab64d1449cb0194b919737b800",
            "fe36a4a151c7425e9b726a4553f96cfb",
            "9d45cab53964426990253a3b4a6df1fe",
            "2cbfa2ce2bdf4869b3320645b342f691",
            "5a896644b50e44baba2a34b1510f3d80"
          ]
        },
        "id": "handled-pleasure",
        "outputId": "b7ac2851-d717-465f-91da-e1bfb9fcb708"
      },
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for path in tqdm(paths[: int(len(paths))]):\n",
        "    X, y = create_dataset_from_json(path, standing=0)  # use only winners' moves\n",
        "    if X is not 0:\n",
        "        X_train.append(X)\n",
        "        y_train.append(y)\n",
        "        \n",
        "X_train = np.concatenate(X_train)\n",
        "y_train = np.concatenate(y_train)\n",
        "\n",
        "print(f\"Num episode: {len(X_train)}\")"
      ],
      "id": "handled-pleasure",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa44b46ab6364b85a8a40191f6445b99",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1001.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Num episode: 642304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:02:25.736079Z",
          "iopub.status.busy": "2021-05-12T03:02:25.694905Z",
          "iopub.status.idle": "2021-05-12T03:03:14.427579Z",
          "shell.execute_reply": "2021-05-12T03:03:14.428005Z"
        },
        "papermill": {
          "duration": 112.92618,
          "end_time": "2021-05-12T03:03:14.428162",
          "exception": false,
          "start_time": "2021-05-12T03:01:21.501982",
          "status": "completed"
        },
        "tags": [],
        "id": "persistent-loading"
      },
      "source": [
        "# take a long time...\n",
        "X_train, unique_index = np.unique(X_train, axis=0, return_index=True)  # remove duplicate\n",
        "y_train = y_train[unique_index]\n",
        "\n",
        "# y_train = np.eye(4, dtype=\"uint8\")[y_train]  # to categorical\n",
        "\n",
        "print(f\"Num episode: {len(X_train)}\")"
      ],
      "id": "persistent-loading",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:15.358147Z",
          "iopub.status.busy": "2021-05-12T03:03:15.357428Z",
          "iopub.status.idle": "2021-05-12T03:03:15.360295Z",
          "shell.execute_reply": "2021-05-12T03:03:15.359841Z"
        },
        "papermill": {
          "duration": 0.033413,
          "end_time": "2021-05-12T03:03:15.360395",
          "exception": false,
          "start_time": "2021-05-12T03:03:15.326982",
          "status": "completed"
        },
        "tags": [],
        "id": "micro-french"
      },
      "source": [
        "if Config.debug:\n",
        "    X_train = X_train[:1000]\n",
        "    y_train = y_train[:1000]"
      ],
      "id": "micro-french",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:15.421673Z",
          "iopub.status.busy": "2021-05-12T03:03:15.421167Z",
          "iopub.status.idle": "2021-05-12T03:03:15.425045Z",
          "shell.execute_reply": "2021-05-12T03:03:15.424564Z"
        },
        "papermill": {
          "duration": 0.036161,
          "end_time": "2021-05-12T03:03:15.425149",
          "exception": false,
          "start_time": "2021-05-12T03:03:15.388988",
          "status": "completed"
        },
        "tags": [],
        "id": "wrong-pastor"
      },
      "source": [
        "y_df = pd.DataFrame(y_train)\n",
        "y_df.columns = [\"action\"]\n",
        "y_df"
      ],
      "id": "wrong-pastor",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.027968,
          "end_time": "2021-05-12T03:03:15.557122",
          "exception": false,
          "start_time": "2021-05-12T03:03:15.529154",
          "status": "completed"
        },
        "tags": [],
        "id": "touched-coordinate"
      },
      "source": [
        "## CV Split"
      ],
      "id": "touched-coordinate"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:15.619838Z",
          "iopub.status.busy": "2021-05-12T03:03:15.617632Z",
          "iopub.status.idle": "2021-05-12T03:03:15.787410Z",
          "shell.execute_reply": "2021-05-12T03:03:15.786989Z"
        },
        "papermill": {
          "duration": 0.202337,
          "end_time": "2021-05-12T03:03:15.787529",
          "exception": false,
          "start_time": "2021-05-12T03:03:15.585192",
          "status": "completed"
        },
        "tags": [],
        "id": "moving-skill"
      },
      "source": [
        "folds = y_df.copy()\n",
        "Fold = StratifiedKFold(n_splits=Config.n_fold, shuffle=True, random_state=Config.seed)\n",
        "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[\"action\"])):\n",
        "    folds.loc[val_index, \"fold\"] = int(n)\n",
        "folds[\"fold\"] = folds[\"fold\"].astype(int)\n",
        "print(folds.groupby([\"fold\", \"action\"]).size())"
      ],
      "id": "moving-skill",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.029031,
          "end_time": "2021-05-12T03:03:15.845114",
          "exception": false,
          "start_time": "2021-05-12T03:03:15.816083",
          "status": "completed"
        },
        "tags": [],
        "id": "creative-football"
      },
      "source": [
        "## Dataset"
      ],
      "id": "creative-football"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:15.908966Z",
          "iopub.status.busy": "2021-05-12T03:03:15.908282Z",
          "iopub.status.idle": "2021-05-12T03:03:15.911117Z",
          "shell.execute_reply": "2021-05-12T03:03:15.910685Z"
        },
        "papermill": {
          "duration": 0.037264,
          "end_time": "2021-05-12T03:03:15.911219",
          "exception": false,
          "start_time": "2021-05-12T03:03:15.873955",
          "status": "completed"
        },
        "tags": [],
        "id": "other-murder"
      },
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, array, label):\n",
        "        self.array = array\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.array.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.array[idx], torch.tensor(self.label[idx]).long()\n",
        "\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, array):\n",
        "        self.array = array\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.array.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.array[idx]"
      ],
      "id": "other-murder",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:15.976092Z",
          "iopub.status.busy": "2021-05-12T03:03:15.975444Z",
          "iopub.status.idle": "2021-05-12T03:03:16.003593Z",
          "shell.execute_reply": "2021-05-12T03:03:16.003099Z"
        },
        "papermill": {
          "duration": 0.063691,
          "end_time": "2021-05-12T03:03:16.003693",
          "exception": false,
          "start_time": "2021-05-12T03:03:15.940002",
          "status": "completed"
        },
        "tags": [],
        "id": "adjusted-delhi"
      },
      "source": [
        "# Test\n",
        "\n",
        "train_ds = TrainDataset(X_train, y_train)\n",
        "\n",
        "for i in range(1):\n",
        "    obs, action = train_ds[i]\n",
        "    print(obs.shape, action)"
      ],
      "id": "adjusted-delhi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.02876,
          "end_time": "2021-05-12T03:03:16.061575",
          "exception": false,
          "start_time": "2021-05-12T03:03:16.032815",
          "status": "completed"
        },
        "tags": [],
        "id": "ceramic-startup"
      },
      "source": [
        "## Model"
      ],
      "id": "ceramic-startup"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:16.128034Z",
          "iopub.status.busy": "2021-05-12T03:03:16.127367Z",
          "iopub.status.idle": "2021-05-12T03:03:16.130137Z",
          "shell.execute_reply": "2021-05-12T03:03:16.129621Z"
        },
        "papermill": {
          "duration": 0.039055,
          "end_time": "2021-05-12T03:03:16.130239",
          "exception": false,
          "start_time": "2021-05-12T03:03:16.091184",
          "status": "completed"
        },
        "tags": [],
        "id": "unique-trick"
      },
      "source": [
        "class TorusConv2d(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
        "        super().__init__()\n",
        "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
        "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
        "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = torch.cat([x[:, :, :, -self.edge_size[1] :], x, x[:, :, :, : self.edge_size[1]]], dim=3)\n",
        "        h = torch.cat([h[:, :, -self.edge_size[0] :], h, h[:, :, : self.edge_size[0]]], dim=2)\n",
        "        h = self.conv(h)\n",
        "        h = self.bn(h) if self.bn is not None else h\n",
        "        return h"
      ],
      "id": "unique-trick",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:16.199989Z",
          "iopub.status.busy": "2021-05-12T03:03:16.199254Z",
          "iopub.status.idle": "2021-05-12T03:03:16.201923Z",
          "shell.execute_reply": "2021-05-12T03:03:16.201414Z"
        },
        "papermill": {
          "duration": 0.042421,
          "end_time": "2021-05-12T03:03:16.202024",
          "exception": false,
          "start_time": "2021-05-12T03:03:16.159603",
          "status": "completed"
        },
        "tags": [],
        "id": "extra-bradford"
      },
      "source": [
        "class GeeseNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        layers, filters = 12, 32\n",
        "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
        "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
        "\n",
        "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
        "        self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
        "\n",
        "        self.head_p = nn.Linear(filters, 4, bias=False)\n",
        "        self.head_v1 = nn.Linear(filters * 2, filters, bias=False)\n",
        "        self.head_v2 = nn.Linear(filters, 1, bias=False)\n",
        "\n",
        "    def forward(self, x, _=None):\n",
        "        h = F.relu_(self.conv0(x))\n",
        "        for block in self.blocks:\n",
        "            h = F.relu_(h + block(h))\n",
        "\n",
        "        h_p = F.relu_(self.conv_p(h))\n",
        "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
        "        p = self.head_p(h_head_p)\n",
        "\n",
        "        h_v = F.relu_(self.conv_v(h))\n",
        "        h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
        "        h_avg_v = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
        "\n",
        "        h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_avg_v], 1)))\n",
        "        v = torch.tanh(self.head_v2(h_v))\n",
        "\n",
        "        return {\"policy\": p, \"value\": v}"
      ],
      "id": "extra-bradford",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jspEE71c2Yma"
      },
      "source": [
        "class GeeseNetAlpha(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        layers, filters = 12, 64\n",
        "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
        "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
        "\n",
        "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
        "        # self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
        "\n",
        "        self.head_p1 = nn.Linear(filters * 2 + 77 + 1, filters * 2, bias=False)\n",
        "        self.head_p2 = nn.Linear(filters * 2, 4, bias=False)\n",
        "        # self.head_v1 = nn.Linear(filters * 2 + 1, filters, bias=False)\n",
        "        # self.head_v2 = nn.Linear(filters, 1, bias=False)\n",
        "\n",
        "    def forward(self, x, _=None):\n",
        "        x = x[:, :-1]\n",
        "        num_step = x[:, -1, 0, 0].view(x.size(0), 1)\n",
        "\n",
        "        h = F.relu_(self.conv0(x))\n",
        "        for block in self.blocks:\n",
        "            h = F.relu_(h + block(h))\n",
        "\n",
        "        h_p = F.relu_(self.conv_p(h))\n",
        "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
        "        h_avg_p1 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(-1)\n",
        "        h_avg_p2 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(1)\n",
        "\n",
        "        h_p = F.relu_(self.head_p1(torch.cat([h_head_p, h_avg_p1, h_avg_p2, num_step], 1)))\n",
        "        p = self.head_p2(h_p)\n",
        "\n",
        "        # h_v = F.relu_(self.conv_v(h))\n",
        "        # h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
        "        # h_avg_v = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
        "\n",
        "        # h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_avg_v, num_step], 1)))\n",
        "        # v = torch.tanh(self.head_v2(h_v))\n",
        "\n",
        "        return {\"policy\": p}  # \"value\": v"
      ],
      "id": "jspEE71c2Yma",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:16.271521Z",
          "iopub.status.busy": "2021-05-12T03:03:16.270975Z",
          "iopub.status.idle": "2021-05-12T03:03:21.187210Z",
          "shell.execute_reply": "2021-05-12T03:03:21.186277Z"
        },
        "papermill": {
          "duration": 4.955868,
          "end_time": "2021-05-12T03:03:21.187355",
          "exception": false,
          "start_time": "2021-05-12T03:03:16.231487",
          "status": "completed"
        },
        "tags": [],
        "id": "objective-victoria"
      },
      "source": [
        "# Test\n",
        "\n",
        "model = GeeseNetAlpha()\n",
        "# print(model)\n",
        "\n",
        "train_ds = TrainDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
        "\n",
        "for obs, action in train_loader:\n",
        "    output = model(obs)\n",
        "    print(output)\n",
        "    print(f\"{torch.argmax(output['policy'], dim=1)}\")\n",
        "    break"
      ],
      "id": "objective-victoria",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.033001,
          "end_time": "2021-05-12T03:03:21.255277",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.222276",
          "status": "completed"
        },
        "tags": [],
        "id": "military-fiction"
      },
      "source": [
        "## Loss"
      ],
      "id": "military-fiction"
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.031759,
          "end_time": "2021-05-12T03:03:21.319849",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.288090",
          "status": "completed"
        },
        "tags": [],
        "id": "sophisticated-hearts"
      },
      "source": [
        ""
      ],
      "id": "sophisticated-hearts",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.03139,
          "end_time": "2021-05-12T03:03:21.383038",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.351648",
          "status": "completed"
        },
        "tags": [],
        "id": "designing-detective"
      },
      "source": [
        "## Scoring"
      ],
      "id": "designing-detective"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:21.451759Z",
          "iopub.status.busy": "2021-05-12T03:03:21.450940Z",
          "iopub.status.idle": "2021-05-12T03:03:21.453955Z",
          "shell.execute_reply": "2021-05-12T03:03:21.453477Z"
        },
        "papermill": {
          "duration": 0.038846,
          "end_time": "2021-05-12T03:03:21.454085",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.415239",
          "status": "completed"
        },
        "tags": [],
        "id": "passive-cooper"
      },
      "source": [
        "def get_score(y_true, y_pred):\n",
        "    return accuracy_score(y_true, y_pred)"
      ],
      "id": "passive-cooper",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.0293,
          "end_time": "2021-05-12T03:03:21.514179",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.484879",
          "status": "completed"
        },
        "tags": [],
        "id": "thirty-tracy"
      },
      "source": [
        "## Helper functions"
      ],
      "id": "thirty-tracy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:21.580683Z",
          "iopub.status.busy": "2021-05-12T03:03:21.580046Z",
          "iopub.status.idle": "2021-05-12T03:03:21.582848Z",
          "shell.execute_reply": "2021-05-12T03:03:21.582463Z"
        },
        "papermill": {
          "duration": 0.039424,
          "end_time": "2021-05-12T03:03:21.582969",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.543545",
          "status": "completed"
        },
        "tags": [],
        "id": "introductory-brooklyn"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return \"%dm %ds\" % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
      ],
      "id": "introductory-brooklyn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:21.652644Z",
          "iopub.status.busy": "2021-05-12T03:03:21.651807Z",
          "iopub.status.idle": "2021-05-12T03:03:21.654450Z",
          "shell.execute_reply": "2021-05-12T03:03:21.654030Z"
        },
        "papermill": {
          "duration": 0.042063,
          "end_time": "2021-05-12T03:03:21.654559",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.612496",
          "status": "completed"
        },
        "tags": [],
        "id": "raising-laugh"
      },
      "source": [
        "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    scores = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    start = end = time.time()\n",
        "    global_step = 0\n",
        "\n",
        "    for step, (obs, action) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "        obs = obs.to(device)\n",
        "        action = action.to(device)\n",
        "        batch_size = action.size(0)\n",
        "\n",
        "        y_preds = model(obs.float())[\"policy\"]\n",
        "\n",
        "        loss = criterion(y_preds, action)\n",
        "\n",
        "        # record loss\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        if Config.gradient_accumulation_steps > 1:\n",
        "            loss = loss / Config.gradient_accumulation_steps\n",
        "        if Config.apex:\n",
        "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                scaled_loss.backward()\n",
        "        else:\n",
        "            loss.backward()\n",
        "\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), Config.max_grad_norm)\n",
        "\n",
        "        if (step + 1) % Config.gradient_accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            global_step += 1\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
        "            print(\n",
        "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
        "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
        "                f\"Loss: {losses.val:.4f}({losses.avg:.4f}) \"\n",
        "                f\"Grad: {grad_norm:.4f} \"\n",
        "                f\"LR: {scheduler.get_last_lr()[0]:.6f}  \"\n",
        "            )\n",
        "\n",
        "    return losses.avg"
      ],
      "id": "raising-laugh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:21.724634Z",
          "iopub.status.busy": "2021-05-12T03:03:21.723879Z",
          "iopub.status.idle": "2021-05-12T03:03:21.726483Z",
          "shell.execute_reply": "2021-05-12T03:03:21.726090Z"
        },
        "papermill": {
          "duration": 0.041056,
          "end_time": "2021-05-12T03:03:21.726585",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.685529",
          "status": "completed"
        },
        "tags": [],
        "id": "plain-neighbor"
      },
      "source": [
        "def valid_fn(valid_loader, model, criterion, device):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    scores = AverageMeter()\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    start = end = time.time()\n",
        "\n",
        "    for step, (obs, action) in enumerate(valid_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "        obs = obs.to(device)\n",
        "        action = action.to(device)\n",
        "        batch_size = action.size(0)\n",
        "\n",
        "        # compute loss\n",
        "        with torch.no_grad():\n",
        "            y_preds = model(obs)[\"policy\"]\n",
        "\n",
        "        loss = criterion(y_preds, action)\n",
        "        losses.update(loss.item(), batch_size)\n",
        "\n",
        "        # record accuracy\n",
        "        preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
        "        if Config.gradient_accumulation_steps > 1:\n",
        "            loss = loss / Config.gradient_accumulation_steps\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
        "            print(\n",
        "                f\"EVAL: [{step}/{len(valid_loader)}] \"\n",
        "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
        "                f\"Loss: {losses.val:.4f}({losses.avg:.4f}) \"\n",
        "            )\n",
        "    predictions = np.concatenate(preds)\n",
        "    return losses.avg, predictions"
      ],
      "id": "plain-neighbor",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.029832,
          "end_time": "2021-05-12T03:03:21.786427",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.756595",
          "status": "completed"
        },
        "tags": [],
        "id": "integrated-classification"
      },
      "source": [
        "## Train loop"
      ],
      "id": "integrated-classification"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:21.867202Z",
          "iopub.status.busy": "2021-05-12T03:03:21.865599Z",
          "iopub.status.idle": "2021-05-12T03:03:21.867975Z",
          "shell.execute_reply": "2021-05-12T03:03:21.868446Z"
        },
        "papermill": {
          "duration": 0.05136,
          "end_time": "2021-05-12T03:03:21.868561",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.817201",
          "status": "completed"
        },
        "tags": [],
        "id": "harmful-explanation"
      },
      "source": [
        "def train_loop(folds, fold):\n",
        "\n",
        "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
        "\n",
        "    # ====================================================\n",
        "    # Data Loader\n",
        "    # ====================================================\n",
        "    X_train_folds = X_train[folds[\"fold\"] != fold]\n",
        "    X_valid_folds = X_train[folds[\"fold\"] == fold]\n",
        "\n",
        "    y_train_folds = y_train[folds[\"fold\"] != fold]\n",
        "    y_valid_folds = y_train[folds[\"fold\"] == fold]\n",
        "\n",
        "    y_df_train_folds = y_df[folds[\"fold\"] != fold]\n",
        "    y_df_valid_folds = y_df[folds[\"fold\"] == fold]\n",
        "\n",
        "    train_dataset = TrainDataset(X_train_folds, y_train_folds)\n",
        "    valid_dataset = TrainDataset(X_valid_folds, y_valid_folds)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=Config.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=Config.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=Config.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=Config.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=False,\n",
        "    )\n",
        "\n",
        "    # ====================================================\n",
        "    # Scheduler\n",
        "    # ====================================================\n",
        "    def get_scheduler(optimizer):\n",
        "        if Config.scheduler == \"ReduceLROnPlateau\":\n",
        "            scheduler = ReduceLROnPlateau(\n",
        "                optimizer, mode=\"min\", factor=Config.factor, patience=Config.patience, verbose=True, eps=Config.eps\n",
        "            )\n",
        "        elif Config.scheduler == \"CosineAnnealingLR\":\n",
        "            scheduler = CosineAnnealingLR(optimizer, T_max=Config.T_max, eta_min=Config.min_lr, last_epoch=-1)\n",
        "        elif Config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
        "            scheduler = CosineAnnealingWarmRestarts(\n",
        "                optimizer, T_0=Config.T_0, T_mult=1, eta_min=Config.min_lr, last_epoch=-1\n",
        "            )\n",
        "        return scheduler\n",
        "\n",
        "    # ====================================================\n",
        "    # model & optimizer\n",
        "    # ====================================================\n",
        "    model = GeeseNetAlpha()\n",
        "    model.to(device)\n",
        "\n",
        "    # Use multi GPU\n",
        "    if device == torch.device(\"cuda\") and not Config.apex:\n",
        "        model = torch.nn.DataParallel(model)  # make parallel\n",
        "        # torch.backends.cudnn.benchmark=True\n",
        "\n",
        "    optimizer = Adam(model.parameters(), lr=Config.lr, weight_decay=Config.weight_decay, amsgrad=False)\n",
        "    scheduler = get_scheduler(optimizer)\n",
        "\n",
        "    # ====================================================\n",
        "    # apex\n",
        "    # ====================================================\n",
        "    if Config.apex:\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
        "\n",
        "    # ====================================================\n",
        "    # Criterion\n",
        "    # ====================================================\n",
        "    def get_criterion():\n",
        "        if Config.criterion == \"CrossEntropyLoss\":\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "        return criterion\n",
        "\n",
        "    criterion = get_criterion()\n",
        "\n",
        "    # ====================================================\n",
        "    # loop\n",
        "    # ====================================================\n",
        "    best_score = 0.0\n",
        "    best_loss = np.inf\n",
        "\n",
        "    for epoch in range(Config.epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # train\n",
        "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
        "\n",
        "        # eval\n",
        "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
        "\n",
        "        if isinstance(scheduler, ReduceLROnPlateau):\n",
        "            scheduler.step(avg_val_loss)\n",
        "        elif isinstance(scheduler, CosineAnnealingLR):\n",
        "            scheduler.step()\n",
        "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
        "            scheduler.step()\n",
        "\n",
        "        # scoring\n",
        "        score = get_score(y_valid_folds, preds.argmax(1))\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        LOGGER.info(\n",
        "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
        "        )\n",
        "        LOGGER.info(f\"Epoch {epoch+1} - Accuracy: {score}\")\n",
        "\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n",
        "            torch.save(\n",
        "                {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_best.pth\"\n",
        "            )\n",
        "\n",
        "        if epoch == Config.epochs - 1:\n",
        "            LOGGER.info(f\"Epoch {epoch+1} - Save final model\")\n",
        "            torch.save(\n",
        "                {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_final.pth\"\n",
        "            )\n",
        "\n",
        "    check_point = torch.load(OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_best.pth\")\n",
        "\n",
        "    y_df_valid_folds[[str(c) for c in range(Config.n_class)]] = check_point[\"preds\"]\n",
        "    y_df_valid_folds[\"preds\"] = check_point[\"preds\"].argmax(1)\n",
        "\n",
        "    return y_df_valid_folds"
      ],
      "id": "harmful-explanation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.030218,
          "end_time": "2021-05-12T03:03:21.928896",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.898678",
          "status": "completed"
        },
        "tags": [],
        "id": "complimentary-wright"
      },
      "source": [
        "## Main\n"
      ],
      "id": "complimentary-wright"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:21.998085Z",
          "iopub.status.busy": "2021-05-12T03:03:21.997385Z",
          "iopub.status.idle": "2021-05-12T03:03:22.000039Z",
          "shell.execute_reply": "2021-05-12T03:03:21.999634Z"
        },
        "papermill": {
          "duration": 0.04089,
          "end_time": "2021-05-12T03:03:22.000150",
          "exception": false,
          "start_time": "2021-05-12T03:03:21.959260",
          "status": "completed"
        },
        "tags": [],
        "id": "particular-adaptation"
      },
      "source": [
        "def main():\n",
        "    def get_result(result_df):\n",
        "        preds = result_df[\"preds\"].values\n",
        "        labels = result_df[\"action\"].values\n",
        "        score = get_score(labels, preds)\n",
        "        LOGGER.info(f\"Score: {score:<.5f}\")\n",
        "\n",
        "    if Config.train:\n",
        "        # train\n",
        "        oof_df = pd.DataFrame()\n",
        "        for fold in range(Config.n_fold):\n",
        "            _oof_df = train_loop(folds, fold)\n",
        "            oof_df = pd.concat([oof_df, _oof_df])\n",
        "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
        "            get_result(_oof_df)\n",
        "        # CV result\n",
        "        LOGGER.info(f\"========== CV ==========\")\n",
        "        get_result(oof_df)\n",
        "        # save result\n",
        "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)"
      ],
      "id": "particular-adaptation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-12T03:03:22.069767Z",
          "iopub.status.busy": "2021-05-12T03:03:22.068862Z",
          "iopub.status.idle": "2021-05-12T03:49:59.678255Z",
          "shell.execute_reply": "2021-05-12T03:49:59.677710Z"
        },
        "papermill": {
          "duration": 2797.64711,
          "end_time": "2021-05-12T03:49:59.678400",
          "exception": false,
          "start_time": "2021-05-12T03:03:22.031290",
          "status": "completed"
        },
        "tags": [],
        "id": "backed-journal"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "id": "backed-journal",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.209774,
          "end_time": "2021-05-12T03:50:00.096860",
          "exception": false,
          "start_time": "2021-05-12T03:49:59.887086",
          "status": "completed"
        },
        "tags": [],
        "id": "human-arena"
      },
      "source": [
        ""
      ],
      "id": "human-arena",
      "execution_count": null,
      "outputs": []
    }
  ]
}
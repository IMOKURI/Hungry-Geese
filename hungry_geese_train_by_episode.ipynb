{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abroad-piece",
    "papermill": {
     "duration": 0.025714,
     "end_time": "2021-05-12T03:01:02.640708",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.614994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About this notebook ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GX0zm2Gdvr7u"
   },
   "source": [
    "## Prepare for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2tFzcJBNvvJ5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QKDVdCItvx_T"
   },
   "outputs": [],
   "source": [
    "COMPETE = \"hungry-geese\"\n",
    "DATASETS = [\n",
    "    \"imokuri/hungrygeeseepisode\",\n",
    "]\n",
    "KERNEL_OUTPUTS = [\n",
    "    # \"imokuri/notebook8d5846e909\",\n",
    "    # \"imokuri/notebook42cdc46ffc\",\n",
    "]\n",
    "PACKAGES = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cRvzBjztxH02",
    "outputId": "8fab44ba-fca5-4247-a8dd-b9013fc24897"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    # Work around for python2 exception.\n",
    "    !python2 -m pip uninstall kaggle -y\n",
    "    !python3 -m pip uninstall kaggle -y\n",
    "    !python3 -m pip install -U -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8YygQsTv-a7",
    "outputId": "f31b0c87-c0b0-4cc2-c137-b5838c2b61d9"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    !pip install -q -U git+https://github.com/IMOKURI/kaggle_on_google_colab.git\n",
    "\n",
    "    from kaggle_on_google_colab import setup\n",
    "    kaggle = setup.Setup()\n",
    "    kaggle.dirs(COMPETE)\n",
    "\n",
    "    # !kaggle competitions download -p /content/zip {COMPETE}\n",
    "    # !unzip -q -n /content/zip/{COMPETE}.zip -d /content/{COMPETE}/input/{COMPETE}\n",
    "\n",
    "    for dataset in DATASETS:\n",
    "        dataset_name = dataset.split(\"/\")[-1]\n",
    "        !kaggle datasets download -p /content/zip {dataset}\n",
    "        !unzip -q -n /content/zip/{dataset_name}.zip -d /content/{COMPETE}/input/{dataset_name}\n",
    "\n",
    "    for kernel in KERNEL_OUTPUTS:\n",
    "        kernel_name = kernel.split(\"/\")[-1]\n",
    "        !kaggle kernels output -p /content/{COMPETE}/input/{kernel_name} {kernel}\n",
    "\n",
    "    for package in PACKAGES:\n",
    "        !pip install -q {package}\n",
    "\n",
    "    %cd /content/{COMPETE}/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pressing-commercial",
    "papermill": {
     "duration": 0.024272,
     "end_time": "2021-05-12T03:01:02.689850",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.665578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "german-ethics",
    "papermill": {
     "duration": 1.852306,
     "end_time": "2021-05-12T03:01:04.566362",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.714056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "apparent-fiction",
    "papermill": {
     "duration": 0.030961,
     "end_time": "2021-05-12T03:01:04.622818",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.591857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robust-humanity",
    "papermill": {
     "duration": 0.024539,
     "end_time": "2021-05-12T03:01:04.672270",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.647731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "designed-effect",
    "papermill": {
     "duration": 0.031167,
     "end_time": "2021-05-12T03:01:04.728079",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.696912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"../input/hungrygeeseepisode/hungry-geese-episode/\"\n",
    "OUTPUT_DIR = \"pre-models/\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "special-broadcast",
    "outputId": "c440e1e9-5651-42ee-eb0f-08c822d7471a",
    "papermill": {
     "duration": 0.31211,
     "end_time": "2021-05-12T03:01:05.064722",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.752612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4508\n"
     ]
    }
   ],
   "source": [
    "paths = [path for path in glob.glob(BASE_DIR + \"*.json\") if \"info\" not in path]\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "editorial-haiti",
    "papermill": {
     "duration": 0.024908,
     "end_time": "2021-05-12T03:01:05.115280",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.090372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "opened-python",
    "papermill": {
     "duration": 0.035637,
     "end_time": "2021-05-12T03:01:05.176119",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.140482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 440\n",
    "\n",
    "    n_class = 4\n",
    "    n_fold = 10  # 今回は fold 1つしかまわさない\n",
    "\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "\n",
    "    num_workers = 4\n",
    "    batch_size = 3200\n",
    "\n",
    "    scheduler = \"CosineAnnealingWarmRestarts\"\n",
    "    # factor = 0.2  # ReduceLROnPlateau\n",
    "    # patience = 4  # ReduceLROnPlateau\n",
    "    # eps = 1e-6  # ReduceLROnPlateau\n",
    "    # T_max = 10  # CosineAnnealingLR\n",
    "    T_0 = 10  # CosineAnnealingWarmRestarts\n",
    "\n",
    "    criterion = \"CrossEntropyLoss\"\n",
    "    lr = 1e-3\n",
    "    min_lr = 1e-4\n",
    "    weight_decay = 0\n",
    "\n",
    "    epochs = 10\n",
    "    model_name = \"geese_net\"\n",
    "\n",
    "    print_freq = 100\n",
    "\n",
    "    train = True\n",
    "    debug = False\n",
    "    apex = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "contained-singles",
    "papermill": {
     "duration": 0.031266,
     "end_time": "2021-05-12T03:01:05.235456",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.204190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    Config.epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dietary-track",
    "papermill": {
     "duration": 0.031421,
     "end_time": "2021-05-12T03:01:05.292382",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.260961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.apex:\n",
    "    from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "invalid-dispute",
    "papermill": {
     "duration": 0.169531,
     "end_time": "2021-05-12T03:01:05.488665",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.319134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "treated-serum",
    "papermill": {
     "duration": 0.025219,
     "end_time": "2021-05-12T03:01:05.539482",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.514263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "gothic-alloy",
    "papermill": {
     "duration": 0.070842,
     "end_time": "2021-05-12T03:01:05.642364",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.571522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=Config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "experienced-correspondence",
    "papermill": {
     "duration": 0.053842,
     "end_time": "2021-05-12T03:01:05.741858",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.688016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reverse_ns(y):\n",
    "    if y == 0:\n",
    "        return 1\n",
    "    if y == 1:\n",
    "        return 0\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_we(y):\n",
    "    if y == 2:\n",
    "        return 3\n",
    "    if y == 3:\n",
    "        return 2\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_nswe(y):\n",
    "    return reverse_ns(reverse_we(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "further-transaction",
    "papermill": {
     "duration": 0.042365,
     "end_time": "2021-05-12T03:01:05.826807",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.784442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "naughty-clause",
    "papermill": {
     "duration": 0.058537,
     "end_time": "2021-05-12T03:01:05.928292",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.869755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_input(obses):\n",
    "    b = np.zeros((17, 7 * 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "        pid = (p - obs[\"index\"]) % 4\n",
    "\n",
    "        # head position\n",
    "        for pos in pos_list[:1]:\n",
    "            b[0 + pid, pos] = 1\n",
    "        # tip position\n",
    "        for pos in pos_list[-1:]:\n",
    "            b[4 + pid, pos] = 1\n",
    "        # whole position\n",
    "        for pos in pos_list:\n",
    "            b[8 + pid, pos] = 1\n",
    "\n",
    "    # previous head position\n",
    "    if len(obses) > 1:\n",
    "        obs_prev = obses[-2]\n",
    "        for p, pos_list in enumerate(obs_prev[\"geese\"]):\n",
    "            for pos in pos_list[:1]:\n",
    "                b[12 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    # food\n",
    "    for pos in obs[\"food\"]:\n",
    "        b[16, pos] = 1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "i6lOS7itC0da"
   },
   "outputs": [],
   "source": [
    "def observation_num_step(obses):\n",
    "    b = np.zeros((7, 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    num_step = obs[\"step\"]  # 0-198\n",
    "    b[0, 0] = num_step / 198\n",
    "\n",
    "    return b.reshape(1, 7, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pretty-aaron",
    "papermill": {
     "duration": 0.042985,
     "end_time": "2021-05-12T03:01:06.014038",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.971053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "international-secret",
    "papermill": {
     "duration": 0.064855,
     "end_time": "2021-05-12T03:01:06.121648",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.056793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset_from_json(filepath, json_object=None, standing=0):\n",
    "    if json_object is None:\n",
    "        json_open = open(path, \"r\")\n",
    "        json_load = json.load(json_open)\n",
    "    else:\n",
    "        json_load = json_object\n",
    "\n",
    "    try:\n",
    "        winner_index = np.argmax(np.argsort(json_load[\"rewards\"]) == 3 - standing)\n",
    "\n",
    "        obses = []\n",
    "        X = []\n",
    "        y = []\n",
    "        actions = {\"NORTH\": 0, \"SOUTH\": 1, \"WEST\": 2, \"EAST\": 3}\n",
    "\n",
    "        for i in range(len(json_load[\"steps\"]) - 1):\n",
    "            if json_load[\"steps\"][i][winner_index][\"status\"] == \"ACTIVE\":\n",
    "                y_ = json_load[\"steps\"][i + 1][winner_index][\"action\"]\n",
    "                if y_ is not None:\n",
    "                    step = json_load[\"steps\"][i]\n",
    "                    step[winner_index][\"observation\"][\"geese\"] = step[0][\"observation\"][\"geese\"]\n",
    "                    step[winner_index][\"observation\"][\"food\"] = step[0][\"observation\"][\"food\"]\n",
    "                    step[winner_index][\"observation\"][\"step\"] = step[0][\"observation\"][\"step\"]\n",
    "                    obses.append(step[winner_index][\"observation\"])\n",
    "                    y.append(actions[y_])\n",
    "\n",
    "                    y.append(reverse_ns(actions[y_]))  # 上下反転\n",
    "                    y.append(reverse_we(actions[y_]))  # 左右反転\n",
    "                    y.append(reverse_nswe(actions[y_]))  # 上下左右反転\n",
    "\n",
    "        for j in range(len(obses)):\n",
    "            # X_ = make_input(obses[: j + 1])\n",
    "\n",
    "            X_ = []\n",
    "            X_.append(make_input(obses[: j + 1]))\n",
    "            # X_.append(observation_num_step(obses[: j + 1]))\n",
    "            X_ = np.concatenate(X_)\n",
    "\n",
    "            X.append(X_)\n",
    "\n",
    "            X.append(X_[:, ::-1, :])  # 上下反転\n",
    "            X.append(X_[:, :, ::-1])  # 左右反転\n",
    "            X.append(X_[:, ::-1, ::-1])  # 上下左右反転\n",
    "\n",
    "        X = np.array(X, dtype=np.float32)  # [starting_step:]\n",
    "        y = np.array(y, dtype=np.uint8)  # [starting_step:]\n",
    "\n",
    "        return X, y\n",
    "    except:\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "4134662bdbe04a918d9809632e268ef8",
      "8ddb49ac3c91409f99a569a061a70b3d",
      "0857c0fa22b544488d65bb2c7dad18ee",
      "e33e4f894b424988b316c468bc9225ce",
      "c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "f905db5005be40b194ea150c8b0deb9f",
      "04a486aa6f454d8f92e388dba1b9ee21",
      "507d2b6a02bb43d0bb4c8c2734f19cbb"
     ]
    },
    "id": "handled-pleasure",
    "outputId": "955c1c6b-36bc-4b30-dc44-b72b05398f8c",
    "papermill": {
     "duration": 15.320591,
     "end_time": "2021-05-12T03:01:21.474816",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.154225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4f23b7053947a49511ad16380c32cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4508.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num episode: 2863164\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for path in tqdm(paths[: int(len(paths))]):\n",
    "    X, y = create_dataset_from_json(path, standing=0)  # use only winners' moves\n",
    "    if X is not 0:\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "persistent-loading",
    "papermill": {
     "duration": 112.92618,
     "end_time": "2021-05-12T03:03:14.428162",
     "exception": false,
     "start_time": "2021-05-12T03:01:21.501982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: データをuniqueにしたいがメモリエラーになってしまう。\n",
    "\n",
    "# X_train, unique_index = np.unique(X_train, axis=0, return_index=True)  # remove duplicate\n",
    "# y_train = y_train[unique_index]\n",
    "\n",
    "# y_train = np.eye(4, dtype=\"uint8\")[y_train]  # to categorical\n",
    "\n",
    "# print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# まとめてuniqueかけるとメモリ量が足りないので、いくつかのグループに分けてuniqueにする\n",
    "\n",
    "X_train_sum_obs = X_train.reshape(X_train.shape[0], -1).sum(1)\n",
    "X_train_group = np.unique(X_train_sum_obs)\n",
    "X_train_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f76000a2df4141b217835818623eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=75.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num episode: 2862924\n"
     ]
    }
   ],
   "source": [
    "X_train_unique = []\n",
    "y_train_unique = []\n",
    "for group in tqdm(X_train_group):\n",
    "    group_index = np.where(X_train_sum_obs == group)\n",
    "\n",
    "    X_train_ = X_train[group_index]\n",
    "    y_train_ = y_train[group_index]\n",
    "\n",
    "    X_train_, unique_index = np.unique(X_train_, axis=0, return_index=True)  # remove duplicate\n",
    "    y_train_ = y_train_[unique_index]\n",
    "\n",
    "    X_train_unique.append(X_train_)\n",
    "    y_train_unique.append(y_train_)\n",
    "\n",
    "X_train = np.concatenate(X_train_unique)\n",
    "y_train = np.concatenate(y_train_unique)\n",
    "\n",
    "print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "micro-french",
    "papermill": {
     "duration": 0.033413,
     "end_time": "2021-05-12T03:03:15.360395",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.326982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    X_train = X_train[:1000]\n",
    "    y_train = y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "wrong-pastor",
    "outputId": "406a2f1d-0b8a-46bf-ca01-546f3110c301",
    "papermill": {
     "duration": 0.036161,
     "end_time": "2021-05-12T03:03:15.425149",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.388988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2862919</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2862920</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2862921</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2862922</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2862923</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2862924 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         action\n",
       "0             1\n",
       "1             1\n",
       "2             3\n",
       "3             0\n",
       "4             2\n",
       "...         ...\n",
       "2862919       1\n",
       "2862920       2\n",
       "2862921       3\n",
       "2862922       2\n",
       "2862923       3\n",
       "\n",
       "[2862924 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(y_train)\n",
    "y_df.columns = [\"action\"]\n",
    "y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "touched-coordinate",
    "papermill": {
     "duration": 0.027968,
     "end_time": "2021-05-12T03:03:15.557122",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.529154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "moving-skill",
    "outputId": "7542c4b4-f7d3-444c-8450-50bffddb1892",
    "papermill": {
     "duration": 0.202337,
     "end_time": "2021-05-12T03:03:15.787529",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.585192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  action\n",
      "0     0         68407\n",
      "      1         68407\n",
      "      2         74739\n",
      "      3         74740\n",
      "1     0         68407\n",
      "      1         68407\n",
      "      2         74739\n",
      "      3         74740\n",
      "2     0         68407\n",
      "      1         68407\n",
      "      2         74740\n",
      "      3         74739\n",
      "3     0         68407\n",
      "      1         68407\n",
      "      2         74740\n",
      "      3         74739\n",
      "4     0         68407\n",
      "      1         68407\n",
      "      2         74739\n",
      "      3         74739\n",
      "5     0         68407\n",
      "      1         68407\n",
      "      2         74739\n",
      "      3         74739\n",
      "6     0         68407\n",
      "      1         68407\n",
      "      2         74739\n",
      "      3         74739\n",
      "7     0         68407\n",
      "      1         68407\n",
      "      2         74739\n",
      "      3         74739\n",
      "8     0         68407\n",
      "      1         68407\n",
      "      2         74739\n",
      "      3         74739\n",
      "9     0         68407\n",
      "      1         68407\n",
      "      2         74739\n",
      "      3         74739\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "folds = y_df.copy()\n",
    "Fold = StratifiedKFold(n_splits=Config.n_fold, shuffle=True, random_state=Config.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[\"action\"])):\n",
    "    folds.loc[val_index, \"fold\"] = int(n)\n",
    "folds[\"fold\"] = folds[\"fold\"].astype(int)\n",
    "print(folds.groupby([\"fold\", \"action\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "creative-football",
    "papermill": {
     "duration": 0.029031,
     "end_time": "2021-05-12T03:03:15.845114",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.816083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "other-murder",
    "papermill": {
     "duration": 0.037264,
     "end_time": "2021-05-12T03:03:15.911219",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.873955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, array, label):\n",
    "        self.array = array\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx], torch.tensor(self.label[idx]).long()\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, array):\n",
    "        self.array = array\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adjusted-delhi",
    "outputId": "39504950-84bc-4692-8b90-8a5b64f741e0",
    "papermill": {
     "duration": 0.063691,
     "end_time": "2021-05-12T03:03:16.003693",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.940002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 7, 11) tensor(1)\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "train_ds = TrainDataset(X_train, y_train)\n",
    "\n",
    "for i in range(1):\n",
    "    obs, action = train_ds[i]\n",
    "    print(obs.shape, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceramic-startup",
    "papermill": {
     "duration": 0.02876,
     "end_time": "2021-05-12T03:03:16.061575",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.032815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "unique-trick",
    "papermill": {
     "duration": 0.039055,
     "end_time": "2021-05-12T03:03:16.130239",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.091184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TorusConv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
    "        super().__init__()\n",
    "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([x[:, :, :, -self.edge_size[1] :], x, x[:, :, :, : self.edge_size[1]]], dim=3)\n",
    "        h = torch.cat([h[:, :, -self.edge_size[0] :], h, h[:, :, : self.edge_size[0]]], dim=2)\n",
    "        h = self.conv(h)\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "extra-bradford",
    "papermill": {
     "duration": 0.042421,
     "end_time": "2021-05-12T03:03:16.202024",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.159603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GeeseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers, filters = 12, 32\n",
    "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p = nn.Linear(filters, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(filters * 2, filters, bias=False)\n",
    "        self.head_v2 = nn.Linear(filters, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h_p = F.relu_(self.conv_p(h))\n",
    "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        p = self.head_p(h_head_p)\n",
    "\n",
    "        h_v = F.relu_(self.conv_v(h))\n",
    "        h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_avg_v = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
    "\n",
    "        h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_avg_v], 1)))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p, \"value\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "jspEE71c2Yma"
   },
   "outputs": [],
   "source": [
    "class GeeseNetAlpha(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers, filters = 12, 64\n",
    "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        # self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p1 = nn.Linear(filters * 2 + 77, filters, bias=False)\n",
    "        self.head_p2 = nn.Linear(filters, 4, bias=False)\n",
    "        # self.head_v1 = nn.Linear(filters * 2, filters, bias=False)\n",
    "        # self.head_v2 = nn.Linear(filters, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        # x = x[:, :-1]\n",
    "        # num_step = x[:, -1, 0, 0].view(x.size(0), 1)\n",
    "\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h_p = F.relu_(self.conv_p(h))\n",
    "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_avg_p1 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(-1)\n",
    "        h_avg_p2 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(1)\n",
    "\n",
    "        h_p = F.relu_(self.head_p1(torch.cat([h_head_p, h_avg_p1, h_avg_p2], 1)))\n",
    "        p = self.head_p2(h_p)\n",
    "\n",
    "        # h_v = F.relu_(self.conv_v(h))\n",
    "        # h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        # h_avg_v = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
    "\n",
    "        # h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_avg_v], 1)))\n",
    "        # v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p}  # \"value\": v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "objective-victoria",
    "outputId": "1ab137a5-e26e-4b9c-ff85-95fef713b755",
    "papermill": {
     "duration": 4.955868,
     "end_time": "2021-05-12T03:03:21.187355",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.231487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: 505,088\n",
      "{'policy': tensor([[-0.0146,  0.0525,  0.0750,  0.0517],\n",
      "        [-0.0780, -0.0301,  0.1190,  0.0674],\n",
      "        [-0.1203,  0.0389,  0.0797,  0.0230],\n",
      "        [-0.0968, -0.1358, -0.0216,  0.0691]], grad_fn=<MmBackward>)}\n",
      "tensor([2, 2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "model = GeeseNetAlpha()\n",
    "# print(model)\n",
    "\n",
    "params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"params: {params:,}\")\n",
    "\n",
    "train_ds = TrainDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "for obs, action in train_loader:\n",
    "    output = model(obs)\n",
    "    print(output)\n",
    "    print(f\"{torch.argmax(output['policy'], dim=1)}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "military-fiction",
    "papermill": {
     "duration": 0.033001,
     "end_time": "2021-05-12T03:03:21.255277",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.222276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sophisticated-hearts",
    "papermill": {
     "duration": 0.031759,
     "end_time": "2021-05-12T03:03:21.319849",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.288090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "designing-detective",
    "papermill": {
     "duration": 0.03139,
     "end_time": "2021-05-12T03:03:21.383038",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.351648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "passive-cooper",
    "papermill": {
     "duration": 0.038846,
     "end_time": "2021-05-12T03:03:21.454085",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.415239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thirty-tracy",
    "papermill": {
     "duration": 0.0293,
     "end_time": "2021-05-12T03:03:21.514179",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.484879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "introductory-brooklyn",
    "papermill": {
     "duration": 0.039424,
     "end_time": "2021-05-12T03:03:21.582969",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.543545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "raising-laugh",
    "papermill": {
     "duration": 0.042063,
     "end_time": "2021-05-12T03:03:21.654559",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.612496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "\n",
    "    for step, (obs, action) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        y_preds = model(obs.float())[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "\n",
    "        # record loss\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "        if Config.apex:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), Config.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % Config.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print(\n",
    "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
    "                f\"Loss: {losses.val:.4f}({losses.avg:.4f}) \"\n",
    "                f\"Grad: {grad_norm:.4f} \"\n",
    "                f\"LR: {scheduler.get_last_lr()[0]:.6f}  \"\n",
    "            )\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "plain-neighbor",
    "papermill": {
     "duration": 0.041056,
     "end_time": "2021-05-12T03:03:21.726585",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.685529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "\n",
    "    for step, (obs, action) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(obs)[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print(\n",
    "                f\"EVAL: [{step}/{len(valid_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
    "                f\"Loss: {losses.val:.4f}({losses.avg:.4f}) \"\n",
    "            )\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "integrated-classification",
    "papermill": {
     "duration": 0.029832,
     "end_time": "2021-05-12T03:03:21.786427",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.756595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "harmful-explanation",
    "papermill": {
     "duration": 0.05136,
     "end_time": "2021-05-12T03:03:21.868561",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.817201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(folds, fold):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    X_train_folds = X_train[folds[\"fold\"] != fold]\n",
    "    X_valid_folds = X_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    y_train_folds = y_train[folds[\"fold\"] != fold]\n",
    "    y_valid_folds = y_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    y_df_train_folds = y_df[folds[\"fold\"] != fold]\n",
    "    y_df_valid_folds = y_df[folds[\"fold\"] == fold]\n",
    "\n",
    "    train_dataset = TrainDataset(X_train_folds, y_train_folds)\n",
    "    valid_dataset = TrainDataset(X_valid_folds, y_valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if Config.scheduler == \"ReduceLROnPlateau\":\n",
    "            scheduler = ReduceLROnPlateau(\n",
    "                optimizer, mode=\"min\", factor=Config.factor, patience=Config.patience, verbose=True, eps=Config.eps\n",
    "            )\n",
    "        elif Config.scheduler == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=Config.T_max, eta_min=Config.min_lr, last_epoch=-1)\n",
    "        elif Config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "            scheduler = CosineAnnealingWarmRestarts(\n",
    "                optimizer, T_0=Config.T_0, T_mult=1, eta_min=Config.min_lr, last_epoch=-1\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = GeeseNetAlpha()\n",
    "    model.to(device)\n",
    "\n",
    "    # Use multi GPU\n",
    "    if device == torch.device(\"cuda\") and not Config.apex:\n",
    "        model = torch.nn.DataParallel(model)  # make parallel\n",
    "        # torch.backends.cudnn.benchmark=True\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=Config.lr, weight_decay=Config.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # apex\n",
    "    # ====================================================\n",
    "    if Config.apex:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
    "\n",
    "    # ====================================================\n",
    "    # Criterion\n",
    "    # ====================================================\n",
    "    def get_criterion():\n",
    "        if Config.criterion == \"CrossEntropyLoss\":\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        return criterion\n",
    "\n",
    "    criterion = get_criterion()\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    best_score = 0.0\n",
    "    best_loss = np.inf\n",
    "    best_preds = None\n",
    "\n",
    "    for epoch in range(Config.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "\n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(y_valid_folds, preds.argmax(1))\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Accuracy: {score}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n",
    "            torch.save(\n",
    "                # {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_best.pth\"\n",
    "                model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_best.pth\"\n",
    "            )\n",
    "            best_preds = preds\n",
    "\n",
    "        if epoch == Config.epochs - 1:\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save final model\")\n",
    "            torch.save(\n",
    "                # {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_final.pth\"\n",
    "                model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_final.pth\"\n",
    "            )\n",
    "\n",
    "    # check_point = torch.load(OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_best.pth\")\n",
    "\n",
    "    y_df_valid_folds[[str(c) for c in range(Config.n_class)]] = best_preds  # check_point[\"preds\"]\n",
    "    y_df_valid_folds[\"preds\"] = best_preds.argmax(1)  # check_point[\"preds\"].argmax(1)\n",
    "\n",
    "    return y_df_valid_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "complimentary-wright",
    "papermill": {
     "duration": 0.030218,
     "end_time": "2021-05-12T03:03:21.928896",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.898678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "particular-adaptation",
    "papermill": {
     "duration": 0.04089,
     "end_time": "2021-05-12T03:03:22.000150",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.959260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    def get_result(result_df):\n",
    "        preds = result_df[\"preds\"].values\n",
    "        labels = result_df[\"action\"].values\n",
    "        score = get_score(labels, preds)\n",
    "        LOGGER.info(f\"Score: {score:<.5f}\")\n",
    "\n",
    "    if Config.train:\n",
    "        # train\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(Config.n_fold):\n",
    "            _oof_df = train_loop(folds, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df)\n",
    "            break  # 今回は fold 1つしかまわさない\n",
    "        # CV result\n",
    "        # LOGGER.info(f\"========== CV ==========\")\n",
    "        # get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "backed-journal",
    "outputId": "c9f0ff3d-795e-466b-e22e-9ba21d08c874",
    "papermill": {
     "duration": 2797.64711,
     "end_time": "2021-05-12T03:49:59.678400",
     "exception": false,
     "start_time": "2021-05-12T03:03:22.031290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/805] Elapsed 0m 3s (remain 43m 49s) Loss: 1.3881(1.3881) Grad: 0.3445 LR: 0.001000  \n",
      "Epoch: [1][100/805] Elapsed 1m 11s (remain 8m 18s) Loss: 0.6174(0.6839) Grad: 1.1552 LR: 0.001000  \n",
      "Epoch: [1][200/805] Elapsed 2m 19s (remain 6m 59s) Loss: 0.5495(0.6304) Grad: 0.6035 LR: 0.001000  \n",
      "Epoch: [1][300/805] Elapsed 3m 27s (remain 5m 48s) Loss: 0.5227(0.6028) Grad: 0.9458 LR: 0.001000  \n",
      "Epoch: [1][400/805] Elapsed 4m 36s (remain 4m 38s) Loss: 0.4957(0.5840) Grad: 0.4088 LR: 0.001000  \n",
      "Epoch: [1][500/805] Elapsed 5m 44s (remain 3m 28s) Loss: 0.5237(0.5714) Grad: 0.5722 LR: 0.001000  \n",
      "Epoch: [1][600/805] Elapsed 6m 52s (remain 2m 20s) Loss: 0.5289(0.5613) Grad: 0.4071 LR: 0.001000  \n",
      "Epoch: [1][700/805] Elapsed 8m 0s (remain 1m 11s) Loss: 0.5178(0.5537) Grad: 0.3928 LR: 0.001000  \n",
      "Epoch: [1][800/805] Elapsed 9m 9s (remain 0m 2s) Loss: 0.5150(0.5475) Grad: 0.3996 LR: 0.001000  \n",
      "Epoch: [1][804/805] Elapsed 9m 11s (remain 0m 0s) Loss: 0.4934(0.5473) Grad: 0.4207 LR: 0.001000  \n",
      "EVAL: [0/90] Elapsed 0m 0s (remain 0m 51s) Loss: 0.7082(0.7082) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.5473  avg_val_loss: 0.5028  time: 569s\n",
      "Epoch 1 - Accuracy: 0.777025634577164\n",
      "Epoch 1 - Save Best Score: 0.7770 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [89/90] Elapsed 0m 16s (remain 0m 0s) Loss: 0.3072(0.5028) \n",
      "Epoch: [2][0/805] Elapsed 0m 1s (remain 18m 21s) Loss: 0.4945(0.4945) Grad: 0.3693 LR: 0.000978  \n",
      "Epoch: [2][100/805] Elapsed 1m 9s (remain 8m 5s) Loss: 0.4764(0.4936) Grad: 0.5142 LR: 0.000978  \n",
      "Epoch: [2][200/805] Elapsed 2m 17s (remain 6m 54s) Loss: 0.5062(0.4932) Grad: 0.6635 LR: 0.000978  \n",
      "Epoch: [2][300/805] Elapsed 3m 26s (remain 5m 45s) Loss: 0.4858(0.4924) Grad: 0.2970 LR: 0.000978  \n",
      "Epoch: [2][400/805] Elapsed 4m 34s (remain 4m 36s) Loss: 0.4932(0.4912) Grad: 0.6144 LR: 0.000978  \n",
      "Epoch: [2][500/805] Elapsed 5m 42s (remain 3m 27s) Loss: 0.4927(0.4908) Grad: 0.5036 LR: 0.000978  \n",
      "Epoch: [2][600/805] Elapsed 6m 50s (remain 2m 19s) Loss: 0.5040(0.4897) Grad: 0.4105 LR: 0.000978  \n",
      "Epoch: [2][700/805] Elapsed 7m 59s (remain 1m 11s) Loss: 0.4797(0.4887) Grad: 0.4742 LR: 0.000978  \n",
      "Epoch: [2][800/805] Elapsed 9m 7s (remain 0m 2s) Loss: 0.4630(0.4878) Grad: 0.3651 LR: 0.000978  \n",
      "Epoch: [2][804/805] Elapsed 9m 10s (remain 0m 0s) Loss: 0.4947(0.4878) Grad: 0.4934 LR: 0.000978  \n",
      "EVAL: [0/90] Elapsed 0m 0s (remain 0m 52s) Loss: 0.6968(0.6968) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4878  avg_val_loss: 0.4878  time: 567s\n",
      "Epoch 2 - Accuracy: 0.7840010059624231\n",
      "Epoch 2 - Save Best Score: 0.7840 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [89/90] Elapsed 0m 16s (remain 0m 0s) Loss: 0.2953(0.4878) \n",
      "Epoch: [3][0/805] Elapsed 0m 1s (remain 16m 55s) Loss: 0.4709(0.4709) Grad: 0.3525 LR: 0.000914  \n",
      "Epoch: [3][100/805] Elapsed 1m 9s (remain 8m 4s) Loss: 0.4679(0.4754) Grad: 0.3862 LR: 0.000914  \n",
      "Epoch: [3][200/805] Elapsed 2m 17s (remain 6m 54s) Loss: 0.4640(0.4743) Grad: 0.3633 LR: 0.000914  \n",
      "Epoch: [3][300/805] Elapsed 3m 26s (remain 5m 45s) Loss: 0.4838(0.4741) Grad: 0.4831 LR: 0.000914  \n",
      "Epoch: [3][400/805] Elapsed 4m 34s (remain 4m 36s) Loss: 0.4678(0.4744) Grad: 0.3511 LR: 0.000914  \n",
      "Epoch: [3][500/805] Elapsed 5m 42s (remain 3m 28s) Loss: 0.4793(0.4743) Grad: 0.4359 LR: 0.000914  \n",
      "Epoch: [3][600/805] Elapsed 6m 51s (remain 2m 19s) Loss: 0.4837(0.4741) Grad: 0.2932 LR: 0.000914  \n",
      "Epoch: [3][700/805] Elapsed 7m 59s (remain 1m 11s) Loss: 0.4775(0.4736) Grad: 0.3003 LR: 0.000914  \n",
      "Epoch: [3][800/805] Elapsed 9m 7s (remain 0m 2s) Loss: 0.4716(0.4735) Grad: 0.2590 LR: 0.000914  \n",
      "Epoch: [3][804/805] Elapsed 9m 10s (remain 0m 0s) Loss: 0.4996(0.4735) Grad: 0.4274 LR: 0.000914  \n",
      "EVAL: [0/90] Elapsed 0m 0s (remain 0m 59s) Loss: 0.6908(0.6908) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.4735  avg_val_loss: 0.4753  time: 568s\n",
      "Epoch 3 - Accuracy: 0.7902917640319532\n",
      "Epoch 3 - Save Best Score: 0.7903 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [89/90] Elapsed 0m 16s (remain 0m 0s) Loss: 0.2933(0.4753) \n",
      "Epoch: [4][0/805] Elapsed 0m 1s (remain 17m 6s) Loss: 0.4787(0.4787) Grad: 0.3925 LR: 0.000815  \n",
      "Epoch: [4][100/805] Elapsed 1m 9s (remain 8m 4s) Loss: 0.4446(0.4655) Grad: 0.2700 LR: 0.000815  \n",
      "Epoch: [4][200/805] Elapsed 2m 17s (remain 6m 53s) Loss: 0.4900(0.4648) Grad: 0.3623 LR: 0.000815  \n",
      "Epoch: [4][300/805] Elapsed 3m 25s (remain 5m 44s) Loss: 0.4673(0.4649) Grad: 0.3450 LR: 0.000815  \n",
      "Epoch: [4][400/805] Elapsed 4m 34s (remain 4m 36s) Loss: 0.4636(0.4651) Grad: 0.4003 LR: 0.000815  \n",
      "Epoch: [4][500/805] Elapsed 5m 42s (remain 3m 27s) Loss: 0.4784(0.4653) Grad: 0.4368 LR: 0.000815  \n",
      "Epoch: [4][600/805] Elapsed 6m 50s (remain 2m 19s) Loss: 0.4609(0.4653) Grad: 0.4037 LR: 0.000815  \n",
      "Epoch: [4][700/805] Elapsed 7m 59s (remain 1m 11s) Loss: 0.4510(0.4651) Grad: 0.3115 LR: 0.000815  \n",
      "Epoch: [4][800/805] Elapsed 9m 7s (remain 0m 2s) Loss: 0.4523(0.4648) Grad: 0.3132 LR: 0.000815  \n",
      "Epoch: [4][804/805] Elapsed 9m 10s (remain 0m 0s) Loss: 0.4653(0.4648) Grad: 0.5064 LR: 0.000815  \n",
      "EVAL: [0/90] Elapsed 0m 0s (remain 0m 53s) Loss: 0.6972(0.6972) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.4648  avg_val_loss: 0.4742  time: 567s\n",
      "Epoch 4 - Accuracy: 0.790875082520355\n",
      "Epoch 4 - Save Best Score: 0.7909 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [89/90] Elapsed 0m 16s (remain 0m 0s) Loss: 0.2949(0.4742) \n",
      "Epoch: [5][0/805] Elapsed 0m 1s (remain 17m 14s) Loss: 0.4624(0.4624) Grad: 0.2779 LR: 0.000689  \n",
      "Epoch: [5][100/805] Elapsed 1m 9s (remain 8m 4s) Loss: 0.4603(0.4565) Grad: 0.3781 LR: 0.000689  \n",
      "Epoch: [5][200/805] Elapsed 2m 17s (remain 6m 54s) Loss: 0.4537(0.4561) Grad: 0.3008 LR: 0.000689  \n",
      "Epoch: [5][300/805] Elapsed 3m 26s (remain 5m 45s) Loss: 0.4381(0.4562) Grad: 0.3195 LR: 0.000689  \n",
      "Epoch: [5][400/805] Elapsed 4m 34s (remain 4m 36s) Loss: 0.4428(0.4566) Grad: 0.2803 LR: 0.000689  \n",
      "Epoch: [5][500/805] Elapsed 5m 42s (remain 3m 27s) Loss: 0.4395(0.4570) Grad: 0.2527 LR: 0.000689  \n",
      "Epoch: [5][600/805] Elapsed 6m 50s (remain 2m 19s) Loss: 0.4465(0.4573) Grad: 0.3193 LR: 0.000689  \n",
      "Epoch: [5][700/805] Elapsed 7m 59s (remain 1m 11s) Loss: 0.4466(0.4575) Grad: 0.4570 LR: 0.000689  \n",
      "Epoch: [5][800/805] Elapsed 9m 7s (remain 0m 2s) Loss: 0.4669(0.4577) Grad: 0.3471 LR: 0.000689  \n",
      "Epoch: [5][804/805] Elapsed 9m 10s (remain 0m 0s) Loss: 0.4752(0.4578) Grad: 0.4431 LR: 0.000689  \n",
      "EVAL: [0/90] Elapsed 0m 0s (remain 0m 53s) Loss: 0.6960(0.6960) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.4578  avg_val_loss: 0.4727  time: 567s\n",
      "Epoch 5 - Accuracy: 0.7911510236016948\n",
      "Epoch 5 - Save Best Score: 0.7912 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [89/90] Elapsed 0m 16s (remain 0m 0s) Loss: 0.2840(0.4727) \n",
      "Epoch: [6][0/805] Elapsed 0m 1s (remain 17m 21s) Loss: 0.4473(0.4473) Grad: 0.3251 LR: 0.000550  \n",
      "Epoch: [6][100/805] Elapsed 1m 9s (remain 8m 5s) Loss: 0.4477(0.4488) Grad: 0.4414 LR: 0.000550  \n",
      "Epoch: [6][200/805] Elapsed 2m 17s (remain 6m 54s) Loss: 0.4412(0.4494) Grad: 0.3024 LR: 0.000550  \n",
      "Epoch: [6][300/805] Elapsed 3m 26s (remain 5m 44s) Loss: 0.4406(0.4502) Grad: 0.2307 LR: 0.000550  \n",
      "Epoch: [6][400/805] Elapsed 4m 34s (remain 4m 36s) Loss: 0.4711(0.4505) Grad: 0.3267 LR: 0.000550  \n",
      "Epoch: [6][500/805] Elapsed 5m 42s (remain 3m 27s) Loss: 0.4407(0.4508) Grad: 0.3069 LR: 0.000550  \n",
      "Epoch: [6][600/805] Elapsed 6m 50s (remain 2m 19s) Loss: 0.4273(0.4507) Grad: 0.3648 LR: 0.000550  \n",
      "Epoch: [6][700/805] Elapsed 7m 59s (remain 1m 11s) Loss: 0.4491(0.4511) Grad: 0.3046 LR: 0.000550  \n",
      "Epoch: [6][800/805] Elapsed 9m 7s (remain 0m 2s) Loss: 0.4392(0.4511) Grad: 0.2575 LR: 0.000550  \n",
      "Epoch: [6][804/805] Elapsed 9m 10s (remain 0m 0s) Loss: 0.4574(0.4512) Grad: 0.3659 LR: 0.000550  \n",
      "EVAL: [0/90] Elapsed 0m 0s (remain 0m 53s) Loss: 0.6897(0.6897) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.4512  avg_val_loss: 0.4672  time: 567s\n",
      "Epoch 6 - Accuracy: 0.7941619250208702\n",
      "Epoch 6 - Save Best Score: 0.7942 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [89/90] Elapsed 0m 16s (remain 0m 0s) Loss: 0.2832(0.4672) \n",
      "Epoch: [7][0/805] Elapsed 0m 1s (remain 17m 14s) Loss: 0.4393(0.4393) Grad: 0.2739 LR: 0.000411  \n",
      "Epoch: [7][100/805] Elapsed 1m 9s (remain 8m 4s) Loss: 0.4510(0.4434) Grad: 0.3307 LR: 0.000411  \n",
      "Epoch: [7][200/805] Elapsed 2m 17s (remain 6m 54s) Loss: 0.4275(0.4426) Grad: 0.2370 LR: 0.000411  \n",
      "Epoch: [7][300/805] Elapsed 3m 25s (remain 5m 44s) Loss: 0.4511(0.4430) Grad: 0.2744 LR: 0.000411  \n",
      "Epoch: [7][400/805] Elapsed 4m 34s (remain 4m 36s) Loss: 0.4666(0.4438) Grad: 0.3290 LR: 0.000411  \n",
      "Epoch: [7][500/805] Elapsed 5m 42s (remain 3m 27s) Loss: 0.4596(0.4439) Grad: 0.3414 LR: 0.000411  \n",
      "Epoch: [7][600/805] Elapsed 6m 50s (remain 2m 19s) Loss: 0.4596(0.4441) Grad: 0.3949 LR: 0.000411  \n",
      "Epoch: [7][700/805] Elapsed 7m 59s (remain 1m 11s) Loss: 0.4724(0.4446) Grad: 0.3638 LR: 0.000411  \n",
      "Epoch: [7][800/805] Elapsed 9m 7s (remain 0m 2s) Loss: 0.4493(0.4448) Grad: 0.3192 LR: 0.000411  \n",
      "Epoch: [7][804/805] Elapsed 9m 10s (remain 0m 0s) Loss: 0.4558(0.4449) Grad: 0.2407 LR: 0.000411  \n",
      "EVAL: [0/90] Elapsed 0m 0s (remain 0m 52s) Loss: 0.6899(0.6899) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.4449  avg_val_loss: 0.4644  time: 567s\n",
      "Epoch 7 - Accuracy: 0.7955835455285319\n",
      "Epoch 7 - Save Best Score: 0.7956 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [89/90] Elapsed 0m 16s (remain 0m 0s) Loss: 0.2820(0.4644) \n",
      "Epoch: [8][0/805] Elapsed 0m 1s (remain 17m 15s) Loss: 0.4309(0.4309) Grad: 0.2764 LR: 0.000285  \n",
      "Epoch: [8][100/805] Elapsed 1m 9s (remain 8m 4s) Loss: 0.4329(0.4359) Grad: 0.2673 LR: 0.000285  \n",
      "Epoch: [8][200/805] Elapsed 2m 17s (remain 6m 54s) Loss: 0.4386(0.4369) Grad: 0.2889 LR: 0.000285  \n",
      "Epoch: [8][300/805] Elapsed 3m 26s (remain 5m 45s) Loss: 0.4406(0.4372) Grad: 0.2616 LR: 0.000285  \n",
      "Epoch: [8][400/805] Elapsed 4m 34s (remain 4m 36s) Loss: 0.4517(0.4374) Grad: 0.3849 LR: 0.000285  \n",
      "Epoch: [8][500/805] Elapsed 5m 42s (remain 3m 27s) Loss: 0.4315(0.4377) Grad: 0.3417 LR: 0.000285  \n",
      "Epoch: [8][600/805] Elapsed 6m 50s (remain 2m 19s) Loss: 0.4235(0.4378) Grad: 0.4205 LR: 0.000285  \n",
      "Epoch: [8][700/805] Elapsed 7m 59s (remain 1m 11s) Loss: 0.4580(0.4384) Grad: 0.3266 LR: 0.000285  \n",
      "Epoch: [8][800/805] Elapsed 9m 7s (remain 0m 2s) Loss: 0.4146(0.4384) Grad: 0.2937 LR: 0.000285  \n",
      "Epoch: [8][804/805] Elapsed 9m 10s (remain 0m 0s) Loss: 0.4510(0.4385) Grad: 0.3402 LR: 0.000285  \n",
      "EVAL: [0/90] Elapsed 0m 0s (remain 0m 54s) Loss: 0.6832(0.6832) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.4385  avg_val_loss: 0.4642  time: 567s\n",
      "Epoch 8 - Accuracy: 0.7957651776327049\n",
      "Epoch 8 - Save Best Score: 0.7958 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [89/90] Elapsed 0m 16s (remain 0m 0s) Loss: 0.2848(0.4642) \n",
      "Epoch: [9][0/805] Elapsed 0m 1s (remain 17m 15s) Loss: 0.4318(0.4318) Grad: 0.2694 LR: 0.000186  \n",
      "Epoch: [9][100/805] Elapsed 1m 9s (remain 8m 5s) Loss: 0.4105(0.4301) Grad: 0.3077 LR: 0.000186  \n",
      "Epoch: [9][200/805] Elapsed 2m 17s (remain 6m 54s) Loss: 0.4286(0.4323) Grad: 0.3014 LR: 0.000186  \n",
      "Epoch: [9][300/805] Elapsed 3m 26s (remain 5m 45s) Loss: 0.4279(0.4320) Grad: 0.2779 LR: 0.000186  \n",
      "Epoch: [9][400/805] Elapsed 4m 34s (remain 4m 36s) Loss: 0.4436(0.4318) Grad: 0.4073 LR: 0.000186  \n",
      "Epoch: [9][500/805] Elapsed 5m 42s (remain 3m 28s) Loss: 0.4411(0.4320) Grad: 0.2936 LR: 0.000186  \n",
      "Epoch: [9][600/805] Elapsed 6m 51s (remain 2m 19s) Loss: 0.4181(0.4322) Grad: 0.4184 LR: 0.000186  \n",
      "Epoch: [9][700/805] Elapsed 7m 59s (remain 1m 11s) Loss: 0.4240(0.4325) Grad: 0.2943 LR: 0.000186  \n",
      "Epoch: [9][800/805] Elapsed 9m 7s (remain 0m 2s) Loss: 0.4417(0.4326) Grad: 0.3289 LR: 0.000186  \n",
      "Epoch: [9][804/805] Elapsed 9m 10s (remain 0m 0s) Loss: 0.4284(0.4327) Grad: 0.2665 LR: 0.000186  \n",
      "EVAL: [0/90] Elapsed 0m 0s (remain 1m 3s) Loss: 0.6836(0.6836) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.4327  avg_val_loss: 0.4639  time: 567s\n",
      "Epoch 9 - Accuracy: 0.7960550904143657\n",
      "Epoch 9 - Save Best Score: 0.7961 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [89/90] Elapsed 0m 16s (remain 0m 0s) Loss: 0.2846(0.4639) \n",
      "Epoch: [10][0/805] Elapsed 0m 1s (remain 18m 21s) Loss: 0.4371(0.4371) Grad: 0.3335 LR: 0.000122  \n",
      "Epoch: [10][100/805] Elapsed 1m 9s (remain 8m 6s) Loss: 0.4198(0.4249) Grad: 0.2861 LR: 0.000122  \n",
      "Epoch: [10][200/805] Elapsed 2m 18s (remain 6m 54s) Loss: 0.4292(0.4263) Grad: 0.3284 LR: 0.000122  \n",
      "Epoch: [10][300/805] Elapsed 3m 26s (remain 5m 45s) Loss: 0.4192(0.4269) Grad: 0.3282 LR: 0.000122  \n",
      "Epoch: [10][400/805] Elapsed 4m 34s (remain 4m 36s) Loss: 0.4375(0.4273) Grad: 0.3146 LR: 0.000122  \n",
      "Epoch: [10][500/805] Elapsed 5m 42s (remain 3m 28s) Loss: 0.4224(0.4275) Grad: 0.2937 LR: 0.000122  \n",
      "Epoch: [10][600/805] Elapsed 6m 51s (remain 2m 19s) Loss: 0.4194(0.4278) Grad: 0.3225 LR: 0.000122  \n",
      "Epoch: [10][700/805] Elapsed 7m 59s (remain 1m 11s) Loss: 0.4387(0.4278) Grad: 0.3909 LR: 0.000122  \n",
      "Epoch: [10][800/805] Elapsed 9m 7s (remain 0m 2s) Loss: 0.4389(0.4283) Grad: 0.3634 LR: 0.000122  \n",
      "Epoch: [10][804/805] Elapsed 9m 10s (remain 0m 0s) Loss: 0.4310(0.4282) Grad: 0.3546 LR: 0.000122  \n",
      "EVAL: [0/90] Elapsed 0m 0s (remain 0m 55s) Loss: 0.6867(0.6867) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.4282  avg_val_loss: 0.4647  time: 568s\n",
      "Epoch 10 - Accuracy: 0.7958979087857545\n",
      "Epoch 10 - Save final model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [89/90] Elapsed 0m 16s (remain 0m 0s) Loss: 0.2861(0.4647) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 result ==========\n",
      "Score: 0.79606\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "human-arena",
    "papermill": {
     "duration": 0.209774,
     "end_time": "2021-05-12T03:50:00.096860",
     "exception": false,
     "start_time": "2021-05-12T03:49:59.887086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "hungry-geese-train-by-episode.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2945.71762,
   "end_time": "2021-05-12T03:50:02.012348",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-12T03:00:56.294728",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04a486aa6f454d8f92e388dba1b9ee21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0857c0fa22b544488d65bb2c7dad18ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f905db5005be40b194ea150c8b0deb9f",
      "max": 1001,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "value": 1001
     }
    },
    "4134662bdbe04a918d9809632e268ef8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0857c0fa22b544488d65bb2c7dad18ee",
       "IPY_MODEL_e33e4f894b424988b316c468bc9225ce"
      ],
      "layout": "IPY_MODEL_8ddb49ac3c91409f99a569a061a70b3d"
     }
    },
    "507d2b6a02bb43d0bb4c8c2734f19cbb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ddb49ac3c91409f99a569a061a70b3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c96b7bfbdf0243a8ae1dbb3d9aedf123": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e33e4f894b424988b316c468bc9225ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_507d2b6a02bb43d0bb4c8c2734f19cbb",
      "placeholder": "​",
      "style": "IPY_MODEL_04a486aa6f454d8f92e388dba1b9ee21",
      "value": " 1001/1001 [03:35&lt;00:00,  4.64it/s]"
     }
    },
    "f905db5005be40b194ea150c8b0deb9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

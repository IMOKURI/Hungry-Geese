{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abroad-piece",
    "papermill": {
     "duration": 0.025714,
     "end_time": "2021-05-12T03:01:02.640708",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.614994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About this notebook ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GX0zm2Gdvr7u"
   },
   "source": [
    "## Prepare for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tFzcJBNvvJ5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKDVdCItvx_T"
   },
   "outputs": [],
   "source": [
    "COMPETE = \"hungry-geese\"\n",
    "DATASETS = [\n",
    "    \"imokuri/hungrygeeseepisode\",\n",
    "]\n",
    "KERNEL_OUTPUTS = [\n",
    "    # \"imokuri/notebook8d5846e909\",\n",
    "    # \"imokuri/notebook42cdc46ffc\",\n",
    "]\n",
    "PACKAGES = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cRvzBjztxH02",
    "outputId": "8fab44ba-fca5-4247-a8dd-b9013fc24897"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    # Work around for python2 exception.\n",
    "    !python2 -m pip uninstall kaggle -y\n",
    "    !python3 -m pip uninstall kaggle -y\n",
    "    !python3 -m pip install -U -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8YygQsTv-a7",
    "outputId": "f31b0c87-c0b0-4cc2-c137-b5838c2b61d9"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    !pip install -q -U git+https://github.com/IMOKURI/kaggle_on_google_colab.git\n",
    "\n",
    "    from kaggle_on_google_colab import setup\n",
    "    kaggle = setup.Setup()\n",
    "    kaggle.dirs(COMPETE)\n",
    "\n",
    "    # !kaggle competitions download -p /content/zip {COMPETE}\n",
    "    # !unzip -q -n /content/zip/{COMPETE}.zip -d /content/{COMPETE}/input/{COMPETE}\n",
    "\n",
    "    for dataset in DATASETS:\n",
    "        dataset_name = dataset.split(\"/\")[-1]\n",
    "        !kaggle datasets download -p /content/zip {dataset}\n",
    "        !unzip -q -n /content/zip/{dataset_name}.zip -d /content/{COMPETE}/input/{dataset_name}\n",
    "\n",
    "    for kernel in KERNEL_OUTPUTS:\n",
    "        kernel_name = kernel.split(\"/\")[-1]\n",
    "        !kaggle kernels output -p /content/{COMPETE}/input/{kernel_name} {kernel}\n",
    "\n",
    "    for package in PACKAGES:\n",
    "        !pip install -q {package}\n",
    "\n",
    "    %cd /content/{COMPETE}/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pressing-commercial",
    "papermill": {
     "duration": 0.024272,
     "end_time": "2021-05-12T03:01:02.689850",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.665578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "german-ethics",
    "papermill": {
     "duration": 1.852306,
     "end_time": "2021-05-12T03:01:04.566362",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.714056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "apparent-fiction",
    "papermill": {
     "duration": 0.030961,
     "end_time": "2021-05-12T03:01:04.622818",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.591857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robust-humanity",
    "papermill": {
     "duration": 0.024539,
     "end_time": "2021-05-12T03:01:04.672270",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.647731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "designed-effect",
    "papermill": {
     "duration": 0.031167,
     "end_time": "2021-05-12T03:01:04.728079",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.696912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"../input/hungrygeeseepisode/hungry-geese-episode/\"\n",
    "OUTPUT_DIR = \"pre-models/\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "special-broadcast",
    "outputId": "c440e1e9-5651-42ee-eb0f-08c822d7471a",
    "papermill": {
     "duration": 0.31211,
     "end_time": "2021-05-12T03:01:05.064722",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.752612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = [path for path in glob.glob(BASE_DIR + \"*.json\") if \"info\" not in path]\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "editorial-haiti",
    "papermill": {
     "duration": 0.024908,
     "end_time": "2021-05-12T03:01:05.115280",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.090372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opened-python",
    "papermill": {
     "duration": 0.035637,
     "end_time": "2021-05-12T03:01:05.176119",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.140482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 440\n",
    "\n",
    "    n_class = 4\n",
    "    n_fold = 5\n",
    "\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "\n",
    "    num_workers = 4\n",
    "    batch_size = 800\n",
    "\n",
    "    scheduler = \"CosineAnnealingWarmRestarts\"\n",
    "    # factor = 0.2  # ReduceLROnPlateau\n",
    "    # patience = 4  # ReduceLROnPlateau\n",
    "    # eps = 1e-6  # ReduceLROnPlateau\n",
    "    # T_max = 10  # CosineAnnealingLR\n",
    "    T_0 = 10  # CosineAnnealingWarmRestarts\n",
    "\n",
    "    criterion = \"CrossEntropyLoss\"\n",
    "    lr = 1e-3\n",
    "    min_lr = 5e-5\n",
    "    weight_decay = 0\n",
    "\n",
    "    epochs = 10\n",
    "    model_name = \"geese_net\"\n",
    "\n",
    "    print_freq = 100\n",
    "\n",
    "    train = True\n",
    "    debug = False\n",
    "    apex = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "contained-singles",
    "papermill": {
     "duration": 0.031266,
     "end_time": "2021-05-12T03:01:05.235456",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.204190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    Config.epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dietary-track",
    "papermill": {
     "duration": 0.031421,
     "end_time": "2021-05-12T03:01:05.292382",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.260961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.apex:\n",
    "    from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "invalid-dispute",
    "papermill": {
     "duration": 0.169531,
     "end_time": "2021-05-12T03:01:05.488665",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.319134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "treated-serum",
    "papermill": {
     "duration": 0.025219,
     "end_time": "2021-05-12T03:01:05.539482",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.514263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gothic-alloy",
    "papermill": {
     "duration": 0.070842,
     "end_time": "2021-05-12T03:01:05.642364",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.571522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=Config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "experienced-correspondence",
    "papermill": {
     "duration": 0.053842,
     "end_time": "2021-05-12T03:01:05.741858",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.688016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reverse_ns(y):\n",
    "    if y == 0:\n",
    "        return 1\n",
    "    if y == 1:\n",
    "        return 0\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_we(y):\n",
    "    if y == 2:\n",
    "        return 3\n",
    "    if y == 3:\n",
    "        return 2\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_nswe(y):\n",
    "    return reverse_ns(reverse_we(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "further-transaction",
    "papermill": {
     "duration": 0.042365,
     "end_time": "2021-05-12T03:01:05.826807",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.784442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "naughty-clause",
    "papermill": {
     "duration": 0.058537,
     "end_time": "2021-05-12T03:01:05.928292",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.869755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_input(obses):\n",
    "    b = np.zeros((17, 7 * 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "        pid = (p - obs[\"index\"]) % 4\n",
    "\n",
    "        # head position\n",
    "        for pos in pos_list[:1]:\n",
    "            b[0 + pid, pos] = 1\n",
    "        # tip position\n",
    "        for pos in pos_list[-1:]:\n",
    "            b[4 + pid, pos] = 1\n",
    "        # whole position\n",
    "        for pos in pos_list:\n",
    "            b[8 + pid, pos] = 1\n",
    "\n",
    "    # previous head position\n",
    "    if len(obses) > 1:\n",
    "        obs_prev = obses[-2]\n",
    "        for p, pos_list in enumerate(obs_prev[\"geese\"]):\n",
    "            for pos in pos_list[:1]:\n",
    "                b[12 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    # food\n",
    "    for pos in obs[\"food\"]:\n",
    "        b[16, pos] = 1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i6lOS7itC0da"
   },
   "outputs": [],
   "source": [
    "def observation_num_step(obses):\n",
    "    b = np.zeros((7, 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    num_step = obs[\"step\"]  # 0-198\n",
    "    b[0, 0] = num_step / 198\n",
    "\n",
    "    return b.reshape(1, 7, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pretty-aaron",
    "papermill": {
     "duration": 0.042985,
     "end_time": "2021-05-12T03:01:06.014038",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.971053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "international-secret",
    "papermill": {
     "duration": 0.064855,
     "end_time": "2021-05-12T03:01:06.121648",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.056793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset_from_json(filepath, json_object=None, standing=0):\n",
    "    if json_object is None:\n",
    "        json_open = open(path, \"r\")\n",
    "        json_load = json.load(json_open)\n",
    "    else:\n",
    "        json_load = json_object\n",
    "\n",
    "    try:\n",
    "        winner_index = np.argmax(np.argsort(json_load[\"rewards\"]) == 3 - standing)\n",
    "\n",
    "        obses = []\n",
    "        X = []\n",
    "        y = []\n",
    "        actions = {\"NORTH\": 0, \"SOUTH\": 1, \"WEST\": 2, \"EAST\": 3}\n",
    "\n",
    "        for i in range(len(json_load[\"steps\"]) - 1):\n",
    "            if json_load[\"steps\"][i][winner_index][\"status\"] == \"ACTIVE\":\n",
    "                y_ = json_load[\"steps\"][i + 1][winner_index][\"action\"]\n",
    "                if y_ is not None:\n",
    "                    step = json_load[\"steps\"][i]\n",
    "                    step[winner_index][\"observation\"][\"geese\"] = step[0][\"observation\"][\"geese\"]\n",
    "                    step[winner_index][\"observation\"][\"food\"] = step[0][\"observation\"][\"food\"]\n",
    "                    step[winner_index][\"observation\"][\"step\"] = step[0][\"observation\"][\"step\"]\n",
    "                    obses.append(step[winner_index][\"observation\"])\n",
    "                    y.append(actions[y_])\n",
    "\n",
    "                    y.append(reverse_ns(actions[y_]))  # 上下反転\n",
    "                    y.append(reverse_we(actions[y_]))  # 左右反転\n",
    "                    y.append(reverse_nswe(actions[y_]))  # 上下左右反転\n",
    "\n",
    "        for j in range(len(obses)):\n",
    "            # X_ = make_input(obses[: j + 1])\n",
    "\n",
    "            X_ = []\n",
    "            X_.append(make_input(obses[: j + 1]))\n",
    "            # X_.append(observation_num_step(obses[: j + 1]))\n",
    "            X_ = np.concatenate(X_)\n",
    "\n",
    "            X.append(X_)\n",
    "\n",
    "            X.append(X_[:, ::-1, :])  # 上下反転\n",
    "            X.append(X_[:, :, ::-1])  # 左右反転\n",
    "            X.append(X_[:, ::-1, ::-1])  # 上下左右反転\n",
    "\n",
    "        X = np.array(X, dtype=np.float32)  # [starting_step:]\n",
    "        y = np.array(y, dtype=np.uint8)  # [starting_step:]\n",
    "\n",
    "        return X, y\n",
    "    except:\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "4134662bdbe04a918d9809632e268ef8",
      "8ddb49ac3c91409f99a569a061a70b3d",
      "0857c0fa22b544488d65bb2c7dad18ee",
      "e33e4f894b424988b316c468bc9225ce",
      "c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "f905db5005be40b194ea150c8b0deb9f",
      "04a486aa6f454d8f92e388dba1b9ee21",
      "507d2b6a02bb43d0bb4c8c2734f19cbb"
     ]
    },
    "id": "handled-pleasure",
    "outputId": "955c1c6b-36bc-4b30-dc44-b72b05398f8c",
    "papermill": {
     "duration": 15.320591,
     "end_time": "2021-05-12T03:01:21.474816",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.154225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for path in tqdm(paths[: int(len(paths))]):\n",
    "    X, y = create_dataset_from_json(path, standing=0)  # use only winners' moves\n",
    "    if X is not 0:\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "persistent-loading",
    "papermill": {
     "duration": 112.92618,
     "end_time": "2021-05-12T03:03:14.428162",
     "exception": false,
     "start_time": "2021-05-12T03:01:21.501982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: データをuniqueにしたいがメモリエラーになってしまう。\n",
    "\n",
    "# X_train, unique_index = np.unique(X_train, axis=0, return_index=True)  # remove duplicate\n",
    "# y_train = y_train[unique_index]\n",
    "\n",
    "# y_train = np.eye(4, dtype=\"uint8\")[y_train]  # to categorical\n",
    "\n",
    "# print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# まとめてuniqueかけるとメモリ量が足りないので、いくつかのグループに分けてuniqueにする\n",
    "\n",
    "X_train_sum_obs = X_train.reshape(X_train.shape[0], -1).sum(1)\n",
    "X_train_group = np.unique(X_train_sum_obs)\n",
    "X_train_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unique = []\n",
    "y_train_unique = []\n",
    "for group in tqdm(X_train_group):\n",
    "    group_index = np.where(X_train_sum_obs == group)\n",
    "\n",
    "    X_train_ = X_train[group_index]\n",
    "    y_train_ = y_train[group_index]\n",
    "\n",
    "    X_train_, unique_index = np.unique(X_train_, axis=0, return_index=True)  # remove duplicate\n",
    "    y_train_ = y_train_[unique_index]\n",
    "\n",
    "    X_train_unique.append(X_train_)\n",
    "    y_train_unique.append(y_train_)\n",
    "\n",
    "X_train = np.concatenate(X_train_unique)\n",
    "y_train = np.concatenate(y_train_unique)\n",
    "\n",
    "print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "micro-french",
    "papermill": {
     "duration": 0.033413,
     "end_time": "2021-05-12T03:03:15.360395",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.326982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    X_train = X_train[:1000]\n",
    "    y_train = y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "wrong-pastor",
    "outputId": "406a2f1d-0b8a-46bf-ca01-546f3110c301",
    "papermill": {
     "duration": 0.036161,
     "end_time": "2021-05-12T03:03:15.425149",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.388988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(y_train)\n",
    "y_df.columns = [\"action\"]\n",
    "y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "touched-coordinate",
    "papermill": {
     "duration": 0.027968,
     "end_time": "2021-05-12T03:03:15.557122",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.529154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "moving-skill",
    "outputId": "7542c4b4-f7d3-444c-8450-50bffddb1892",
    "papermill": {
     "duration": 0.202337,
     "end_time": "2021-05-12T03:03:15.787529",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.585192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folds = y_df.copy()\n",
    "Fold = StratifiedKFold(n_splits=Config.n_fold, shuffle=True, random_state=Config.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[\"action\"])):\n",
    "    folds.loc[val_index, \"fold\"] = int(n)\n",
    "folds[\"fold\"] = folds[\"fold\"].astype(int)\n",
    "print(folds.groupby([\"fold\", \"action\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "creative-football",
    "papermill": {
     "duration": 0.029031,
     "end_time": "2021-05-12T03:03:15.845114",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.816083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "other-murder",
    "papermill": {
     "duration": 0.037264,
     "end_time": "2021-05-12T03:03:15.911219",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.873955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, array, label):\n",
    "        self.array = array\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx], torch.tensor(self.label[idx]).long()\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, array):\n",
    "        self.array = array\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adjusted-delhi",
    "outputId": "39504950-84bc-4692-8b90-8a5b64f741e0",
    "papermill": {
     "duration": 0.063691,
     "end_time": "2021-05-12T03:03:16.003693",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.940002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "train_ds = TrainDataset(X_train, y_train)\n",
    "\n",
    "for i in range(1):\n",
    "    obs, action = train_ds[i]\n",
    "    print(obs.shape, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceramic-startup",
    "papermill": {
     "duration": 0.02876,
     "end_time": "2021-05-12T03:03:16.061575",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.032815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unique-trick",
    "papermill": {
     "duration": 0.039055,
     "end_time": "2021-05-12T03:03:16.130239",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.091184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TorusConv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
    "        super().__init__()\n",
    "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([x[:, :, :, -self.edge_size[1] :], x, x[:, :, :, : self.edge_size[1]]], dim=3)\n",
    "        h = torch.cat([h[:, :, -self.edge_size[0] :], h, h[:, :, : self.edge_size[0]]], dim=2)\n",
    "        h = self.conv(h)\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "extra-bradford",
    "papermill": {
     "duration": 0.042421,
     "end_time": "2021-05-12T03:03:16.202024",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.159603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GeeseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers, filters = 12, 32\n",
    "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p = nn.Linear(filters, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(filters * 2, filters, bias=False)\n",
    "        self.head_v2 = nn.Linear(filters, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h_p = F.relu_(self.conv_p(h))\n",
    "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        p = self.head_p(h_head_p)\n",
    "\n",
    "        h_v = F.relu_(self.conv_v(h))\n",
    "        h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        h_avg_v = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
    "\n",
    "        h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_avg_v], 1)))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p, \"value\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jspEE71c2Yma"
   },
   "outputs": [],
   "source": [
    "class GeeseNetAlpha(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers, filters = 12, 64\n",
    "        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.conv_p = TorusConv2d(filters, filters, (3, 3), True)\n",
    "        # self.conv_v = TorusConv2d(filters, filters, (3, 3), True)\n",
    "\n",
    "        self.head_p1 = nn.Linear(filters * 2 + 77, filters, bias=False)\n",
    "        self.head_p2 = nn.Linear(filters, 4, bias=False)\n",
    "        # self.head_v1 = nn.Linear(filters * 2, filters, bias=False)\n",
    "        # self.head_v2 = nn.Linear(filters, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        # x = x[:, :-1]\n",
    "        # num_step = x[:, -1, 0, 0].view(x.size(0), 1)\n",
    "\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h_p = F.relu_(self.conv_p(h))\n",
    "        h_head_p = (h_p * x[:, :1]).view(h_p.size(0), h_p.size(1), -1).sum(-1)\n",
    "        h_avg_p1 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(-1)\n",
    "        h_avg_p2 = h_p.view(h_p.size(0), h_p.size(1), -1).mean(1)\n",
    "\n",
    "        h_p = F.relu_(self.head_p1(torch.cat([h_head_p, h_avg_p1, h_avg_p2], 1)))\n",
    "        p = self.head_p2(h_p)\n",
    "\n",
    "        # h_v = F.relu_(self.conv_v(h))\n",
    "        # h_head_v = (h_v * x[:, :1]).view(h_v.size(0), h_v.size(1), -1).sum(-1)\n",
    "        # h_avg_v = h_v.view(h_v.size(0), h_v.size(1), -1).mean(-1)\n",
    "\n",
    "        # h_v = F.relu_(self.head_v1(torch.cat([h_head_v, h_avg_v], 1)))\n",
    "        # v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p}  # \"value\": v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "objective-victoria",
    "outputId": "1ab137a5-e26e-4b9c-ff85-95fef713b755",
    "papermill": {
     "duration": 4.955868,
     "end_time": "2021-05-12T03:03:21.187355",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.231487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "model = GeeseNetAlpha()\n",
    "# print(model)\n",
    "\n",
    "params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"params: {params:,}\")\n",
    "\n",
    "train_ds = TrainDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "for obs, action in train_loader:\n",
    "    output = model(obs)\n",
    "    print(output)\n",
    "    print(f\"{torch.argmax(output['policy'], dim=1)}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "military-fiction",
    "papermill": {
     "duration": 0.033001,
     "end_time": "2021-05-12T03:03:21.255277",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.222276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sophisticated-hearts",
    "papermill": {
     "duration": 0.031759,
     "end_time": "2021-05-12T03:03:21.319849",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.288090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "designing-detective",
    "papermill": {
     "duration": 0.03139,
     "end_time": "2021-05-12T03:03:21.383038",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.351648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "passive-cooper",
    "papermill": {
     "duration": 0.038846,
     "end_time": "2021-05-12T03:03:21.454085",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.415239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thirty-tracy",
    "papermill": {
     "duration": 0.0293,
     "end_time": "2021-05-12T03:03:21.514179",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.484879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "introductory-brooklyn",
    "papermill": {
     "duration": 0.039424,
     "end_time": "2021-05-12T03:03:21.582969",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.543545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "raising-laugh",
    "papermill": {
     "duration": 0.042063,
     "end_time": "2021-05-12T03:03:21.654559",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.612496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "\n",
    "    for step, (obs, action) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        y_preds = model(obs.float())[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "\n",
    "        # record loss\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "        if Config.apex:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), Config.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % Config.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print(\n",
    "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
    "                f\"Loss: {losses.val:.4f}({losses.avg:.4f}) \"\n",
    "                f\"Grad: {grad_norm:.4f} \"\n",
    "                f\"LR: {scheduler.get_last_lr()[0]:.6f}  \"\n",
    "            )\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plain-neighbor",
    "papermill": {
     "duration": 0.041056,
     "end_time": "2021-05-12T03:03:21.726585",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.685529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "\n",
    "    for step, (obs, action) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(obs)[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print(\n",
    "                f\"EVAL: [{step}/{len(valid_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
    "                f\"Loss: {losses.val:.4f}({losses.avg:.4f}) \"\n",
    "            )\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "integrated-classification",
    "papermill": {
     "duration": 0.029832,
     "end_time": "2021-05-12T03:03:21.786427",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.756595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "harmful-explanation",
    "papermill": {
     "duration": 0.05136,
     "end_time": "2021-05-12T03:03:21.868561",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.817201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(folds, fold):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    X_train_folds = X_train[folds[\"fold\"] != fold]\n",
    "    X_valid_folds = X_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    y_train_folds = y_train[folds[\"fold\"] != fold]\n",
    "    y_valid_folds = y_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    y_df_train_folds = y_df[folds[\"fold\"] != fold]\n",
    "    y_df_valid_folds = y_df[folds[\"fold\"] == fold]\n",
    "\n",
    "    train_dataset = TrainDataset(X_train_folds, y_train_folds)\n",
    "    valid_dataset = TrainDataset(X_valid_folds, y_valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if Config.scheduler == \"ReduceLROnPlateau\":\n",
    "            scheduler = ReduceLROnPlateau(\n",
    "                optimizer, mode=\"min\", factor=Config.factor, patience=Config.patience, verbose=True, eps=Config.eps\n",
    "            )\n",
    "        elif Config.scheduler == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=Config.T_max, eta_min=Config.min_lr, last_epoch=-1)\n",
    "        elif Config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "            scheduler = CosineAnnealingWarmRestarts(\n",
    "                optimizer, T_0=Config.T_0, T_mult=1, eta_min=Config.min_lr, last_epoch=-1\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = GeeseNetAlpha()\n",
    "    model.to(device)\n",
    "\n",
    "    # Use multi GPU\n",
    "    if device == torch.device(\"cuda\") and not Config.apex:\n",
    "        model = torch.nn.DataParallel(model)  # make parallel\n",
    "        # torch.backends.cudnn.benchmark=True\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=Config.lr, weight_decay=Config.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # apex\n",
    "    # ====================================================\n",
    "    if Config.apex:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
    "\n",
    "    # ====================================================\n",
    "    # Criterion\n",
    "    # ====================================================\n",
    "    def get_criterion():\n",
    "        if Config.criterion == \"CrossEntropyLoss\":\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        return criterion\n",
    "\n",
    "    criterion = get_criterion()\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    best_score = 0.0\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(Config.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "\n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(y_valid_folds, preds.argmax(1))\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Accuracy: {score}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n",
    "            torch.save(\n",
    "                {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_best.pth\"\n",
    "            )\n",
    "\n",
    "        if epoch == Config.epochs - 1:\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save final model\")\n",
    "            torch.save(\n",
    "                {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_final.pth\"\n",
    "            )\n",
    "\n",
    "    check_point = torch.load(OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_best.pth\")\n",
    "\n",
    "    y_df_valid_folds[[str(c) for c in range(Config.n_class)]] = check_point[\"preds\"]\n",
    "    y_df_valid_folds[\"preds\"] = check_point[\"preds\"].argmax(1)\n",
    "\n",
    "    return y_df_valid_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "complimentary-wright",
    "papermill": {
     "duration": 0.030218,
     "end_time": "2021-05-12T03:03:21.928896",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.898678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "particular-adaptation",
    "papermill": {
     "duration": 0.04089,
     "end_time": "2021-05-12T03:03:22.000150",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.959260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    def get_result(result_df):\n",
    "        preds = result_df[\"preds\"].values\n",
    "        labels = result_df[\"action\"].values\n",
    "        score = get_score(labels, preds)\n",
    "        LOGGER.info(f\"Score: {score:<.5f}\")\n",
    "\n",
    "    if Config.train:\n",
    "        # train\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(Config.n_fold):\n",
    "            _oof_df = train_loop(folds, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df)\n",
    "        # CV result\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "backed-journal",
    "outputId": "c9f0ff3d-795e-466b-e22e-9ba21d08c874",
    "papermill": {
     "duration": 2797.64711,
     "end_time": "2021-05-12T03:49:59.678400",
     "exception": false,
     "start_time": "2021-05-12T03:03:22.031290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "human-arena",
    "papermill": {
     "duration": 0.209774,
     "end_time": "2021-05-12T03:50:00.096860",
     "exception": false,
     "start_time": "2021-05-12T03:49:59.887086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "hungry-geese-train-by-episode.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2945.71762,
   "end_time": "2021-05-12T03:50:02.012348",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-12T03:00:56.294728",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04a486aa6f454d8f92e388dba1b9ee21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0857c0fa22b544488d65bb2c7dad18ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f905db5005be40b194ea150c8b0deb9f",
      "max": 1001,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "value": 1001
     }
    },
    "4134662bdbe04a918d9809632e268ef8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0857c0fa22b544488d65bb2c7dad18ee",
       "IPY_MODEL_e33e4f894b424988b316c468bc9225ce"
      ],
      "layout": "IPY_MODEL_8ddb49ac3c91409f99a569a061a70b3d"
     }
    },
    "507d2b6a02bb43d0bb4c8c2734f19cbb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ddb49ac3c91409f99a569a061a70b3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c96b7bfbdf0243a8ae1dbb3d9aedf123": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e33e4f894b424988b316c468bc9225ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_507d2b6a02bb43d0bb4c8c2734f19cbb",
      "placeholder": "​",
      "style": "IPY_MODEL_04a486aa6f454d8f92e388dba1b9ee21",
      "value": " 1001/1001 [03:35&lt;00:00,  4.64it/s]"
     }
    },
    "f905db5005be40b194ea150c8b0deb9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

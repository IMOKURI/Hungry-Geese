{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abroad-piece",
    "papermill": {
     "duration": 0.025714,
     "end_time": "2021-05-12T03:01:02.640708",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.614994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About this notebook ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pressing-commercial",
    "papermill": {
     "duration": 0.024272,
     "end_time": "2021-05-12T03:01:02.689850",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.665578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "german-ethics",
    "papermill": {
     "duration": 1.852306,
     "end_time": "2021-05-12T03:01:04.566362",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.714056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "apparent-fiction",
    "papermill": {
     "duration": 0.030961,
     "end_time": "2021-05-12T03:01:04.622818",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.591857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "editorial-haiti",
    "papermill": {
     "duration": 0.024908,
     "end_time": "2021-05-12T03:01:05.115280",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.090372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_defaults = {\n",
    "    \"seed\": 440,\n",
    "    \"data_size\": 8_000_000,\n",
    "    \"n_class\": 4,\n",
    "    \"n_fold\": 10,\n",
    "    \"geese_net_layers\": 12,\n",
    "    \"geese_net_filters\": 48,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"max_grad_norm\": 1000,\n",
    "    \"num_workers\": 4,\n",
    "    \"batch_size\": 3200,\n",
    "    \"epochs\": 20,\n",
    "    \"scheduler\": \"CosineAnnealingWarmRestarts\",\n",
    "    \"criterion\": \"CrossEntropyLoss\",\n",
    "    \"lr\": 1e-3,\n",
    "    \"min_lr\": 1e-4,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"model_name\": \"geese_net_alpha\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config_defaults[\"scheduler\"] == \"CosineAnnealingWarmRestarts\":\n",
    "    config_defaults[\"T_0\"] = config_defaults[\"epochs\"]\n",
    "\n",
    "elif config_defaults[\"scheduler\"] == \"CosineAnnealingLR\":\n",
    "    config_defaults[\"T_max\"] = config_defaults[\"epochs\"]\n",
    "\n",
    "elif config_defaults[\"scheduler\"] == \"ReduceLROnPlateau\":\n",
    "    config_defaults[\"factor\"] = 0.2\n",
    "    config_defaults[\"patience\"] = 4\n",
    "    config_defaults[\"eps\"] = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "opened-python",
    "papermill": {
     "duration": 0.035637,
     "end_time": "2021-05-12T03:01:05.176119",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.140482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    pre_train_file = \"\"\n",
    "    print_freq = 100\n",
    "    train = True\n",
    "    debug = False\n",
    "    apex = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">morning-sea-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/imokuri/hungry-geese\" target=\"_blank\">https://wandb.ai/imokuri/hungry-geese</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/imokuri/hungry-geese/runs/2l6upyjt\" target=\"_blank\">https://wandb.ai/imokuri/hungry-geese/runs/2l6upyjt</a><br/>\n",
       "                Run data is saved locally in <code>/home/ubuntu/github/Hungry-Geese2/wandb/run-20210630_232911-2l6upyjt</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if Config.debug:\n",
    "    wandb.init(project=\"hungry-geese\", config=config_defaults, mode=\"disabled\")\n",
    "else:\n",
    "    wandb.init(project=\"hungry-geese\", config=config_defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "contained-singles",
    "papermill": {
     "duration": 0.031266,
     "end_time": "2021-05-12T03:01:05.235456",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.204190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    config.update({\"epochs\": 1, \"data_size\": 10_000}, allow_val_change=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dietary-track",
    "papermill": {
     "duration": 0.031421,
     "end_time": "2021-05-12T03:01:05.292382",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.260961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.apex:\n",
    "    from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "invalid-dispute",
    "papermill": {
     "duration": 0.169531,
     "end_time": "2021-05-12T03:01:05.488665",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.319134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robust-humanity",
    "papermill": {
     "duration": 0.024539,
     "end_time": "2021-05-12T03:01:04.672270",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.647731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "designed-effect",
    "papermill": {
     "duration": 0.031167,
     "end_time": "2021-05-12T03:01:04.728079",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.696912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"../input/hungrygeeseepisode/hungry-geese-episode/\"\n",
    "OUTPUT_DIR = \"pre-models/\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "special-broadcast",
    "outputId": "c440e1e9-5651-42ee-eb0f-08c822d7471a",
    "papermill": {
     "duration": 0.31211,
     "end_time": "2021-05-12T03:01:05.064722",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.752612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29048\n"
     ]
    }
   ],
   "source": [
    "paths = [path for path in glob.glob(BASE_DIR + \"*.json\") if \"info\" not in path]\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "treated-serum",
    "papermill": {
     "duration": 0.025219,
     "end_time": "2021-05-12T03:01:05.539482",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.514263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "gothic-alloy",
    "papermill": {
     "duration": 0.070842,
     "end_time": "2021-05-12T03:01:05.642364",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.571522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "experienced-correspondence",
    "papermill": {
     "duration": 0.053842,
     "end_time": "2021-05-12T03:01:05.741858",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.688016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ident(y):\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_ns(y):\n",
    "    if y == 0:\n",
    "        return 1\n",
    "    if y == 1:\n",
    "        return 0\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_we(y):\n",
    "    if y == 2:\n",
    "        return 3\n",
    "    if y == 3:\n",
    "        return 2\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_nswe(y):\n",
    "    return reverse_ns(reverse_we(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_flip(image):\n",
    "    return image\n",
    "\n",
    "\n",
    "def h_flip(image):\n",
    "    return image[:, :, ::-1]\n",
    "\n",
    "\n",
    "def v_flip(image):\n",
    "    return image[:, ::-1, :]\n",
    "\n",
    "\n",
    "def hv_flip(image):\n",
    "    return image[:, ::-1, ::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "further-transaction",
    "papermill": {
     "duration": 0.042365,
     "end_time": "2021-05-12T03:01:05.826807",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.784442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_position_map = {}\n",
    "for pos in range(77):\n",
    "    position = []\n",
    "    position.append((11 * (1 + pos // 11) + pos % 11) % 77)\n",
    "    position.append((11 * (-1 + pos // 11) + pos % 11) % 77)\n",
    "    position.append((11 * (pos // 11) + (pos + 1) % 11) % 77)\n",
    "    position.append((11 * (pos // 11) + (pos - 1) % 11) % 77)\n",
    "    next_position_map[pos] = set(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "naughty-clause",
    "papermill": {
     "duration": 0.058537,
     "end_time": "2021-05-12T03:01:05.928292",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.869755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_input(obses):\n",
    "    b = np.zeros((17, 7 * 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "        pid = (p - obs[\"index\"]) % 4\n",
    "\n",
    "        # head position\n",
    "        for pos in pos_list[:1]:\n",
    "            b[0 + pid, pos] = 1\n",
    "        # tip position\n",
    "        for pos in pos_list[-1:]:\n",
    "            b[4 + pid, pos] = 1\n",
    "        # whole position\n",
    "        for pos in pos_list:\n",
    "            b[8 + pid, pos] = 1\n",
    "\n",
    "    # previous head position\n",
    "    if len(obses) > 1:\n",
    "        obs_prev = obses[-2]\n",
    "        for p, pos_list in enumerate(obs_prev[\"geese\"]):\n",
    "            for pos in pos_list[:1]:\n",
    "                b[12 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    # food\n",
    "    for pos in obs[\"food\"]:\n",
    "        b[16, pos] = 1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reverse_cube(obses):\n",
    "    \"\"\"\n",
    "    尻尾から順番に 1, 0.9, 0.8, ... という並び\n",
    "    \"\"\"\n",
    "    b = np.zeros((4, 7 * 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, geese in enumerate(obs[\"geese\"]):\n",
    "        # whole position reverse\n",
    "        for num_reverse, pos in enumerate(geese[::-1]):\n",
    "            b[(p - obs[\"index\"]) % 4, pos] = 1 - num_reverse * 0.1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_disappear_cube(obses):\n",
    "    \"\"\"\n",
    "    次になくなる場所: 1\n",
    "    次になくなる可能性のある場所: 0.5\n",
    "    \"\"\"\n",
    "    b = np.zeros((4, 7 * 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "    step = obs[\"step\"]\n",
    "\n",
    "    # foodを食べる可能性があるか。\n",
    "    eat_food_possibility = defaultdict(int)\n",
    "    for p, geese in enumerate(obs[\"geese\"]):\n",
    "        for pos in geese[:1]:\n",
    "            if not next_position_map[pos].isdisjoint(obs[\"food\"]):\n",
    "                eat_food_possibility[p] = 1\n",
    "\n",
    "    if (step % 40) == 39:  # 1つ短くなる\n",
    "        for p, geese in enumerate(obs[\"geese\"]):\n",
    "            if eat_food_possibility[p]:  # 尻尾が1、尻尾の１つ前0.5\n",
    "                for pos in geese[-1:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 1\n",
    "                for pos in geese[-2:-1]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 0.5\n",
    "            else:  # 食べる可能性なし -> 尻尾が1, 尻尾の1つ前1\n",
    "                for pos in geese[-2:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 1\n",
    "    else:  # 1つ短くならない\n",
    "        for p, geese in enumerate(obs[\"geese\"]):\n",
    "            if eat_food_possibility[p]:  # 食べる可能性があり -> 尻尾を0.5\n",
    "                for pos in geese[-1:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 0.5\n",
    "            else:  # 食べる可能性なし # 尻尾を1\n",
    "                for pos in geese[-1:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_step_cube_v2(obses):\n",
    "    \"\"\"\n",
    "    step0: 0, step199: 1\n",
    "    step0: 0, step39 + 40n: 1\n",
    "    \"\"\"\n",
    "    b = np.zeros((1, 7, 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "    step = obs[\"step\"]\n",
    "\n",
    "    b[:, :, :5] = (step % 200) / 199\n",
    "    b[:, :, 5:] = (step % 40) / 39\n",
    "\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_cube(obses):\n",
    "    b = np.zeros((2, 7, 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    my_length = len(obs[\"geese\"][obs[\"index\"]])\n",
    "    opposite1_length = len(obs[\"geese\"][(obs[\"index\"] + 1) % 4])\n",
    "    opposite2_length = len(obs[\"geese\"][(obs[\"index\"] + 2) % 4])\n",
    "    opposite3_length = len(obs[\"geese\"][(obs[\"index\"] + 3) % 4])\n",
    "\n",
    "    b[0] = my_length / 10\n",
    "    max_opposite_length = max(opposite1_length, opposite2_length, opposite3_length)\n",
    "    b[1, :, 0:2] = (my_length - max_opposite_length) / 10\n",
    "    b[1, :, 2:5] = (my_length - opposite1_length) / 10\n",
    "    b[1, :, 5:8] = (my_length - opposite2_length) / 10\n",
    "    b[1, :, 8:11] = (my_length - opposite3_length) / 10\n",
    "\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(obses):\n",
    "    b = np.zeros((7 * 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "    step = obs[\"step\"]\n",
    "\n",
    "    my_goose = obs[\"geese\"][obs[\"index\"]]\n",
    "    my_length = len(my_goose)\n",
    "\n",
    "    # num step\n",
    "    b[0] = (step - 194) if step >= 195 else 0\n",
    "    b[1] = (step % 40 - 35) if step % 40 > 35 else 0\n",
    "\n",
    "    \"\"\"\n",
    "    2-4: difference between my_length and opponent length (-3 to 3)\n",
    "    \"\"\"\n",
    "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "        pid = (p - obs[\"index\"]) % 4\n",
    "        p_length = len(pos_list)\n",
    "\n",
    "        if pid == 0:\n",
    "            continue\n",
    "\n",
    "        b[1 + pid] = max(min(my_length - p_length, 3), -3) + 3\n",
    "\n",
    "    \"\"\"\n",
    "    5-7: difference between my head position and opponent one\n",
    "    \"\"\"\n",
    "    if my_length != 0:\n",
    "\n",
    "        for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "            pid = (p - obs[\"index\"]) % 4\n",
    "\n",
    "            if pid == 0 or len(pos_list) == 0:\n",
    "                continue\n",
    "\n",
    "            diff = abs(my_goose[0] - pos_list[0])\n",
    "            x_ = diff % 11\n",
    "            x = min(x_, 11 - x_)\n",
    "            y_ = diff // 11\n",
    "            y = min(y_, 7 - y_)\n",
    "            b[4 + pid] = x + y\n",
    "\n",
    "    return b.reshape(1, 7, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pretty-aaron",
    "papermill": {
     "duration": 0.042985,
     "end_time": "2021-05-12T03:01:06.014038",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.971053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((config.data_size, 26, 7, 11), dtype=np.float32)\n",
    "y_train = np.zeros((config.data_size,), dtype=np.uint8)\n",
    "\n",
    "X_count = 0\n",
    "y_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "international-secret",
    "papermill": {
     "duration": 0.064855,
     "end_time": "2021-05-12T03:01:06.121648",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.056793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset_from_json(filepath, json_object=None, standing=0):\n",
    "    global X_train\n",
    "    global y_train\n",
    "    global X_count\n",
    "    global y_count\n",
    "\n",
    "    if json_object is None:\n",
    "        json_open = open(path, \"r\")\n",
    "        json_load = json.load(json_open)\n",
    "    else:\n",
    "        json_load = json_object\n",
    "\n",
    "    try:\n",
    "        winner_index = np.argmax(np.argsort(json_load[\"rewards\"]) == 3 - standing)\n",
    "\n",
    "        obses = []\n",
    "        actions = {\"NORTH\": 0, \"SOUTH\": 1, \"WEST\": 2, \"EAST\": 3}\n",
    "\n",
    "        for i in range(len(json_load[\"steps\"]) - 1):\n",
    "            if json_load[\"steps\"][i][winner_index][\"status\"] == \"ACTIVE\":\n",
    "                y_ = json_load[\"steps\"][i + 1][winner_index][\"action\"]\n",
    "                if y_ is not None:\n",
    "                    step = json_load[\"steps\"][i]\n",
    "                    step[winner_index][\"observation\"][\"geese\"] = step[0][\"observation\"][\"geese\"]\n",
    "                    step[winner_index][\"observation\"][\"food\"] = step[0][\"observation\"][\"food\"]\n",
    "                    step[winner_index][\"observation\"][\"step\"] = step[0][\"observation\"][\"step\"]\n",
    "                    obses.append(step[winner_index][\"observation\"])\n",
    "\n",
    "                    for func in [ident, reverse_ns, reverse_we, reverse_nswe]:\n",
    "                        if y_count >= config.data_size:\n",
    "                            break\n",
    "\n",
    "                        y_train[y_count] = func(actions[y_])\n",
    "                        y_count += 1\n",
    "\n",
    "                    if y_count >= config.data_size:\n",
    "                        break\n",
    "\n",
    "        for j in range(len(obses)):\n",
    "            # X_ = make_input(obses[: j + 1])\n",
    "\n",
    "            # 反転可能な特徴量\n",
    "            X_ = []\n",
    "            X_.append(make_input(obses[: j + 1]))\n",
    "            X_.append(get_reverse_cube(obses[: j + 1]))\n",
    "            X_.append(get_next_disappear_cube(obses[: j + 1]))\n",
    "\n",
    "            # 反転不可能な特徴量\n",
    "            X_i = []\n",
    "            # X_i.append(get_step_cube_v2(obses[: j + 1]))\n",
    "            # X_i.append(get_length_cube(obses[: j + 1]))\n",
    "            X_i.append(get_features(obses[: j + 1]))\n",
    "\n",
    "            X_ = np.concatenate(X_)\n",
    "            X_i = np.concatenate(X_i)\n",
    "\n",
    "            for func in [no_flip, v_flip, h_flip, hv_flip]:\n",
    "                if X_count >= config.data_size:\n",
    "                    break\n",
    "\n",
    "                X_train[X_count] = np.concatenate([func(X_), X_i])\n",
    "                X_count += 1\n",
    "\n",
    "            if X_count >= config.data_size:\n",
    "                break\n",
    "\n",
    "        return\n",
    "    except Exception as e:\n",
    "        if Config.debug:\n",
    "            raise Exception from e\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "4134662bdbe04a918d9809632e268ef8",
      "8ddb49ac3c91409f99a569a061a70b3d",
      "0857c0fa22b544488d65bb2c7dad18ee",
      "e33e4f894b424988b316c468bc9225ce",
      "c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "f905db5005be40b194ea150c8b0deb9f",
      "04a486aa6f454d8f92e388dba1b9ee21",
      "507d2b6a02bb43d0bb4c8c2734f19cbb"
     ]
    },
    "id": "handled-pleasure",
    "outputId": "955c1c6b-36bc-4b30-dc44-b72b05398f8c",
    "papermill": {
     "duration": 15.320591,
     "end_time": "2021-05-12T03:01:21.474816",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.154225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ab393d463a41e49a870a0dd4f10b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29048.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num episode: 8,000,000\n"
     ]
    }
   ],
   "source": [
    "for path in tqdm(paths[::-1]):\n",
    "    create_dataset_from_json(path, standing=0)  # use only winners' moves\n",
    "    if X_count >= config.data_size:\n",
    "        break\n",
    "\n",
    "print(f\"Num episode: {len(X_train):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "micro-french",
    "papermill": {
     "duration": 0.033413,
     "end_time": "2021-05-12T03:03:15.360395",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.326982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    X_train = X_train[:1000]\n",
    "    y_train = y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "wrong-pastor",
    "outputId": "406a2f1d-0b8a-46bf-ca01-546f3110c301",
    "papermill": {
     "duration": 0.036161,
     "end_time": "2021-05-12T03:03:15.425149",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.388988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999996</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999998</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         action\n",
       "0             2\n",
       "1             2\n",
       "2             3\n",
       "3             3\n",
       "4             0\n",
       "...         ...\n",
       "7999995       0\n",
       "7999996       1\n",
       "7999997       0\n",
       "7999998       1\n",
       "7999999       0\n",
       "\n",
       "[8000000 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(y_train, dtype=np.uint8)\n",
    "y_df.columns = [\"action\"]\n",
    "y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "touched-coordinate",
    "papermill": {
     "duration": 0.027968,
     "end_time": "2021-05-12T03:03:15.557122",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.529154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "moving-skill",
    "outputId": "7542c4b4-f7d3-444c-8450-50bffddb1892",
    "papermill": {
     "duration": 0.202337,
     "end_time": "2021-05-12T03:03:15.787529",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.585192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  action\n",
      "0     0         193103\n",
      "      1         193103\n",
      "      2         206897\n",
      "      3         206897\n",
      "1     0         193103\n",
      "      1         193103\n",
      "      2         206897\n",
      "      3         206897\n",
      "2     0         193104\n",
      "      1         193103\n",
      "      2         206897\n",
      "      3         206896\n",
      "3     0         193104\n",
      "      1         193103\n",
      "      2         206897\n",
      "      3         206896\n",
      "4     0         193104\n",
      "      1         193103\n",
      "      2         206897\n",
      "      3         206896\n",
      "5     0         193104\n",
      "      1         193103\n",
      "      2         206897\n",
      "      3         206896\n",
      "6     0         193103\n",
      "      1         193104\n",
      "      2         206896\n",
      "      3         206897\n",
      "7     0         193103\n",
      "      1         193104\n",
      "      2         206896\n",
      "      3         206897\n",
      "8     0         193103\n",
      "      1         193104\n",
      "      2         206896\n",
      "      3         206897\n",
      "9     0         193103\n",
      "      1         193104\n",
      "      2         206896\n",
      "      3         206897\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "folds = y_df.copy()\n",
    "Fold = StratifiedKFold(n_splits=config.n_fold, shuffle=True, random_state=config.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[\"action\"])):\n",
    "    folds.loc[val_index, \"fold\"] = int(n)\n",
    "folds[\"fold\"] = folds[\"fold\"].astype(np.uint8)\n",
    "print(folds.groupby([\"fold\", \"action\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "creative-football",
    "papermill": {
     "duration": 0.029031,
     "end_time": "2021-05-12T03:03:15.845114",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.816083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "other-murder",
    "papermill": {
     "duration": 0.037264,
     "end_time": "2021-05-12T03:03:15.911219",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.873955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, array, label):\n",
    "        self.array = array\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx], torch.tensor(self.label[idx]).long()\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, array):\n",
    "        self.array = array\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adjusted-delhi",
    "outputId": "39504950-84bc-4692-8b90-8a5b64f741e0",
    "papermill": {
     "duration": 0.063691,
     "end_time": "2021-05-12T03:03:16.003693",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.940002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "if Config.debug or False:\n",
    "    train_ds = TrainDataset(X_train, y_train)\n",
    "\n",
    "    for i in range(1):\n",
    "        obs, action = train_ds[i]\n",
    "        print(obs.shape, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceramic-startup",
    "papermill": {
     "duration": 0.02876,
     "end_time": "2021-05-12T03:03:16.061575",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.032815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "unique-trick",
    "papermill": {
     "duration": 0.039055,
     "end_time": "2021-05-12T03:03:16.130239",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.091184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TorusConv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, do=False, bn=True):\n",
    "        super().__init__()\n",
    "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.do = nn.Dropout2d(p=0.1) if do else None\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([x[:, :, :, -self.edge_size[1] :], x, x[:, :, :, : self.edge_size[1]]], dim=3)\n",
    "        h = torch.cat([h[:, :, -self.edge_size[0] :], h, h[:, :, : self.edge_size[0]]], dim=2)\n",
    "        h = self.conv(h)\n",
    "        h = self.do(h) if self.do is not None else h\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "jspEE71c2Yma"
   },
   "outputs": [],
   "source": [
    "class GeeseNetAlpha(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = config.geese_net_layers\n",
    "        filters = config.geese_net_filters\n",
    "        dim = filters * 5 + 30\n",
    "\n",
    "        self.embed_step = nn.Embedding(5, 3)\n",
    "        self.embed_hunger = nn.Embedding(5, 3)\n",
    "        self.embed_diff_len = nn.Embedding(7, 4)\n",
    "        self.embed_diff_head = nn.Embedding(9, 4)\n",
    "\n",
    "        self.conv0 = TorusConv2d(25, filters, (3, 3))\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3)) for _ in range(layers)])\n",
    "        self.conv1 = TorusConv2d(filters, filters, (5, 5))\n",
    "\n",
    "        # self.attention = nn.MultiheadAttention(dim, 1)\n",
    "\n",
    "        self.head_p1 = nn.Linear(dim, dim // 2, bias=True)\n",
    "        self.head_p2 = nn.Linear(dim // 2, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(dim, dim // 2, bias=True)\n",
    "        self.head_v2 = nn.Linear(dim // 2, 1, bias=False)\n",
    "\n",
    "        self.bn_p1 = nn.BatchNorm1d(dim // 2)\n",
    "        self.bn_v1 = nn.BatchNorm1d(dim // 2)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        x_feats = x[:, -1].view(x.size(0), -1).long()\n",
    "\n",
    "        # Embedding for features\n",
    "        e_step = self.embed_step(x_feats[:, 0])\n",
    "        e_hung = self.embed_hunger(x_feats[:, 1])\n",
    "        e_diff_l = self.embed_diff_len(x_feats[:, 2:5]).view(x.size(0), -1)\n",
    "        e_diff_h = self.embed_diff_head(x_feats[:, 5:8]).view(x.size(0), -1)\n",
    "\n",
    "        x = x[:, :-1].float()\n",
    "\n",
    "        # CNN for observation\n",
    "        h = F.relu_(self.conv0(x))\n",
    "\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h = F.relu_(h + self.conv1(h))\n",
    "\n",
    "        # Extract head position\n",
    "        h_head = (h * x[:, :1]).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        h_head2 = (h * x[:, 1:2]).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        h_head3 = (h * x[:, 2:3]).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        h_head4 = (h * x[:, 3:4]).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        h_avg = h.view(h.size(0), h.size(1), -1).mean(-1)\n",
    "\n",
    "        # Merge features\n",
    "        h = torch.cat(\n",
    "            [\n",
    "                h_head,\n",
    "                h_head2,\n",
    "                h_head3,\n",
    "                h_head4,\n",
    "                h_avg,\n",
    "                e_step,\n",
    "                e_hung,\n",
    "                e_diff_l,\n",
    "                e_diff_h,\n",
    "            ],\n",
    "            1,\n",
    "        ).view(1, h.size(0), -1)\n",
    "\n",
    "        # h, _ = self.attention(h, h, h)\n",
    "\n",
    "        h_p = F.relu_(self.bn_p1(self.head_p1(h.view(x.size(0), -1))))\n",
    "        p = self.head_p2(h_p)\n",
    "\n",
    "        h_v = F.relu_(self.bn_v1(self.head_v1(h.view(x.size(0), -1))))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p, \"value\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "objective-victoria",
    "outputId": "1ab137a5-e26e-4b9c-ff85-95fef713b755",
    "papermill": {
     "duration": 4.955868,
     "end_time": "2021-05-12T03:03:21.187355",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.231487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "if Config.debug or False:\n",
    "    model = GeeseNetAlpha()\n",
    "    # print(model)\n",
    "\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"params: {params:,}\")\n",
    "\n",
    "    train_ds = TrainDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "    for obs, action in train_loader:\n",
    "        print(f\"input shape: {obs.shape}\")\n",
    "        output = model(obs)\n",
    "        print(output)\n",
    "        print(f\"{torch.argmax(output['policy'], dim=1)}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "military-fiction",
    "papermill": {
     "duration": 0.033001,
     "end_time": "2021-05-12T03:03:21.255277",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.222276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sophisticated-hearts",
    "papermill": {
     "duration": 0.031759,
     "end_time": "2021-05-12T03:03:21.319849",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.288090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "designing-detective",
    "papermill": {
     "duration": 0.03139,
     "end_time": "2021-05-12T03:03:21.383038",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.351648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "passive-cooper",
    "papermill": {
     "duration": 0.038846,
     "end_time": "2021-05-12T03:03:21.454085",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.415239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(result_df):\n",
    "    preds = result_df[\"preds\"].values\n",
    "    labels = result_df[\"action\"].values\n",
    "    score = get_score(labels, preds)\n",
    "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thirty-tracy",
    "papermill": {
     "duration": 0.0293,
     "end_time": "2021-05-12T03:03:21.514179",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.484879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "introductory-brooklyn",
    "papermill": {
     "duration": 0.039424,
     "end_time": "2021-05-12T03:03:21.582969",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.543545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "raising-laugh",
    "papermill": {
     "duration": 0.042063,
     "end_time": "2021-05-12T03:03:21.654559",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.612496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (obs, action) in enumerate(train_loader):\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        y_preds = model(obs)[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / config.gradient_accumulation_steps\n",
    "        if Config.apex:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % config.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print(\n",
    "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
    "                f\"Loss avg.: {losses.avg:.4f} \"\n",
    "                f\"Grad: {grad_norm:.4f} \"\n",
    "                f\"LR: {scheduler.get_last_lr()[0]:.5f}  \"\n",
    "            )\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "plain-neighbor",
    "papermill": {
     "duration": 0.041056,
     "end_time": "2021-05-12T03:03:21.726585",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.685529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (obs, action) in enumerate(valid_loader):\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(obs)[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        if config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / config.gradient_accumulation_steps\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print(\n",
    "                f\"Eval: [{step}/{len(valid_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
    "                f\"Loss avg.: {losses.avg:.4f} \"\n",
    "            )\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "integrated-classification",
    "papermill": {
     "duration": 0.029832,
     "end_time": "2021-05-12T03:03:21.786427",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.756595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "harmful-explanation",
    "papermill": {
     "duration": 0.05136,
     "end_time": "2021-05-12T03:03:21.868561",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.817201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(folds, fold):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    # X_train_folds = X_train[folds[\"fold\"] != fold]\n",
    "    # X_valid_folds = X_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    # y_train_folds = y_train[folds[\"fold\"] != fold]\n",
    "    y_valid_folds = y_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    # y_df_train_folds = y_df[folds[\"fold\"] != fold]\n",
    "    y_df_valid_folds = y_df[folds[\"fold\"] == fold]\n",
    "\n",
    "    # train_dataset = TrainDataset(X_train[folds[\"fold\"] != fold], y_train[folds[\"fold\"] != fold])\n",
    "    # valid_dataset = TrainDataset(X_train[folds[\"fold\"] == fold], y_valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        TrainDataset(X_train[folds[\"fold\"] != fold], y_train[folds[\"fold\"] != fold]),\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        TrainDataset(X_train[folds[\"fold\"] == fold], y_valid_folds),\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if config.scheduler == \"ReduceLROnPlateau\":\n",
    "            scheduler = ReduceLROnPlateau(\n",
    "                optimizer, mode=\"min\", factor=config.factor, patience=config.patience, verbose=True, eps=config.eps\n",
    "            )\n",
    "        elif config.scheduler == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=config.T_max, eta_min=config.min_lr, last_epoch=-1)\n",
    "        elif config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "            scheduler = CosineAnnealingWarmRestarts(\n",
    "                optimizer, T_0=config.T_0, T_mult=1, eta_min=config.min_lr, last_epoch=-1\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = GeeseNetAlpha()\n",
    "    # try:\n",
    "    #     model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, Config.pre_train_file)))\n",
    "    # except:\n",
    "    #     print(f\"Failed to load pre-train weight.\")\n",
    "\n",
    "    # Disable training for value network\n",
    "    # for param in model.head_v1.parameters():\n",
    "    #     param.requires_grad = False\n",
    "    # for param in model.head_v2.parameters():\n",
    "    #     param.requires_grad = False\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Use multi GPU\n",
    "    if device == torch.device(\"cuda\") and not Config.apex:\n",
    "        model = torch.nn.DataParallel(model)  # make parallel\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # apex\n",
    "    # ====================================================\n",
    "    if Config.apex:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
    "\n",
    "    # ====================================================\n",
    "    # Criterion\n",
    "    # ====================================================\n",
    "    def get_criterion():\n",
    "        if config.criterion == \"CrossEntropyLoss\":\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        return criterion\n",
    "\n",
    "    criterion = get_criterion()\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    best_score = 0.0\n",
    "    best_loss = np.inf\n",
    "    best_preds = None\n",
    "\n",
    "    # wandb.watch(model, log_freq=Config.print_freq)\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "\n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(y_valid_folds, preds.argmax(1))\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Accuracy: {score}\")\n",
    "\n",
    "        wandb.log({\"epoch\": epoch + 1, \"train_loss\": avg_loss, \"val_loss\": avg_val_loss, \"accuracy\": score})\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{config.model_name}_fold{fold}_best.pth\")\n",
    "            best_preds = preds\n",
    "\n",
    "        if epoch == config.epochs - 1:\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save final model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{config.model_name}_fold{fold}_final.pth\")\n",
    "\n",
    "    y_df_valid_folds[[str(c) for c in range(config.n_class)]] = best_preds\n",
    "    y_df_valid_folds[\"preds\"] = best_preds.argmax(1)\n",
    "\n",
    "    return y_df_valid_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "complimentary-wright",
    "papermill": {
     "duration": 0.030218,
     "end_time": "2021-05-12T03:03:21.928896",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.898678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "particular-adaptation",
    "papermill": {
     "duration": 0.04089,
     "end_time": "2021-05-12T03:03:22.000150",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.959260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if Config.train:\n",
    "        # train\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(config.n_fold):\n",
    "            _oof_df = train_loop(folds, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df)\n",
    "            break  # fold 1つだけ\n",
    "        # CV result\n",
    "        # LOGGER.info(f\"========== CV ==========\")\n",
    "        # get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "backed-journal",
    "outputId": "c9f0ff3d-795e-466b-e22e-9ba21d08c874",
    "papermill": {
     "duration": 2797.64711,
     "end_time": "2021-05-12T03:49:59.678400",
     "exception": false,
     "start_time": "2021-05-12T03:03:22.031290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2250] Elapsed 0m 5s (remain 221m 50s) Loss avg.: 1.4240 Grad: 0.9038 LR: 0.00100  \n",
      "Epoch: [1][100/2250] Elapsed 1m 6s (remain 23m 30s) Loss avg.: 0.6920 Grad: 0.5552 LR: 0.00100  \n",
      "Epoch: [1][200/2250] Elapsed 2m 6s (remain 21m 32s) Loss avg.: 0.6289 Grad: 0.4413 LR: 0.00100  \n",
      "Epoch: [1][300/2250] Elapsed 3m 7s (remain 20m 12s) Loss avg.: 0.5979 Grad: 0.3612 LR: 0.00100  \n",
      "Epoch: [1][400/2250] Elapsed 4m 8s (remain 19m 3s) Loss avg.: 0.5771 Grad: 0.3872 LR: 0.00100  \n",
      "Epoch: [1][500/2250] Elapsed 5m 8s (remain 17m 56s) Loss avg.: 0.5631 Grad: 0.4723 LR: 0.00100  \n",
      "Epoch: [1][600/2250] Elapsed 6m 8s (remain 16m 51s) Loss avg.: 0.5522 Grad: 0.3364 LR: 0.00100  \n",
      "Epoch: [1][700/2250] Elapsed 7m 9s (remain 15m 48s) Loss avg.: 0.5440 Grad: 0.3549 LR: 0.00100  \n",
      "Epoch: [1][800/2250] Elapsed 8m 9s (remain 14m 45s) Loss avg.: 0.5370 Grad: 0.3054 LR: 0.00100  \n",
      "Epoch: [1][900/2250] Elapsed 9m 9s (remain 13m 43s) Loss avg.: 0.5312 Grad: 0.3589 LR: 0.00100  \n",
      "Epoch: [1][1000/2250] Elapsed 10m 10s (remain 12m 41s) Loss avg.: 0.5262 Grad: 0.3285 LR: 0.00100  \n",
      "Epoch: [1][1100/2250] Elapsed 11m 10s (remain 11m 40s) Loss avg.: 0.5219 Grad: 0.3398 LR: 0.00100  \n",
      "Epoch: [1][1200/2250] Elapsed 12m 11s (remain 10m 38s) Loss avg.: 0.5182 Grad: 0.3061 LR: 0.00100  \n",
      "Epoch: [1][1300/2250] Elapsed 13m 11s (remain 9m 37s) Loss avg.: 0.5148 Grad: 0.2745 LR: 0.00100  \n",
      "Epoch: [1][1400/2250] Elapsed 14m 12s (remain 8m 36s) Loss avg.: 0.5120 Grad: 0.3251 LR: 0.00100  \n",
      "Epoch: [1][1500/2250] Elapsed 15m 12s (remain 7m 35s) Loss avg.: 0.5094 Grad: 0.2914 LR: 0.00100  \n",
      "Epoch: [1][1600/2250] Elapsed 16m 13s (remain 6m 34s) Loss avg.: 0.5070 Grad: 0.2732 LR: 0.00100  \n",
      "Epoch: [1][1700/2250] Elapsed 17m 13s (remain 5m 33s) Loss avg.: 0.5047 Grad: 0.3105 LR: 0.00100  \n",
      "Epoch: [1][1800/2250] Elapsed 18m 14s (remain 4m 32s) Loss avg.: 0.5027 Grad: 0.2991 LR: 0.00100  \n",
      "Epoch: [1][1900/2250] Elapsed 19m 15s (remain 3m 32s) Loss avg.: 0.5008 Grad: 0.2653 LR: 0.00100  \n",
      "Epoch: [1][2000/2250] Elapsed 20m 15s (remain 2m 31s) Loss avg.: 0.4992 Grad: 0.2330 LR: 0.00100  \n",
      "Epoch: [1][2100/2250] Elapsed 21m 16s (remain 1m 30s) Loss avg.: 0.4976 Grad: 0.2726 LR: 0.00100  \n",
      "Epoch: [1][2200/2250] Elapsed 22m 16s (remain 0m 29s) Loss avg.: 0.4961 Grad: 0.2602 LR: 0.00100  \n",
      "Epoch: [1][2249/2250] Elapsed 22m 46s (remain 0m 0s) Loss avg.: 0.4954 Grad: 0.2598 LR: 0.00100  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 10m 44s) Loss avg.: 0.5037 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4676 \n",
      "Eval: [200/250] Elapsed 0m 34s (remain 0m 8s) Loss avg.: 0.4666 \n",
      "Eval: [249/250] Elapsed 0m 42s (remain 0m 0s) Loss avg.: 0.4658 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4954  avg_val_loss: 0.4658  time: 1412s\n",
      "Epoch 1 - Accuracy: 0.7981775\n",
      "Epoch 1 - Save Best Score: 0.7982 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2250] Elapsed 0m 3s (remain 141m 54s) Loss avg.: 0.4493 Grad: 0.2547 LR: 0.00099  \n",
      "Epoch: [2][100/2250] Elapsed 1m 4s (remain 22m 51s) Loss avg.: 0.4621 Grad: 0.2467 LR: 0.00099  \n",
      "Epoch: [2][200/2250] Elapsed 2m 5s (remain 21m 15s) Loss avg.: 0.4605 Grad: 0.2824 LR: 0.00099  \n",
      "Epoch: [2][300/2250] Elapsed 3m 5s (remain 20m 2s) Loss avg.: 0.4606 Grad: 0.2625 LR: 0.00099  \n",
      "Epoch: [2][400/2250] Elapsed 4m 6s (remain 18m 56s) Loss avg.: 0.4598 Grad: 0.2411 LR: 0.00099  \n",
      "Epoch: [2][500/2250] Elapsed 5m 7s (remain 17m 51s) Loss avg.: 0.4596 Grad: 0.2651 LR: 0.00099  \n",
      "Epoch: [2][600/2250] Elapsed 6m 7s (remain 16m 48s) Loss avg.: 0.4592 Grad: 0.2486 LR: 0.00099  \n",
      "Epoch: [2][700/2250] Elapsed 7m 8s (remain 15m 46s) Loss avg.: 0.4589 Grad: 0.2560 LR: 0.00099  \n",
      "Epoch: [2][800/2250] Elapsed 8m 8s (remain 14m 44s) Loss avg.: 0.4592 Grad: 0.2649 LR: 0.00099  \n",
      "Epoch: [2][900/2250] Elapsed 9m 9s (remain 13m 42s) Loss avg.: 0.4590 Grad: 0.2120 LR: 0.00099  \n",
      "Epoch: [2][1000/2250] Elapsed 10m 9s (remain 12m 40s) Loss avg.: 0.4588 Grad: 0.2786 LR: 0.00099  \n",
      "Epoch: [2][1100/2250] Elapsed 11m 10s (remain 11m 39s) Loss avg.: 0.4587 Grad: 0.2591 LR: 0.00099  \n",
      "Epoch: [2][1200/2250] Elapsed 12m 10s (remain 10m 38s) Loss avg.: 0.4584 Grad: 0.2530 LR: 0.00099  \n",
      "Epoch: [2][1300/2250] Elapsed 13m 11s (remain 9m 37s) Loss avg.: 0.4581 Grad: 0.2319 LR: 0.00099  \n",
      "Epoch: [2][1400/2250] Elapsed 14m 11s (remain 8m 36s) Loss avg.: 0.4578 Grad: 0.2309 LR: 0.00099  \n",
      "Epoch: [2][1500/2250] Elapsed 15m 12s (remain 7m 35s) Loss avg.: 0.4574 Grad: 0.2581 LR: 0.00099  \n",
      "Epoch: [2][1600/2250] Elapsed 16m 12s (remain 6m 34s) Loss avg.: 0.4573 Grad: 0.1985 LR: 0.00099  \n",
      "Epoch: [2][1700/2250] Elapsed 17m 13s (remain 5m 33s) Loss avg.: 0.4570 Grad: 0.2245 LR: 0.00099  \n",
      "Epoch: [2][1800/2250] Elapsed 18m 13s (remain 4m 32s) Loss avg.: 0.4569 Grad: 0.2021 LR: 0.00099  \n",
      "Epoch: [2][1900/2250] Elapsed 19m 14s (remain 3m 31s) Loss avg.: 0.4567 Grad: 0.2230 LR: 0.00099  \n",
      "Epoch: [2][2000/2250] Elapsed 20m 14s (remain 2m 31s) Loss avg.: 0.4566 Grad: 0.2151 LR: 0.00099  \n",
      "Epoch: [2][2100/2250] Elapsed 21m 15s (remain 1m 30s) Loss avg.: 0.4564 Grad: 0.2193 LR: 0.00099  \n",
      "Epoch: [2][2200/2250] Elapsed 22m 15s (remain 0m 29s) Loss avg.: 0.4562 Grad: 0.2007 LR: 0.00099  \n",
      "Epoch: [2][2249/2250] Elapsed 22m 45s (remain 0m 0s) Loss avg.: 0.4561 Grad: 0.2011 LR: 0.00099  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 9m 51s) Loss avg.: 0.4905 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4557 \n",
      "Eval: [200/250] Elapsed 0m 34s (remain 0m 8s) Loss avg.: 0.4544 \n",
      "Eval: [249/250] Elapsed 0m 42s (remain 0m 0s) Loss avg.: 0.4537 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4561  avg_val_loss: 0.4537  time: 1410s\n",
      "Epoch 2 - Accuracy: 0.80415\n",
      "Epoch 2 - Save Best Score: 0.8042 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/2250] Elapsed 0m 3s (remain 134m 27s) Loss avg.: 0.4435 Grad: 0.1923 LR: 0.00098  \n",
      "Epoch: [3][100/2250] Elapsed 1m 4s (remain 22m 47s) Loss avg.: 0.4495 Grad: 0.2073 LR: 0.00098  \n",
      "Epoch: [3][200/2250] Elapsed 2m 4s (remain 21m 11s) Loss avg.: 0.4498 Grad: 0.2100 LR: 0.00098  \n",
      "Epoch: [3][300/2250] Elapsed 3m 5s (remain 20m 0s) Loss avg.: 0.4493 Grad: 0.1912 LR: 0.00098  \n",
      "Epoch: [3][400/2250] Elapsed 4m 5s (remain 18m 53s) Loss avg.: 0.4488 Grad: 0.2054 LR: 0.00098  \n",
      "Epoch: [3][500/2250] Elapsed 5m 6s (remain 17m 49s) Loss avg.: 0.4489 Grad: 0.2218 LR: 0.00098  \n",
      "Epoch: [3][600/2250] Elapsed 6m 6s (remain 16m 46s) Loss avg.: 0.4486 Grad: 0.1934 LR: 0.00098  \n",
      "Epoch: [3][700/2250] Elapsed 7m 7s (remain 15m 44s) Loss avg.: 0.4487 Grad: 0.2038 LR: 0.00098  \n",
      "Epoch: [3][800/2250] Elapsed 8m 7s (remain 14m 42s) Loss avg.: 0.4489 Grad: 0.2074 LR: 0.00098  \n",
      "Epoch: [3][900/2250] Elapsed 9m 8s (remain 13m 40s) Loss avg.: 0.4488 Grad: 0.2097 LR: 0.00098  \n",
      "Epoch: [3][1000/2250] Elapsed 10m 8s (remain 12m 39s) Loss avg.: 0.4487 Grad: 0.2445 LR: 0.00098  \n",
      "Epoch: [3][1100/2250] Elapsed 11m 9s (remain 11m 38s) Loss avg.: 0.4487 Grad: 0.1837 LR: 0.00098  \n",
      "Epoch: [3][1200/2250] Elapsed 12m 9s (remain 10m 37s) Loss avg.: 0.4485 Grad: 0.2237 LR: 0.00098  \n",
      "Epoch: [3][1300/2250] Elapsed 13m 10s (remain 9m 36s) Loss avg.: 0.4484 Grad: 0.2072 LR: 0.00098  \n",
      "Epoch: [3][1400/2250] Elapsed 14m 10s (remain 8m 35s) Loss avg.: 0.4482 Grad: 0.1911 LR: 0.00098  \n",
      "Epoch: [3][1500/2250] Elapsed 15m 11s (remain 7m 34s) Loss avg.: 0.4481 Grad: 0.2253 LR: 0.00098  \n",
      "Epoch: [3][1600/2250] Elapsed 16m 11s (remain 6m 33s) Loss avg.: 0.4481 Grad: 0.2034 LR: 0.00098  \n",
      "Epoch: [3][1700/2250] Elapsed 17m 12s (remain 5m 33s) Loss avg.: 0.4480 Grad: 0.1733 LR: 0.00098  \n",
      "Epoch: [3][1800/2250] Elapsed 18m 12s (remain 4m 32s) Loss avg.: 0.4479 Grad: 0.1781 LR: 0.00098  \n",
      "Epoch: [3][1900/2250] Elapsed 19m 13s (remain 3m 31s) Loss avg.: 0.4480 Grad: 0.1788 LR: 0.00098  \n",
      "Epoch: [3][2000/2250] Elapsed 20m 13s (remain 2m 31s) Loss avg.: 0.4479 Grad: 0.1897 LR: 0.00098  \n",
      "Epoch: [3][2100/2250] Elapsed 21m 14s (remain 1m 30s) Loss avg.: 0.4479 Grad: 0.1671 LR: 0.00098  \n",
      "Epoch: [3][2200/2250] Elapsed 22m 14s (remain 0m 29s) Loss avg.: 0.4477 Grad: 0.1844 LR: 0.00098  \n",
      "Epoch: [3][2249/2250] Elapsed 22m 44s (remain 0m 0s) Loss avg.: 0.4477 Grad: 0.1971 LR: 0.00098  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 10m 38s) Loss avg.: 0.4857 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4546 \n",
      "Eval: [200/250] Elapsed 0m 34s (remain 0m 8s) Loss avg.: 0.4534 \n",
      "Eval: [249/250] Elapsed 0m 42s (remain 0m 0s) Loss avg.: 0.4527 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.4477  avg_val_loss: 0.4527  time: 1410s\n",
      "Epoch 3 - Accuracy: 0.8046075\n",
      "Epoch 3 - Save Best Score: 0.8046 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/2250] Elapsed 0m 3s (remain 126m 14s) Loss avg.: 0.4615 Grad: 0.2314 LR: 0.00095  \n",
      "Epoch: [4][100/2250] Elapsed 1m 3s (remain 22m 34s) Loss avg.: 0.4427 Grad: 0.1717 LR: 0.00095  \n",
      "Epoch: [4][200/2250] Elapsed 2m 4s (remain 21m 4s) Loss avg.: 0.4429 Grad: 0.1976 LR: 0.00095  \n",
      "Epoch: [4][300/2250] Elapsed 3m 4s (remain 19m 54s) Loss avg.: 0.4431 Grad: 0.1905 LR: 0.00095  \n",
      "Epoch: [4][400/2250] Elapsed 4m 4s (remain 18m 49s) Loss avg.: 0.4429 Grad: 0.1670 LR: 0.00095  \n",
      "Epoch: [4][500/2250] Elapsed 5m 5s (remain 17m 46s) Loss avg.: 0.4433 Grad: 0.1904 LR: 0.00095  \n",
      "Epoch: [4][600/2250] Elapsed 6m 5s (remain 16m 43s) Loss avg.: 0.4431 Grad: 0.2006 LR: 0.00095  \n",
      "Epoch: [4][700/2250] Elapsed 7m 6s (remain 15m 42s) Loss avg.: 0.4428 Grad: 0.1965 LR: 0.00095  \n",
      "Epoch: [4][800/2250] Elapsed 8m 7s (remain 14m 41s) Loss avg.: 0.4427 Grad: 0.1840 LR: 0.00095  \n",
      "Epoch: [4][900/2250] Elapsed 9m 7s (remain 13m 39s) Loss avg.: 0.4426 Grad: 0.1657 LR: 0.00095  \n",
      "Epoch: [4][1000/2250] Elapsed 10m 7s (remain 12m 38s) Loss avg.: 0.4427 Grad: 0.1514 LR: 0.00095  \n",
      "Epoch: [4][1100/2250] Elapsed 11m 8s (remain 11m 37s) Loss avg.: 0.4427 Grad: 0.1886 LR: 0.00095  \n",
      "Epoch: [4][1200/2250] Elapsed 12m 8s (remain 10m 36s) Loss avg.: 0.4429 Grad: 0.1879 LR: 0.00095  \n",
      "Epoch: [4][1300/2250] Elapsed 13m 9s (remain 9m 35s) Loss avg.: 0.4429 Grad: 0.1794 LR: 0.00095  \n",
      "Epoch: [4][1400/2250] Elapsed 14m 9s (remain 8m 35s) Loss avg.: 0.4429 Grad: 0.2165 LR: 0.00095  \n",
      "Epoch: [4][1500/2250] Elapsed 15m 10s (remain 7m 34s) Loss avg.: 0.4429 Grad: 0.1941 LR: 0.00095  \n",
      "Epoch: [4][1600/2250] Elapsed 16m 11s (remain 6m 33s) Loss avg.: 0.4428 Grad: 0.1830 LR: 0.00095  \n",
      "Epoch: [4][1700/2250] Elapsed 17m 11s (remain 5m 32s) Loss avg.: 0.4428 Grad: 0.1880 LR: 0.00095  \n",
      "Epoch: [4][1800/2250] Elapsed 18m 12s (remain 4m 32s) Loss avg.: 0.4429 Grad: 0.1672 LR: 0.00095  \n",
      "Epoch: [4][1900/2250] Elapsed 19m 12s (remain 3m 31s) Loss avg.: 0.4428 Grad: 0.1685 LR: 0.00095  \n",
      "Epoch: [4][2000/2250] Elapsed 20m 13s (remain 2m 30s) Loss avg.: 0.4428 Grad: 0.1674 LR: 0.00095  \n",
      "Epoch: [4][2100/2250] Elapsed 21m 13s (remain 1m 30s) Loss avg.: 0.4428 Grad: 0.1588 LR: 0.00095  \n",
      "Epoch: [4][2200/2250] Elapsed 22m 14s (remain 0m 29s) Loss avg.: 0.4428 Grad: 0.1933 LR: 0.00095  \n",
      "Epoch: [4][2249/2250] Elapsed 22m 43s (remain 0m 0s) Loss avg.: 0.4427 Grad: 0.1613 LR: 0.00095  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 10m 36s) Loss avg.: 0.4814 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4482 \n",
      "Eval: [200/250] Elapsed 0m 34s (remain 0m 8s) Loss avg.: 0.4469 \n",
      "Eval: [249/250] Elapsed 0m 42s (remain 0m 0s) Loss avg.: 0.4461 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.4427  avg_val_loss: 0.4461  time: 1410s\n",
      "Epoch 4 - Accuracy: 0.8078125\n",
      "Epoch 4 - Save Best Score: 0.8078 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/2250] Elapsed 0m 3s (remain 140m 25s) Loss avg.: 0.4408 Grad: 0.1721 LR: 0.00091  \n",
      "Epoch: [5][100/2250] Elapsed 1m 4s (remain 22m 48s) Loss avg.: 0.4374 Grad: 0.1821 LR: 0.00091  \n",
      "Epoch: [5][200/2250] Elapsed 2m 4s (remain 21m 12s) Loss avg.: 0.4380 Grad: 0.1721 LR: 0.00091  \n",
      "Epoch: [5][300/2250] Elapsed 3m 5s (remain 20m 0s) Loss avg.: 0.4383 Grad: 0.1757 LR: 0.00091  \n",
      "Epoch: [5][400/2250] Elapsed 4m 6s (remain 18m 54s) Loss avg.: 0.4386 Grad: 0.1692 LR: 0.00091  \n",
      "Epoch: [5][500/2250] Elapsed 5m 6s (remain 17m 49s) Loss avg.: 0.4387 Grad: 0.2064 LR: 0.00091  \n",
      "Epoch: [5][600/2250] Elapsed 6m 6s (remain 16m 46s) Loss avg.: 0.4390 Grad: 0.1519 LR: 0.00091  \n",
      "Epoch: [5][700/2250] Elapsed 7m 7s (remain 15m 43s) Loss avg.: 0.4390 Grad: 0.1703 LR: 0.00091  \n",
      "Epoch: [5][800/2250] Elapsed 8m 7s (remain 14m 42s) Loss avg.: 0.4395 Grad: 0.1715 LR: 0.00091  \n",
      "Epoch: [5][900/2250] Elapsed 9m 7s (remain 13m 40s) Loss avg.: 0.4395 Grad: 0.1565 LR: 0.00091  \n",
      "Epoch: [5][1000/2250] Elapsed 10m 8s (remain 12m 39s) Loss avg.: 0.4395 Grad: 0.1903 LR: 0.00091  \n",
      "Epoch: [5][1100/2250] Elapsed 11m 8s (remain 11m 38s) Loss avg.: 0.4394 Grad: 0.1715 LR: 0.00091  \n",
      "Epoch: [5][1200/2250] Elapsed 12m 9s (remain 10m 36s) Loss avg.: 0.4392 Grad: 0.1679 LR: 0.00091  \n",
      "Epoch: [5][1300/2250] Elapsed 13m 9s (remain 9m 35s) Loss avg.: 0.4392 Grad: 0.1553 LR: 0.00091  \n",
      "Epoch: [5][1400/2250] Elapsed 14m 9s (remain 8m 35s) Loss avg.: 0.4392 Grad: 0.1446 LR: 0.00091  \n",
      "Epoch: [5][1500/2250] Elapsed 15m 10s (remain 7m 34s) Loss avg.: 0.4392 Grad: 0.1887 LR: 0.00091  \n",
      "Epoch: [5][1600/2250] Elapsed 16m 10s (remain 6m 33s) Loss avg.: 0.4391 Grad: 0.1630 LR: 0.00091  \n",
      "Epoch: [5][1700/2250] Elapsed 17m 10s (remain 5m 32s) Loss avg.: 0.4391 Grad: 0.1547 LR: 0.00091  \n",
      "Epoch: [5][1800/2250] Elapsed 18m 11s (remain 4m 31s) Loss avg.: 0.4392 Grad: 0.1768 LR: 0.00091  \n",
      "Epoch: [5][1900/2250] Elapsed 19m 11s (remain 3m 31s) Loss avg.: 0.4392 Grad: 0.1867 LR: 0.00091  \n",
      "Epoch: [5][2000/2250] Elapsed 20m 11s (remain 2m 30s) Loss avg.: 0.4392 Grad: 0.1597 LR: 0.00091  \n",
      "Epoch: [5][2100/2250] Elapsed 21m 12s (remain 1m 30s) Loss avg.: 0.4393 Grad: 0.1572 LR: 0.00091  \n",
      "Epoch: [5][2200/2250] Elapsed 22m 12s (remain 0m 29s) Loss avg.: 0.4393 Grad: 0.1631 LR: 0.00091  \n",
      "Epoch: [5][2249/2250] Elapsed 22m 42s (remain 0m 0s) Loss avg.: 0.4393 Grad: 0.1603 LR: 0.00091  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 10m 11s) Loss avg.: 0.4848 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4468 \n",
      "Eval: [200/250] Elapsed 0m 34s (remain 0m 8s) Loss avg.: 0.4454 \n",
      "Eval: [249/250] Elapsed 0m 42s (remain 0m 0s) Loss avg.: 0.4446 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.4393  avg_val_loss: 0.4446  time: 1409s\n",
      "Epoch 5 - Accuracy: 0.8086375\n",
      "Epoch 5 - Save Best Score: 0.8086 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/2250] Elapsed 0m 3s (remain 141m 17s) Loss avg.: 0.4408 Grad: 0.1602 LR: 0.00087  \n",
      "Epoch: [6][100/2250] Elapsed 1m 4s (remain 22m 53s) Loss avg.: 0.4352 Grad: 0.1616 LR: 0.00087  \n",
      "Epoch: [6][200/2250] Elapsed 2m 5s (remain 21m 14s) Loss avg.: 0.4359 Grad: 0.1503 LR: 0.00087  \n",
      "Epoch: [6][300/2250] Elapsed 3m 5s (remain 20m 0s) Loss avg.: 0.4358 Grad: 0.1924 LR: 0.00087  \n",
      "Epoch: [6][400/2250] Elapsed 4m 5s (remain 18m 54s) Loss avg.: 0.4358 Grad: 0.1736 LR: 0.00087  \n",
      "Epoch: [6][500/2250] Elapsed 5m 6s (remain 17m 49s) Loss avg.: 0.4359 Grad: 0.1614 LR: 0.00087  \n",
      "Epoch: [6][600/2250] Elapsed 6m 6s (remain 16m 46s) Loss avg.: 0.4360 Grad: 0.1606 LR: 0.00087  \n",
      "Epoch: [6][700/2250] Elapsed 7m 7s (remain 15m 44s) Loss avg.: 0.4363 Grad: 0.1488 LR: 0.00087  \n",
      "Epoch: [6][800/2250] Elapsed 8m 8s (remain 14m 42s) Loss avg.: 0.4363 Grad: 0.1572 LR: 0.00087  \n",
      "Epoch: [6][900/2250] Elapsed 9m 8s (remain 13m 41s) Loss avg.: 0.4365 Grad: 0.1567 LR: 0.00087  \n",
      "Epoch: [6][1000/2250] Elapsed 10m 9s (remain 12m 40s) Loss avg.: 0.4365 Grad: 0.1522 LR: 0.00087  \n",
      "Epoch: [6][1100/2250] Elapsed 11m 9s (remain 11m 38s) Loss avg.: 0.4366 Grad: 0.1772 LR: 0.00087  \n",
      "Epoch: [6][1200/2250] Elapsed 12m 10s (remain 10m 37s) Loss avg.: 0.4365 Grad: 0.1560 LR: 0.00087  \n",
      "Epoch: [6][1300/2250] Elapsed 13m 10s (remain 9m 36s) Loss avg.: 0.4364 Grad: 0.1400 LR: 0.00087  \n",
      "Epoch: [6][1400/2250] Elapsed 14m 10s (remain 8m 35s) Loss avg.: 0.4364 Grad: 0.1698 LR: 0.00087  \n",
      "Epoch: [6][1500/2250] Elapsed 15m 11s (remain 7m 34s) Loss avg.: 0.4364 Grad: 0.1601 LR: 0.00087  \n",
      "Epoch: [6][1600/2250] Elapsed 16m 12s (remain 6m 34s) Loss avg.: 0.4366 Grad: 0.1621 LR: 0.00087  \n",
      "Epoch: [6][1700/2250] Elapsed 17m 12s (remain 5m 33s) Loss avg.: 0.4366 Grad: 0.1662 LR: 0.00087  \n",
      "Epoch: [6][1800/2250] Elapsed 18m 13s (remain 4m 32s) Loss avg.: 0.4366 Grad: 0.1615 LR: 0.00087  \n",
      "Epoch: [6][1900/2250] Elapsed 19m 13s (remain 3m 31s) Loss avg.: 0.4365 Grad: 0.1805 LR: 0.00087  \n",
      "Epoch: [6][2000/2250] Elapsed 20m 14s (remain 2m 31s) Loss avg.: 0.4364 Grad: 0.1720 LR: 0.00087  \n",
      "Epoch: [6][2100/2250] Elapsed 21m 14s (remain 1m 30s) Loss avg.: 0.4364 Grad: 0.1520 LR: 0.00087  \n",
      "Epoch: [6][2200/2250] Elapsed 22m 15s (remain 0m 29s) Loss avg.: 0.4364 Grad: 0.1509 LR: 0.00087  \n",
      "Epoch: [6][2249/2250] Elapsed 22m 44s (remain 0m 0s) Loss avg.: 0.4364 Grad: 0.1457 LR: 0.00087  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 10m 34s) Loss avg.: 0.4854 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4480 \n",
      "Eval: [200/250] Elapsed 0m 34s (remain 0m 8s) Loss avg.: 0.4465 \n",
      "Eval: [249/250] Elapsed 0m 42s (remain 0m 0s) Loss avg.: 0.4457 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.4364  avg_val_loss: 0.4457  time: 1411s\n",
      "Epoch 6 - Accuracy: 0.8078325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/2250] Elapsed 0m 3s (remain 141m 22s) Loss avg.: 0.4317 Grad: 0.1617 LR: 0.00081  \n",
      "Epoch: [7][100/2250] Elapsed 1m 4s (remain 22m 46s) Loss avg.: 0.4315 Grad: 0.1487 LR: 0.00081  \n",
      "Epoch: [7][200/2250] Elapsed 2m 4s (remain 21m 9s) Loss avg.: 0.4320 Grad: 0.1683 LR: 0.00081  \n",
      "Epoch: [7][300/2250] Elapsed 3m 4s (remain 19m 57s) Loss avg.: 0.4326 Grad: 0.1551 LR: 0.00081  \n",
      "Epoch: [7][400/2250] Elapsed 4m 5s (remain 18m 50s) Loss avg.: 0.4329 Grad: 0.1594 LR: 0.00081  \n",
      "Epoch: [7][500/2250] Elapsed 5m 5s (remain 17m 47s) Loss avg.: 0.4330 Grad: 0.1436 LR: 0.00081  \n",
      "Epoch: [7][600/2250] Elapsed 6m 6s (remain 16m 44s) Loss avg.: 0.4333 Grad: 0.1672 LR: 0.00081  \n",
      "Epoch: [7][700/2250] Elapsed 7m 6s (remain 15m 42s) Loss avg.: 0.4333 Grad: 0.1473 LR: 0.00081  \n",
      "Epoch: [7][800/2250] Elapsed 8m 6s (remain 14m 40s) Loss avg.: 0.4333 Grad: 0.1509 LR: 0.00081  \n",
      "Epoch: [7][900/2250] Elapsed 9m 7s (remain 13m 39s) Loss avg.: 0.4333 Grad: 0.1424 LR: 0.00081  \n",
      "Epoch: [7][1000/2250] Elapsed 10m 7s (remain 12m 37s) Loss avg.: 0.4333 Grad: 0.1505 LR: 0.00081  \n",
      "Epoch: [7][1100/2250] Elapsed 11m 7s (remain 11m 36s) Loss avg.: 0.4335 Grad: 0.1616 LR: 0.00081  \n",
      "Epoch: [7][1200/2250] Elapsed 12m 8s (remain 10m 36s) Loss avg.: 0.4336 Grad: 0.1874 LR: 0.00081  \n",
      "Epoch: [7][1300/2250] Elapsed 13m 8s (remain 9m 35s) Loss avg.: 0.4336 Grad: 0.1458 LR: 0.00081  \n",
      "Epoch: [7][1400/2250] Elapsed 14m 9s (remain 8m 34s) Loss avg.: 0.4337 Grad: 0.1783 LR: 0.00081  \n",
      "Epoch: [7][1500/2250] Elapsed 15m 9s (remain 7m 33s) Loss avg.: 0.4339 Grad: 0.1386 LR: 0.00081  \n",
      "Epoch: [7][1600/2250] Elapsed 16m 9s (remain 6m 33s) Loss avg.: 0.4339 Grad: 0.1556 LR: 0.00081  \n",
      "Epoch: [7][1700/2250] Elapsed 17m 10s (remain 5m 32s) Loss avg.: 0.4339 Grad: 0.1542 LR: 0.00081  \n",
      "Epoch: [7][1800/2250] Elapsed 18m 10s (remain 4m 31s) Loss avg.: 0.4339 Grad: 0.1525 LR: 0.00081  \n",
      "Epoch: [7][1900/2250] Elapsed 19m 11s (remain 3m 31s) Loss avg.: 0.4339 Grad: 0.1699 LR: 0.00081  \n",
      "Epoch: [7][2000/2250] Elapsed 20m 11s (remain 2m 30s) Loss avg.: 0.4340 Grad: 0.1615 LR: 0.00081  \n",
      "Epoch: [7][2100/2250] Elapsed 21m 12s (remain 1m 30s) Loss avg.: 0.4340 Grad: 0.1402 LR: 0.00081  \n",
      "Epoch: [7][2200/2250] Elapsed 22m 12s (remain 0m 29s) Loss avg.: 0.4340 Grad: 0.1486 LR: 0.00081  \n",
      "Epoch: [7][2249/2250] Elapsed 22m 42s (remain 0m 0s) Loss avg.: 0.4341 Grad: 0.1579 LR: 0.00081  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 10m 56s) Loss avg.: 0.4829 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4437 \n",
      "Eval: [200/250] Elapsed 0m 34s (remain 0m 8s) Loss avg.: 0.4422 \n",
      "Eval: [249/250] Elapsed 0m 42s (remain 0m 0s) Loss avg.: 0.4416 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.4341  avg_val_loss: 0.4416  time: 1407s\n",
      "Epoch 7 - Accuracy: 0.80953125\n",
      "Epoch 7 - Save Best Score: 0.8095 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/2250] Elapsed 0m 3s (remain 132m 15s) Loss avg.: 0.4399 Grad: 0.1614 LR: 0.00075  \n",
      "Epoch: [8][100/2250] Elapsed 1m 4s (remain 22m 45s) Loss avg.: 0.4315 Grad: 0.1740 LR: 0.00075  \n",
      "Epoch: [8][200/2250] Elapsed 2m 4s (remain 21m 12s) Loss avg.: 0.4314 Grad: 0.1620 LR: 0.00075  \n",
      "Epoch: [8][300/2250] Elapsed 3m 5s (remain 19m 59s) Loss avg.: 0.4314 Grad: 0.1585 LR: 0.00075  \n",
      "Epoch: [8][400/2250] Elapsed 4m 5s (remain 18m 53s) Loss avg.: 0.4308 Grad: 0.1557 LR: 0.00075  \n",
      "Epoch: [8][500/2250] Elapsed 5m 6s (remain 17m 48s) Loss avg.: 0.4308 Grad: 0.1580 LR: 0.00075  \n",
      "Epoch: [8][600/2250] Elapsed 6m 6s (remain 16m 45s) Loss avg.: 0.4307 Grad: 0.1555 LR: 0.00075  \n",
      "Epoch: [8][700/2250] Elapsed 7m 7s (remain 15m 43s) Loss avg.: 0.4311 Grad: 0.1391 LR: 0.00075  \n",
      "Epoch: [8][800/2250] Elapsed 8m 7s (remain 14m 41s) Loss avg.: 0.4311 Grad: 0.1644 LR: 0.00075  \n",
      "Epoch: [8][900/2250] Elapsed 9m 8s (remain 13m 40s) Loss avg.: 0.4310 Grad: 0.1518 LR: 0.00075  \n",
      "Epoch: [8][1000/2250] Elapsed 10m 8s (remain 12m 39s) Loss avg.: 0.4312 Grad: 0.1560 LR: 0.00075  \n",
      "Epoch: [8][1100/2250] Elapsed 11m 9s (remain 11m 38s) Loss avg.: 0.4313 Grad: 0.1660 LR: 0.00075  \n",
      "Epoch: [8][1200/2250] Elapsed 12m 9s (remain 10m 37s) Loss avg.: 0.4314 Grad: 0.1607 LR: 0.00075  \n",
      "Epoch: [8][1300/2250] Elapsed 13m 9s (remain 9m 36s) Loss avg.: 0.4315 Grad: 0.1440 LR: 0.00075  \n",
      "Epoch: [8][1400/2250] Elapsed 14m 10s (remain 8m 35s) Loss avg.: 0.4315 Grad: 0.1562 LR: 0.00075  \n",
      "Epoch: [8][1500/2250] Elapsed 15m 10s (remain 7m 34s) Loss avg.: 0.4315 Grad: 0.1628 LR: 0.00075  \n",
      "Epoch: [8][1600/2250] Elapsed 16m 11s (remain 6m 33s) Loss avg.: 0.4316 Grad: 0.1535 LR: 0.00075  \n",
      "Epoch: [8][1700/2250] Elapsed 17m 11s (remain 5m 33s) Loss avg.: 0.4316 Grad: 0.1525 LR: 0.00075  \n",
      "Epoch: [8][1800/2250] Elapsed 18m 12s (remain 4m 32s) Loss avg.: 0.4316 Grad: 0.1441 LR: 0.00075  \n",
      "Epoch: [8][1900/2250] Elapsed 19m 12s (remain 3m 31s) Loss avg.: 0.4318 Grad: 0.1527 LR: 0.00075  \n",
      "Epoch: [8][2000/2250] Elapsed 20m 13s (remain 2m 30s) Loss avg.: 0.4319 Grad: 0.1605 LR: 0.00075  \n",
      "Epoch: [8][2100/2250] Elapsed 21m 13s (remain 1m 30s) Loss avg.: 0.4319 Grad: 0.1553 LR: 0.00075  \n",
      "Epoch: [8][2200/2250] Elapsed 22m 14s (remain 0m 29s) Loss avg.: 0.4320 Grad: 0.1538 LR: 0.00075  \n",
      "Epoch: [8][2249/2250] Elapsed 22m 44s (remain 0m 0s) Loss avg.: 0.4320 Grad: 0.1543 LR: 0.00075  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 11m 9s) Loss avg.: 0.4792 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4439 \n",
      "Eval: [200/250] Elapsed 0m 35s (remain 0m 8s) Loss avg.: 0.4424 \n",
      "Eval: [249/250] Elapsed 0m 43s (remain 0m 0s) Loss avg.: 0.4417 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.4320  avg_val_loss: 0.4417  time: 1410s\n",
      "Epoch 8 - Accuracy: 0.80963125\n",
      "Epoch 8 - Save Best Score: 0.8096 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/2250] Elapsed 0m 3s (remain 140m 37s) Loss avg.: 0.4363 Grad: 0.1802 LR: 0.00069  \n",
      "Epoch: [9][100/2250] Elapsed 1m 4s (remain 22m 47s) Loss avg.: 0.4250 Grad: 0.1561 LR: 0.00069  \n",
      "Epoch: [9][200/2250] Elapsed 2m 4s (remain 21m 12s) Loss avg.: 0.4279 Grad: 0.1457 LR: 0.00069  \n",
      "Epoch: [9][300/2250] Elapsed 3m 5s (remain 20m 0s) Loss avg.: 0.4280 Grad: 0.1523 LR: 0.00069  \n",
      "Epoch: [9][400/2250] Elapsed 4m 5s (remain 18m 53s) Loss avg.: 0.4280 Grad: 0.1748 LR: 0.00069  \n",
      "Epoch: [9][500/2250] Elapsed 5m 6s (remain 17m 49s) Loss avg.: 0.4284 Grad: 0.1475 LR: 0.00069  \n",
      "Epoch: [9][600/2250] Elapsed 6m 7s (remain 16m 47s) Loss avg.: 0.4286 Grad: 0.1777 LR: 0.00069  \n",
      "Epoch: [9][700/2250] Elapsed 7m 7s (remain 15m 44s) Loss avg.: 0.4286 Grad: 0.1616 LR: 0.00069  \n",
      "Epoch: [9][800/2250] Elapsed 8m 7s (remain 14m 42s) Loss avg.: 0.4286 Grad: 0.1653 LR: 0.00069  \n",
      "Epoch: [9][900/2250] Elapsed 9m 8s (remain 13m 40s) Loss avg.: 0.4288 Grad: 0.1566 LR: 0.00069  \n",
      "Epoch: [9][1000/2250] Elapsed 10m 8s (remain 12m 39s) Loss avg.: 0.4288 Grad: 0.1591 LR: 0.00069  \n",
      "Epoch: [9][1100/2250] Elapsed 11m 8s (remain 11m 38s) Loss avg.: 0.4291 Grad: 0.1509 LR: 0.00069  \n",
      "Epoch: [9][1200/2250] Elapsed 12m 9s (remain 10m 36s) Loss avg.: 0.4292 Grad: 0.1634 LR: 0.00069  \n",
      "Epoch: [9][1300/2250] Elapsed 13m 9s (remain 9m 36s) Loss avg.: 0.4293 Grad: 0.1443 LR: 0.00069  \n",
      "Epoch: [9][1400/2250] Elapsed 14m 10s (remain 8m 35s) Loss avg.: 0.4293 Grad: 0.1695 LR: 0.00069  \n",
      "Epoch: [9][1500/2250] Elapsed 15m 10s (remain 7m 34s) Loss avg.: 0.4294 Grad: 0.1678 LR: 0.00069  \n",
      "Epoch: [9][1600/2250] Elapsed 16m 10s (remain 6m 33s) Loss avg.: 0.4296 Grad: 0.1651 LR: 0.00069  \n",
      "Epoch: [9][1700/2250] Elapsed 17m 11s (remain 5m 32s) Loss avg.: 0.4297 Grad: 0.1523 LR: 0.00069  \n",
      "Epoch: [9][1800/2250] Elapsed 18m 11s (remain 4m 32s) Loss avg.: 0.4298 Grad: 0.1578 LR: 0.00069  \n",
      "Epoch: [9][1900/2250] Elapsed 19m 12s (remain 3m 31s) Loss avg.: 0.4297 Grad: 0.1437 LR: 0.00069  \n",
      "Epoch: [9][2000/2250] Elapsed 20m 12s (remain 2m 30s) Loss avg.: 0.4298 Grad: 0.1587 LR: 0.00069  \n",
      "Epoch: [9][2100/2250] Elapsed 21m 13s (remain 1m 30s) Loss avg.: 0.4299 Grad: 0.1408 LR: 0.00069  \n",
      "Epoch: [9][2200/2250] Elapsed 22m 13s (remain 0m 29s) Loss avg.: 0.4299 Grad: 0.1857 LR: 0.00069  \n",
      "Epoch: [9][2249/2250] Elapsed 22m 43s (remain 0m 0s) Loss avg.: 0.4299 Grad: 0.1490 LR: 0.00069  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 10m 40s) Loss avg.: 0.4791 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4432 \n",
      "Eval: [200/250] Elapsed 0m 34s (remain 0m 8s) Loss avg.: 0.4418 \n",
      "Eval: [249/250] Elapsed 0m 42s (remain 0m 0s) Loss avg.: 0.4412 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.4299  avg_val_loss: 0.4412  time: 1410s\n",
      "Epoch 9 - Accuracy: 0.8096275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/2250] Elapsed 0m 3s (remain 135m 13s) Loss avg.: 0.4543 Grad: 0.1587 LR: 0.00062  \n",
      "Epoch: [10][100/2250] Elapsed 1m 4s (remain 22m 45s) Loss avg.: 0.4267 Grad: 0.1494 LR: 0.00062  \n",
      "Epoch: [10][200/2250] Elapsed 2m 4s (remain 21m 10s) Loss avg.: 0.4262 Grad: 0.1460 LR: 0.00062  \n",
      "Epoch: [10][300/2250] Elapsed 3m 5s (remain 20m 0s) Loss avg.: 0.4258 Grad: 0.1660 LR: 0.00062  \n",
      "Epoch: [10][400/2250] Elapsed 4m 5s (remain 18m 53s) Loss avg.: 0.4258 Grad: 0.1594 LR: 0.00062  \n",
      "Epoch: [10][500/2250] Elapsed 5m 6s (remain 17m 49s) Loss avg.: 0.4261 Grad: 0.1465 LR: 0.00062  \n",
      "Epoch: [10][600/2250] Elapsed 6m 6s (remain 16m 46s) Loss avg.: 0.4264 Grad: 0.1535 LR: 0.00062  \n",
      "Epoch: [10][700/2250] Elapsed 7m 7s (remain 15m 44s) Loss avg.: 0.4266 Grad: 0.1593 LR: 0.00062  \n",
      "Epoch: [10][800/2250] Elapsed 8m 7s (remain 14m 42s) Loss avg.: 0.4267 Grad: 0.1575 LR: 0.00062  \n",
      "Epoch: [10][900/2250] Elapsed 9m 8s (remain 13m 41s) Loss avg.: 0.4270 Grad: 0.1674 LR: 0.00062  \n",
      "Epoch: [10][1000/2250] Elapsed 10m 9s (remain 12m 40s) Loss avg.: 0.4272 Grad: 0.1645 LR: 0.00062  \n",
      "Epoch: [10][1100/2250] Elapsed 11m 9s (remain 11m 39s) Loss avg.: 0.4274 Grad: 0.1453 LR: 0.00062  \n",
      "Epoch: [10][1200/2250] Elapsed 12m 10s (remain 10m 37s) Loss avg.: 0.4273 Grad: 0.1527 LR: 0.00062  \n",
      "Epoch: [10][1300/2250] Elapsed 13m 10s (remain 9m 36s) Loss avg.: 0.4273 Grad: 0.1606 LR: 0.00062  \n",
      "Epoch: [10][1400/2250] Elapsed 14m 11s (remain 8m 35s) Loss avg.: 0.4273 Grad: 0.1711 LR: 0.00062  \n",
      "Epoch: [10][1500/2250] Elapsed 15m 11s (remain 7m 35s) Loss avg.: 0.4275 Grad: 0.1559 LR: 0.00062  \n",
      "Epoch: [10][1600/2250] Elapsed 16m 12s (remain 6m 34s) Loss avg.: 0.4276 Grad: 0.1479 LR: 0.00062  \n",
      "Epoch: [10][1700/2250] Elapsed 17m 13s (remain 5m 33s) Loss avg.: 0.4277 Grad: 0.1513 LR: 0.00062  \n",
      "Epoch: [10][1800/2250] Elapsed 18m 13s (remain 4m 32s) Loss avg.: 0.4278 Grad: 0.1595 LR: 0.00062  \n",
      "Epoch: [10][1900/2250] Elapsed 19m 14s (remain 3m 31s) Loss avg.: 0.4278 Grad: 0.1494 LR: 0.00062  \n",
      "Epoch: [10][2000/2250] Elapsed 20m 14s (remain 2m 31s) Loss avg.: 0.4278 Grad: 0.1703 LR: 0.00062  \n",
      "Epoch: [10][2100/2250] Elapsed 21m 15s (remain 1m 30s) Loss avg.: 0.4278 Grad: 0.1523 LR: 0.00062  \n",
      "Epoch: [10][2200/2250] Elapsed 22m 15s (remain 0m 29s) Loss avg.: 0.4279 Grad: 0.1702 LR: 0.00062  \n",
      "Epoch: [10][2249/2250] Elapsed 22m 45s (remain 0m 0s) Loss avg.: 0.4278 Grad: 0.1725 LR: 0.00062  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 10m 38s) Loss avg.: 0.4783 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4414 \n",
      "Eval: [200/250] Elapsed 0m 34s (remain 0m 8s) Loss avg.: 0.4400 \n",
      "Eval: [249/250] Elapsed 0m 42s (remain 0m 0s) Loss avg.: 0.4393 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.4278  avg_val_loss: 0.4393  time: 1410s\n",
      "Epoch 10 - Accuracy: 0.810645\n",
      "Epoch 10 - Save Best Score: 0.8106 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [11][0/2250] Elapsed 0m 3s (remain 142m 15s) Loss avg.: 0.4573 Grad: 0.1619 LR: 0.00055  \n",
      "Epoch: [11][100/2250] Elapsed 1m 4s (remain 22m 46s) Loss avg.: 0.4240 Grad: 0.1554 LR: 0.00055  \n",
      "Epoch: [11][200/2250] Elapsed 2m 4s (remain 21m 11s) Loss avg.: 0.4243 Grad: 0.1543 LR: 0.00055  \n",
      "Epoch: [11][300/2250] Elapsed 3m 5s (remain 19m 59s) Loss avg.: 0.4247 Grad: 0.1650 LR: 0.00055  \n",
      "Epoch: [11][400/2250] Elapsed 4m 5s (remain 18m 53s) Loss avg.: 0.4250 Grad: 0.1691 LR: 0.00055  \n",
      "Epoch: [11][500/2250] Elapsed 5m 6s (remain 17m 49s) Loss avg.: 0.4249 Grad: 0.1957 LR: 0.00055  \n",
      "Epoch: [11][600/2250] Elapsed 6m 6s (remain 16m 46s) Loss avg.: 0.4251 Grad: 0.1690 LR: 0.00055  \n",
      "Epoch: [11][700/2250] Elapsed 7m 7s (remain 15m 44s) Loss avg.: 0.4253 Grad: 0.1719 LR: 0.00055  \n",
      "Epoch: [11][800/2250] Elapsed 8m 7s (remain 14m 42s) Loss avg.: 0.4254 Grad: 0.1623 LR: 0.00055  \n",
      "Epoch: [11][900/2250] Elapsed 9m 8s (remain 13m 40s) Loss avg.: 0.4254 Grad: 0.1625 LR: 0.00055  \n",
      "Epoch: [11][1000/2250] Elapsed 10m 8s (remain 12m 39s) Loss avg.: 0.4253 Grad: 0.1674 LR: 0.00055  \n",
      "Epoch: [11][1100/2250] Elapsed 11m 8s (remain 11m 38s) Loss avg.: 0.4255 Grad: 0.1539 LR: 0.00055  \n",
      "Epoch: [11][1200/2250] Elapsed 12m 9s (remain 10m 37s) Loss avg.: 0.4255 Grad: 0.1646 LR: 0.00055  \n",
      "Epoch: [11][1300/2250] Elapsed 13m 9s (remain 9m 36s) Loss avg.: 0.4255 Grad: 0.1536 LR: 0.00055  \n",
      "Epoch: [11][1400/2250] Elapsed 14m 10s (remain 8m 35s) Loss avg.: 0.4256 Grad: 0.1624 LR: 0.00055  \n",
      "Epoch: [11][1500/2250] Elapsed 15m 10s (remain 7m 34s) Loss avg.: 0.4256 Grad: 0.1641 LR: 0.00055  \n",
      "Epoch: [11][1600/2250] Elapsed 16m 11s (remain 6m 33s) Loss avg.: 0.4257 Grad: 0.1583 LR: 0.00055  \n",
      "Epoch: [11][1700/2250] Elapsed 17m 11s (remain 5m 32s) Loss avg.: 0.4256 Grad: 0.1705 LR: 0.00055  \n",
      "Epoch: [11][1800/2250] Elapsed 18m 11s (remain 4m 32s) Loss avg.: 0.4256 Grad: 0.1604 LR: 0.00055  \n",
      "Epoch: [11][1900/2250] Elapsed 19m 12s (remain 3m 31s) Loss avg.: 0.4255 Grad: 0.1518 LR: 0.00055  \n",
      "Epoch: [11][2000/2250] Elapsed 20m 12s (remain 2m 30s) Loss avg.: 0.4256 Grad: 0.1595 LR: 0.00055  \n",
      "Epoch: [11][2100/2250] Elapsed 21m 13s (remain 1m 30s) Loss avg.: 0.4258 Grad: 0.1667 LR: 0.00055  \n",
      "Epoch: [11][2200/2250] Elapsed 22m 13s (remain 0m 29s) Loss avg.: 0.4258 Grad: 0.1667 LR: 0.00055  \n",
      "Epoch: [11][2249/2250] Elapsed 22m 43s (remain 0m 0s) Loss avg.: 0.4258 Grad: 0.1763 LR: 0.00055  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 9m 52s) Loss avg.: 0.4747 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4410 \n",
      "Eval: [200/250] Elapsed 0m 34s (remain 0m 8s) Loss avg.: 0.4397 \n",
      "Eval: [249/250] Elapsed 0m 42s (remain 0m 0s) Loss avg.: 0.4390 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - avg_train_loss: 0.4258  avg_val_loss: 0.4390  time: 1409s\n",
      "Epoch 11 - Accuracy: 0.81070125\n",
      "Epoch 11 - Save Best Score: 0.8107 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [12][0/2250] Elapsed 0m 3s (remain 135m 57s) Loss avg.: 0.4294 Grad: 0.1625 LR: 0.00048  \n",
      "Epoch: [12][100/2250] Elapsed 1m 4s (remain 22m 42s) Loss avg.: 0.4213 Grad: 0.1572 LR: 0.00048  \n",
      "Epoch: [12][200/2250] Elapsed 2m 4s (remain 21m 8s) Loss avg.: 0.4215 Grad: 0.1787 LR: 0.00048  \n",
      "Epoch: [12][300/2250] Elapsed 3m 4s (remain 19m 57s) Loss avg.: 0.4220 Grad: 0.1671 LR: 0.00048  \n",
      "Epoch: [12][400/2250] Elapsed 4m 5s (remain 18m 52s) Loss avg.: 0.4221 Grad: 0.1823 LR: 0.00048  \n",
      "Epoch: [12][500/2250] Elapsed 5m 5s (remain 17m 48s) Loss avg.: 0.4220 Grad: 0.1581 LR: 0.00048  \n",
      "Epoch: [12][600/2250] Elapsed 6m 6s (remain 16m 45s) Loss avg.: 0.4221 Grad: 0.1668 LR: 0.00048  \n",
      "Epoch: [12][700/2250] Elapsed 7m 6s (remain 15m 43s) Loss avg.: 0.4224 Grad: 0.1614 LR: 0.00048  \n",
      "Epoch: [12][800/2250] Elapsed 8m 7s (remain 14m 41s) Loss avg.: 0.4225 Grad: 0.1697 LR: 0.00048  \n",
      "Epoch: [12][900/2250] Elapsed 9m 7s (remain 13m 40s) Loss avg.: 0.4225 Grad: 0.1722 LR: 0.00048  \n",
      "Epoch: [12][1000/2250] Elapsed 10m 8s (remain 12m 39s) Loss avg.: 0.4226 Grad: 0.1665 LR: 0.00048  \n",
      "Epoch: [12][1100/2250] Elapsed 11m 9s (remain 11m 38s) Loss avg.: 0.4228 Grad: 0.1577 LR: 0.00048  \n",
      "Epoch: [12][1200/2250] Elapsed 12m 9s (remain 10m 37s) Loss avg.: 0.4228 Grad: 0.1739 LR: 0.00048  \n",
      "Epoch: [12][1300/2250] Elapsed 13m 9s (remain 9m 36s) Loss avg.: 0.4230 Grad: 0.1628 LR: 0.00048  \n",
      "Epoch: [12][1400/2250] Elapsed 14m 10s (remain 8m 35s) Loss avg.: 0.4231 Grad: 0.1559 LR: 0.00048  \n",
      "Epoch: [12][1500/2250] Elapsed 15m 10s (remain 7m 34s) Loss avg.: 0.4231 Grad: 0.1749 LR: 0.00048  \n",
      "Epoch: [12][1600/2250] Elapsed 16m 11s (remain 6m 33s) Loss avg.: 0.4232 Grad: 0.1651 LR: 0.00048  \n",
      "Epoch: [12][1700/2250] Elapsed 17m 11s (remain 5m 33s) Loss avg.: 0.4233 Grad: 0.1641 LR: 0.00048  \n",
      "Epoch: [12][1800/2250] Elapsed 18m 12s (remain 4m 32s) Loss avg.: 0.4233 Grad: 0.1608 LR: 0.00048  \n",
      "Epoch: [12][1900/2250] Elapsed 19m 12s (remain 3m 31s) Loss avg.: 0.4235 Grad: 0.1759 LR: 0.00048  \n",
      "Epoch: [12][2000/2250] Elapsed 20m 13s (remain 2m 30s) Loss avg.: 0.4235 Grad: 0.1894 LR: 0.00048  \n",
      "Epoch: [12][2100/2250] Elapsed 21m 13s (remain 1m 30s) Loss avg.: 0.4235 Grad: 0.1662 LR: 0.00048  \n",
      "Epoch: [12][2200/2250] Elapsed 22m 14s (remain 0m 29s) Loss avg.: 0.4236 Grad: 0.1569 LR: 0.00048  \n",
      "Epoch: [12][2249/2250] Elapsed 22m 44s (remain 0m 0s) Loss avg.: 0.4237 Grad: 0.1797 LR: 0.00048  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 10m 39s) Loss avg.: 0.4778 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4402 \n",
      "Eval: [200/250] Elapsed 0m 34s (remain 0m 8s) Loss avg.: 0.4389 \n",
      "Eval: [249/250] Elapsed 0m 42s (remain 0m 0s) Loss avg.: 0.4382 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 - avg_train_loss: 0.4237  avg_val_loss: 0.4382  time: 1410s\n",
      "Epoch 12 - Accuracy: 0.8111075\n",
      "Epoch 12 - Save Best Score: 0.8111 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [13][0/2250] Elapsed 0m 3s (remain 142m 30s) Loss avg.: 0.4400 Grad: 0.1736 LR: 0.00041  \n",
      "Epoch: [13][100/2250] Elapsed 1m 4s (remain 22m 48s) Loss avg.: 0.4174 Grad: 0.1667 LR: 0.00041  \n",
      "Epoch: [13][200/2250] Elapsed 2m 4s (remain 21m 12s) Loss avg.: 0.4185 Grad: 0.1681 LR: 0.00041  \n",
      "Epoch: [13][300/2250] Elapsed 3m 5s (remain 19m 59s) Loss avg.: 0.4197 Grad: 0.1767 LR: 0.00041  \n",
      "Epoch: [13][400/2250] Elapsed 4m 5s (remain 18m 53s) Loss avg.: 0.4197 Grad: 0.1793 LR: 0.00041  \n",
      "Epoch: [13][500/2250] Elapsed 5m 6s (remain 17m 49s) Loss avg.: 0.4199 Grad: 0.1799 LR: 0.00041  \n",
      "Epoch: [13][600/2250] Elapsed 6m 6s (remain 16m 46s) Loss avg.: 0.4201 Grad: 0.1741 LR: 0.00041  \n",
      "Epoch: [13][700/2250] Elapsed 7m 7s (remain 15m 44s) Loss avg.: 0.4202 Grad: 0.1672 LR: 0.00041  \n",
      "Epoch: [13][800/2250] Elapsed 8m 7s (remain 14m 42s) Loss avg.: 0.4201 Grad: 0.1712 LR: 0.00041  \n",
      "Epoch: [13][900/2250] Elapsed 9m 8s (remain 13m 40s) Loss avg.: 0.4204 Grad: 0.1795 LR: 0.00041  \n",
      "Epoch: [13][1000/2250] Elapsed 10m 8s (remain 12m 39s) Loss avg.: 0.4205 Grad: 0.1620 LR: 0.00041  \n",
      "Epoch: [13][1100/2250] Elapsed 11m 8s (remain 11m 38s) Loss avg.: 0.4208 Grad: 0.1729 LR: 0.00041  \n",
      "Epoch: [13][1200/2250] Elapsed 12m 9s (remain 10m 37s) Loss avg.: 0.4210 Grad: 0.1633 LR: 0.00041  \n",
      "Epoch: [13][1300/2250] Elapsed 13m 9s (remain 9m 35s) Loss avg.: 0.4210 Grad: 0.1785 LR: 0.00041  \n",
      "Epoch: [13][1400/2250] Elapsed 14m 9s (remain 8m 35s) Loss avg.: 0.4211 Grad: 0.1717 LR: 0.00041  \n",
      "Epoch: [13][1500/2250] Elapsed 15m 10s (remain 7m 34s) Loss avg.: 0.4213 Grad: 0.1712 LR: 0.00041  \n",
      "Epoch: [13][1600/2250] Elapsed 16m 10s (remain 6m 33s) Loss avg.: 0.4213 Grad: 0.1645 LR: 0.00041  \n",
      "Epoch: [13][1700/2250] Elapsed 17m 11s (remain 5m 32s) Loss avg.: 0.4214 Grad: 0.1706 LR: 0.00041  \n",
      "Epoch: [13][1800/2250] Elapsed 18m 11s (remain 4m 32s) Loss avg.: 0.4213 Grad: 0.1740 LR: 0.00041  \n",
      "Epoch: [13][1900/2250] Elapsed 19m 11s (remain 3m 31s) Loss avg.: 0.4214 Grad: 0.1616 LR: 0.00041  \n",
      "Epoch: [13][2000/2250] Elapsed 20m 12s (remain 2m 30s) Loss avg.: 0.4214 Grad: 0.1784 LR: 0.00041  \n",
      "Epoch: [13][2100/2250] Elapsed 21m 12s (remain 1m 30s) Loss avg.: 0.4215 Grad: 0.1751 LR: 0.00041  \n",
      "Epoch: [13][2200/2250] Elapsed 22m 12s (remain 0m 29s) Loss avg.: 0.4215 Grad: 0.1740 LR: 0.00041  \n",
      "Epoch: [13][2249/2250] Elapsed 22m 42s (remain 0m 0s) Loss avg.: 0.4216 Grad: 0.1965 LR: 0.00041  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 10m 13s) Loss avg.: 0.4780 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4400 \n",
      "Eval: [200/250] Elapsed 0m 34s (remain 0m 8s) Loss avg.: 0.4387 \n",
      "Eval: [249/250] Elapsed 0m 42s (remain 0m 0s) Loss avg.: 0.4380 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 - avg_train_loss: 0.4216  avg_val_loss: 0.4380  time: 1409s\n",
      "Epoch 13 - Accuracy: 0.81130625\n",
      "Epoch 13 - Save Best Score: 0.8113 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [14][0/2250] Elapsed 0m 3s (remain 134m 39s) Loss avg.: 0.4220 Grad: 0.1607 LR: 0.00035  \n",
      "Epoch: [14][100/2250] Elapsed 1m 4s (remain 22m 42s) Loss avg.: 0.4173 Grad: 0.1694 LR: 0.00035  \n",
      "Epoch: [14][200/2250] Elapsed 2m 4s (remain 21m 8s) Loss avg.: 0.4174 Grad: 0.1780 LR: 0.00035  \n",
      "Epoch: [14][300/2250] Elapsed 3m 4s (remain 19m 57s) Loss avg.: 0.4173 Grad: 0.1807 LR: 0.00035  \n",
      "Epoch: [14][400/2250] Elapsed 4m 5s (remain 18m 52s) Loss avg.: 0.4179 Grad: 0.1686 LR: 0.00035  \n",
      "Epoch: [14][500/2250] Elapsed 5m 6s (remain 17m 49s) Loss avg.: 0.4179 Grad: 0.1700 LR: 0.00035  \n",
      "Epoch: [14][600/2250] Elapsed 6m 6s (remain 16m 46s) Loss avg.: 0.4183 Grad: 0.1770 LR: 0.00035  \n",
      "Epoch: [14][700/2250] Elapsed 7m 7s (remain 15m 44s) Loss avg.: 0.4185 Grad: 0.1771 LR: 0.00035  \n",
      "Epoch: [14][800/2250] Elapsed 8m 7s (remain 14m 42s) Loss avg.: 0.4185 Grad: 0.1762 LR: 0.00035  \n",
      "Epoch: [14][900/2250] Elapsed 9m 8s (remain 13m 40s) Loss avg.: 0.4187 Grad: 0.1668 LR: 0.00035  \n",
      "Epoch: [14][1000/2250] Elapsed 10m 8s (remain 12m 39s) Loss avg.: 0.4188 Grad: 0.1811 LR: 0.00035  \n",
      "Epoch: [14][1100/2250] Elapsed 11m 9s (remain 11m 38s) Loss avg.: 0.4188 Grad: 0.1922 LR: 0.00035  \n",
      "Epoch: [14][1200/2250] Elapsed 12m 9s (remain 10m 37s) Loss avg.: 0.4190 Grad: 0.1705 LR: 0.00035  \n",
      "Epoch: [14][1300/2250] Elapsed 13m 10s (remain 9m 36s) Loss avg.: 0.4192 Grad: 0.1749 LR: 0.00035  \n",
      "Epoch: [14][1400/2250] Elapsed 14m 10s (remain 8m 35s) Loss avg.: 0.4193 Grad: 0.1803 LR: 0.00035  \n",
      "Epoch: [14][1500/2250] Elapsed 15m 11s (remain 7m 34s) Loss avg.: 0.4192 Grad: 0.1840 LR: 0.00035  \n",
      "Epoch: [14][1600/2250] Elapsed 16m 11s (remain 6m 33s) Loss avg.: 0.4192 Grad: 0.1851 LR: 0.00035  \n",
      "Epoch: [14][1700/2250] Elapsed 17m 12s (remain 5m 33s) Loss avg.: 0.4192 Grad: 0.2006 LR: 0.00035  \n",
      "Epoch: [14][1800/2250] Elapsed 18m 12s (remain 4m 32s) Loss avg.: 0.4193 Grad: 0.1751 LR: 0.00035  \n",
      "Epoch: [14][1900/2250] Elapsed 19m 13s (remain 3m 31s) Loss avg.: 0.4193 Grad: 0.1708 LR: 0.00035  \n",
      "Epoch: [14][2000/2250] Elapsed 20m 14s (remain 2m 31s) Loss avg.: 0.4193 Grad: 0.1835 LR: 0.00035  \n",
      "Epoch: [14][2100/2250] Elapsed 21m 14s (remain 1m 30s) Loss avg.: 0.4193 Grad: 0.1810 LR: 0.00035  \n",
      "Epoch: [14][2200/2250] Elapsed 22m 15s (remain 0m 29s) Loss avg.: 0.4194 Grad: 0.1812 LR: 0.00035  \n",
      "Epoch: [14][2249/2250] Elapsed 22m 44s (remain 0m 0s) Loss avg.: 0.4194 Grad: 0.1811 LR: 0.00035  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 10m 44s) Loss avg.: 0.4786 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4394 \n",
      "Eval: [200/250] Elapsed 0m 34s (remain 0m 8s) Loss avg.: 0.4381 \n",
      "Eval: [249/250] Elapsed 0m 42s (remain 0m 0s) Loss avg.: 0.4374 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 - avg_train_loss: 0.4194  avg_val_loss: 0.4374  time: 1411s\n",
      "Epoch 14 - Accuracy: 0.8117925\n",
      "Epoch 14 - Save Best Score: 0.8118 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][0/2250] Elapsed 0m 3s (remain 145m 16s) Loss avg.: 0.4403 Grad: 0.1854 LR: 0.00029  \n",
      "Epoch: [15][100/2250] Elapsed 1m 4s (remain 22m 56s) Loss avg.: 0.4160 Grad: 0.1824 LR: 0.00029  \n",
      "Epoch: [15][200/2250] Elapsed 2m 4s (remain 21m 14s) Loss avg.: 0.4152 Grad: 0.1994 LR: 0.00029  \n",
      "Epoch: [15][300/2250] Elapsed 3m 5s (remain 19m 59s) Loss avg.: 0.4157 Grad: 0.1893 LR: 0.00029  \n",
      "Epoch: [15][400/2250] Elapsed 4m 5s (remain 18m 52s) Loss avg.: 0.4155 Grad: 0.1712 LR: 0.00029  \n",
      "Epoch: [15][500/2250] Elapsed 5m 5s (remain 17m 47s) Loss avg.: 0.4154 Grad: 0.1889 LR: 0.00029  \n",
      "Epoch: [15][600/2250] Elapsed 6m 6s (remain 16m 44s) Loss avg.: 0.4156 Grad: 0.2044 LR: 0.00029  \n",
      "Epoch: [15][700/2250] Elapsed 7m 6s (remain 15m 42s) Loss avg.: 0.4156 Grad: 0.1835 LR: 0.00029  \n",
      "Epoch: [15][800/2250] Elapsed 8m 6s (remain 14m 40s) Loss avg.: 0.4159 Grad: 0.1901 LR: 0.00029  \n",
      "Epoch: [15][900/2250] Elapsed 9m 7s (remain 13m 39s) Loss avg.: 0.4161 Grad: 0.1768 LR: 0.00029  \n",
      "Epoch: [15][1000/2250] Elapsed 10m 7s (remain 12m 38s) Loss avg.: 0.4162 Grad: 0.2254 LR: 0.00029  \n",
      "Epoch: [15][1100/2250] Elapsed 11m 8s (remain 11m 37s) Loss avg.: 0.4163 Grad: 0.1866 LR: 0.00029  \n",
      "Epoch: [15][1200/2250] Elapsed 12m 8s (remain 10m 36s) Loss avg.: 0.4165 Grad: 0.1797 LR: 0.00029  \n",
      "Epoch: [15][1300/2250] Elapsed 13m 8s (remain 9m 35s) Loss avg.: 0.4166 Grad: 0.1888 LR: 0.00029  \n",
      "Epoch: [15][1400/2250] Elapsed 14m 9s (remain 8m 34s) Loss avg.: 0.4166 Grad: 0.1802 LR: 0.00029  \n",
      "Epoch: [15][1500/2250] Elapsed 15m 9s (remain 7m 33s) Loss avg.: 0.4168 Grad: 0.1874 LR: 0.00029  \n",
      "Epoch: [15][1600/2250] Elapsed 16m 10s (remain 6m 33s) Loss avg.: 0.4168 Grad: 0.1739 LR: 0.00029  \n",
      "Epoch: [15][1700/2250] Elapsed 17m 10s (remain 5m 32s) Loss avg.: 0.4168 Grad: 0.1807 LR: 0.00029  \n",
      "Epoch: [15][1800/2250] Elapsed 18m 10s (remain 4m 31s) Loss avg.: 0.4170 Grad: 0.1818 LR: 0.00029  \n",
      "Epoch: [15][1900/2250] Elapsed 19m 11s (remain 3m 31s) Loss avg.: 0.4170 Grad: 0.1931 LR: 0.00029  \n",
      "Epoch: [15][2000/2250] Elapsed 20m 11s (remain 2m 30s) Loss avg.: 0.4172 Grad: 0.1943 LR: 0.00029  \n",
      "Epoch: [15][2100/2250] Elapsed 21m 11s (remain 1m 30s) Loss avg.: 0.4172 Grad: 0.1878 LR: 0.00029  \n",
      "Epoch: [15][2200/2250] Elapsed 22m 12s (remain 0m 29s) Loss avg.: 0.4172 Grad: 0.2034 LR: 0.00029  \n",
      "Epoch: [15][2249/2250] Elapsed 22m 41s (remain 0m 0s) Loss avg.: 0.4172 Grad: 0.1775 LR: 0.00029  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 10m 22s) Loss avg.: 0.4761 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4394 \n",
      "Eval: [200/250] Elapsed 0m 34s (remain 0m 8s) Loss avg.: 0.4380 \n",
      "Eval: [249/250] Elapsed 0m 42s (remain 0m 0s) Loss avg.: 0.4374 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 - avg_train_loss: 0.4172  avg_val_loss: 0.4374  time: 1406s\n",
      "Epoch 15 - Accuracy: 0.81164625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [16][0/2250] Elapsed 0m 3s (remain 125m 44s) Loss avg.: 0.4204 Grad: 0.1802 LR: 0.00023  \n",
      "Epoch: [16][100/2250] Elapsed 1m 3s (remain 22m 38s) Loss avg.: 0.4126 Grad: 0.1855 LR: 0.00023  \n",
      "Epoch: [16][200/2250] Elapsed 2m 4s (remain 21m 6s) Loss avg.: 0.4132 Grad: 0.1893 LR: 0.00023  \n",
      "Epoch: [16][300/2250] Elapsed 3m 4s (remain 19m 55s) Loss avg.: 0.4132 Grad: 0.1902 LR: 0.00023  \n",
      "Epoch: [16][400/2250] Elapsed 4m 4s (remain 18m 49s) Loss avg.: 0.4138 Grad: 0.1866 LR: 0.00023  \n",
      "Epoch: [16][500/2250] Elapsed 5m 5s (remain 17m 46s) Loss avg.: 0.4137 Grad: 0.1924 LR: 0.00023  \n",
      "Epoch: [16][600/2250] Elapsed 6m 6s (remain 16m 44s) Loss avg.: 0.4140 Grad: 0.1952 LR: 0.00023  \n",
      "Epoch: [16][700/2250] Elapsed 7m 6s (remain 15m 43s) Loss avg.: 0.4140 Grad: 0.1857 LR: 0.00023  \n",
      "Epoch: [16][800/2250] Elapsed 8m 7s (remain 14m 41s) Loss avg.: 0.4143 Grad: 0.1867 LR: 0.00023  \n",
      "Epoch: [16][900/2250] Elapsed 9m 7s (remain 13m 40s) Loss avg.: 0.4142 Grad: 0.1990 LR: 0.00023  \n",
      "Epoch: [16][1000/2250] Elapsed 10m 8s (remain 12m 39s) Loss avg.: 0.4144 Grad: 0.1883 LR: 0.00023  \n",
      "Epoch: [16][1100/2250] Elapsed 11m 9s (remain 11m 38s) Loss avg.: 0.4144 Grad: 0.2002 LR: 0.00023  \n",
      "Epoch: [16][1200/2250] Elapsed 12m 9s (remain 10m 37s) Loss avg.: 0.4146 Grad: 0.1881 LR: 0.00023  \n",
      "Epoch: [16][1300/2250] Elapsed 13m 10s (remain 9m 36s) Loss avg.: 0.4146 Grad: 0.2004 LR: 0.00023  \n",
      "Epoch: [16][1400/2250] Elapsed 14m 11s (remain 8m 35s) Loss avg.: 0.4147 Grad: 0.1986 LR: 0.00023  \n",
      "Epoch: [16][1500/2250] Elapsed 15m 11s (remain 7m 34s) Loss avg.: 0.4148 Grad: 0.1941 LR: 0.00023  \n",
      "Epoch: [16][1600/2250] Elapsed 16m 12s (remain 6m 34s) Loss avg.: 0.4148 Grad: 0.1890 LR: 0.00023  \n",
      "Epoch: [16][1700/2250] Elapsed 17m 12s (remain 5m 33s) Loss avg.: 0.4148 Grad: 0.1869 LR: 0.00023  \n",
      "Epoch: [16][1800/2250] Elapsed 18m 13s (remain 4m 32s) Loss avg.: 0.4149 Grad: 0.1826 LR: 0.00023  \n",
      "Epoch: [16][1900/2250] Elapsed 19m 13s (remain 3m 31s) Loss avg.: 0.4149 Grad: 0.1996 LR: 0.00023  \n",
      "Epoch: [16][2000/2250] Elapsed 20m 14s (remain 2m 31s) Loss avg.: 0.4150 Grad: 0.1837 LR: 0.00023  \n",
      "Epoch: [16][2100/2250] Elapsed 21m 14s (remain 1m 30s) Loss avg.: 0.4151 Grad: 0.1918 LR: 0.00023  \n",
      "Epoch: [16][2200/2250] Elapsed 22m 15s (remain 0m 29s) Loss avg.: 0.4152 Grad: 0.1776 LR: 0.00023  \n",
      "Epoch: [16][2249/2250] Elapsed 22m 45s (remain 0m 0s) Loss avg.: 0.4152 Grad: 0.2023 LR: 0.00023  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 10m 47s) Loss avg.: 0.4762 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4395 \n",
      "Eval: [200/250] Elapsed 0m 34s (remain 0m 8s) Loss avg.: 0.4382 \n",
      "Eval: [249/250] Elapsed 0m 42s (remain 0m 0s) Loss avg.: 0.4375 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 - avg_train_loss: 0.4152  avg_val_loss: 0.4375  time: 1410s\n",
      "Epoch 16 - Accuracy: 0.81193875\n",
      "Epoch 16 - Save Best Score: 0.8119 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [17][0/2250] Elapsed 0m 3s (remain 141m 38s) Loss avg.: 0.4126 Grad: 0.1877 LR: 0.00019  \n",
      "Epoch: [17][100/2250] Elapsed 1m 4s (remain 22m 49s) Loss avg.: 0.4119 Grad: 0.1986 LR: 0.00019  \n",
      "Epoch: [17][200/2250] Elapsed 2m 4s (remain 21m 11s) Loss avg.: 0.4117 Grad: 0.1940 LR: 0.00019  \n",
      "Epoch: [17][300/2250] Elapsed 3m 5s (remain 19m 59s) Loss avg.: 0.4122 Grad: 0.2035 LR: 0.00019  \n",
      "Epoch: [17][400/2250] Elapsed 4m 5s (remain 18m 52s) Loss avg.: 0.4124 Grad: 0.2065 LR: 0.00019  \n",
      "Epoch: [17][500/2250] Elapsed 5m 5s (remain 17m 47s) Loss avg.: 0.4124 Grad: 0.2161 LR: 0.00019  \n",
      "Epoch: [17][600/2250] Elapsed 6m 6s (remain 16m 44s) Loss avg.: 0.4121 Grad: 0.1916 LR: 0.00019  \n",
      "Epoch: [17][700/2250] Elapsed 7m 6s (remain 15m 42s) Loss avg.: 0.4124 Grad: 0.2108 LR: 0.00019  \n",
      "Epoch: [17][800/2250] Elapsed 8m 6s (remain 14m 40s) Loss avg.: 0.4122 Grad: 0.2012 LR: 0.00019  \n",
      "Epoch: [17][900/2250] Elapsed 9m 7s (remain 13m 39s) Loss avg.: 0.4122 Grad: 0.2097 LR: 0.00019  \n",
      "Epoch: [17][1000/2250] Elapsed 10m 7s (remain 12m 38s) Loss avg.: 0.4120 Grad: 0.2006 LR: 0.00019  \n",
      "Epoch: [17][1100/2250] Elapsed 11m 8s (remain 11m 37s) Loss avg.: 0.4121 Grad: 0.2061 LR: 0.00019  \n",
      "Epoch: [17][1200/2250] Elapsed 12m 8s (remain 10m 36s) Loss avg.: 0.4122 Grad: 0.2045 LR: 0.00019  \n",
      "Epoch: [17][1300/2250] Elapsed 13m 9s (remain 9m 35s) Loss avg.: 0.4123 Grad: 0.2210 LR: 0.00019  \n",
      "Epoch: [17][1400/2250] Elapsed 14m 9s (remain 8m 34s) Loss avg.: 0.4124 Grad: 0.1969 LR: 0.00019  \n",
      "Epoch: [17][1500/2250] Elapsed 15m 10s (remain 7m 34s) Loss avg.: 0.4123 Grad: 0.2050 LR: 0.00019  \n",
      "Epoch: [17][1600/2250] Elapsed 16m 10s (remain 6m 33s) Loss avg.: 0.4124 Grad: 0.2017 LR: 0.00019  \n",
      "Epoch: [17][1700/2250] Elapsed 17m 11s (remain 5m 32s) Loss avg.: 0.4126 Grad: 0.1940 LR: 0.00019  \n",
      "Epoch: [17][1800/2250] Elapsed 18m 11s (remain 4m 32s) Loss avg.: 0.4126 Grad: 0.1987 LR: 0.00019  \n",
      "Epoch: [17][1900/2250] Elapsed 19m 11s (remain 3m 31s) Loss avg.: 0.4127 Grad: 0.2007 LR: 0.00019  \n",
      "Epoch: [17][2000/2250] Elapsed 20m 12s (remain 2m 30s) Loss avg.: 0.4128 Grad: 0.2022 LR: 0.00019  \n",
      "Epoch: [17][2100/2250] Elapsed 21m 12s (remain 1m 30s) Loss avg.: 0.4129 Grad: 0.2077 LR: 0.00019  \n",
      "Epoch: [17][2200/2250] Elapsed 22m 13s (remain 0m 29s) Loss avg.: 0.4131 Grad: 0.1923 LR: 0.00019  \n",
      "Epoch: [17][2249/2250] Elapsed 22m 42s (remain 0m 0s) Loss avg.: 0.4131 Grad: 0.2021 LR: 0.00019  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 9m 58s) Loss avg.: 0.4753 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4395 \n",
      "Eval: [200/250] Elapsed 0m 34s (remain 0m 8s) Loss avg.: 0.4382 \n",
      "Eval: [249/250] Elapsed 0m 42s (remain 0m 0s) Loss avg.: 0.4375 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 - avg_train_loss: 0.4131  avg_val_loss: 0.4375  time: 1409s\n",
      "Epoch 17 - Accuracy: 0.81197125\n",
      "Epoch 17 - Save Best Score: 0.8120 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [18][0/2250] Elapsed 0m 3s (remain 141m 55s) Loss avg.: 0.4237 Grad: 0.2053 LR: 0.00015  \n",
      "Epoch: [18][100/2250] Elapsed 1m 4s (remain 22m 45s) Loss avg.: 0.4104 Grad: 0.2027 LR: 0.00015  \n",
      "Epoch: [18][200/2250] Elapsed 2m 4s (remain 21m 11s) Loss avg.: 0.4103 Grad: 0.2164 LR: 0.00015  \n",
      "Epoch: [18][300/2250] Elapsed 3m 5s (remain 19m 58s) Loss avg.: 0.4110 Grad: 0.2098 LR: 0.00015  \n",
      "Epoch: [18][400/2250] Elapsed 4m 5s (remain 18m 51s) Loss avg.: 0.4118 Grad: 0.2072 LR: 0.00015  \n",
      "Epoch: [18][500/2250] Elapsed 5m 5s (remain 17m 47s) Loss avg.: 0.4115 Grad: 0.2193 LR: 0.00015  \n",
      "Epoch: [18][600/2250] Elapsed 6m 6s (remain 16m 44s) Loss avg.: 0.4114 Grad: 0.2124 LR: 0.00015  \n",
      "Epoch: [18][700/2250] Elapsed 7m 6s (remain 15m 42s) Loss avg.: 0.4114 Grad: 0.2026 LR: 0.00015  \n",
      "Epoch: [18][800/2250] Elapsed 8m 6s (remain 14m 40s) Loss avg.: 0.4111 Grad: 0.2061 LR: 0.00015  \n",
      "Epoch: [18][900/2250] Elapsed 9m 7s (remain 13m 39s) Loss avg.: 0.4111 Grad: 0.2137 LR: 0.00015  \n",
      "Epoch: [18][1000/2250] Elapsed 10m 7s (remain 12m 38s) Loss avg.: 0.4110 Grad: 0.2089 LR: 0.00015  \n",
      "Epoch: [18][1100/2250] Elapsed 11m 7s (remain 11m 37s) Loss avg.: 0.4110 Grad: 0.2083 LR: 0.00015  \n",
      "Epoch: [18][1200/2250] Elapsed 12m 8s (remain 10m 36s) Loss avg.: 0.4111 Grad: 0.2036 LR: 0.00015  \n",
      "Epoch: [18][1300/2250] Elapsed 13m 8s (remain 9m 35s) Loss avg.: 0.4110 Grad: 0.2092 LR: 0.00015  \n",
      "Epoch: [18][1400/2250] Elapsed 14m 9s (remain 8m 34s) Loss avg.: 0.4111 Grad: 0.2159 LR: 0.00015  \n",
      "Epoch: [18][1500/2250] Elapsed 15m 9s (remain 7m 33s) Loss avg.: 0.4111 Grad: 0.2059 LR: 0.00015  \n",
      "Epoch: [18][1600/2250] Elapsed 16m 10s (remain 6m 33s) Loss avg.: 0.4112 Grad: 0.2084 LR: 0.00015  \n",
      "Epoch: [18][1700/2250] Elapsed 17m 10s (remain 5m 32s) Loss avg.: 0.4112 Grad: 0.2179 LR: 0.00015  \n",
      "Epoch: [18][1800/2250] Elapsed 18m 10s (remain 4m 31s) Loss avg.: 0.4114 Grad: 0.2108 LR: 0.00015  \n",
      "Epoch: [18][1900/2250] Elapsed 19m 11s (remain 3m 31s) Loss avg.: 0.4114 Grad: 0.2216 LR: 0.00015  \n",
      "Epoch: [18][2000/2250] Elapsed 20m 11s (remain 2m 30s) Loss avg.: 0.4115 Grad: 0.2176 LR: 0.00015  \n",
      "Epoch: [18][2100/2250] Elapsed 21m 12s (remain 1m 30s) Loss avg.: 0.4114 Grad: 0.2180 LR: 0.00015  \n",
      "Epoch: [18][2200/2250] Elapsed 22m 12s (remain 0m 29s) Loss avg.: 0.4114 Grad: 0.2065 LR: 0.00015  \n",
      "Epoch: [18][2249/2250] Elapsed 22m 42s (remain 0m 0s) Loss avg.: 0.4113 Grad: 0.2267 LR: 0.00015  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 9m 48s) Loss avg.: 0.4772 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4399 \n",
      "Eval: [200/250] Elapsed 0m 34s (remain 0m 8s) Loss avg.: 0.4386 \n",
      "Eval: [249/250] Elapsed 0m 42s (remain 0m 0s) Loss avg.: 0.4379 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 - avg_train_loss: 0.4113  avg_val_loss: 0.4379  time: 1409s\n",
      "Epoch 18 - Accuracy: 0.8118425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19][0/2250] Elapsed 0m 3s (remain 134m 3s) Loss avg.: 0.3888 Grad: 0.2091 LR: 0.00012  \n",
      "Epoch: [19][100/2250] Elapsed 1m 4s (remain 22m 47s) Loss avg.: 0.4071 Grad: 0.2123 LR: 0.00012  \n",
      "Epoch: [19][200/2250] Elapsed 2m 4s (remain 21m 12s) Loss avg.: 0.4090 Grad: 0.2131 LR: 0.00012  \n",
      "Epoch: [19][300/2250] Elapsed 3m 5s (remain 20m 0s) Loss avg.: 0.4085 Grad: 0.2022 LR: 0.00012  \n",
      "Epoch: [19][400/2250] Elapsed 4m 6s (remain 18m 54s) Loss avg.: 0.4084 Grad: 0.2123 LR: 0.00012  \n",
      "Epoch: [19][500/2250] Elapsed 5m 6s (remain 17m 50s) Loss avg.: 0.4084 Grad: 0.2149 LR: 0.00012  \n",
      "Epoch: [19][600/2250] Elapsed 6m 7s (remain 16m 47s) Loss avg.: 0.4084 Grad: 0.2196 LR: 0.00012  \n",
      "Epoch: [19][700/2250] Elapsed 7m 7s (remain 15m 44s) Loss avg.: 0.4084 Grad: 0.2186 LR: 0.00012  \n",
      "Epoch: [19][800/2250] Elapsed 8m 8s (remain 14m 43s) Loss avg.: 0.4085 Grad: 0.2144 LR: 0.00012  \n",
      "Epoch: [19][900/2250] Elapsed 9m 8s (remain 13m 41s) Loss avg.: 0.4087 Grad: 0.2129 LR: 0.00012  \n",
      "Epoch: [19][1000/2250] Elapsed 10m 9s (remain 12m 40s) Loss avg.: 0.4089 Grad: 0.2084 LR: 0.00012  \n",
      "Epoch: [19][1100/2250] Elapsed 11m 10s (remain 11m 39s) Loss avg.: 0.4090 Grad: 0.2164 LR: 0.00012  \n",
      "Epoch: [19][1200/2250] Elapsed 12m 10s (remain 10m 38s) Loss avg.: 0.4091 Grad: 0.2187 LR: 0.00012  \n",
      "Epoch: [19][1300/2250] Elapsed 13m 11s (remain 9m 37s) Loss avg.: 0.4092 Grad: 0.2132 LR: 0.00012  \n",
      "Epoch: [19][1400/2250] Elapsed 14m 11s (remain 8m 36s) Loss avg.: 0.4094 Grad: 0.2178 LR: 0.00012  \n",
      "Epoch: [19][1500/2250] Elapsed 15m 12s (remain 7m 35s) Loss avg.: 0.4095 Grad: 0.2068 LR: 0.00012  \n",
      "Epoch: [19][1600/2250] Elapsed 16m 12s (remain 6m 34s) Loss avg.: 0.4094 Grad: 0.2096 LR: 0.00012  \n",
      "Epoch: [19][1700/2250] Elapsed 17m 13s (remain 5m 33s) Loss avg.: 0.4095 Grad: 0.2091 LR: 0.00012  \n",
      "Epoch: [19][1800/2250] Elapsed 18m 13s (remain 4m 32s) Loss avg.: 0.4096 Grad: 0.2187 LR: 0.00012  \n",
      "Epoch: [19][1900/2250] Elapsed 19m 14s (remain 3m 31s) Loss avg.: 0.4097 Grad: 0.2167 LR: 0.00012  \n",
      "Epoch: [19][2000/2250] Elapsed 20m 14s (remain 2m 31s) Loss avg.: 0.4097 Grad: 0.2190 LR: 0.00012  \n",
      "Epoch: [19][2100/2250] Elapsed 21m 15s (remain 1m 30s) Loss avg.: 0.4098 Grad: 0.2124 LR: 0.00012  \n",
      "Epoch: [19][2200/2250] Elapsed 22m 15s (remain 0m 29s) Loss avg.: 0.4098 Grad: 0.2159 LR: 0.00012  \n",
      "Epoch: [19][2249/2250] Elapsed 22m 45s (remain 0m 0s) Loss avg.: 0.4098 Grad: 0.2290 LR: 0.00012  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 10m 30s) Loss avg.: 0.4761 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4399 \n",
      "Eval: [200/250] Elapsed 0m 34s (remain 0m 8s) Loss avg.: 0.4387 \n",
      "Eval: [249/250] Elapsed 0m 42s (remain 0m 0s) Loss avg.: 0.4380 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 - avg_train_loss: 0.4098  avg_val_loss: 0.4380  time: 1411s\n",
      "Epoch 19 - Accuracy: 0.811815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [20][0/2250] Elapsed 0m 3s (remain 143m 47s) Loss avg.: 0.4043 Grad: 0.2078 LR: 0.00011  \n",
      "Epoch: [20][100/2250] Elapsed 1m 4s (remain 22m 55s) Loss avg.: 0.4083 Grad: 0.2299 LR: 0.00011  \n",
      "Epoch: [20][200/2250] Elapsed 2m 5s (remain 21m 14s) Loss avg.: 0.4078 Grad: 0.2153 LR: 0.00011  \n",
      "Epoch: [20][300/2250] Elapsed 3m 5s (remain 20m 0s) Loss avg.: 0.4076 Grad: 0.2206 LR: 0.00011  \n",
      "Epoch: [20][400/2250] Elapsed 4m 5s (remain 18m 53s) Loss avg.: 0.4079 Grad: 0.2227 LR: 0.00011  \n",
      "Epoch: [20][500/2250] Elapsed 5m 6s (remain 17m 48s) Loss avg.: 0.4080 Grad: 0.2220 LR: 0.00011  \n",
      "Epoch: [20][600/2250] Elapsed 6m 6s (remain 16m 45s) Loss avg.: 0.4083 Grad: 0.2166 LR: 0.00011  \n",
      "Epoch: [20][700/2250] Elapsed 7m 7s (remain 15m 43s) Loss avg.: 0.4081 Grad: 0.2197 LR: 0.00011  \n",
      "Epoch: [20][800/2250] Elapsed 8m 7s (remain 14m 42s) Loss avg.: 0.4081 Grad: 0.2214 LR: 0.00011  \n",
      "Epoch: [20][900/2250] Elapsed 9m 7s (remain 13m 40s) Loss avg.: 0.4079 Grad: 0.2233 LR: 0.00011  \n",
      "Epoch: [20][1000/2250] Elapsed 10m 8s (remain 12m 39s) Loss avg.: 0.4079 Grad: 0.2179 LR: 0.00011  \n",
      "Epoch: [20][1100/2250] Elapsed 11m 8s (remain 11m 37s) Loss avg.: 0.4079 Grad: 0.2276 LR: 0.00011  \n",
      "Epoch: [20][1200/2250] Elapsed 12m 9s (remain 10m 36s) Loss avg.: 0.4081 Grad: 0.2069 LR: 0.00011  \n",
      "Epoch: [20][1300/2250] Elapsed 13m 9s (remain 9m 35s) Loss avg.: 0.4080 Grad: 0.2223 LR: 0.00011  \n",
      "Epoch: [20][1400/2250] Elapsed 14m 9s (remain 8m 35s) Loss avg.: 0.4079 Grad: 0.2293 LR: 0.00011  \n",
      "Epoch: [20][1500/2250] Elapsed 15m 10s (remain 7m 34s) Loss avg.: 0.4080 Grad: 0.2223 LR: 0.00011  \n",
      "Epoch: [20][1600/2250] Elapsed 16m 11s (remain 6m 33s) Loss avg.: 0.4082 Grad: 0.2380 LR: 0.00011  \n",
      "Epoch: [20][1700/2250] Elapsed 17m 11s (remain 5m 32s) Loss avg.: 0.4083 Grad: 0.2327 LR: 0.00011  \n",
      "Epoch: [20][1800/2250] Elapsed 18m 12s (remain 4m 32s) Loss avg.: 0.4084 Grad: 0.2171 LR: 0.00011  \n",
      "Epoch: [20][1900/2250] Elapsed 19m 12s (remain 3m 31s) Loss avg.: 0.4084 Grad: 0.2310 LR: 0.00011  \n",
      "Epoch: [20][2000/2250] Elapsed 20m 12s (remain 2m 30s) Loss avg.: 0.4086 Grad: 0.2116 LR: 0.00011  \n",
      "Epoch: [20][2100/2250] Elapsed 21m 13s (remain 1m 30s) Loss avg.: 0.4086 Grad: 0.2238 LR: 0.00011  \n",
      "Epoch: [20][2200/2250] Elapsed 22m 13s (remain 0m 29s) Loss avg.: 0.4086 Grad: 0.2190 LR: 0.00011  \n",
      "Epoch: [20][2249/2250] Elapsed 22m 43s (remain 0m 0s) Loss avg.: 0.4087 Grad: 0.2244 LR: 0.00011  \n",
      "Eval: [0/250] Elapsed 0m 2s (remain 10m 41s) Loss avg.: 0.4733 \n",
      "Eval: [100/250] Elapsed 0m 18s (remain 0m 27s) Loss avg.: 0.4406 \n",
      "Eval: [200/250] Elapsed 0m 34s (remain 0m 8s) Loss avg.: 0.4395 \n",
      "Eval: [249/250] Elapsed 0m 42s (remain 0m 0s) Loss avg.: 0.4388 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 - avg_train_loss: 0.4087  avg_val_loss: 0.4388  time: 1409s\n",
      "Epoch 20 - Accuracy: 0.8116875\n",
      "Epoch 20 - Save final model\n",
      "========== fold: 0 result ==========\n",
      "Score: 0.81197\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "hungry-geese-train-by-episode.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2945.71762,
   "end_time": "2021-05-12T03:50:02.012348",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-12T03:00:56.294728",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04a486aa6f454d8f92e388dba1b9ee21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0857c0fa22b544488d65bb2c7dad18ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f905db5005be40b194ea150c8b0deb9f",
      "max": 1001,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "value": 1001
     }
    },
    "4134662bdbe04a918d9809632e268ef8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0857c0fa22b544488d65bb2c7dad18ee",
       "IPY_MODEL_e33e4f894b424988b316c468bc9225ce"
      ],
      "layout": "IPY_MODEL_8ddb49ac3c91409f99a569a061a70b3d"
     }
    },
    "507d2b6a02bb43d0bb4c8c2734f19cbb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ddb49ac3c91409f99a569a061a70b3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c96b7bfbdf0243a8ae1dbb3d9aedf123": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e33e4f894b424988b316c468bc9225ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_507d2b6a02bb43d0bb4c8c2734f19cbb",
      "placeholder": "​",
      "style": "IPY_MODEL_04a486aa6f454d8f92e388dba1b9ee21",
      "value": " 1001/1001 [03:35&lt;00:00,  4.64it/s]"
     }
    },
    "f905db5005be40b194ea150c8b0deb9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abroad-piece",
    "papermill": {
     "duration": 0.025714,
     "end_time": "2021-05-12T03:01:02.640708",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.614994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About this notebook ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pressing-commercial",
    "papermill": {
     "duration": 0.024272,
     "end_time": "2021-05-12T03:01:02.689850",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.665578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "german-ethics",
    "papermill": {
     "duration": 1.852306,
     "end_time": "2021-05-12T03:01:04.566362",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.714056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "apparent-fiction",
    "papermill": {
     "duration": 0.030961,
     "end_time": "2021-05-12T03:01:04.622818",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.591857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "editorial-haiti",
    "papermill": {
     "duration": 0.024908,
     "end_time": "2021-05-12T03:01:05.115280",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.090372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "opened-python",
    "papermill": {
     "duration": 0.035637,
     "end_time": "2021-05-12T03:01:05.176119",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.140482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 440\n",
    "\n",
    "    n_class = 4\n",
    "    n_fold = 10\n",
    "\n",
    "    geese_net_layers = 12\n",
    "    geese_net_filters = 32\n",
    "\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "\n",
    "    num_workers = 4\n",
    "    batch_size = 3200\n",
    "\n",
    "    scheduler = \"CosineAnnealingWarmRestarts\"\n",
    "    # factor = 0.2  # ReduceLROnPlateau\n",
    "    # patience = 4  # ReduceLROnPlateau\n",
    "    # eps = 1e-6  # ReduceLROnPlateau\n",
    "    # T_max = 10  # CosineAnnealingLR\n",
    "    T_0 = 10  # CosineAnnealingWarmRestarts\n",
    "\n",
    "    criterion = \"CrossEntropyLoss\"\n",
    "    lr = 1e-3\n",
    "    min_lr = 1e-4\n",
    "    weight_decay = 1e-5\n",
    "\n",
    "    epochs = 10\n",
    "    model_name = \"geese_net\"\n",
    "    pre_train_file = \"\"\n",
    "\n",
    "    print_freq = 100\n",
    "\n",
    "    train = True\n",
    "    tuning = False\n",
    "    debug = False\n",
    "    apex = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "contained-singles",
    "papermill": {
     "duration": 0.031266,
     "end_time": "2021-05-12T03:01:05.235456",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.204190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.tuning:\n",
    "    Config.epochs = 2\n",
    "\n",
    "if Config.debug:\n",
    "    Config.epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dietary-track",
    "papermill": {
     "duration": 0.031421,
     "end_time": "2021-05-12T03:01:05.292382",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.260961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.apex:\n",
    "    from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "invalid-dispute",
    "papermill": {
     "duration": 0.169531,
     "end_time": "2021-05-12T03:01:05.488665",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.319134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robust-humanity",
    "papermill": {
     "duration": 0.024539,
     "end_time": "2021-05-12T03:01:04.672270",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.647731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "designed-effect",
    "papermill": {
     "duration": 0.031167,
     "end_time": "2021-05-12T03:01:04.728079",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.696912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"../input/hungrygeeseepisode/hungry-geese-episode/\"\n",
    "OUTPUT_DIR = \"pre-models/\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "special-broadcast",
    "outputId": "c440e1e9-5651-42ee-eb0f-08c822d7471a",
    "papermill": {
     "duration": 0.31211,
     "end_time": "2021-05-12T03:01:05.064722",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.752612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27362\n"
     ]
    }
   ],
   "source": [
    "paths = [path for path in glob.glob(BASE_DIR + \"*.json\") if \"info\" not in path]\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n"
     ]
    }
   ],
   "source": [
    "# fit for memory size...\n",
    "paths = paths[-11000:]\n",
    "# paths = paths[:-11000]\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    paths = paths[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "treated-serum",
    "papermill": {
     "duration": 0.025219,
     "end_time": "2021-05-12T03:01:05.539482",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.514263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gothic-alloy",
    "papermill": {
     "duration": 0.070842,
     "end_time": "2021-05-12T03:01:05.642364",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.571522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=Config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "experienced-correspondence",
    "papermill": {
     "duration": 0.053842,
     "end_time": "2021-05-12T03:01:05.741858",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.688016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reverse_ns(y):\n",
    "    if y == 0:\n",
    "        return 1\n",
    "    if y == 1:\n",
    "        return 0\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_we(y):\n",
    "    if y == 2:\n",
    "        return 3\n",
    "    if y == 3:\n",
    "        return 2\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_nswe(y):\n",
    "    return reverse_ns(reverse_we(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "further-transaction",
    "papermill": {
     "duration": 0.042365,
     "end_time": "2021-05-12T03:01:05.826807",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.784442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_position_map = {}\n",
    "for pos in range(77):\n",
    "    position = []\n",
    "    position.append((11 * (1 + pos // 11) + pos % 11) % 77)\n",
    "    position.append((11 * (-1 + pos // 11) + pos % 11) % 77)\n",
    "    position.append((11 * (pos // 11) + (pos + 1) % 11) % 77)\n",
    "    position.append((11 * (pos // 11) + (pos - 1) % 11) % 77)\n",
    "    next_position_map[pos] = set(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "naughty-clause",
    "papermill": {
     "duration": 0.058537,
     "end_time": "2021-05-12T03:01:05.928292",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.869755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_input(obses):\n",
    "    b = np.zeros((17, 7 * 11), dtype=np.float16)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "        pid = (p - obs[\"index\"]) % 4\n",
    "\n",
    "        # head position\n",
    "        for pos in pos_list[:1]:\n",
    "            b[0 + pid, pos] = 1\n",
    "        # tip position\n",
    "        for pos in pos_list[-1:]:\n",
    "            b[4 + pid, pos] = 1\n",
    "        # whole position\n",
    "        for pos in pos_list:\n",
    "            b[8 + pid, pos] = 1\n",
    "\n",
    "    # previous head position\n",
    "    if len(obses) > 1:\n",
    "        obs_prev = obses[-2]\n",
    "        for p, pos_list in enumerate(obs_prev[\"geese\"]):\n",
    "            for pos in pos_list[:1]:\n",
    "                b[12 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    # food\n",
    "    for pos in obs[\"food\"]:\n",
    "        b[16, pos] = 1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reverse_cube(obses):\n",
    "    \"\"\"\n",
    "    尻尾から順番に 1, 0.9, 0.8, ... という並び\n",
    "    \"\"\"\n",
    "    b = np.zeros((4, 7 * 11), dtype=np.float16)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, geese in enumerate(obs[\"geese\"]):\n",
    "        # whole position reverse\n",
    "        for num_reverse, pos in enumerate(geese[::-1]):\n",
    "            b[(p - obs[\"index\"]) % 4, pos] = 1 - num_reverse * 0.1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_disappear_cube(obses):\n",
    "    \"\"\"\n",
    "    次になくなる場所: 1\n",
    "    次になくなる可能性のある場所: 0.5\n",
    "    \"\"\"\n",
    "    b = np.zeros((4, 7 * 11), dtype=np.float16)\n",
    "    obs = obses[-1]\n",
    "    step = obs[\"step\"]\n",
    "\n",
    "    # foodを食べる可能性があるか。\n",
    "    eat_food_possibility = defaultdict(int)\n",
    "    for p, geese in enumerate(obs[\"geese\"]):\n",
    "        for pos in geese[:1]:\n",
    "            if not next_position_map[pos].isdisjoint(obs[\"food\"]):\n",
    "                eat_food_possibility[p] = 1\n",
    "\n",
    "    if (step % 40) == 39:  # 1つ短くなる\n",
    "        for p, geese in enumerate(obs[\"geese\"]):\n",
    "            if eat_food_possibility[p]:  # 尻尾が1、尻尾の１つ前0.5\n",
    "                for pos in geese[-1:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 1\n",
    "                for pos in geese[-2:-1]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 0.5\n",
    "            else:  # 食べる可能性なし -> 尻尾が1, 尻尾の1つ前1\n",
    "                for pos in geese[-2:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 1\n",
    "    else:  # 1つ短くならない\n",
    "        for p, geese in enumerate(obs[\"geese\"]):\n",
    "            if eat_food_possibility[p]:  # 食べる可能性があり -> 尻尾を0.5\n",
    "                for pos in geese[-1:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 0.5\n",
    "            else:  # 食べる可能性なし # 尻尾を1\n",
    "                for pos in geese[-1:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_step_cube_v2(obses):\n",
    "    \"\"\"\n",
    "    step0: 0, step199: 1\n",
    "    step0: 0, step39 + 40n: 1\n",
    "    \"\"\"\n",
    "    b = np.zeros((1, 7, 11), dtype=np.float16)\n",
    "    obs = obses[-1]\n",
    "    step = obs[\"step\"]\n",
    "\n",
    "    b[:, :, :5] = (step % 200) / 199\n",
    "    b[:, :, 5:] = (step % 40) / 39\n",
    "\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_cube(obses):\n",
    "    b = np.zeros((2, 7, 11), dtype=np.float16)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    my_length = len(obs[\"geese\"][obs[\"index\"]])\n",
    "    opposite1_length = len(obs[\"geese\"][(obs[\"index\"] + 1) % 4])\n",
    "    opposite2_length = len(obs[\"geese\"][(obs[\"index\"] + 2) % 4])\n",
    "    opposite3_length = len(obs[\"geese\"][(obs[\"index\"] + 3) % 4])\n",
    "\n",
    "    b[0] = my_length / 10\n",
    "    max_opposite_length = max(opposite1_length, opposite2_length, opposite3_length)\n",
    "    b[1, :, 0:2] = (my_length - max_opposite_length) / 10\n",
    "    b[1, :, 2:5] = (my_length - opposite1_length) / 10\n",
    "    b[1, :, 5:8] = (my_length - opposite2_length) / 10\n",
    "    b[1, :, 8:11] = (my_length - opposite3_length) / 10\n",
    "\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(obses):\n",
    "    b = np.zeros((7 * 11), dtype=np.float16)\n",
    "    obs = obses[-1]\n",
    "    step = obs[\"step\"]\n",
    "\n",
    "    my_goose = obs[\"geese\"][obs[\"index\"]]\n",
    "    my_length = len(my_goose)\n",
    "\n",
    "    # num step\n",
    "    b[0] = (step - 194) if step >= 195 else 0\n",
    "    b[1] = (step % 40 - 35) if step % 40 > 35 else 0\n",
    "\n",
    "    \"\"\"\n",
    "    2-4: difference between my_length and opponent length (-3 to 3)\n",
    "    \"\"\"\n",
    "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "        pid = (p - obs[\"index\"]) % 4\n",
    "        p_length = len(pos_list)\n",
    "\n",
    "        if pid == 0:\n",
    "            continue\n",
    "\n",
    "        b[1 + pid] = max(min(my_length - p_length, 3), -3) + 3\n",
    "\n",
    "    \"\"\"\n",
    "    5-7: difference between my head position and opponent one\n",
    "    \"\"\"\n",
    "    if my_length != 0:\n",
    "\n",
    "        for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "            pid = (p - obs[\"index\"]) % 4\n",
    "\n",
    "            if pid == 0 or len(pos_list) == 0:\n",
    "                continue\n",
    "\n",
    "            diff = abs(my_goose[0] - pos_list[0])\n",
    "            x_ = diff % 11\n",
    "            x = min(x_, 11 - x_)\n",
    "            y_ = diff // 11\n",
    "            y = min(y_, 7 - y_)\n",
    "            b[4 + pid] = x + y\n",
    "\n",
    "    return b.reshape(1, 7, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pretty-aaron",
    "papermill": {
     "duration": 0.042985,
     "end_time": "2021-05-12T03:01:06.014038",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.971053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "international-secret",
    "papermill": {
     "duration": 0.064855,
     "end_time": "2021-05-12T03:01:06.121648",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.056793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset_from_json(filepath, json_object=None, standing=0):\n",
    "    if json_object is None:\n",
    "        json_open = open(path, \"r\")\n",
    "        json_load = json.load(json_open)\n",
    "    else:\n",
    "        json_load = json_object\n",
    "\n",
    "    try:\n",
    "        winner_index = np.argmax(np.argsort(json_load[\"rewards\"]) == 3 - standing)\n",
    "\n",
    "        obses = []\n",
    "        X = []\n",
    "        y = []\n",
    "        actions = {\"NORTH\": 0, \"SOUTH\": 1, \"WEST\": 2, \"EAST\": 3}\n",
    "\n",
    "        for i in range(len(json_load[\"steps\"]) - 1):\n",
    "            if json_load[\"steps\"][i][winner_index][\"status\"] == \"ACTIVE\":\n",
    "                y_ = json_load[\"steps\"][i + 1][winner_index][\"action\"]\n",
    "                if y_ is not None:\n",
    "                    step = json_load[\"steps\"][i]\n",
    "                    step[winner_index][\"observation\"][\"geese\"] = step[0][\"observation\"][\"geese\"]\n",
    "                    step[winner_index][\"observation\"][\"food\"] = step[0][\"observation\"][\"food\"]\n",
    "                    step[winner_index][\"observation\"][\"step\"] = step[0][\"observation\"][\"step\"]\n",
    "                    obses.append(step[winner_index][\"observation\"])\n",
    "                    y.append(actions[y_])\n",
    "\n",
    "                    y.append(reverse_ns(actions[y_]))  # 上下反転\n",
    "                    y.append(reverse_we(actions[y_]))  # 左右反転\n",
    "                    y.append(reverse_nswe(actions[y_]))  # 上下左右反転\n",
    "\n",
    "        for j in range(len(obses)):\n",
    "            # X_ = make_input(obses[: j + 1])\n",
    "\n",
    "            # 反転可能な特徴量\n",
    "            X_ = []\n",
    "            X_.append(make_input(obses[: j + 1]))\n",
    "            X_.append(get_reverse_cube(obses[: j + 1]))\n",
    "            X_.append(get_next_disappear_cube(obses[: j + 1]))\n",
    "\n",
    "            # 反転不可能な特徴量\n",
    "            X_i = []\n",
    "            # X_i.append(get_step_cube_v2(obses[: j + 1]))\n",
    "            # X_i.append(get_length_cube(obses[: j + 1]))\n",
    "            X_i.append(get_features(obses[: j + 1]))\n",
    "\n",
    "            X_ = np.concatenate(X_)\n",
    "            X_i = np.concatenate(X_i)\n",
    "\n",
    "            X.append(np.concatenate([X_, X_i]))\n",
    "            X.append(np.concatenate([X_[:, ::-1, :], X_i]))  # 上下反転\n",
    "            X.append(np.concatenate([X_[:, :, ::-1], X_i]))  # 左右反転\n",
    "            X.append(np.concatenate([X_[:, ::-1, ::-1], X_i]))  # 上下左右反転\n",
    "\n",
    "        X = np.array(X, dtype=np.float16)  # [starting_step:]\n",
    "        y = np.array(y, dtype=np.uint8)  # [starting_step:]\n",
    "\n",
    "        return X, y\n",
    "    except Exception as e:\n",
    "        if Config.debug:\n",
    "            raise Exception from e\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "4134662bdbe04a918d9809632e268ef8",
      "8ddb49ac3c91409f99a569a061a70b3d",
      "0857c0fa22b544488d65bb2c7dad18ee",
      "e33e4f894b424988b316c468bc9225ce",
      "c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "f905db5005be40b194ea150c8b0deb9f",
      "04a486aa6f454d8f92e388dba1b9ee21",
      "507d2b6a02bb43d0bb4c8c2734f19cbb"
     ]
    },
    "id": "handled-pleasure",
    "outputId": "955c1c6b-36bc-4b30-dc44-b72b05398f8c",
    "papermill": {
     "duration": 15.320591,
     "end_time": "2021-05-12T03:01:21.474816",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.154225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26b9e06e2a944a8b66191a1fe1bc57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num episode: 6861292\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for path in tqdm(paths[: int(len(paths))]):\n",
    "    X, y = create_dataset_from_json(path, standing=0)  # use only winners' moves\n",
    "    if X is not 0:\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "persistent-loading",
    "papermill": {
     "duration": 112.92618,
     "end_time": "2021-05-12T03:03:14.428162",
     "exception": false,
     "start_time": "2021-05-12T03:01:21.501982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# X_train, unique_index = np.unique(X_train, axis=0, return_index=True)  # remove duplicate\n",
    "# y_train = y_train[unique_index]\n",
    "\n",
    "# y_train = np.eye(4, dtype=\"uint8\")[y_train]  # to categorical\n",
    "\n",
    "# print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_:\n",
    "    X_train_sum_obs = X_train.reshape(X_train.shape[0], -1).sum(1)\n",
    "    X_train_group = np.unique(X_train_sum_obs)\n",
    "    X_train_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_:\n",
    "    X_train_unique = []\n",
    "    y_train_unique = []\n",
    "    for group in tqdm(X_train_group):\n",
    "        group_index = np.where(X_train_sum_obs == group)\n",
    "\n",
    "        X_train_ = X_train[group_index]\n",
    "        y_train_ = y_train[group_index]\n",
    "\n",
    "        X_train_, unique_index = np.unique(X_train_, axis=0, return_index=True)  # remove duplicate\n",
    "        y_train_ = y_train_[unique_index]\n",
    "\n",
    "        X_train_unique.append(X_train_)\n",
    "        y_train_unique.append(y_train_)\n",
    "\n",
    "    X_train = np.concatenate(X_train_unique)\n",
    "    y_train = np.concatenate(y_train_unique)\n",
    "\n",
    "    print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_:\n",
    "    del X_train_sum_obs\n",
    "    del X_train_group\n",
    "    del X_train_unique\n",
    "    del y_train_unique\n",
    "    del X_train_\n",
    "    del y_train_\n",
    "    del group_index\n",
    "    del unique_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "micro-french",
    "papermill": {
     "duration": 0.033413,
     "end_time": "2021-05-12T03:03:15.360395",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.326982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    X_train = X_train[:1000]\n",
    "    y_train = y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "wrong-pastor",
    "outputId": "406a2f1d-0b8a-46bf-ca01-546f3110c301",
    "papermill": {
     "duration": 0.036161,
     "end_time": "2021-05-12T03:03:15.425149",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.388988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6861287</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6861288</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6861289</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6861290</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6861291</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6861292 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         action\n",
       "0             3\n",
       "1             3\n",
       "2             2\n",
       "3             2\n",
       "4             0\n",
       "...         ...\n",
       "6861287       3\n",
       "6861288       1\n",
       "6861289       0\n",
       "6861290       1\n",
       "6861291       0\n",
       "\n",
       "[6861292 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(y_train, dtype=np.uint8)\n",
    "y_df.columns = [\"action\"]\n",
    "y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "touched-coordinate",
    "papermill": {
     "duration": 0.027968,
     "end_time": "2021-05-12T03:03:15.557122",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.529154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "moving-skill",
    "outputId": "7542c4b4-f7d3-444c-8450-50bffddb1892",
    "papermill": {
     "duration": 0.202337,
     "end_time": "2021-05-12T03:03:15.787529",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.585192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  action\n",
      "0     0         165425\n",
      "      1         165426\n",
      "      2         177639\n",
      "      3         177640\n",
      "1     0         165425\n",
      "      1         165426\n",
      "      2         177639\n",
      "      3         177640\n",
      "2     0         165425\n",
      "      1         165425\n",
      "      2         177640\n",
      "      3         177639\n",
      "3     0         165425\n",
      "      1         165425\n",
      "      2         177640\n",
      "      3         177639\n",
      "4     0         165426\n",
      "      1         165425\n",
      "      2         177639\n",
      "      3         177639\n",
      "5     0         165426\n",
      "      1         165425\n",
      "      2         177639\n",
      "      3         177639\n",
      "6     0         165426\n",
      "      1         165425\n",
      "      2         177639\n",
      "      3         177639\n",
      "7     0         165426\n",
      "      1         165425\n",
      "      2         177639\n",
      "      3         177639\n",
      "8     0         165425\n",
      "      1         165426\n",
      "      2         177639\n",
      "      3         177639\n",
      "9     0         165425\n",
      "      1         165426\n",
      "      2         177639\n",
      "      3         177639\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "folds = y_df.copy()\n",
    "Fold = StratifiedKFold(n_splits=Config.n_fold, shuffle=True, random_state=Config.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[\"action\"])):\n",
    "    folds.loc[val_index, \"fold\"] = int(n)\n",
    "folds[\"fold\"] = folds[\"fold\"].astype(np.uint8)\n",
    "print(folds.groupby([\"fold\", \"action\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "creative-football",
    "papermill": {
     "duration": 0.029031,
     "end_time": "2021-05-12T03:03:15.845114",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.816083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "other-murder",
    "papermill": {
     "duration": 0.037264,
     "end_time": "2021-05-12T03:03:15.911219",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.873955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, array, label):\n",
    "        self.array = array\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx], torch.tensor(self.label[idx]).long()\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, array):\n",
    "        self.array = array\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adjusted-delhi",
    "outputId": "39504950-84bc-4692-8b90-8a5b64f741e0",
    "papermill": {
     "duration": 0.063691,
     "end_time": "2021-05-12T03:03:16.003693",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.940002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "if Config.debug or False:\n",
    "    train_ds = TrainDataset(X_train, y_train)\n",
    "\n",
    "    for i in range(1):\n",
    "        obs, action = train_ds[i]\n",
    "        print(obs.shape, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceramic-startup",
    "papermill": {
     "duration": 0.02876,
     "end_time": "2021-05-12T03:03:16.061575",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.032815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "unique-trick",
    "papermill": {
     "duration": 0.039055,
     "end_time": "2021-05-12T03:03:16.130239",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.091184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TorusConv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, do=False, bn=True):\n",
    "        super().__init__()\n",
    "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.do = nn.Dropout2d(p=0.1) if do else None\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([x[:, :, :, -self.edge_size[1] :], x, x[:, :, :, : self.edge_size[1]]], dim=3)\n",
    "        h = torch.cat([h[:, :, -self.edge_size[0] :], h, h[:, :, : self.edge_size[0]]], dim=2)\n",
    "        h = self.conv(h)\n",
    "        h = self.do(h) if self.do is not None else h\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "jspEE71c2Yma"
   },
   "outputs": [],
   "source": [
    "class GeeseNetAlpha(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = Config.geese_net_layers\n",
    "        filters = Config.geese_net_filters\n",
    "        dim = filters * 5 + 30\n",
    "\n",
    "        self.embed_step = nn.Embedding(5, 3)\n",
    "        self.embed_hunger = nn.Embedding(5, 3)\n",
    "        self.embed_diff_len = nn.Embedding(7, 4)\n",
    "        self.embed_diff_head = nn.Embedding(9, 4)\n",
    "\n",
    "        self.conv0 = TorusConv2d(25, filters, (3, 3))\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "        self.conv1 = TorusConv2d(filters, filters, (5, 5))\n",
    "\n",
    "        self.head_p1 = nn.Linear(dim, dim // 2, bias=True)\n",
    "        self.head_p2 = nn.Linear(dim // 2, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(dim, dim // 2, bias=True)\n",
    "        self.head_v2 = nn.Linear(dim // 2, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        x_feats = x[:, -1].view(x.size(0), -1).long()\n",
    "\n",
    "        # Embedding for features\n",
    "        e_step = self.embed_step(x_feats[:, 0])\n",
    "        e_hung = self.embed_hunger(x_feats[:, 1])\n",
    "        e_diff_l = self.embed_diff_len(x_feats[:, 2:5]).view(x.size(0), -1)\n",
    "        e_diff_h = self.embed_diff_head(x_feats[:, 5:8]).view(x.size(0), -1)\n",
    "\n",
    "        x = x[:, :-1].float()\n",
    "\n",
    "        # CNN for observation\n",
    "        h = F.relu_(self.conv0(x))\n",
    "\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        h = F.relu_(h + self.conv1(h))\n",
    "\n",
    "        # Extract head position\n",
    "        h_head = (h * x[:, :1]).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        h_head2 = (h * x[:, 1:2]).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        h_head3 = (h * x[:, 2:3]).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        h_head4 = (h * x[:, 3:4]).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        h_avg = h.view(h.size(0), h.size(1), -1).mean(-1)\n",
    "\n",
    "        # Merge features\n",
    "        h = torch.cat(\n",
    "            [\n",
    "                h_head,\n",
    "                h_head2,\n",
    "                h_head3,\n",
    "                h_head4,\n",
    "                h_avg,\n",
    "                e_step,\n",
    "                e_hung,\n",
    "                e_diff_l,\n",
    "                e_diff_h,\n",
    "            ],\n",
    "            1,\n",
    "        ).view(1, h.size(0), -1)\n",
    "\n",
    "        h_p = F.relu_(self.head_p1(h.view(x.size(0), -1)))\n",
    "        p = self.head_p2(h_p)\n",
    "\n",
    "        h_v = F.relu_(self.head_v1(h.view(x.size(0), -1)))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p, \"value\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "objective-victoria",
    "outputId": "1ab137a5-e26e-4b9c-ff85-95fef713b755",
    "papermill": {
     "duration": 4.955868,
     "end_time": "2021-05-12T03:03:21.187355",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.231487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "if Config.debug or False:\n",
    "    model = GeeseNetAlpha()\n",
    "    # print(model)\n",
    "\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"params: {params:,}\")\n",
    "\n",
    "    train_ds = TrainDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "    for obs, action in train_loader:\n",
    "        print(f\"input shape: {obs.shape}\")\n",
    "        output = model(obs)\n",
    "        print(output)\n",
    "        print(f\"{torch.argmax(output['policy'], dim=1)}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "military-fiction",
    "papermill": {
     "duration": 0.033001,
     "end_time": "2021-05-12T03:03:21.255277",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.222276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sophisticated-hearts",
    "papermill": {
     "duration": 0.031759,
     "end_time": "2021-05-12T03:03:21.319849",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.288090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "designing-detective",
    "papermill": {
     "duration": 0.03139,
     "end_time": "2021-05-12T03:03:21.383038",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.351648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "passive-cooper",
    "papermill": {
     "duration": 0.038846,
     "end_time": "2021-05-12T03:03:21.454085",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.415239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(result_df):\n",
    "    preds = result_df[\"preds\"].values\n",
    "    labels = result_df[\"action\"].values\n",
    "    score = get_score(labels, preds)\n",
    "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thirty-tracy",
    "papermill": {
     "duration": 0.0293,
     "end_time": "2021-05-12T03:03:21.514179",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.484879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "introductory-brooklyn",
    "papermill": {
     "duration": 0.039424,
     "end_time": "2021-05-12T03:03:21.582969",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.543545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "raising-laugh",
    "papermill": {
     "duration": 0.042063,
     "end_time": "2021-05-12T03:03:21.654559",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.612496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (obs, action) in enumerate(train_loader):\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        y_preds = model(obs)[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "        if Config.apex:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), Config.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % Config.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print(\n",
    "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
    "                f\"Loss avg.: {losses.avg:.4f} \"\n",
    "                f\"Grad: {grad_norm:.4f} \"\n",
    "                f\"LR: {scheduler.get_last_lr()[0]:.5f}  \"\n",
    "            )\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "plain-neighbor",
    "papermill": {
     "duration": 0.041056,
     "end_time": "2021-05-12T03:03:21.726585",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.685529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (obs, action) in enumerate(valid_loader):\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(obs)[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print(\n",
    "                f\"Eval: [{step}/{len(valid_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
    "                f\"Loss avg.: {losses.avg:.4f} \"\n",
    "            )\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "integrated-classification",
    "papermill": {
     "duration": 0.029832,
     "end_time": "2021-05-12T03:03:21.786427",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.756595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "harmful-explanation",
    "papermill": {
     "duration": 0.05136,
     "end_time": "2021-05-12T03:03:21.868561",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.817201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(folds, fold):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    # X_train_folds = X_train[folds[\"fold\"] != fold]\n",
    "    # X_valid_folds = X_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    # y_train_folds = y_train[folds[\"fold\"] != fold]\n",
    "    y_valid_folds = y_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    # y_df_train_folds = y_df[folds[\"fold\"] != fold]\n",
    "    y_df_valid_folds = y_df[folds[\"fold\"] == fold]\n",
    "\n",
    "    # train_dataset = TrainDataset(X_train[folds[\"fold\"] != fold], y_train[folds[\"fold\"] != fold])\n",
    "    # valid_dataset = TrainDataset(X_train[folds[\"fold\"] == fold], y_valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        TrainDataset(X_train[folds[\"fold\"] != fold], y_train[folds[\"fold\"] != fold]),\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        TrainDataset(X_train[folds[\"fold\"] == fold], y_valid_folds),\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if Config.scheduler == \"ReduceLROnPlateau\":\n",
    "            scheduler = ReduceLROnPlateau(\n",
    "                optimizer, mode=\"min\", factor=Config.factor, patience=Config.patience, verbose=True, eps=Config.eps\n",
    "            )\n",
    "        elif Config.scheduler == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=Config.T_max, eta_min=Config.min_lr, last_epoch=-1)\n",
    "        elif Config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "            scheduler = CosineAnnealingWarmRestarts(\n",
    "                optimizer, T_0=Config.T_0, T_mult=1, eta_min=Config.min_lr, last_epoch=-1\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = GeeseNetAlpha()\n",
    "    # try:\n",
    "    #     model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, Config.pre_train_file)))\n",
    "    # except:\n",
    "    #     print(f\"Failed to load pre-train weight.\")\n",
    "\n",
    "    # Disable training for value network\n",
    "    # for param in model.head_v1.parameters():\n",
    "    #     param.requires_grad = False\n",
    "    # for param in model.head_v2.parameters():\n",
    "    #     param.requires_grad = False\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Use multi GPU\n",
    "    if device == torch.device(\"cuda\") and not Config.apex:\n",
    "        model = torch.nn.DataParallel(model)  # make parallel\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=Config.lr, weight_decay=Config.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # apex\n",
    "    # ====================================================\n",
    "    if Config.apex:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
    "\n",
    "    # ====================================================\n",
    "    # Criterion\n",
    "    # ====================================================\n",
    "    def get_criterion():\n",
    "        if Config.criterion == \"CrossEntropyLoss\":\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        return criterion\n",
    "\n",
    "    criterion = get_criterion()\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    best_score = 0.0\n",
    "    best_loss = np.inf\n",
    "    best_preds = None\n",
    "\n",
    "    for epoch in range(Config.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "\n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(y_valid_folds, preds.argmax(1))\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Accuracy: {score}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_best.pth\")\n",
    "            best_preds = preds\n",
    "\n",
    "        if epoch == Config.epochs - 1:\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save final model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_final.pth\")\n",
    "\n",
    "    if Config.train:\n",
    "        y_df_valid_folds[[str(c) for c in range(Config.n_class)]] = best_preds\n",
    "        y_df_valid_folds[\"preds\"] = best_preds.argmax(1)\n",
    "\n",
    "        return y_df_valid_folds\n",
    "\n",
    "    if Config.tuning:\n",
    "        score = get_score(y_df_valid_folds[\"action\"].values, best_preds.argmax(1))\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    Config.geese_net_layers = trial.suggest_int(\"layers\", 6, 18)\n",
    "    Config.geese_net_filters = trial.suggest_int(\"filters\", 32, 128)\n",
    "\n",
    "    score = train_loop(folds, 0)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "complimentary-wright",
    "papermill": {
     "duration": 0.030218,
     "end_time": "2021-05-12T03:03:21.928896",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.898678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "particular-adaptation",
    "papermill": {
     "duration": 0.04089,
     "end_time": "2021-05-12T03:03:22.000150",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.959260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if Config.train:\n",
    "        # train\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(Config.n_fold):\n",
    "            _oof_df = train_loop(folds, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df)\n",
    "            # break  # fold 1つだけ\n",
    "        # CV result\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
    "\n",
    "    if Config.tuning:\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=10)\n",
    "\n",
    "        trial = study.best_trial\n",
    "        print(\"Best trial:\")\n",
    "        print(\"  Value: \", trial.value)\n",
    "        print(\"  Params: \")\n",
    "        for key, value in trial.params.items():\n",
    "            print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "backed-journal",
    "outputId": "c9f0ff3d-795e-466b-e22e-9ba21d08c874",
    "papermill": {
     "duration": 2797.64711,
     "end_time": "2021-05-12T03:49:59.678400",
     "exception": false,
     "start_time": "2021-05-12T03:03:22.031290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load pre-train weight.\n",
      "Epoch: [1][0/1929] Elapsed 0m 4s (remain 140m 19s) Loss avg.: 1.3964 Grad: 0.3497 LR: 0.00100  \n",
      "Epoch: [1][100/1929] Elapsed 1m 4s (remain 19m 18s) Loss avg.: 0.6997 Grad: 0.4585 LR: 0.00100  \n",
      "Epoch: [1][200/1929] Elapsed 2m 3s (remain 17m 43s) Loss avg.: 0.6335 Grad: 0.9590 LR: 0.00100  \n",
      "Epoch: [1][300/1929] Elapsed 3m 3s (remain 16m 31s) Loss avg.: 0.6019 Grad: 0.7024 LR: 0.00100  \n",
      "Epoch: [1][400/1929] Elapsed 4m 2s (remain 15m 25s) Loss avg.: 0.5811 Grad: 0.5451 LR: 0.00100  \n",
      "Epoch: [1][500/1929] Elapsed 5m 2s (remain 14m 23s) Loss avg.: 0.5668 Grad: 0.6449 LR: 0.00100  \n",
      "Epoch: [1][600/1929] Elapsed 6m 2s (remain 13m 20s) Loss avg.: 0.5557 Grad: 0.5673 LR: 0.00100  \n",
      "Epoch: [1][700/1929] Elapsed 7m 2s (remain 12m 19s) Loss avg.: 0.5473 Grad: 0.4344 LR: 0.00100  \n",
      "Epoch: [1][800/1929] Elapsed 8m 1s (remain 11m 18s) Loss avg.: 0.5399 Grad: 0.4112 LR: 0.00100  \n",
      "Epoch: [1][900/1929] Elapsed 9m 1s (remain 10m 17s) Loss avg.: 0.5341 Grad: 0.3787 LR: 0.00100  \n",
      "Epoch: [1][1000/1929] Elapsed 10m 0s (remain 9m 17s) Loss avg.: 0.5291 Grad: 0.4501 LR: 0.00100  \n",
      "Epoch: [1][1100/1929] Elapsed 11m 0s (remain 8m 16s) Loss avg.: 0.5250 Grad: 0.4460 LR: 0.00100  \n",
      "Epoch: [1][1200/1929] Elapsed 12m 0s (remain 7m 16s) Loss avg.: 0.5212 Grad: 0.4599 LR: 0.00100  \n",
      "Epoch: [1][1300/1929] Elapsed 13m 0s (remain 6m 16s) Loss avg.: 0.5181 Grad: 0.3417 LR: 0.00100  \n",
      "Epoch: [1][1400/1929] Elapsed 14m 0s (remain 5m 16s) Loss avg.: 0.5148 Grad: 0.3160 LR: 0.00100  \n",
      "Epoch: [1][1500/1929] Elapsed 14m 59s (remain 4m 16s) Loss avg.: 0.5120 Grad: 0.3935 LR: 0.00100  \n",
      "Epoch: [1][1600/1929] Elapsed 15m 59s (remain 3m 16s) Loss avg.: 0.5095 Grad: 0.5010 LR: 0.00100  \n",
      "Epoch: [1][1700/1929] Elapsed 16m 59s (remain 2m 16s) Loss avg.: 0.5073 Grad: 0.3554 LR: 0.00100  \n",
      "Epoch: [1][1800/1929] Elapsed 17m 58s (remain 1m 16s) Loss avg.: 0.5052 Grad: 0.3290 LR: 0.00100  \n",
      "Epoch: [1][1900/1929] Elapsed 18m 58s (remain 0m 16s) Loss avg.: 0.5034 Grad: 0.2878 LR: 0.00100  \n",
      "Epoch: [1][1928/1929] Elapsed 19m 15s (remain 0m 0s) Loss avg.: 0.5029 Grad: 0.3780 LR: 0.00100  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 31s) Loss avg.: 0.4532 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4711 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4713 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4717 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.5029  avg_val_loss: 0.4717  time: 1191s\n",
      "Epoch 1 - Accuracy: 0.7951131709734307\n",
      "Epoch 1 - Save Best Score: 0.7951 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1929] Elapsed 0m 1s (remain 62m 4s) Loss avg.: 0.4927 Grad: 0.3201 LR: 0.00098  \n",
      "Epoch: [2][100/1929] Elapsed 1m 1s (remain 18m 36s) Loss avg.: 0.4629 Grad: 0.6122 LR: 0.00098  \n",
      "Epoch: [2][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4634 Grad: 0.3572 LR: 0.00098  \n",
      "Epoch: [2][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4637 Grad: 0.2942 LR: 0.00098  \n",
      "Epoch: [2][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4632 Grad: 0.3097 LR: 0.00098  \n",
      "Epoch: [2][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4631 Grad: 0.3064 LR: 0.00098  \n",
      "Epoch: [2][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4628 Grad: 0.3038 LR: 0.00098  \n",
      "Epoch: [2][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4627 Grad: 0.2515 LR: 0.00098  \n",
      "Epoch: [2][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4624 Grad: 0.3119 LR: 0.00098  \n",
      "Epoch: [2][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4623 Grad: 0.3561 LR: 0.00098  \n",
      "Epoch: [2][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4620 Grad: 0.2682 LR: 0.00098  \n",
      "Epoch: [2][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4618 Grad: 0.3330 LR: 0.00098  \n",
      "Epoch: [2][1200/1929] Elapsed 11m 59s (remain 7m 15s) Loss avg.: 0.4616 Grad: 0.3702 LR: 0.00098  \n",
      "Epoch: [2][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4615 Grad: 0.4415 LR: 0.00098  \n",
      "Epoch: [2][1400/1929] Elapsed 13m 58s (remain 5m 16s) Loss avg.: 0.4612 Grad: 0.4658 LR: 0.00098  \n",
      "Epoch: [2][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4610 Grad: 0.2530 LR: 0.00098  \n",
      "Epoch: [2][1600/1929] Elapsed 15m 58s (remain 3m 16s) Loss avg.: 0.4609 Grad: 0.3401 LR: 0.00098  \n",
      "Epoch: [2][1700/1929] Elapsed 16m 58s (remain 2m 16s) Loss avg.: 0.4607 Grad: 0.3392 LR: 0.00098  \n",
      "Epoch: [2][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4605 Grad: 0.3007 LR: 0.00098  \n",
      "Epoch: [2][1900/1929] Elapsed 18m 57s (remain 0m 16s) Loss avg.: 0.4602 Grad: 0.2379 LR: 0.00098  \n",
      "Epoch: [2][1928/1929] Elapsed 19m 14s (remain 0m 0s) Loss avg.: 0.4601 Grad: 0.3692 LR: 0.00098  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 32s) Loss avg.: 0.4346 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4559 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4561 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4565 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4601  avg_val_loss: 0.4565  time: 1190s\n",
      "Epoch 2 - Accuracy: 0.8025053561278475\n",
      "Epoch 2 - Save Best Score: 0.8025 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1929] Elapsed 0m 2s (remain 65m 52s) Loss avg.: 0.4413 Grad: 0.2800 LR: 0.00091  \n",
      "Epoch: [3][100/1929] Elapsed 1m 1s (remain 18m 38s) Loss avg.: 0.4525 Grad: 0.3244 LR: 0.00091  \n",
      "Epoch: [3][200/1929] Elapsed 2m 1s (remain 17m 25s) Loss avg.: 0.4519 Grad: 0.3165 LR: 0.00091  \n",
      "Epoch: [3][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4516 Grad: 0.2890 LR: 0.00091  \n",
      "Epoch: [3][400/1929] Elapsed 4m 1s (remain 15m 18s) Loss avg.: 0.4515 Grad: 0.2794 LR: 0.00091  \n",
      "Epoch: [3][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4517 Grad: 0.3532 LR: 0.00091  \n",
      "Epoch: [3][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4514 Grad: 0.2316 LR: 0.00091  \n",
      "Epoch: [3][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4513 Grad: 0.2906 LR: 0.00091  \n",
      "Epoch: [3][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4512 Grad: 0.2520 LR: 0.00091  \n",
      "Epoch: [3][900/1929] Elapsed 8m 59s (remain 10m 16s) Loss avg.: 0.4511 Grad: 0.2716 LR: 0.00091  \n",
      "Epoch: [3][1000/1929] Elapsed 9m 59s (remain 9m 16s) Loss avg.: 0.4512 Grad: 0.3422 LR: 0.00091  \n",
      "Epoch: [3][1100/1929] Elapsed 10m 59s (remain 8m 16s) Loss avg.: 0.4511 Grad: 0.3007 LR: 0.00091  \n",
      "Epoch: [3][1200/1929] Elapsed 11m 59s (remain 7m 16s) Loss avg.: 0.4512 Grad: 0.3068 LR: 0.00091  \n",
      "Epoch: [3][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.4511 Grad: 0.3146 LR: 0.00091  \n",
      "Epoch: [3][1400/1929] Elapsed 13m 58s (remain 5m 16s) Loss avg.: 0.4511 Grad: 0.2661 LR: 0.00091  \n",
      "Epoch: [3][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4510 Grad: 0.2976 LR: 0.00091  \n",
      "Epoch: [3][1600/1929] Elapsed 15m 58s (remain 3m 16s) Loss avg.: 0.4509 Grad: 0.2223 LR: 0.00091  \n",
      "Epoch: [3][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4508 Grad: 0.2679 LR: 0.00091  \n",
      "Epoch: [3][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4507 Grad: 0.2115 LR: 0.00091  \n",
      "Epoch: [3][1900/1929] Elapsed 18m 57s (remain 0m 16s) Loss avg.: 0.4507 Grad: 0.2961 LR: 0.00091  \n",
      "Epoch: [3][1928/1929] Elapsed 19m 14s (remain 0m 0s) Loss avg.: 0.4507 Grad: 0.3158 LR: 0.00091  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 28s) Loss avg.: 0.4282 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4514 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4515 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4519 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.4507  avg_val_loss: 0.4519  time: 1190s\n",
      "Epoch 3 - Accuracy: 0.8048503927827089\n",
      "Epoch 3 - Save Best Score: 0.8049 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/1929] Elapsed 0m 1s (remain 60m 48s) Loss avg.: 0.4413 Grad: 0.2877 LR: 0.00081  \n",
      "Epoch: [4][100/1929] Elapsed 1m 1s (remain 18m 34s) Loss avg.: 0.4432 Grad: 0.3173 LR: 0.00081  \n",
      "Epoch: [4][200/1929] Elapsed 2m 1s (remain 17m 22s) Loss avg.: 0.4438 Grad: 0.2349 LR: 0.00081  \n",
      "Epoch: [4][300/1929] Elapsed 3m 0s (remain 16m 18s) Loss avg.: 0.4435 Grad: 0.3095 LR: 0.00081  \n",
      "Epoch: [4][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4440 Grad: 0.2790 LR: 0.00081  \n",
      "Epoch: [4][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4441 Grad: 0.2568 LR: 0.00081  \n",
      "Epoch: [4][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4441 Grad: 0.2841 LR: 0.00081  \n",
      "Epoch: [4][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4440 Grad: 0.2244 LR: 0.00081  \n",
      "Epoch: [4][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4440 Grad: 0.2448 LR: 0.00081  \n",
      "Epoch: [4][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4442 Grad: 0.2559 LR: 0.00081  \n",
      "Epoch: [4][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4443 Grad: 0.2160 LR: 0.00081  \n",
      "Epoch: [4][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4444 Grad: 0.2401 LR: 0.00081  \n",
      "Epoch: [4][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4445 Grad: 0.3171 LR: 0.00081  \n",
      "Epoch: [4][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4445 Grad: 0.2521 LR: 0.00081  \n",
      "Epoch: [4][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4446 Grad: 0.2476 LR: 0.00081  \n",
      "Epoch: [4][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4446 Grad: 0.2712 LR: 0.00081  \n",
      "Epoch: [4][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4446 Grad: 0.2277 LR: 0.00081  \n",
      "Epoch: [4][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4446 Grad: 0.2763 LR: 0.00081  \n",
      "Epoch: [4][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4446 Grad: 0.3231 LR: 0.00081  \n",
      "Epoch: [4][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4446 Grad: 0.2103 LR: 0.00081  \n",
      "Epoch: [4][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4446 Grad: 0.2885 LR: 0.00081  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 29s) Loss avg.: 0.4262 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4484 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4483 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4486 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.4446  avg_val_loss: 0.4486  time: 1189s\n",
      "Epoch 4 - Accuracy: 0.8065818430909595\n",
      "Epoch 4 - Save Best Score: 0.8066 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/1929] Elapsed 0m 1s (remain 61m 54s) Loss avg.: 0.4210 Grad: 0.2014 LR: 0.00069  \n",
      "Epoch: [5][100/1929] Elapsed 1m 1s (remain 18m 38s) Loss avg.: 0.4393 Grad: 0.2184 LR: 0.00069  \n",
      "Epoch: [5][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4392 Grad: 0.2662 LR: 0.00069  \n",
      "Epoch: [5][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4388 Grad: 0.2086 LR: 0.00069  \n",
      "Epoch: [5][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4385 Grad: 0.2093 LR: 0.00069  \n",
      "Epoch: [5][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4384 Grad: 0.2382 LR: 0.00069  \n",
      "Epoch: [5][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4384 Grad: 0.2461 LR: 0.00069  \n",
      "Epoch: [5][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4387 Grad: 0.1902 LR: 0.00069  \n",
      "Epoch: [5][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4392 Grad: 0.2353 LR: 0.00069  \n",
      "Epoch: [5][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4392 Grad: 0.2084 LR: 0.00069  \n",
      "Epoch: [5][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4394 Grad: 0.2357 LR: 0.00069  \n",
      "Epoch: [5][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4394 Grad: 0.2269 LR: 0.00069  \n",
      "Epoch: [5][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4394 Grad: 0.2528 LR: 0.00069  \n",
      "Epoch: [5][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4394 Grad: 0.2212 LR: 0.00069  \n",
      "Epoch: [5][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4395 Grad: 0.1966 LR: 0.00069  \n",
      "Epoch: [5][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4395 Grad: 0.3098 LR: 0.00069  \n",
      "Epoch: [5][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4398 Grad: 0.2611 LR: 0.00069  \n",
      "Epoch: [5][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4398 Grad: 0.2061 LR: 0.00069  \n",
      "Epoch: [5][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4398 Grad: 0.1984 LR: 0.00069  \n",
      "Epoch: [5][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4398 Grad: 0.2290 LR: 0.00069  \n",
      "Epoch: [5][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4398 Grad: 0.2259 LR: 0.00069  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 32s) Loss avg.: 0.4195 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4448 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4451 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4454 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.4398  avg_val_loss: 0.4454  time: 1189s\n",
      "Epoch 5 - Accuracy: 0.8080713567399764\n",
      "Epoch 5 - Save Best Score: 0.8081 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/1929] Elapsed 0m 1s (remain 61m 24s) Loss avg.: 0.4383 Grad: 0.2092 LR: 0.00055  \n",
      "Epoch: [6][100/1929] Elapsed 1m 1s (remain 18m 34s) Loss avg.: 0.4367 Grad: 0.1976 LR: 0.00055  \n",
      "Epoch: [6][200/1929] Elapsed 2m 1s (remain 17m 22s) Loss avg.: 0.4358 Grad: 0.2336 LR: 0.00055  \n",
      "Epoch: [6][300/1929] Elapsed 3m 0s (remain 16m 17s) Loss avg.: 0.4352 Grad: 0.2374 LR: 0.00055  \n",
      "Epoch: [6][400/1929] Elapsed 4m 0s (remain 15m 16s) Loss avg.: 0.4352 Grad: 0.2375 LR: 0.00055  \n",
      "Epoch: [6][500/1929] Elapsed 5m 0s (remain 14m 15s) Loss avg.: 0.4349 Grad: 0.2950 LR: 0.00055  \n",
      "Epoch: [6][600/1929] Elapsed 5m 59s (remain 13m 14s) Loss avg.: 0.4349 Grad: 0.2350 LR: 0.00055  \n",
      "Epoch: [6][700/1929] Elapsed 6m 59s (remain 12m 14s) Loss avg.: 0.4349 Grad: 0.2424 LR: 0.00055  \n",
      "Epoch: [6][800/1929] Elapsed 7m 59s (remain 11m 14s) Loss avg.: 0.4349 Grad: 0.1953 LR: 0.00055  \n",
      "Epoch: [6][900/1929] Elapsed 8m 58s (remain 10m 14s) Loss avg.: 0.4350 Grad: 0.2189 LR: 0.00055  \n",
      "Epoch: [6][1000/1929] Elapsed 9m 58s (remain 9m 14s) Loss avg.: 0.4352 Grad: 0.2224 LR: 0.00055  \n",
      "Epoch: [6][1100/1929] Elapsed 10m 58s (remain 8m 14s) Loss avg.: 0.4353 Grad: 0.3445 LR: 0.00055  \n",
      "Epoch: [6][1200/1929] Elapsed 11m 57s (remain 7m 15s) Loss avg.: 0.4353 Grad: 0.1887 LR: 0.00055  \n",
      "Epoch: [6][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4352 Grad: 0.2056 LR: 0.00055  \n",
      "Epoch: [6][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4352 Grad: 0.1955 LR: 0.00055  \n",
      "Epoch: [6][1500/1929] Elapsed 14m 56s (remain 4m 15s) Loss avg.: 0.4354 Grad: 0.2436 LR: 0.00055  \n",
      "Epoch: [6][1600/1929] Elapsed 15m 56s (remain 3m 15s) Loss avg.: 0.4353 Grad: 0.2357 LR: 0.00055  \n",
      "Epoch: [6][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4354 Grad: 0.2220 LR: 0.00055  \n",
      "Epoch: [6][1800/1929] Elapsed 17m 55s (remain 1m 16s) Loss avg.: 0.4354 Grad: 0.2492 LR: 0.00055  \n",
      "Epoch: [6][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4355 Grad: 0.2186 LR: 0.00055  \n",
      "Epoch: [6][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4355 Grad: 0.2777 LR: 0.00055  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 32s) Loss avg.: 0.4196 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4425 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4427 \n",
      "Eval: [214/215] Elapsed 0m 34s (remain 0m 0s) Loss avg.: 0.4430 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.4355  avg_val_loss: 0.4430  time: 1188s\n",
      "Epoch 6 - Accuracy: 0.8093233060790229\n",
      "Epoch 6 - Save Best Score: 0.8093 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/1929] Elapsed 0m 1s (remain 61m 11s) Loss avg.: 0.4234 Grad: 0.2873 LR: 0.00041  \n",
      "Epoch: [7][100/1929] Elapsed 1m 1s (remain 18m 36s) Loss avg.: 0.4300 Grad: 0.2432 LR: 0.00041  \n",
      "Epoch: [7][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4298 Grad: 0.1963 LR: 0.00041  \n",
      "Epoch: [7][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4297 Grad: 0.2611 LR: 0.00041  \n",
      "Epoch: [7][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4303 Grad: 0.1887 LR: 0.00041  \n",
      "Epoch: [7][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4301 Grad: 0.1754 LR: 0.00041  \n",
      "Epoch: [7][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4302 Grad: 0.1958 LR: 0.00041  \n",
      "Epoch: [7][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4303 Grad: 0.2239 LR: 0.00041  \n",
      "Epoch: [7][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4305 Grad: 0.2598 LR: 0.00041  \n",
      "Epoch: [7][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4306 Grad: 0.2092 LR: 0.00041  \n",
      "Epoch: [7][1000/1929] Elapsed 9m 58s (remain 9m 14s) Loss avg.: 0.4307 Grad: 0.3062 LR: 0.00041  \n",
      "Epoch: [7][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4309 Grad: 0.2241 LR: 0.00041  \n",
      "Epoch: [7][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4310 Grad: 0.2410 LR: 0.00041  \n",
      "Epoch: [7][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4310 Grad: 0.2114 LR: 0.00041  \n",
      "Epoch: [7][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4311 Grad: 0.2187 LR: 0.00041  \n",
      "Epoch: [7][1500/1929] Elapsed 14m 56s (remain 4m 15s) Loss avg.: 0.4311 Grad: 0.2886 LR: 0.00041  \n",
      "Epoch: [7][1600/1929] Elapsed 15m 56s (remain 3m 15s) Loss avg.: 0.4312 Grad: 0.2369 LR: 0.00041  \n",
      "Epoch: [7][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4312 Grad: 0.2199 LR: 0.00041  \n",
      "Epoch: [7][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4313 Grad: 0.1928 LR: 0.00041  \n",
      "Epoch: [7][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4313 Grad: 0.2279 LR: 0.00041  \n",
      "Epoch: [7][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4313 Grad: 0.2729 LR: 0.00041  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 35s) Loss avg.: 0.4210 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4413 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4415 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4418 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.4313  avg_val_loss: 0.4418  time: 1188s\n",
      "Epoch 7 - Accuracy: 0.8095069447480798\n",
      "Epoch 7 - Save Best Score: 0.8095 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/1929] Elapsed 0m 1s (remain 62m 7s) Loss avg.: 0.4219 Grad: 0.2655 LR: 0.00029  \n",
      "Epoch: [8][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4278 Grad: 0.2337 LR: 0.00029  \n",
      "Epoch: [8][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4276 Grad: 0.2238 LR: 0.00029  \n",
      "Epoch: [8][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4266 Grad: 0.2057 LR: 0.00029  \n",
      "Epoch: [8][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4262 Grad: 0.2234 LR: 0.00029  \n",
      "Epoch: [8][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4261 Grad: 0.1954 LR: 0.00029  \n",
      "Epoch: [8][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4264 Grad: 0.2146 LR: 0.00029  \n",
      "Epoch: [8][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4264 Grad: 0.3155 LR: 0.00029  \n",
      "Epoch: [8][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4266 Grad: 0.2954 LR: 0.00029  \n",
      "Epoch: [8][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4266 Grad: 0.2034 LR: 0.00029  \n",
      "Epoch: [8][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4267 Grad: 0.2037 LR: 0.00029  \n",
      "Epoch: [8][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4267 Grad: 0.2304 LR: 0.00029  \n",
      "Epoch: [8][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4269 Grad: 0.2654 LR: 0.00029  \n",
      "Epoch: [8][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4269 Grad: 0.2470 LR: 0.00029  \n",
      "Epoch: [8][1400/1929] Elapsed 13m 58s (remain 5m 16s) Loss avg.: 0.4271 Grad: 0.2217 LR: 0.00029  \n",
      "Epoch: [8][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4270 Grad: 0.2275 LR: 0.00029  \n",
      "Epoch: [8][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4271 Grad: 0.1999 LR: 0.00029  \n",
      "Epoch: [8][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4271 Grad: 0.2430 LR: 0.00029  \n",
      "Epoch: [8][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4272 Grad: 0.1929 LR: 0.00029  \n",
      "Epoch: [8][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4273 Grad: 0.2148 LR: 0.00029  \n",
      "Epoch: [8][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4274 Grad: 0.2089 LR: 0.00029  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 34s) Loss avg.: 0.4190 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4397 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4399 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4401 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.4274  avg_val_loss: 0.4401  time: 1189s\n",
      "Epoch 8 - Accuracy: 0.8104965531313308\n",
      "Epoch 8 - Save Best Score: 0.8105 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/1929] Elapsed 0m 1s (remain 62m 4s) Loss avg.: 0.4427 Grad: 0.2789 LR: 0.00019  \n",
      "Epoch: [9][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4231 Grad: 0.2113 LR: 0.00019  \n",
      "Epoch: [9][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4229 Grad: 0.2125 LR: 0.00019  \n",
      "Epoch: [9][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4225 Grad: 0.2365 LR: 0.00019  \n",
      "Epoch: [9][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4226 Grad: 0.2511 LR: 0.00019  \n",
      "Epoch: [9][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4229 Grad: 0.2613 LR: 0.00019  \n",
      "Epoch: [9][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4233 Grad: 0.3050 LR: 0.00019  \n",
      "Epoch: [9][700/1929] Elapsed 7m 0s (remain 12m 15s) Loss avg.: 0.4236 Grad: 0.1965 LR: 0.00019  \n",
      "Epoch: [9][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4236 Grad: 0.2367 LR: 0.00019  \n",
      "Epoch: [9][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4237 Grad: 0.2290 LR: 0.00019  \n",
      "Epoch: [9][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4237 Grad: 0.2243 LR: 0.00019  \n",
      "Epoch: [9][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4237 Grad: 0.2845 LR: 0.00019  \n",
      "Epoch: [9][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4237 Grad: 0.2268 LR: 0.00019  \n",
      "Epoch: [9][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4238 Grad: 0.2205 LR: 0.00019  \n",
      "Epoch: [9][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4239 Grad: 0.2130 LR: 0.00019  \n",
      "Epoch: [9][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4240 Grad: 0.2600 LR: 0.00019  \n",
      "Epoch: [9][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4240 Grad: 0.2449 LR: 0.00019  \n",
      "Epoch: [9][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4241 Grad: 0.2202 LR: 0.00019  \n",
      "Epoch: [9][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4240 Grad: 0.2330 LR: 0.00019  \n",
      "Epoch: [9][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4240 Grad: 0.2325 LR: 0.00019  \n",
      "Epoch: [9][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4240 Grad: 0.2801 LR: 0.00019  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 33s) Loss avg.: 0.4181 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4376 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4378 \n",
      "Eval: [214/215] Elapsed 0m 34s (remain 0m 0s) Loss avg.: 0.4381 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.4240  avg_val_loss: 0.4381  time: 1188s\n",
      "Epoch 9 - Accuracy: 0.8113447888884031\n",
      "Epoch 9 - Save Best Score: 0.8113 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/1929] Elapsed 0m 2s (remain 65m 27s) Loss avg.: 0.4409 Grad: 0.2264 LR: 0.00012  \n",
      "Epoch: [10][100/1929] Elapsed 1m 1s (remain 18m 42s) Loss avg.: 0.4211 Grad: 0.2031 LR: 0.00012  \n",
      "Epoch: [10][200/1929] Elapsed 2m 1s (remain 17m 25s) Loss avg.: 0.4205 Grad: 0.2336 LR: 0.00012  \n",
      "Epoch: [10][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4210 Grad: 0.2344 LR: 0.00012  \n",
      "Epoch: [10][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4211 Grad: 0.2431 LR: 0.00012  \n",
      "Epoch: [10][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4209 Grad: 0.2242 LR: 0.00012  \n",
      "Epoch: [10][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4211 Grad: 0.2572 LR: 0.00012  \n",
      "Epoch: [10][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4213 Grad: 0.2452 LR: 0.00012  \n",
      "Epoch: [10][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4214 Grad: 0.2292 LR: 0.00012  \n",
      "Epoch: [10][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4214 Grad: 0.1952 LR: 0.00012  \n",
      "Epoch: [10][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4215 Grad: 0.2529 LR: 0.00012  \n",
      "Epoch: [10][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4214 Grad: 0.2182 LR: 0.00012  \n",
      "Epoch: [10][1200/1929] Elapsed 11m 59s (remain 7m 15s) Loss avg.: 0.4212 Grad: 0.2207 LR: 0.00012  \n",
      "Epoch: [10][1300/1929] Elapsed 12m 58s (remain 6m 16s) Loss avg.: 0.4212 Grad: 0.3063 LR: 0.00012  \n",
      "Epoch: [10][1400/1929] Elapsed 13m 58s (remain 5m 16s) Loss avg.: 0.4213 Grad: 0.2192 LR: 0.00012  \n",
      "Epoch: [10][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4213 Grad: 0.2445 LR: 0.00012  \n",
      "Epoch: [10][1600/1929] Elapsed 15m 58s (remain 3m 16s) Loss avg.: 0.4213 Grad: 0.2195 LR: 0.00012  \n",
      "Epoch: [10][1700/1929] Elapsed 16m 58s (remain 2m 16s) Loss avg.: 0.4213 Grad: 0.2219 LR: 0.00012  \n",
      "Epoch: [10][1800/1929] Elapsed 17m 58s (remain 1m 16s) Loss avg.: 0.4213 Grad: 0.2308 LR: 0.00012  \n",
      "Epoch: [10][1900/1929] Elapsed 18m 58s (remain 0m 16s) Loss avg.: 0.4214 Grad: 0.2409 LR: 0.00012  \n",
      "Epoch: [10][1928/1929] Elapsed 19m 14s (remain 0m 0s) Loss avg.: 0.4214 Grad: 0.2240 LR: 0.00012  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 29s) Loss avg.: 0.4171 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4374 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4376 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4378 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.4214  avg_val_loss: 0.4378  time: 1191s\n",
      "Epoch 10 - Accuracy: 0.8115940127964089\n",
      "Epoch 10 - Save Best Score: 0.8116 Model\n",
      "Epoch 10 - Save final model\n",
      "========== fold: 0 result ==========\n",
      "Score: 0.81159\n",
      "========== fold: 1 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load pre-train weight.\n",
      "Epoch: [1][0/1929] Elapsed 0m 2s (remain 65m 51s) Loss avg.: 1.3869 Grad: 0.3003 LR: 0.00100  \n",
      "Epoch: [1][100/1929] Elapsed 1m 1s (remain 18m 39s) Loss avg.: 0.6980 Grad: 0.8860 LR: 0.00100  \n",
      "Epoch: [1][200/1929] Elapsed 2m 1s (remain 17m 26s) Loss avg.: 0.6359 Grad: 0.4106 LR: 0.00100  \n",
      "Epoch: [1][300/1929] Elapsed 3m 1s (remain 16m 23s) Loss avg.: 0.6057 Grad: 0.7039 LR: 0.00100  \n",
      "Epoch: [1][400/1929] Elapsed 4m 1s (remain 15m 20s) Loss avg.: 0.5859 Grad: 0.8494 LR: 0.00100  \n",
      "Epoch: [1][500/1929] Elapsed 5m 1s (remain 14m 18s) Loss avg.: 0.5717 Grad: 0.5171 LR: 0.00100  \n",
      "Epoch: [1][600/1929] Elapsed 6m 1s (remain 13m 18s) Loss avg.: 0.5604 Grad: 0.4090 LR: 0.00100  \n",
      "Epoch: [1][700/1929] Elapsed 7m 1s (remain 12m 17s) Loss avg.: 0.5512 Grad: 0.4151 LR: 0.00100  \n",
      "Epoch: [1][800/1929] Elapsed 8m 0s (remain 11m 17s) Loss avg.: 0.5442 Grad: 0.5265 LR: 0.00100  \n",
      "Epoch: [1][900/1929] Elapsed 9m 0s (remain 10m 16s) Loss avg.: 0.5381 Grad: 0.6787 LR: 0.00100  \n",
      "Epoch: [1][1000/1929] Elapsed 10m 0s (remain 9m 16s) Loss avg.: 0.5328 Grad: 0.3488 LR: 0.00100  \n",
      "Epoch: [1][1100/1929] Elapsed 11m 0s (remain 8m 16s) Loss avg.: 0.5286 Grad: 0.3777 LR: 0.00100  \n",
      "Epoch: [1][1200/1929] Elapsed 12m 0s (remain 7m 16s) Loss avg.: 0.5247 Grad: 0.4435 LR: 0.00100  \n",
      "Epoch: [1][1300/1929] Elapsed 13m 0s (remain 6m 16s) Loss avg.: 0.5213 Grad: 0.4903 LR: 0.00100  \n",
      "Epoch: [1][1400/1929] Elapsed 13m 59s (remain 5m 16s) Loss avg.: 0.5181 Grad: 0.5756 LR: 0.00100  \n",
      "Epoch: [1][1500/1929] Elapsed 14m 59s (remain 4m 16s) Loss avg.: 0.5155 Grad: 0.5651 LR: 0.00100  \n",
      "Epoch: [1][1600/1929] Elapsed 15m 59s (remain 3m 16s) Loss avg.: 0.5130 Grad: 0.3594 LR: 0.00100  \n",
      "Epoch: [1][1700/1929] Elapsed 16m 59s (remain 2m 16s) Loss avg.: 0.5107 Grad: 0.5337 LR: 0.00100  \n",
      "Epoch: [1][1800/1929] Elapsed 17m 59s (remain 1m 16s) Loss avg.: 0.5087 Grad: 0.4025 LR: 0.00100  \n",
      "Epoch: [1][1900/1929] Elapsed 18m 59s (remain 0m 16s) Loss avg.: 0.5067 Grad: 0.4628 LR: 0.00100  \n",
      "Epoch: [1][1928/1929] Elapsed 19m 15s (remain 0m 0s) Loss avg.: 0.5062 Grad: 0.4065 LR: 0.00100  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 30s) Loss avg.: 0.4569 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4728 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4722 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4723 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.5062  avg_val_loss: 0.4723  time: 1192s\n",
      "Epoch 1 - Accuracy: 0.7949193301560928\n",
      "Epoch 1 - Save Best Score: 0.7949 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1929] Elapsed 0m 1s (remain 61m 23s) Loss avg.: 0.4560 Grad: 0.3711 LR: 0.00098  \n",
      "Epoch: [2][100/1929] Elapsed 1m 1s (remain 18m 36s) Loss avg.: 0.4678 Grad: 0.3413 LR: 0.00098  \n",
      "Epoch: [2][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4672 Grad: 0.3252 LR: 0.00098  \n",
      "Epoch: [2][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4666 Grad: 0.4059 LR: 0.00098  \n",
      "Epoch: [2][400/1929] Elapsed 4m 0s (remain 15m 18s) Loss avg.: 0.4663 Grad: 0.3320 LR: 0.00098  \n",
      "Epoch: [2][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4658 Grad: 0.3177 LR: 0.00098  \n",
      "Epoch: [2][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4658 Grad: 0.4430 LR: 0.00098  \n",
      "Epoch: [2][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4655 Grad: 0.4419 LR: 0.00098  \n",
      "Epoch: [2][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4653 Grad: 0.4068 LR: 0.00098  \n",
      "Epoch: [2][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4649 Grad: 0.3262 LR: 0.00098  \n",
      "Epoch: [2][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4645 Grad: 0.2368 LR: 0.00098  \n",
      "Epoch: [2][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4642 Grad: 0.4281 LR: 0.00098  \n",
      "Epoch: [2][1200/1929] Elapsed 11m 59s (remain 7m 16s) Loss avg.: 0.4640 Grad: 0.3745 LR: 0.00098  \n",
      "Epoch: [2][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.4637 Grad: 0.2879 LR: 0.00098  \n",
      "Epoch: [2][1400/1929] Elapsed 13m 58s (remain 5m 16s) Loss avg.: 0.4634 Grad: 0.4009 LR: 0.00098  \n",
      "Epoch: [2][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4631 Grad: 0.2658 LR: 0.00098  \n",
      "Epoch: [2][1600/1929] Elapsed 15m 58s (remain 3m 16s) Loss avg.: 0.4628 Grad: 0.3361 LR: 0.00098  \n",
      "Epoch: [2][1700/1929] Elapsed 16m 58s (remain 2m 16s) Loss avg.: 0.4627 Grad: 0.2440 LR: 0.00098  \n",
      "Epoch: [2][1800/1929] Elapsed 17m 58s (remain 1m 16s) Loss avg.: 0.4623 Grad: 0.3535 LR: 0.00098  \n",
      "Epoch: [2][1900/1929] Elapsed 18m 58s (remain 0m 16s) Loss avg.: 0.4621 Grad: 0.3603 LR: 0.00098  \n",
      "Epoch: [2][1928/1929] Elapsed 19m 14s (remain 0m 0s) Loss avg.: 0.4620 Grad: 0.3554 LR: 0.00098  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 59s) Loss avg.: 0.4437 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4568 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4562 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4563 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4620  avg_val_loss: 0.4563  time: 1191s\n",
      "Epoch 2 - Accuracy: 0.8037573054668941\n",
      "Epoch 2 - Save Best Score: 0.8038 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1929] Elapsed 0m 1s (remain 60m 59s) Loss avg.: 0.4599 Grad: 0.2636 LR: 0.00091  \n",
      "Epoch: [3][100/1929] Elapsed 1m 1s (remain 18m 38s) Loss avg.: 0.4525 Grad: 0.2602 LR: 0.00091  \n",
      "Epoch: [3][200/1929] Elapsed 2m 1s (remain 17m 26s) Loss avg.: 0.4529 Grad: 0.2537 LR: 0.00091  \n",
      "Epoch: [3][300/1929] Elapsed 3m 1s (remain 16m 22s) Loss avg.: 0.4534 Grad: 0.2466 LR: 0.00091  \n",
      "Epoch: [3][400/1929] Elapsed 4m 1s (remain 15m 19s) Loss avg.: 0.4533 Grad: 0.4052 LR: 0.00091  \n",
      "Epoch: [3][500/1929] Elapsed 5m 1s (remain 14m 18s) Loss avg.: 0.4533 Grad: 0.2602 LR: 0.00091  \n",
      "Epoch: [3][600/1929] Elapsed 6m 1s (remain 13m 18s) Loss avg.: 0.4533 Grad: 0.2338 LR: 0.00091  \n",
      "Epoch: [3][700/1929] Elapsed 7m 1s (remain 12m 17s) Loss avg.: 0.4532 Grad: 0.2247 LR: 0.00091  \n",
      "Epoch: [3][800/1929] Elapsed 8m 0s (remain 11m 17s) Loss avg.: 0.4530 Grad: 0.3154 LR: 0.00091  \n",
      "Epoch: [3][900/1929] Elapsed 9m 0s (remain 10m 16s) Loss avg.: 0.4530 Grad: 0.4163 LR: 0.00091  \n",
      "Epoch: [3][1000/1929] Elapsed 10m 0s (remain 9m 16s) Loss avg.: 0.4530 Grad: 0.2360 LR: 0.00091  \n",
      "Epoch: [3][1100/1929] Elapsed 11m 0s (remain 8m 16s) Loss avg.: 0.4530 Grad: 0.2606 LR: 0.00091  \n",
      "Epoch: [3][1200/1929] Elapsed 12m 0s (remain 7m 16s) Loss avg.: 0.4529 Grad: 0.3671 LR: 0.00091  \n",
      "Epoch: [3][1300/1929] Elapsed 13m 0s (remain 6m 16s) Loss avg.: 0.4529 Grad: 0.3136 LR: 0.00091  \n",
      "Epoch: [3][1400/1929] Elapsed 14m 0s (remain 5m 16s) Loss avg.: 0.4527 Grad: 0.2128 LR: 0.00091  \n",
      "Epoch: [3][1500/1929] Elapsed 14m 59s (remain 4m 16s) Loss avg.: 0.4526 Grad: 0.3761 LR: 0.00091  \n",
      "Epoch: [3][1600/1929] Elapsed 15m 59s (remain 3m 16s) Loss avg.: 0.4524 Grad: 0.2949 LR: 0.00091  \n",
      "Epoch: [3][1700/1929] Elapsed 16m 59s (remain 2m 16s) Loss avg.: 0.4524 Grad: 0.3395 LR: 0.00091  \n",
      "Epoch: [3][1800/1929] Elapsed 17m 59s (remain 1m 16s) Loss avg.: 0.4523 Grad: 0.2963 LR: 0.00091  \n",
      "Epoch: [3][1900/1929] Elapsed 18m 59s (remain 0m 16s) Loss avg.: 0.4522 Grad: 0.2082 LR: 0.00091  \n",
      "Epoch: [3][1928/1929] Elapsed 19m 15s (remain 0m 0s) Loss avg.: 0.4521 Grad: 0.2399 LR: 0.00091  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 29s) Loss avg.: 0.4360 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4544 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4542 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4543 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.4521  avg_val_loss: 0.4543  time: 1192s\n",
      "Epoch 3 - Accuracy: 0.8041726786469037\n",
      "Epoch 3 - Save Best Score: 0.8042 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/1929] Elapsed 0m 1s (remain 60m 23s) Loss avg.: 0.4429 Grad: 0.2705 LR: 0.00081  \n",
      "Epoch: [4][100/1929] Elapsed 1m 1s (remain 18m 36s) Loss avg.: 0.4456 Grad: 0.2432 LR: 0.00081  \n",
      "Epoch: [4][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4460 Grad: 0.2578 LR: 0.00081  \n",
      "Epoch: [4][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4461 Grad: 0.2875 LR: 0.00081  \n",
      "Epoch: [4][400/1929] Elapsed 4m 1s (remain 15m 18s) Loss avg.: 0.4459 Grad: 0.2552 LR: 0.00081  \n",
      "Epoch: [4][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4465 Grad: 0.3055 LR: 0.00081  \n",
      "Epoch: [4][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4464 Grad: 0.2168 LR: 0.00081  \n",
      "Epoch: [4][700/1929] Elapsed 7m 0s (remain 12m 17s) Loss avg.: 0.4461 Grad: 0.2015 LR: 0.00081  \n",
      "Epoch: [4][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4462 Grad: 0.2521 LR: 0.00081  \n",
      "Epoch: [4][900/1929] Elapsed 9m 0s (remain 10m 16s) Loss avg.: 0.4460 Grad: 0.2570 LR: 0.00081  \n",
      "Epoch: [4][1000/1929] Elapsed 10m 0s (remain 9m 16s) Loss avg.: 0.4459 Grad: 0.3160 LR: 0.00081  \n",
      "Epoch: [4][1100/1929] Elapsed 11m 0s (remain 8m 16s) Loss avg.: 0.4458 Grad: 0.1945 LR: 0.00081  \n",
      "Epoch: [4][1200/1929] Elapsed 11m 59s (remain 7m 16s) Loss avg.: 0.4457 Grad: 0.2982 LR: 0.00081  \n",
      "Epoch: [4][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.4459 Grad: 0.2672 LR: 0.00081  \n",
      "Epoch: [4][1400/1929] Elapsed 13m 59s (remain 5m 16s) Loss avg.: 0.4458 Grad: 0.3454 LR: 0.00081  \n",
      "Epoch: [4][1500/1929] Elapsed 14m 59s (remain 4m 16s) Loss avg.: 0.4459 Grad: 0.4018 LR: 0.00081  \n",
      "Epoch: [4][1600/1929] Elapsed 15m 59s (remain 3m 16s) Loss avg.: 0.4460 Grad: 0.2156 LR: 0.00081  \n",
      "Epoch: [4][1700/1929] Elapsed 16m 59s (remain 2m 16s) Loss avg.: 0.4460 Grad: 0.2201 LR: 0.00081  \n",
      "Epoch: [4][1800/1929] Elapsed 17m 59s (remain 1m 16s) Loss avg.: 0.4459 Grad: 0.2150 LR: 0.00081  \n",
      "Epoch: [4][1900/1929] Elapsed 18m 58s (remain 0m 16s) Loss avg.: 0.4458 Grad: 0.2517 LR: 0.00081  \n",
      "Epoch: [4][1928/1929] Elapsed 19m 15s (remain 0m 0s) Loss avg.: 0.4458 Grad: 0.2051 LR: 0.00081  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 29s) Loss avg.: 0.4378 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4495 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4493 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4495 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.4458  avg_val_loss: 0.4495  time: 1191s\n",
      "Epoch 4 - Accuracy: 0.806899567137423\n",
      "Epoch 4 - Save Best Score: 0.8069 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/1929] Elapsed 0m 2s (remain 64m 51s) Loss avg.: 0.4253 Grad: 0.3395 LR: 0.00069  \n",
      "Epoch: [5][100/1929] Elapsed 1m 2s (remain 18m 43s) Loss avg.: 0.4394 Grad: 0.2847 LR: 0.00069  \n",
      "Epoch: [5][200/1929] Elapsed 2m 1s (remain 17m 28s) Loss avg.: 0.4400 Grad: 0.2470 LR: 0.00069  \n",
      "Epoch: [5][300/1929] Elapsed 3m 1s (remain 16m 22s) Loss avg.: 0.4397 Grad: 0.1891 LR: 0.00069  \n",
      "Epoch: [5][400/1929] Elapsed 4m 1s (remain 15m 19s) Loss avg.: 0.4406 Grad: 0.2821 LR: 0.00069  \n",
      "Epoch: [5][500/1929] Elapsed 5m 1s (remain 14m 18s) Loss avg.: 0.4406 Grad: 0.2125 LR: 0.00069  \n",
      "Epoch: [5][600/1929] Elapsed 6m 0s (remain 13m 17s) Loss avg.: 0.4405 Grad: 0.1997 LR: 0.00069  \n",
      "Epoch: [5][700/1929] Elapsed 7m 0s (remain 12m 17s) Loss avg.: 0.4405 Grad: 0.3826 LR: 0.00069  \n",
      "Epoch: [5][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4407 Grad: 0.2437 LR: 0.00069  \n",
      "Epoch: [5][900/1929] Elapsed 9m 0s (remain 10m 16s) Loss avg.: 0.4408 Grad: 0.2982 LR: 0.00069  \n",
      "Epoch: [5][1000/1929] Elapsed 10m 0s (remain 9m 16s) Loss avg.: 0.4408 Grad: 0.2341 LR: 0.00069  \n",
      "Epoch: [5][1100/1929] Elapsed 11m 0s (remain 8m 16s) Loss avg.: 0.4410 Grad: 0.1844 LR: 0.00069  \n",
      "Epoch: [5][1200/1929] Elapsed 11m 59s (remain 7m 16s) Loss avg.: 0.4409 Grad: 0.2525 LR: 0.00069  \n",
      "Epoch: [5][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.4409 Grad: 0.2004 LR: 0.00069  \n",
      "Epoch: [5][1400/1929] Elapsed 13m 59s (remain 5m 16s) Loss avg.: 0.4408 Grad: 0.2653 LR: 0.00069  \n",
      "Epoch: [5][1500/1929] Elapsed 14m 59s (remain 4m 16s) Loss avg.: 0.4408 Grad: 0.1807 LR: 0.00069  \n",
      "Epoch: [5][1600/1929] Elapsed 15m 59s (remain 3m 16s) Loss avg.: 0.4407 Grad: 0.1846 LR: 0.00069  \n",
      "Epoch: [5][1700/1929] Elapsed 16m 59s (remain 2m 16s) Loss avg.: 0.4408 Grad: 0.2067 LR: 0.00069  \n",
      "Epoch: [5][1800/1929] Elapsed 17m 59s (remain 1m 16s) Loss avg.: 0.4407 Grad: 0.2436 LR: 0.00069  \n",
      "Epoch: [5][1900/1929] Elapsed 18m 58s (remain 0m 16s) Loss avg.: 0.4409 Grad: 0.2067 LR: 0.00069  \n",
      "Epoch: [5][1928/1929] Elapsed 19m 15s (remain 0m 0s) Loss avg.: 0.4409 Grad: 0.1997 LR: 0.00069  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 25s) Loss avg.: 0.4297 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4453 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4448 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4449 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.4409  avg_val_loss: 0.4449  time: 1191s\n",
      "Epoch 5 - Accuracy: 0.8088219433635025\n",
      "Epoch 5 - Save Best Score: 0.8088 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/1929] Elapsed 0m 1s (remain 60m 48s) Loss avg.: 0.4311 Grad: 0.2242 LR: 0.00055  \n",
      "Epoch: [6][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4366 Grad: 0.2381 LR: 0.00055  \n",
      "Epoch: [6][200/1929] Elapsed 2m 1s (remain 17m 25s) Loss avg.: 0.4362 Grad: 0.2251 LR: 0.00055  \n",
      "Epoch: [6][300/1929] Elapsed 3m 1s (remain 16m 22s) Loss avg.: 0.4356 Grad: 0.2337 LR: 0.00055  \n",
      "Epoch: [6][400/1929] Elapsed 4m 1s (remain 15m 20s) Loss avg.: 0.4354 Grad: 0.2343 LR: 0.00055  \n",
      "Epoch: [6][500/1929] Elapsed 5m 1s (remain 14m 18s) Loss avg.: 0.4352 Grad: 0.2299 LR: 0.00055  \n",
      "Epoch: [6][600/1929] Elapsed 6m 1s (remain 13m 17s) Loss avg.: 0.4353 Grad: 0.1862 LR: 0.00055  \n",
      "Epoch: [6][700/1929] Elapsed 7m 0s (remain 12m 17s) Loss avg.: 0.4356 Grad: 0.1967 LR: 0.00055  \n",
      "Epoch: [6][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4358 Grad: 0.1828 LR: 0.00055  \n",
      "Epoch: [6][900/1929] Elapsed 9m 0s (remain 10m 16s) Loss avg.: 0.4360 Grad: 0.2600 LR: 0.00055  \n",
      "Epoch: [6][1000/1929] Elapsed 10m 0s (remain 9m 16s) Loss avg.: 0.4361 Grad: 0.1766 LR: 0.00055  \n",
      "Epoch: [6][1100/1929] Elapsed 11m 0s (remain 8m 16s) Loss avg.: 0.4361 Grad: 0.1877 LR: 0.00055  \n",
      "Epoch: [6][1200/1929] Elapsed 12m 0s (remain 7m 16s) Loss avg.: 0.4362 Grad: 0.2248 LR: 0.00055  \n",
      "Epoch: [6][1300/1929] Elapsed 13m 0s (remain 6m 16s) Loss avg.: 0.4362 Grad: 0.2360 LR: 0.00055  \n",
      "Epoch: [6][1400/1929] Elapsed 13m 59s (remain 5m 16s) Loss avg.: 0.4362 Grad: 0.1933 LR: 0.00055  \n",
      "Epoch: [6][1500/1929] Elapsed 14m 59s (remain 4m 16s) Loss avg.: 0.4363 Grad: 0.2143 LR: 0.00055  \n",
      "Epoch: [6][1600/1929] Elapsed 15m 59s (remain 3m 16s) Loss avg.: 0.4364 Grad: 0.1861 LR: 0.00055  \n",
      "Epoch: [6][1700/1929] Elapsed 16m 59s (remain 2m 16s) Loss avg.: 0.4364 Grad: 0.2023 LR: 0.00055  \n",
      "Epoch: [6][1800/1929] Elapsed 17m 59s (remain 1m 16s) Loss avg.: 0.4364 Grad: 0.2317 LR: 0.00055  \n",
      "Epoch: [6][1900/1929] Elapsed 18m 59s (remain 0m 16s) Loss avg.: 0.4365 Grad: 0.2142 LR: 0.00055  \n",
      "Epoch: [6][1928/1929] Elapsed 19m 15s (remain 0m 0s) Loss avg.: 0.4365 Grad: 0.1916 LR: 0.00055  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 28s) Loss avg.: 0.4301 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4421 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4420 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4421 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.4365  avg_val_loss: 0.4421  time: 1192s\n",
      "Epoch 6 - Accuracy: 0.80988296678472\n",
      "Epoch 6 - Save Best Score: 0.8099 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/1929] Elapsed 0m 1s (remain 60m 49s) Loss avg.: 0.4459 Grad: 0.2019 LR: 0.00041  \n",
      "Epoch: [7][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4334 Grad: 0.2152 LR: 0.00041  \n",
      "Epoch: [7][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4317 Grad: 0.2140 LR: 0.00041  \n",
      "Epoch: [7][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4316 Grad: 0.2248 LR: 0.00041  \n",
      "Epoch: [7][400/1929] Elapsed 4m 1s (remain 15m 19s) Loss avg.: 0.4314 Grad: 0.2858 LR: 0.00041  \n",
      "Epoch: [7][500/1929] Elapsed 5m 1s (remain 14m 18s) Loss avg.: 0.4318 Grad: 0.2242 LR: 0.00041  \n",
      "Epoch: [7][600/1929] Elapsed 6m 0s (remain 13m 17s) Loss avg.: 0.4315 Grad: 0.1895 LR: 0.00041  \n",
      "Epoch: [7][700/1929] Elapsed 7m 0s (remain 12m 17s) Loss avg.: 0.4315 Grad: 0.2187 LR: 0.00041  \n",
      "Epoch: [7][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4316 Grad: 0.2254 LR: 0.00041  \n",
      "Epoch: [7][900/1929] Elapsed 9m 0s (remain 10m 16s) Loss avg.: 0.4318 Grad: 0.2874 LR: 0.00041  \n",
      "Epoch: [7][1000/1929] Elapsed 10m 0s (remain 9m 16s) Loss avg.: 0.4319 Grad: 0.2101 LR: 0.00041  \n",
      "Epoch: [7][1100/1929] Elapsed 11m 0s (remain 8m 16s) Loss avg.: 0.4319 Grad: 0.2074 LR: 0.00041  \n",
      "Epoch: [7][1200/1929] Elapsed 12m 0s (remain 7m 16s) Loss avg.: 0.4320 Grad: 0.1893 LR: 0.00041  \n",
      "Epoch: [7][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.4321 Grad: 0.2194 LR: 0.00041  \n",
      "Epoch: [7][1400/1929] Elapsed 13m 59s (remain 5m 16s) Loss avg.: 0.4321 Grad: 0.1971 LR: 0.00041  \n",
      "Epoch: [7][1500/1929] Elapsed 14m 59s (remain 4m 16s) Loss avg.: 0.4321 Grad: 0.2468 LR: 0.00041  \n",
      "Epoch: [7][1600/1929] Elapsed 15m 59s (remain 3m 16s) Loss avg.: 0.4322 Grad: 0.1931 LR: 0.00041  \n",
      "Epoch: [7][1700/1929] Elapsed 16m 59s (remain 2m 16s) Loss avg.: 0.4322 Grad: 0.2501 LR: 0.00041  \n",
      "Epoch: [7][1800/1929] Elapsed 17m 59s (remain 1m 16s) Loss avg.: 0.4323 Grad: 0.1969 LR: 0.00041  \n",
      "Epoch: [7][1900/1929] Elapsed 18m 59s (remain 0m 16s) Loss avg.: 0.4323 Grad: 0.1791 LR: 0.00041  \n",
      "Epoch: [7][1928/1929] Elapsed 19m 15s (remain 0m 0s) Loss avg.: 0.4323 Grad: 0.2180 LR: 0.00041  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 28s) Loss avg.: 0.4314 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4421 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4416 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4417 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.4323  avg_val_loss: 0.4417  time: 1192s\n",
      "Epoch 7 - Accuracy: 0.8101278183434626\n",
      "Epoch 7 - Save Best Score: 0.8101 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/1929] Elapsed 0m 1s (remain 61m 13s) Loss avg.: 0.4325 Grad: 0.2310 LR: 0.00029  \n",
      "Epoch: [8][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4272 Grad: 0.2521 LR: 0.00029  \n",
      "Epoch: [8][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4277 Grad: 0.2314 LR: 0.00029  \n",
      "Epoch: [8][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4280 Grad: 0.2190 LR: 0.00029  \n",
      "Epoch: [8][400/1929] Elapsed 4m 1s (remain 15m 18s) Loss avg.: 0.4280 Grad: 0.2500 LR: 0.00029  \n",
      "Epoch: [8][500/1929] Elapsed 5m 1s (remain 14m 18s) Loss avg.: 0.4278 Grad: 0.2763 LR: 0.00029  \n",
      "Epoch: [8][600/1929] Elapsed 6m 0s (remain 13m 17s) Loss avg.: 0.4278 Grad: 0.2039 LR: 0.00029  \n",
      "Epoch: [8][700/1929] Elapsed 7m 0s (remain 12m 17s) Loss avg.: 0.4277 Grad: 0.2580 LR: 0.00029  \n",
      "Epoch: [8][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4279 Grad: 0.2383 LR: 0.00029  \n",
      "Epoch: [8][900/1929] Elapsed 9m 0s (remain 10m 16s) Loss avg.: 0.4280 Grad: 0.2198 LR: 0.00029  \n",
      "Epoch: [8][1000/1929] Elapsed 10m 0s (remain 9m 16s) Loss avg.: 0.4279 Grad: 0.2193 LR: 0.00029  \n",
      "Epoch: [8][1100/1929] Elapsed 10m 59s (remain 8m 16s) Loss avg.: 0.4279 Grad: 0.2064 LR: 0.00029  \n",
      "Epoch: [8][1200/1929] Elapsed 11m 59s (remain 7m 16s) Loss avg.: 0.4280 Grad: 0.3528 LR: 0.00029  \n",
      "Epoch: [8][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.4282 Grad: 0.1887 LR: 0.00029  \n",
      "Epoch: [8][1400/1929] Elapsed 13m 59s (remain 5m 16s) Loss avg.: 0.4281 Grad: 0.2115 LR: 0.00029  \n",
      "Epoch: [8][1500/1929] Elapsed 14m 59s (remain 4m 16s) Loss avg.: 0.4281 Grad: 0.2109 LR: 0.00029  \n",
      "Epoch: [8][1600/1929] Elapsed 15m 59s (remain 3m 16s) Loss avg.: 0.4282 Grad: 0.2213 LR: 0.00029  \n",
      "Epoch: [8][1700/1929] Elapsed 16m 59s (remain 2m 16s) Loss avg.: 0.4282 Grad: 0.2041 LR: 0.00029  \n",
      "Epoch: [8][1800/1929] Elapsed 17m 59s (remain 1m 16s) Loss avg.: 0.4282 Grad: 0.2526 LR: 0.00029  \n",
      "Epoch: [8][1900/1929] Elapsed 18m 58s (remain 0m 16s) Loss avg.: 0.4283 Grad: 0.2211 LR: 0.00029  \n",
      "Epoch: [8][1928/1929] Elapsed 19m 15s (remain 0m 0s) Loss avg.: 0.4283 Grad: 0.2684 LR: 0.00029  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 4m 33s) Loss avg.: 0.4299 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4399 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4398 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4398 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.4283  avg_val_loss: 0.4398  time: 1192s\n",
      "Epoch 8 - Accuracy: 0.811101394779415\n",
      "Epoch 8 - Save Best Score: 0.8111 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/1929] Elapsed 0m 1s (remain 61m 11s) Loss avg.: 0.4329 Grad: 0.2296 LR: 0.00019  \n",
      "Epoch: [9][100/1929] Elapsed 1m 1s (remain 18m 38s) Loss avg.: 0.4232 Grad: 0.2926 LR: 0.00019  \n",
      "Epoch: [9][200/1929] Elapsed 2m 1s (remain 17m 25s) Loss avg.: 0.4237 Grad: 0.2409 LR: 0.00019  \n",
      "Epoch: [9][300/1929] Elapsed 3m 1s (remain 16m 21s) Loss avg.: 0.4235 Grad: 0.2441 LR: 0.00019  \n",
      "Epoch: [9][400/1929] Elapsed 4m 1s (remain 15m 19s) Loss avg.: 0.4238 Grad: 0.2270 LR: 0.00019  \n",
      "Epoch: [9][500/1929] Elapsed 5m 1s (remain 14m 18s) Loss avg.: 0.4242 Grad: 0.2186 LR: 0.00019  \n",
      "Epoch: [9][600/1929] Elapsed 6m 0s (remain 13m 17s) Loss avg.: 0.4241 Grad: 0.2221 LR: 0.00019  \n",
      "Epoch: [9][700/1929] Elapsed 7m 0s (remain 12m 17s) Loss avg.: 0.4242 Grad: 0.2704 LR: 0.00019  \n",
      "Epoch: [9][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4243 Grad: 0.2119 LR: 0.00019  \n",
      "Epoch: [9][900/1929] Elapsed 9m 0s (remain 10m 16s) Loss avg.: 0.4245 Grad: 0.2131 LR: 0.00019  \n",
      "Epoch: [9][1000/1929] Elapsed 10m 0s (remain 9m 16s) Loss avg.: 0.4243 Grad: 0.2372 LR: 0.00019  \n",
      "Epoch: [9][1100/1929] Elapsed 10m 59s (remain 8m 16s) Loss avg.: 0.4243 Grad: 0.2342 LR: 0.00019  \n",
      "Epoch: [9][1200/1929] Elapsed 11m 59s (remain 7m 16s) Loss avg.: 0.4247 Grad: 0.2388 LR: 0.00019  \n",
      "Epoch: [9][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.4246 Grad: 0.1968 LR: 0.00019  \n",
      "Epoch: [9][1400/1929] Elapsed 13m 59s (remain 5m 16s) Loss avg.: 0.4246 Grad: 0.2252 LR: 0.00019  \n",
      "Epoch: [9][1500/1929] Elapsed 14m 59s (remain 4m 16s) Loss avg.: 0.4247 Grad: 0.2331 LR: 0.00019  \n",
      "Epoch: [9][1600/1929] Elapsed 15m 58s (remain 3m 16s) Loss avg.: 0.4247 Grad: 0.2000 LR: 0.00019  \n",
      "Epoch: [9][1700/1929] Elapsed 16m 58s (remain 2m 16s) Loss avg.: 0.4246 Grad: 0.2396 LR: 0.00019  \n",
      "Epoch: [9][1800/1929] Elapsed 17m 58s (remain 1m 16s) Loss avg.: 0.4248 Grad: 0.2080 LR: 0.00019  \n",
      "Epoch: [9][1900/1929] Elapsed 18m 58s (remain 0m 16s) Loss avg.: 0.4248 Grad: 0.2428 LR: 0.00019  \n",
      "Epoch: [9][1928/1929] Elapsed 19m 14s (remain 0m 0s) Loss avg.: 0.4249 Grad: 0.2306 LR: 0.00019  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 29s) Loss avg.: 0.4282 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4387 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4385 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4386 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.4249  avg_val_loss: 0.4386  time: 1191s\n",
      "Epoch 9 - Accuracy: 0.8118199175083439\n",
      "Epoch 9 - Save Best Score: 0.8118 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/1929] Elapsed 0m 2s (remain 65m 23s) Loss avg.: 0.4222 Grad: 0.2594 LR: 0.00012  \n",
      "Epoch: [10][100/1929] Elapsed 1m 2s (remain 18m 44s) Loss avg.: 0.4217 Grad: 0.2038 LR: 0.00012  \n",
      "Epoch: [10][200/1929] Elapsed 2m 1s (remain 17m 28s) Loss avg.: 0.4221 Grad: 0.2503 LR: 0.00012  \n",
      "Epoch: [10][300/1929] Elapsed 3m 1s (remain 16m 23s) Loss avg.: 0.4221 Grad: 0.2734 LR: 0.00012  \n",
      "Epoch: [10][400/1929] Elapsed 4m 1s (remain 15m 20s) Loss avg.: 0.4224 Grad: 0.2295 LR: 0.00012  \n",
      "Epoch: [10][500/1929] Elapsed 5m 1s (remain 14m 19s) Loss avg.: 0.4224 Grad: 0.2464 LR: 0.00012  \n",
      "Epoch: [10][600/1929] Elapsed 6m 1s (remain 13m 18s) Loss avg.: 0.4221 Grad: 0.2373 LR: 0.00012  \n",
      "Epoch: [10][700/1929] Elapsed 7m 1s (remain 12m 17s) Loss avg.: 0.4219 Grad: 0.2260 LR: 0.00012  \n",
      "Epoch: [10][800/1929] Elapsed 8m 1s (remain 11m 17s) Loss avg.: 0.4220 Grad: 0.2484 LR: 0.00012  \n",
      "Epoch: [10][900/1929] Elapsed 9m 0s (remain 10m 17s) Loss avg.: 0.4221 Grad: 0.2325 LR: 0.00012  \n",
      "Epoch: [10][1000/1929] Elapsed 10m 0s (remain 9m 16s) Loss avg.: 0.4221 Grad: 0.2397 LR: 0.00012  \n",
      "Epoch: [10][1100/1929] Elapsed 11m 0s (remain 8m 16s) Loss avg.: 0.4220 Grad: 0.2280 LR: 0.00012  \n",
      "Epoch: [10][1200/1929] Elapsed 12m 0s (remain 7m 16s) Loss avg.: 0.4220 Grad: 0.2198 LR: 0.00012  \n",
      "Epoch: [10][1300/1929] Elapsed 13m 0s (remain 6m 16s) Loss avg.: 0.4221 Grad: 0.2181 LR: 0.00012  \n",
      "Epoch: [10][1400/1929] Elapsed 14m 0s (remain 5m 16s) Loss avg.: 0.4222 Grad: 0.3192 LR: 0.00012  \n",
      "Epoch: [10][1500/1929] Elapsed 14m 59s (remain 4m 16s) Loss avg.: 0.4222 Grad: 0.2342 LR: 0.00012  \n",
      "Epoch: [10][1600/1929] Elapsed 16m 0s (remain 3m 16s) Loss avg.: 0.4222 Grad: 0.2582 LR: 0.00012  \n",
      "Epoch: [10][1700/1929] Elapsed 16m 59s (remain 2m 16s) Loss avg.: 0.4223 Grad: 0.2891 LR: 0.00012  \n",
      "Epoch: [10][1800/1929] Elapsed 17m 59s (remain 1m 16s) Loss avg.: 0.4223 Grad: 0.2385 LR: 0.00012  \n",
      "Epoch: [10][1900/1929] Elapsed 18m 59s (remain 0m 16s) Loss avg.: 0.4222 Grad: 0.3108 LR: 0.00012  \n",
      "Epoch: [10][1928/1929] Elapsed 19m 16s (remain 0m 0s) Loss avg.: 0.4222 Grad: 0.2742 LR: 0.00012  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 30s) Loss avg.: 0.4264 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4381 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4377 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4378 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.4222  avg_val_loss: 0.4378  time: 1192s\n",
      "Epoch 10 - Accuracy: 0.8122178012913005\n",
      "Epoch 10 - Save Best Score: 0.8122 Model\n",
      "Epoch 10 - Save final model\n",
      "========== fold: 1 result ==========\n",
      "Score: 0.81222\n",
      "========== fold: 2 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load pre-train weight.\n",
      "Epoch: [1][0/1929] Elapsed 0m 2s (remain 64m 54s) Loss avg.: 1.3959 Grad: 0.3511 LR: 0.00100  \n",
      "Epoch: [1][100/1929] Elapsed 1m 1s (remain 18m 38s) Loss avg.: 0.6997 Grad: 0.5567 LR: 0.00100  \n",
      "Epoch: [1][200/1929] Elapsed 2m 1s (remain 17m 27s) Loss avg.: 0.6347 Grad: 0.4003 LR: 0.00100  \n",
      "Epoch: [1][300/1929] Elapsed 3m 1s (remain 16m 22s) Loss avg.: 0.6027 Grad: 0.5110 LR: 0.00100  \n",
      "Epoch: [1][400/1929] Elapsed 4m 1s (remain 15m 20s) Loss avg.: 0.5820 Grad: 0.5164 LR: 0.00100  \n",
      "Epoch: [1][500/1929] Elapsed 5m 1s (remain 14m 18s) Loss avg.: 0.5677 Grad: 0.7972 LR: 0.00100  \n",
      "Epoch: [1][600/1929] Elapsed 6m 1s (remain 13m 17s) Loss avg.: 0.5568 Grad: 0.5677 LR: 0.00100  \n",
      "Epoch: [1][700/1929] Elapsed 7m 0s (remain 12m 17s) Loss avg.: 0.5482 Grad: 0.5420 LR: 0.00100  \n",
      "Epoch: [1][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.5411 Grad: 0.4672 LR: 0.00100  \n",
      "Epoch: [1][900/1929] Elapsed 9m 0s (remain 10m 16s) Loss avg.: 0.5351 Grad: 0.4059 LR: 0.00100  \n",
      "Epoch: [1][1000/1929] Elapsed 10m 0s (remain 9m 16s) Loss avg.: 0.5300 Grad: 0.3983 LR: 0.00100  \n",
      "Epoch: [1][1100/1929] Elapsed 11m 0s (remain 8m 16s) Loss avg.: 0.5257 Grad: 0.4773 LR: 0.00100  \n",
      "Epoch: [1][1200/1929] Elapsed 12m 0s (remain 7m 16s) Loss avg.: 0.5218 Grad: 0.5218 LR: 0.00100  \n",
      "Epoch: [1][1300/1929] Elapsed 13m 0s (remain 6m 16s) Loss avg.: 0.5183 Grad: 0.3427 LR: 0.00100  \n",
      "Epoch: [1][1400/1929] Elapsed 13m 59s (remain 5m 16s) Loss avg.: 0.5152 Grad: 0.3582 LR: 0.00100  \n",
      "Epoch: [1][1500/1929] Elapsed 14m 59s (remain 4m 16s) Loss avg.: 0.5125 Grad: 0.3769 LR: 0.00100  \n",
      "Epoch: [1][1600/1929] Elapsed 15m 59s (remain 3m 16s) Loss avg.: 0.5101 Grad: 0.3661 LR: 0.00100  \n",
      "Epoch: [1][1700/1929] Elapsed 16m 59s (remain 2m 16s) Loss avg.: 0.5078 Grad: 0.3959 LR: 0.00100  \n",
      "Epoch: [1][1800/1929] Elapsed 17m 59s (remain 1m 16s) Loss avg.: 0.5057 Grad: 0.3467 LR: 0.00100  \n",
      "Epoch: [1][1900/1929] Elapsed 18m 59s (remain 0m 16s) Loss avg.: 0.5037 Grad: 0.4054 LR: 0.00100  \n",
      "Epoch: [1][1928/1929] Elapsed 19m 16s (remain 0m 0s) Loss avg.: 0.5032 Grad: 0.4012 LR: 0.00100  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 29s) Loss avg.: 0.4736 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4747 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4745 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4754 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.5032  avg_val_loss: 0.4754  time: 1192s\n",
      "Epoch 1 - Accuracy: 0.7932210998223366\n",
      "Epoch 1 - Save Best Score: 0.7932 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1929] Elapsed 0m 1s (remain 60m 56s) Loss avg.: 0.4606 Grad: 0.4414 LR: 0.00098  \n",
      "Epoch: [2][100/1929] Elapsed 1m 1s (remain 18m 38s) Loss avg.: 0.4664 Grad: 0.3832 LR: 0.00098  \n",
      "Epoch: [2][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4647 Grad: 0.2859 LR: 0.00098  \n",
      "Epoch: [2][300/1929] Elapsed 3m 1s (remain 16m 22s) Loss avg.: 0.4636 Grad: 0.3775 LR: 0.00098  \n",
      "Epoch: [2][400/1929] Elapsed 4m 1s (remain 15m 19s) Loss avg.: 0.4637 Grad: 0.3639 LR: 0.00098  \n",
      "Epoch: [2][500/1929] Elapsed 5m 1s (remain 14m 18s) Loss avg.: 0.4634 Grad: 0.3593 LR: 0.00098  \n",
      "Epoch: [2][600/1929] Elapsed 6m 0s (remain 13m 17s) Loss avg.: 0.4635 Grad: 0.2995 LR: 0.00098  \n",
      "Epoch: [2][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4635 Grad: 0.2810 LR: 0.00098  \n",
      "Epoch: [2][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4633 Grad: 0.2489 LR: 0.00098  \n",
      "Epoch: [2][900/1929] Elapsed 9m 0s (remain 10m 16s) Loss avg.: 0.4629 Grad: 0.3020 LR: 0.00098  \n",
      "Epoch: [2][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4626 Grad: 0.3482 LR: 0.00098  \n",
      "Epoch: [2][1100/1929] Elapsed 10m 59s (remain 8m 16s) Loss avg.: 0.4625 Grad: 0.2943 LR: 0.00098  \n",
      "Epoch: [2][1200/1929] Elapsed 11m 59s (remain 7m 16s) Loss avg.: 0.4623 Grad: 0.4167 LR: 0.00098  \n",
      "Epoch: [2][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.4621 Grad: 0.3360 LR: 0.00098  \n",
      "Epoch: [2][1400/1929] Elapsed 13m 58s (remain 5m 16s) Loss avg.: 0.4617 Grad: 0.4040 LR: 0.00098  \n",
      "Epoch: [2][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4616 Grad: 0.2878 LR: 0.00098  \n",
      "Epoch: [2][1600/1929] Elapsed 15m 58s (remain 3m 16s) Loss avg.: 0.4613 Grad: 0.3027 LR: 0.00098  \n",
      "Epoch: [2][1700/1929] Elapsed 16m 58s (remain 2m 16s) Loss avg.: 0.4610 Grad: 0.2487 LR: 0.00098  \n",
      "Epoch: [2][1800/1929] Elapsed 17m 58s (remain 1m 16s) Loss avg.: 0.4607 Grad: 0.4378 LR: 0.00098  \n",
      "Epoch: [2][1900/1929] Elapsed 18m 58s (remain 0m 16s) Loss avg.: 0.4605 Grad: 0.3013 LR: 0.00098  \n",
      "Epoch: [2][1928/1929] Elapsed 19m 14s (remain 0m 0s) Loss avg.: 0.4604 Grad: 0.2843 LR: 0.00098  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 29s) Loss avg.: 0.4520 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4598 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4606 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4614 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4604  avg_val_loss: 0.4614  time: 1191s\n",
      "Epoch 2 - Accuracy: 0.800737179160187\n",
      "Epoch 2 - Save Best Score: 0.8007 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1929] Elapsed 0m 1s (remain 61m 33s) Loss avg.: 0.4587 Grad: 0.3018 LR: 0.00091  \n",
      "Epoch: [3][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4520 Grad: 0.2264 LR: 0.00091  \n",
      "Epoch: [3][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4516 Grad: 0.2366 LR: 0.00091  \n",
      "Epoch: [3][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4517 Grad: 0.2877 LR: 0.00091  \n",
      "Epoch: [3][400/1929] Elapsed 4m 1s (remain 15m 18s) Loss avg.: 0.4519 Grad: 0.2606 LR: 0.00091  \n",
      "Epoch: [3][500/1929] Elapsed 5m 1s (remain 14m 18s) Loss avg.: 0.4518 Grad: 0.2236 LR: 0.00091  \n",
      "Epoch: [3][600/1929] Elapsed 6m 0s (remain 13m 17s) Loss avg.: 0.4521 Grad: 0.2623 LR: 0.00091  \n",
      "Epoch: [3][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4519 Grad: 0.2457 LR: 0.00091  \n",
      "Epoch: [3][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4517 Grad: 0.3242 LR: 0.00091  \n",
      "Epoch: [3][900/1929] Elapsed 9m 0s (remain 10m 16s) Loss avg.: 0.4517 Grad: 0.2220 LR: 0.00091  \n",
      "Epoch: [3][1000/1929] Elapsed 9m 59s (remain 9m 16s) Loss avg.: 0.4516 Grad: 0.2556 LR: 0.00091  \n",
      "Epoch: [3][1100/1929] Elapsed 10m 59s (remain 8m 16s) Loss avg.: 0.4515 Grad: 0.2329 LR: 0.00091  \n",
      "Epoch: [3][1200/1929] Elapsed 11m 59s (remain 7m 16s) Loss avg.: 0.4515 Grad: 0.2528 LR: 0.00091  \n",
      "Epoch: [3][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.4514 Grad: 0.3658 LR: 0.00091  \n",
      "Epoch: [3][1400/1929] Elapsed 13m 59s (remain 5m 16s) Loss avg.: 0.4514 Grad: 0.3553 LR: 0.00091  \n",
      "Epoch: [3][1500/1929] Elapsed 14m 59s (remain 4m 16s) Loss avg.: 0.4512 Grad: 0.2593 LR: 0.00091  \n",
      "Epoch: [3][1600/1929] Elapsed 15m 58s (remain 3m 16s) Loss avg.: 0.4512 Grad: 0.3578 LR: 0.00091  \n",
      "Epoch: [3][1700/1929] Elapsed 16m 58s (remain 2m 16s) Loss avg.: 0.4511 Grad: 0.2611 LR: 0.00091  \n",
      "Epoch: [3][1800/1929] Elapsed 17m 58s (remain 1m 16s) Loss avg.: 0.4510 Grad: 0.3334 LR: 0.00091  \n",
      "Epoch: [3][1900/1929] Elapsed 18m 58s (remain 0m 16s) Loss avg.: 0.4509 Grad: 0.2292 LR: 0.00091  \n",
      "Epoch: [3][1928/1929] Elapsed 19m 15s (remain 0m 0s) Loss avg.: 0.4509 Grad: 0.2343 LR: 0.00091  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 4m 19s) Loss avg.: 0.4338 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4512 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4516 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4525 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.4509  avg_val_loss: 0.4525  time: 1191s\n",
      "Epoch 3 - Accuracy: 0.8053092057033007\n",
      "Epoch 3 - Save Best Score: 0.8053 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/1929] Elapsed 0m 1s (remain 60m 42s) Loss avg.: 0.4341 Grad: 0.2787 LR: 0.00081  \n",
      "Epoch: [4][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4445 Grad: 0.2130 LR: 0.00081  \n",
      "Epoch: [4][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4449 Grad: 0.2815 LR: 0.00081  \n",
      "Epoch: [4][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4455 Grad: 0.2803 LR: 0.00081  \n",
      "Epoch: [4][400/1929] Elapsed 4m 1s (remain 15m 18s) Loss avg.: 0.4447 Grad: 0.2228 LR: 0.00081  \n",
      "Epoch: [4][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4447 Grad: 0.1862 LR: 0.00081  \n",
      "Epoch: [4][600/1929] Elapsed 6m 0s (remain 13m 17s) Loss avg.: 0.4448 Grad: 0.2231 LR: 0.00081  \n",
      "Epoch: [4][700/1929] Elapsed 7m 0s (remain 12m 17s) Loss avg.: 0.4451 Grad: 0.3238 LR: 0.00081  \n",
      "Epoch: [4][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4453 Grad: 0.3071 LR: 0.00081  \n",
      "Epoch: [4][900/1929] Elapsed 9m 0s (remain 10m 16s) Loss avg.: 0.4452 Grad: 0.3765 LR: 0.00081  \n",
      "Epoch: [4][1000/1929] Elapsed 10m 0s (remain 9m 16s) Loss avg.: 0.4451 Grad: 0.2414 LR: 0.00081  \n",
      "Epoch: [4][1100/1929] Elapsed 11m 0s (remain 8m 16s) Loss avg.: 0.4450 Grad: 0.1790 LR: 0.00081  \n",
      "Epoch: [4][1200/1929] Elapsed 11m 59s (remain 7m 16s) Loss avg.: 0.4450 Grad: 0.2672 LR: 0.00081  \n",
      "Epoch: [4][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.4449 Grad: 0.2536 LR: 0.00081  \n",
      "Epoch: [4][1400/1929] Elapsed 13m 59s (remain 5m 16s) Loss avg.: 0.4449 Grad: 0.2361 LR: 0.00081  \n",
      "Epoch: [4][1500/1929] Elapsed 14m 59s (remain 4m 16s) Loss avg.: 0.4448 Grad: 0.2847 LR: 0.00081  \n",
      "Epoch: [4][1600/1929] Elapsed 15m 59s (remain 3m 16s) Loss avg.: 0.4448 Grad: 0.2326 LR: 0.00081  \n",
      "Epoch: [4][1700/1929] Elapsed 16m 58s (remain 2m 16s) Loss avg.: 0.4449 Grad: 0.2041 LR: 0.00081  \n",
      "Epoch: [4][1800/1929] Elapsed 17m 58s (remain 1m 16s) Loss avg.: 0.4449 Grad: 0.2284 LR: 0.00081  \n",
      "Epoch: [4][1900/1929] Elapsed 18m 58s (remain 0m 16s) Loss avg.: 0.4449 Grad: 0.1937 LR: 0.00081  \n",
      "Epoch: [4][1928/1929] Elapsed 19m 15s (remain 0m 0s) Loss avg.: 0.4449 Grad: 0.3052 LR: 0.00081  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 30s) Loss avg.: 0.4398 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4472 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4478 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4486 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.4449  avg_val_loss: 0.4486  time: 1191s\n",
      "Epoch 4 - Accuracy: 0.8068016364269692\n",
      "Epoch 4 - Save Best Score: 0.8068 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/1929] Elapsed 0m 1s (remain 61m 18s) Loss avg.: 0.4438 Grad: 0.2460 LR: 0.00069  \n",
      "Epoch: [5][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4398 Grad: 0.2175 LR: 0.00069  \n",
      "Epoch: [5][200/1929] Elapsed 2m 1s (remain 17m 25s) Loss avg.: 0.4400 Grad: 0.1983 LR: 0.00069  \n",
      "Epoch: [5][300/1929] Elapsed 3m 1s (remain 16m 21s) Loss avg.: 0.4393 Grad: 0.2246 LR: 0.00069  \n",
      "Epoch: [5][400/1929] Elapsed 4m 1s (remain 15m 19s) Loss avg.: 0.4394 Grad: 0.2327 LR: 0.00069  \n",
      "Epoch: [5][500/1929] Elapsed 5m 1s (remain 14m 18s) Loss avg.: 0.4398 Grad: 0.2030 LR: 0.00069  \n",
      "Epoch: [5][600/1929] Elapsed 6m 0s (remain 13m 17s) Loss avg.: 0.4396 Grad: 0.1965 LR: 0.00069  \n",
      "Epoch: [5][700/1929] Elapsed 7m 0s (remain 12m 17s) Loss avg.: 0.4397 Grad: 0.2407 LR: 0.00069  \n",
      "Epoch: [5][800/1929] Elapsed 8m 0s (remain 11m 17s) Loss avg.: 0.4398 Grad: 0.2513 LR: 0.00069  \n",
      "Epoch: [5][900/1929] Elapsed 9m 0s (remain 10m 16s) Loss avg.: 0.4398 Grad: 0.2228 LR: 0.00069  \n",
      "Epoch: [5][1000/1929] Elapsed 10m 0s (remain 9m 16s) Loss avg.: 0.4399 Grad: 0.2599 LR: 0.00069  \n",
      "Epoch: [5][1100/1929] Elapsed 11m 0s (remain 8m 16s) Loss avg.: 0.4400 Grad: 0.2568 LR: 0.00069  \n",
      "Epoch: [5][1200/1929] Elapsed 12m 0s (remain 7m 16s) Loss avg.: 0.4400 Grad: 0.2001 LR: 0.00069  \n",
      "Epoch: [5][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.4400 Grad: 0.2357 LR: 0.00069  \n",
      "Epoch: [5][1400/1929] Elapsed 13m 59s (remain 5m 16s) Loss avg.: 0.4399 Grad: 0.2771 LR: 0.00069  \n",
      "Epoch: [5][1500/1929] Elapsed 14m 59s (remain 4m 16s) Loss avg.: 0.4400 Grad: 0.2361 LR: 0.00069  \n",
      "Epoch: [5][1600/1929] Elapsed 15m 59s (remain 3m 16s) Loss avg.: 0.4401 Grad: 0.1740 LR: 0.00069  \n",
      "Epoch: [5][1700/1929] Elapsed 16m 59s (remain 2m 16s) Loss avg.: 0.4401 Grad: 0.2284 LR: 0.00069  \n",
      "Epoch: [5][1800/1929] Elapsed 17m 59s (remain 1m 16s) Loss avg.: 0.4401 Grad: 0.2782 LR: 0.00069  \n",
      "Epoch: [5][1900/1929] Elapsed 18m 59s (remain 0m 16s) Loss avg.: 0.4400 Grad: 0.2258 LR: 0.00069  \n",
      "Epoch: [5][1928/1929] Elapsed 19m 16s (remain 0m 0s) Loss avg.: 0.4400 Grad: 0.2100 LR: 0.00069  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 31s) Loss avg.: 0.4275 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4440 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4448 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4456 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.4400  avg_val_loss: 0.4456  time: 1192s\n",
      "Epoch 5 - Accuracy: 0.8084645890204321\n",
      "Epoch 5 - Save Best Score: 0.8085 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/1929] Elapsed 0m 2s (remain 64m 53s) Loss avg.: 0.4356 Grad: 0.1790 LR: 0.00055  \n",
      "Epoch: [6][100/1929] Elapsed 1m 2s (remain 18m 42s) Loss avg.: 0.4341 Grad: 0.2654 LR: 0.00055  \n",
      "Epoch: [6][200/1929] Elapsed 2m 1s (remain 17m 27s) Loss avg.: 0.4345 Grad: 0.2178 LR: 0.00055  \n",
      "Epoch: [6][300/1929] Elapsed 3m 1s (remain 16m 22s) Loss avg.: 0.4340 Grad: 0.2113 LR: 0.00055  \n",
      "Epoch: [6][400/1929] Elapsed 4m 1s (remain 15m 20s) Loss avg.: 0.4344 Grad: 0.2443 LR: 0.00055  \n",
      "Epoch: [6][500/1929] Elapsed 5m 1s (remain 14m 18s) Loss avg.: 0.4350 Grad: 0.2371 LR: 0.00055  \n",
      "Epoch: [6][600/1929] Elapsed 6m 1s (remain 13m 18s) Loss avg.: 0.4348 Grad: 0.2869 LR: 0.00055  \n",
      "Epoch: [6][700/1929] Elapsed 7m 1s (remain 12m 17s) Loss avg.: 0.4351 Grad: 0.2057 LR: 0.00055  \n",
      "Epoch: [6][800/1929] Elapsed 8m 0s (remain 11m 17s) Loss avg.: 0.4350 Grad: 0.2003 LR: 0.00055  \n",
      "Epoch: [6][900/1929] Elapsed 9m 1s (remain 10m 17s) Loss avg.: 0.4351 Grad: 0.2062 LR: 0.00055  \n",
      "Epoch: [6][1000/1929] Elapsed 10m 0s (remain 9m 16s) Loss avg.: 0.4354 Grad: 0.1951 LR: 0.00055  \n",
      "Epoch: [6][1100/1929] Elapsed 11m 0s (remain 8m 16s) Loss avg.: 0.4354 Grad: 0.1769 LR: 0.00055  \n",
      "Epoch: [6][1200/1929] Elapsed 12m 0s (remain 7m 16s) Loss avg.: 0.4354 Grad: 0.2121 LR: 0.00055  \n",
      "Epoch: [6][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.4355 Grad: 0.2309 LR: 0.00055  \n",
      "Epoch: [6][1400/1929] Elapsed 13m 59s (remain 5m 16s) Loss avg.: 0.4355 Grad: 0.2184 LR: 0.00055  \n",
      "Epoch: [6][1500/1929] Elapsed 14m 59s (remain 4m 16s) Loss avg.: 0.4356 Grad: 0.1916 LR: 0.00055  \n",
      "Epoch: [6][1600/1929] Elapsed 15m 59s (remain 3m 16s) Loss avg.: 0.4356 Grad: 0.2341 LR: 0.00055  \n",
      "Epoch: [6][1700/1929] Elapsed 16m 59s (remain 2m 16s) Loss avg.: 0.4356 Grad: 0.2311 LR: 0.00055  \n",
      "Epoch: [6][1800/1929] Elapsed 17m 59s (remain 1m 16s) Loss avg.: 0.4356 Grad: 0.2337 LR: 0.00055  \n",
      "Epoch: [6][1900/1929] Elapsed 18m 58s (remain 0m 16s) Loss avg.: 0.4356 Grad: 0.2006 LR: 0.00055  \n",
      "Epoch: [6][1928/1929] Elapsed 19m 15s (remain 0m 0s) Loss avg.: 0.4356 Grad: 0.2456 LR: 0.00055  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 32s) Loss avg.: 0.4265 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4412 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4421 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4430 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.4356  avg_val_loss: 0.4430  time: 1191s\n",
      "Epoch 6 - Accuracy: 0.8105443728511694\n",
      "Epoch 6 - Save Best Score: 0.8105 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/1929] Elapsed 0m 1s (remain 61m 36s) Loss avg.: 0.4351 Grad: 0.2338 LR: 0.00041  \n",
      "Epoch: [7][100/1929] Elapsed 1m 1s (remain 18m 36s) Loss avg.: 0.4295 Grad: 0.2385 LR: 0.00041  \n",
      "Epoch: [7][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4298 Grad: 0.2288 LR: 0.00041  \n",
      "Epoch: [7][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4310 Grad: 0.1928 LR: 0.00041  \n",
      "Epoch: [7][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4309 Grad: 0.2654 LR: 0.00041  \n",
      "Epoch: [7][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4308 Grad: 0.2118 LR: 0.00041  \n",
      "Epoch: [7][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4308 Grad: 0.2518 LR: 0.00041  \n",
      "Epoch: [7][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4311 Grad: 0.2177 LR: 0.00041  \n",
      "Epoch: [7][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4312 Grad: 0.2702 LR: 0.00041  \n",
      "Epoch: [7][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4311 Grad: 0.2472 LR: 0.00041  \n",
      "Epoch: [7][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4312 Grad: 0.2175 LR: 0.00041  \n",
      "Epoch: [7][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4310 Grad: 0.2047 LR: 0.00041  \n",
      "Epoch: [7][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4310 Grad: 0.2335 LR: 0.00041  \n",
      "Epoch: [7][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4311 Grad: 0.2111 LR: 0.00041  \n",
      "Epoch: [7][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4313 Grad: 0.2133 LR: 0.00041  \n",
      "Epoch: [7][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4314 Grad: 0.2534 LR: 0.00041  \n",
      "Epoch: [7][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4315 Grad: 0.2244 LR: 0.00041  \n",
      "Epoch: [7][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4315 Grad: 0.2315 LR: 0.00041  \n",
      "Epoch: [7][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4315 Grad: 0.2887 LR: 0.00041  \n",
      "Epoch: [7][1900/1929] Elapsed 18m 57s (remain 0m 16s) Loss avg.: 0.4315 Grad: 0.2047 LR: 0.00041  \n",
      "Epoch: [7][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4315 Grad: 0.2144 LR: 0.00041  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 30s) Loss avg.: 0.4311 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4409 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4414 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4422 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.4315  avg_val_loss: 0.4422  time: 1190s\n",
      "Epoch 7 - Accuracy: 0.8105458303030479\n",
      "Epoch 7 - Save Best Score: 0.8105 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/1929] Elapsed 0m 1s (remain 61m 21s) Loss avg.: 0.4370 Grad: 0.2517 LR: 0.00029  \n",
      "Epoch: [8][100/1929] Elapsed 1m 1s (remain 18m 35s) Loss avg.: 0.4272 Grad: 0.2091 LR: 0.00029  \n",
      "Epoch: [8][200/1929] Elapsed 2m 1s (remain 17m 22s) Loss avg.: 0.4269 Grad: 0.1805 LR: 0.00029  \n",
      "Epoch: [8][300/1929] Elapsed 3m 0s (remain 16m 18s) Loss avg.: 0.4262 Grad: 0.2747 LR: 0.00029  \n",
      "Epoch: [8][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4264 Grad: 0.2060 LR: 0.00029  \n",
      "Epoch: [8][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4266 Grad: 0.2099 LR: 0.00029  \n",
      "Epoch: [8][600/1929] Elapsed 5m 59s (remain 13m 15s) Loss avg.: 0.4268 Grad: 0.2259 LR: 0.00029  \n",
      "Epoch: [8][700/1929] Elapsed 6m 59s (remain 12m 14s) Loss avg.: 0.4266 Grad: 0.2132 LR: 0.00029  \n",
      "Epoch: [8][800/1929] Elapsed 7m 59s (remain 11m 14s) Loss avg.: 0.4265 Grad: 0.2207 LR: 0.00029  \n",
      "Epoch: [8][900/1929] Elapsed 8m 58s (remain 10m 14s) Loss avg.: 0.4266 Grad: 0.1976 LR: 0.00029  \n",
      "Epoch: [8][1000/1929] Elapsed 9m 58s (remain 9m 14s) Loss avg.: 0.4269 Grad: 0.2161 LR: 0.00029  \n",
      "Epoch: [8][1100/1929] Elapsed 10m 57s (remain 8m 14s) Loss avg.: 0.4269 Grad: 0.2059 LR: 0.00029  \n",
      "Epoch: [8][1200/1929] Elapsed 11m 57s (remain 7m 15s) Loss avg.: 0.4271 Grad: 0.2420 LR: 0.00029  \n",
      "Epoch: [8][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4272 Grad: 0.2079 LR: 0.00029  \n",
      "Epoch: [8][1400/1929] Elapsed 13m 56s (remain 5m 15s) Loss avg.: 0.4274 Grad: 0.2213 LR: 0.00029  \n",
      "Epoch: [8][1500/1929] Elapsed 14m 56s (remain 4m 15s) Loss avg.: 0.4274 Grad: 0.2323 LR: 0.00029  \n",
      "Epoch: [8][1600/1929] Elapsed 15m 56s (remain 3m 15s) Loss avg.: 0.4274 Grad: 0.2320 LR: 0.00029  \n",
      "Epoch: [8][1700/1929] Elapsed 16m 55s (remain 2m 16s) Loss avg.: 0.4274 Grad: 0.2269 LR: 0.00029  \n",
      "Epoch: [8][1800/1929] Elapsed 17m 55s (remain 1m 16s) Loss avg.: 0.4275 Grad: 0.2500 LR: 0.00029  \n",
      "Epoch: [8][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4275 Grad: 0.2289 LR: 0.00029  \n",
      "Epoch: [8][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4276 Grad: 0.3008 LR: 0.00029  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 28s) Loss avg.: 0.4298 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4379 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4388 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4396 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.4276  avg_val_loss: 0.4396  time: 1188s\n",
      "Epoch 8 - Accuracy: 0.8115310677729698\n",
      "Epoch 8 - Save Best Score: 0.8115 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/1929] Elapsed 0m 1s (remain 61m 27s) Loss avg.: 0.4172 Grad: 0.2328 LR: 0.00019  \n",
      "Epoch: [9][100/1929] Elapsed 1m 1s (remain 18m 36s) Loss avg.: 0.4229 Grad: 0.2064 LR: 0.00019  \n",
      "Epoch: [9][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4231 Grad: 0.2771 LR: 0.00019  \n",
      "Epoch: [9][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4230 Grad: 0.2412 LR: 0.00019  \n",
      "Epoch: [9][400/1929] Elapsed 4m 0s (remain 15m 16s) Loss avg.: 0.4226 Grad: 0.2516 LR: 0.00019  \n",
      "Epoch: [9][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4234 Grad: 0.2205 LR: 0.00019  \n",
      "Epoch: [9][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4234 Grad: 0.2738 LR: 0.00019  \n",
      "Epoch: [9][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4233 Grad: 0.2089 LR: 0.00019  \n",
      "Epoch: [9][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4237 Grad: 0.2277 LR: 0.00019  \n",
      "Epoch: [9][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4235 Grad: 0.2247 LR: 0.00019  \n",
      "Epoch: [9][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4238 Grad: 0.2709 LR: 0.00019  \n",
      "Epoch: [9][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4238 Grad: 0.2363 LR: 0.00019  \n",
      "Epoch: [9][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4238 Grad: 0.2293 LR: 0.00019  \n",
      "Epoch: [9][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4241 Grad: 0.2295 LR: 0.00019  \n",
      "Epoch: [9][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4242 Grad: 0.2310 LR: 0.00019  \n",
      "Epoch: [9][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4240 Grad: 0.2177 LR: 0.00019  \n",
      "Epoch: [9][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4241 Grad: 0.2182 LR: 0.00019  \n",
      "Epoch: [9][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4242 Grad: 0.2853 LR: 0.00019  \n",
      "Epoch: [9][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4242 Grad: 0.2657 LR: 0.00019  \n",
      "Epoch: [9][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4242 Grad: 0.2056 LR: 0.00019  \n",
      "Epoch: [9][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4242 Grad: 0.2437 LR: 0.00019  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 4m 1s) Loss avg.: 0.4287 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4370 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4379 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4387 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.4242  avg_val_loss: 0.4387  time: 1189s\n",
      "Epoch 9 - Accuracy: 0.8117365684878499\n",
      "Epoch 9 - Save Best Score: 0.8117 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/1929] Elapsed 0m 1s (remain 61m 27s) Loss avg.: 0.4188 Grad: 0.2291 LR: 0.00012  \n",
      "Epoch: [10][100/1929] Elapsed 1m 1s (remain 18m 34s) Loss avg.: 0.4201 Grad: 0.2280 LR: 0.00012  \n",
      "Epoch: [10][200/1929] Elapsed 2m 1s (remain 17m 22s) Loss avg.: 0.4205 Grad: 0.2326 LR: 0.00012  \n",
      "Epoch: [10][300/1929] Elapsed 3m 0s (remain 16m 18s) Loss avg.: 0.4205 Grad: 0.2819 LR: 0.00012  \n",
      "Epoch: [10][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4207 Grad: 0.2818 LR: 0.00012  \n",
      "Epoch: [10][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4205 Grad: 0.2141 LR: 0.00012  \n",
      "Epoch: [10][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4206 Grad: 0.2364 LR: 0.00012  \n",
      "Epoch: [10][700/1929] Elapsed 7m 0s (remain 12m 15s) Loss avg.: 0.4208 Grad: 0.2736 LR: 0.00012  \n",
      "Epoch: [10][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4209 Grad: 0.2223 LR: 0.00012  \n",
      "Epoch: [10][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4210 Grad: 0.2419 LR: 0.00012  \n",
      "Epoch: [10][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4211 Grad: 0.2475 LR: 0.00012  \n",
      "Epoch: [10][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4211 Grad: 0.2269 LR: 0.00012  \n",
      "Epoch: [10][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4212 Grad: 0.2118 LR: 0.00012  \n",
      "Epoch: [10][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4213 Grad: 0.2672 LR: 0.00012  \n",
      "Epoch: [10][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4215 Grad: 0.2388 LR: 0.00012  \n",
      "Epoch: [10][1500/1929] Elapsed 14m 57s (remain 4m 16s) Loss avg.: 0.4215 Grad: 0.2387 LR: 0.00012  \n",
      "Epoch: [10][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4216 Grad: 0.2177 LR: 0.00012  \n",
      "Epoch: [10][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4215 Grad: 0.2342 LR: 0.00012  \n",
      "Epoch: [10][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4215 Grad: 0.2140 LR: 0.00012  \n",
      "Epoch: [10][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4216 Grad: 0.2426 LR: 0.00012  \n",
      "Epoch: [10][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4216 Grad: 0.2324 LR: 0.00012  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 31s) Loss avg.: 0.4279 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4364 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4374 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4381 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.4216  avg_val_loss: 0.4381  time: 1189s\n",
      "Epoch 10 - Accuracy: 0.81231226197989\n",
      "Epoch 10 - Save Best Score: 0.8123 Model\n",
      "Epoch 10 - Save final model\n",
      "========== fold: 2 result ==========\n",
      "Score: 0.81231\n",
      "========== fold: 3 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load pre-train weight.\n",
      "Epoch: [1][0/1929] Elapsed 0m 2s (remain 64m 58s) Loss avg.: 1.4009 Grad: 0.3739 LR: 0.00100  \n",
      "Epoch: [1][100/1929] Elapsed 1m 1s (remain 18m 40s) Loss avg.: 0.7056 Grad: 0.9432 LR: 0.00100  \n",
      "Epoch: [1][200/1929] Elapsed 2m 1s (remain 17m 26s) Loss avg.: 0.6360 Grad: 0.4932 LR: 0.00100  \n",
      "Epoch: [1][300/1929] Elapsed 3m 1s (remain 16m 21s) Loss avg.: 0.6045 Grad: 0.6635 LR: 0.00100  \n",
      "Epoch: [1][400/1929] Elapsed 4m 1s (remain 15m 18s) Loss avg.: 0.5853 Grad: 0.8099 LR: 0.00100  \n",
      "Epoch: [1][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.5702 Grad: 0.5129 LR: 0.00100  \n",
      "Epoch: [1][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.5594 Grad: 0.4330 LR: 0.00100  \n",
      "Epoch: [1][700/1929] Elapsed 7m 0s (remain 12m 15s) Loss avg.: 0.5507 Grad: 0.5694 LR: 0.00100  \n",
      "Epoch: [1][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.5434 Grad: 0.4265 LR: 0.00100  \n",
      "Epoch: [1][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.5374 Grad: 0.4118 LR: 0.00100  \n",
      "Epoch: [1][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.5320 Grad: 0.3099 LR: 0.00100  \n",
      "Epoch: [1][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.5274 Grad: 0.4629 LR: 0.00100  \n",
      "Epoch: [1][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.5234 Grad: 0.4526 LR: 0.00100  \n",
      "Epoch: [1][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.5200 Grad: 0.3832 LR: 0.00100  \n",
      "Epoch: [1][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.5170 Grad: 0.3355 LR: 0.00100  \n",
      "Epoch: [1][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.5141 Grad: 0.3782 LR: 0.00100  \n",
      "Epoch: [1][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.5117 Grad: 0.3514 LR: 0.00100  \n",
      "Epoch: [1][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.5094 Grad: 0.4400 LR: 0.00100  \n",
      "Epoch: [1][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.5071 Grad: 0.3854 LR: 0.00100  \n",
      "Epoch: [1][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.5052 Grad: 0.4601 LR: 0.00100  \n",
      "Epoch: [1][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.5047 Grad: 0.3786 LR: 0.00100  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 32s) Loss avg.: 0.4672 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4669 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4679 \n",
      "Eval: [214/215] Elapsed 0m 34s (remain 0m 0s) Loss avg.: 0.4684 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.5047  avg_val_loss: 0.4684  time: 1188s\n",
      "Epoch 1 - Accuracy: 0.7974797742115549\n",
      "Epoch 1 - Save Best Score: 0.7975 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1929] Elapsed 0m 1s (remain 60m 16s) Loss avg.: 0.4428 Grad: 0.3787 LR: 0.00098  \n",
      "Epoch: [2][100/1929] Elapsed 1m 1s (remain 18m 34s) Loss avg.: 0.4660 Grad: 0.3156 LR: 0.00098  \n",
      "Epoch: [2][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4661 Grad: 0.4256 LR: 0.00098  \n",
      "Epoch: [2][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4648 Grad: 0.3935 LR: 0.00098  \n",
      "Epoch: [2][400/1929] Elapsed 4m 0s (remain 15m 16s) Loss avg.: 0.4643 Grad: 0.6451 LR: 0.00098  \n",
      "Epoch: [2][500/1929] Elapsed 5m 0s (remain 14m 15s) Loss avg.: 0.4641 Grad: 0.4330 LR: 0.00098  \n",
      "Epoch: [2][600/1929] Elapsed 5m 59s (remain 13m 15s) Loss avg.: 0.4641 Grad: 0.4125 LR: 0.00098  \n",
      "Epoch: [2][700/1929] Elapsed 6m 59s (remain 12m 14s) Loss avg.: 0.4639 Grad: 0.2842 LR: 0.00098  \n",
      "Epoch: [2][800/1929] Elapsed 7m 59s (remain 11m 14s) Loss avg.: 0.4636 Grad: 0.3451 LR: 0.00098  \n",
      "Epoch: [2][900/1929] Elapsed 8m 58s (remain 10m 14s) Loss avg.: 0.4631 Grad: 0.3302 LR: 0.00098  \n",
      "Epoch: [2][1000/1929] Elapsed 9m 58s (remain 9m 14s) Loss avg.: 0.4629 Grad: 0.3549 LR: 0.00098  \n",
      "Epoch: [2][1100/1929] Elapsed 10m 58s (remain 8m 14s) Loss avg.: 0.4625 Grad: 0.3144 LR: 0.00098  \n",
      "Epoch: [2][1200/1929] Elapsed 11m 57s (remain 7m 15s) Loss avg.: 0.4622 Grad: 0.3895 LR: 0.00098  \n",
      "Epoch: [2][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4619 Grad: 0.2986 LR: 0.00098  \n",
      "Epoch: [2][1400/1929] Elapsed 13m 56s (remain 5m 15s) Loss avg.: 0.4616 Grad: 0.3261 LR: 0.00098  \n",
      "Epoch: [2][1500/1929] Elapsed 14m 56s (remain 4m 15s) Loss avg.: 0.4616 Grad: 0.3680 LR: 0.00098  \n",
      "Epoch: [2][1600/1929] Elapsed 15m 56s (remain 3m 15s) Loss avg.: 0.4613 Grad: 0.2631 LR: 0.00098  \n",
      "Epoch: [2][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4613 Grad: 0.4507 LR: 0.00098  \n",
      "Epoch: [2][1800/1929] Elapsed 17m 55s (remain 1m 16s) Loss avg.: 0.4610 Grad: 0.3987 LR: 0.00098  \n",
      "Epoch: [2][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4607 Grad: 0.3505 LR: 0.00098  \n",
      "Epoch: [2][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4607 Grad: 0.3009 LR: 0.00098  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 26s) Loss avg.: 0.4581 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4577 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4588 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4594 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4607  avg_val_loss: 0.4594  time: 1188s\n",
      "Epoch 2 - Accuracy: 0.801617480094851\n",
      "Epoch 2 - Save Best Score: 0.8016 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1929] Elapsed 0m 1s (remain 60m 34s) Loss avg.: 0.4404 Grad: 0.2650 LR: 0.00091  \n",
      "Epoch: [3][100/1929] Elapsed 1m 1s (remain 18m 35s) Loss avg.: 0.4526 Grad: 0.2550 LR: 0.00091  \n",
      "Epoch: [3][200/1929] Elapsed 2m 1s (remain 17m 22s) Loss avg.: 0.4525 Grad: 0.2511 LR: 0.00091  \n",
      "Epoch: [3][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4527 Grad: 0.2983 LR: 0.00091  \n",
      "Epoch: [3][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4527 Grad: 0.3858 LR: 0.00091  \n",
      "Epoch: [3][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4523 Grad: 0.3153 LR: 0.00091  \n",
      "Epoch: [3][600/1929] Elapsed 5m 59s (remain 13m 15s) Loss avg.: 0.4521 Grad: 0.3056 LR: 0.00091  \n",
      "Epoch: [3][700/1929] Elapsed 6m 59s (remain 12m 14s) Loss avg.: 0.4522 Grad: 0.2339 LR: 0.00091  \n",
      "Epoch: [3][800/1929] Elapsed 7m 59s (remain 11m 14s) Loss avg.: 0.4524 Grad: 0.3439 LR: 0.00091  \n",
      "Epoch: [3][900/1929] Elapsed 8m 58s (remain 10m 14s) Loss avg.: 0.4524 Grad: 0.3067 LR: 0.00091  \n",
      "Epoch: [3][1000/1929] Elapsed 9m 58s (remain 9m 14s) Loss avg.: 0.4524 Grad: 0.2732 LR: 0.00091  \n",
      "Epoch: [3][1100/1929] Elapsed 10m 58s (remain 8m 14s) Loss avg.: 0.4523 Grad: 0.3122 LR: 0.00091  \n",
      "Epoch: [3][1200/1929] Elapsed 11m 57s (remain 7m 15s) Loss avg.: 0.4521 Grad: 0.3802 LR: 0.00091  \n",
      "Epoch: [3][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4519 Grad: 0.2589 LR: 0.00091  \n",
      "Epoch: [3][1400/1929] Elapsed 13m 56s (remain 5m 15s) Loss avg.: 0.4518 Grad: 0.2388 LR: 0.00091  \n",
      "Epoch: [3][1500/1929] Elapsed 14m 56s (remain 4m 15s) Loss avg.: 0.4516 Grad: 0.2725 LR: 0.00091  \n",
      "Epoch: [3][1600/1929] Elapsed 15m 56s (remain 3m 15s) Loss avg.: 0.4514 Grad: 0.2417 LR: 0.00091  \n",
      "Epoch: [3][1700/1929] Elapsed 16m 55s (remain 2m 16s) Loss avg.: 0.4513 Grad: 0.3214 LR: 0.00091  \n",
      "Epoch: [3][1800/1929] Elapsed 17m 55s (remain 1m 16s) Loss avg.: 0.4512 Grad: 0.4888 LR: 0.00091  \n",
      "Epoch: [3][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4512 Grad: 0.2339 LR: 0.00091  \n",
      "Epoch: [3][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4511 Grad: 0.2751 LR: 0.00091  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 30s) Loss avg.: 0.4535 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4502 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4516 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4521 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.4511  avg_val_loss: 0.4521  time: 1188s\n",
      "Epoch 3 - Accuracy: 0.8057930797269901\n",
      "Epoch 3 - Save Best Score: 0.8058 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/1929] Elapsed 0m 1s (remain 61m 47s) Loss avg.: 0.4355 Grad: 0.2323 LR: 0.00081  \n",
      "Epoch: [4][100/1929] Elapsed 1m 1s (remain 18m 35s) Loss avg.: 0.4450 Grad: 0.2376 LR: 0.00081  \n",
      "Epoch: [4][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4443 Grad: 0.2911 LR: 0.00081  \n",
      "Epoch: [4][300/1929] Elapsed 3m 1s (remain 16m 18s) Loss avg.: 0.4438 Grad: 0.2260 LR: 0.00081  \n",
      "Epoch: [4][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4441 Grad: 0.2038 LR: 0.00081  \n",
      "Epoch: [4][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4442 Grad: 0.3091 LR: 0.00081  \n",
      "Epoch: [4][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4440 Grad: 0.2336 LR: 0.00081  \n",
      "Epoch: [4][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4440 Grad: 0.2498 LR: 0.00081  \n",
      "Epoch: [4][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4440 Grad: 0.2586 LR: 0.00081  \n",
      "Epoch: [4][900/1929] Elapsed 8m 58s (remain 10m 14s) Loss avg.: 0.4441 Grad: 0.2239 LR: 0.00081  \n",
      "Epoch: [4][1000/1929] Elapsed 9m 58s (remain 9m 14s) Loss avg.: 0.4441 Grad: 0.2244 LR: 0.00081  \n",
      "Epoch: [4][1100/1929] Elapsed 10m 58s (remain 8m 14s) Loss avg.: 0.4441 Grad: 0.3067 LR: 0.00081  \n",
      "Epoch: [4][1200/1929] Elapsed 11m 57s (remain 7m 15s) Loss avg.: 0.4443 Grad: 0.3315 LR: 0.00081  \n",
      "Epoch: [4][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4444 Grad: 0.2184 LR: 0.00081  \n",
      "Epoch: [4][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4445 Grad: 0.2836 LR: 0.00081  \n",
      "Epoch: [4][1500/1929] Elapsed 14m 56s (remain 4m 15s) Loss avg.: 0.4446 Grad: 0.2869 LR: 0.00081  \n",
      "Epoch: [4][1600/1929] Elapsed 15m 56s (remain 3m 15s) Loss avg.: 0.4446 Grad: 0.2874 LR: 0.00081  \n",
      "Epoch: [4][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4448 Grad: 0.2100 LR: 0.00081  \n",
      "Epoch: [4][1800/1929] Elapsed 17m 55s (remain 1m 16s) Loss avg.: 0.4449 Grad: 0.3043 LR: 0.00081  \n",
      "Epoch: [4][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4449 Grad: 0.3183 LR: 0.00081  \n",
      "Epoch: [4][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4450 Grad: 0.2578 LR: 0.00081  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 4m 6s) Loss avg.: 0.4535 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4486 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4495 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4501 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.4450  avg_val_loss: 0.4501  time: 1188s\n",
      "Epoch 4 - Accuracy: 0.8063585710558802\n",
      "Epoch 4 - Save Best Score: 0.8064 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/1929] Elapsed 0m 1s (remain 60m 44s) Loss avg.: 0.4455 Grad: 0.2001 LR: 0.00069  \n",
      "Epoch: [5][100/1929] Elapsed 1m 1s (remain 18m 35s) Loss avg.: 0.4379 Grad: 0.2569 LR: 0.00069  \n",
      "Epoch: [5][200/1929] Elapsed 2m 1s (remain 17m 22s) Loss avg.: 0.4383 Grad: 0.1970 LR: 0.00069  \n",
      "Epoch: [5][300/1929] Elapsed 3m 0s (remain 16m 18s) Loss avg.: 0.4384 Grad: 0.2507 LR: 0.00069  \n",
      "Epoch: [5][400/1929] Elapsed 4m 0s (remain 15m 16s) Loss avg.: 0.4390 Grad: 0.2437 LR: 0.00069  \n",
      "Epoch: [5][500/1929] Elapsed 5m 0s (remain 14m 15s) Loss avg.: 0.4394 Grad: 0.2272 LR: 0.00069  \n",
      "Epoch: [5][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4395 Grad: 0.2168 LR: 0.00069  \n",
      "Epoch: [5][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4397 Grad: 0.2626 LR: 0.00069  \n",
      "Epoch: [5][800/1929] Elapsed 7m 59s (remain 11m 14s) Loss avg.: 0.4397 Grad: 0.2396 LR: 0.00069  \n",
      "Epoch: [5][900/1929] Elapsed 8m 58s (remain 10m 14s) Loss avg.: 0.4396 Grad: 0.2756 LR: 0.00069  \n",
      "Epoch: [5][1000/1929] Elapsed 9m 58s (remain 9m 14s) Loss avg.: 0.4396 Grad: 0.3235 LR: 0.00069  \n",
      "Epoch: [5][1100/1929] Elapsed 10m 58s (remain 8m 14s) Loss avg.: 0.4397 Grad: 0.1875 LR: 0.00069  \n",
      "Epoch: [5][1200/1929] Elapsed 11m 57s (remain 7m 15s) Loss avg.: 0.4398 Grad: 0.2662 LR: 0.00069  \n",
      "Epoch: [5][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4399 Grad: 0.2320 LR: 0.00069  \n",
      "Epoch: [5][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4400 Grad: 0.2406 LR: 0.00069  \n",
      "Epoch: [5][1500/1929] Elapsed 14m 56s (remain 4m 15s) Loss avg.: 0.4401 Grad: 0.2009 LR: 0.00069  \n",
      "Epoch: [5][1600/1929] Elapsed 15m 56s (remain 3m 15s) Loss avg.: 0.4402 Grad: 0.2133 LR: 0.00069  \n",
      "Epoch: [5][1700/1929] Elapsed 16m 55s (remain 2m 16s) Loss avg.: 0.4401 Grad: 0.2745 LR: 0.00069  \n",
      "Epoch: [5][1800/1929] Elapsed 17m 55s (remain 1m 16s) Loss avg.: 0.4402 Grad: 0.2254 LR: 0.00069  \n",
      "Epoch: [5][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4402 Grad: 0.2501 LR: 0.00069  \n",
      "Epoch: [5][1928/1929] Elapsed 19m 11s (remain 0m 0s) Loss avg.: 0.4401 Grad: 0.2549 LR: 0.00069  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 29s) Loss avg.: 0.4431 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4443 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4455 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4460 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.4401  avg_val_loss: 0.4460  time: 1188s\n",
      "Epoch 5 - Accuracy: 0.8085564084887827\n",
      "Epoch 5 - Save Best Score: 0.8086 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/1929] Elapsed 0m 1s (remain 60m 47s) Loss avg.: 0.4231 Grad: 0.2198 LR: 0.00055  \n",
      "Epoch: [6][100/1929] Elapsed 1m 1s (remain 18m 34s) Loss avg.: 0.4341 Grad: 0.2108 LR: 0.00055  \n",
      "Epoch: [6][200/1929] Elapsed 2m 1s (remain 17m 21s) Loss avg.: 0.4342 Grad: 0.2545 LR: 0.00055  \n",
      "Epoch: [6][300/1929] Elapsed 3m 0s (remain 16m 17s) Loss avg.: 0.4343 Grad: 0.2151 LR: 0.00055  \n",
      "Epoch: [6][400/1929] Elapsed 4m 0s (remain 15m 15s) Loss avg.: 0.4345 Grad: 0.2271 LR: 0.00055  \n",
      "Epoch: [6][500/1929] Elapsed 4m 59s (remain 14m 14s) Loss avg.: 0.4350 Grad: 0.2288 LR: 0.00055  \n",
      "Epoch: [6][600/1929] Elapsed 5m 59s (remain 13m 14s) Loss avg.: 0.4349 Grad: 0.2698 LR: 0.00055  \n",
      "Epoch: [6][700/1929] Elapsed 6m 59s (remain 12m 14s) Loss avg.: 0.4351 Grad: 0.2775 LR: 0.00055  \n",
      "Epoch: [6][800/1929] Elapsed 7m 59s (remain 11m 14s) Loss avg.: 0.4352 Grad: 0.2283 LR: 0.00055  \n",
      "Epoch: [6][900/1929] Elapsed 8m 58s (remain 10m 14s) Loss avg.: 0.4354 Grad: 0.2313 LR: 0.00055  \n",
      "Epoch: [6][1000/1929] Elapsed 9m 58s (remain 9m 14s) Loss avg.: 0.4355 Grad: 0.3209 LR: 0.00055  \n",
      "Epoch: [6][1100/1929] Elapsed 10m 57s (remain 8m 14s) Loss avg.: 0.4356 Grad: 0.2044 LR: 0.00055  \n",
      "Epoch: [6][1200/1929] Elapsed 11m 57s (remain 7m 15s) Loss avg.: 0.4356 Grad: 0.2103 LR: 0.00055  \n",
      "Epoch: [6][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4357 Grad: 0.2043 LR: 0.00055  \n",
      "Epoch: [6][1400/1929] Elapsed 13m 56s (remain 5m 15s) Loss avg.: 0.4357 Grad: 0.3009 LR: 0.00055  \n",
      "Epoch: [6][1500/1929] Elapsed 14m 56s (remain 4m 15s) Loss avg.: 0.4359 Grad: 0.2516 LR: 0.00055  \n",
      "Epoch: [6][1600/1929] Elapsed 15m 56s (remain 3m 15s) Loss avg.: 0.4358 Grad: 0.1970 LR: 0.00055  \n",
      "Epoch: [6][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4358 Grad: 0.2273 LR: 0.00055  \n",
      "Epoch: [6][1800/1929] Elapsed 17m 55s (remain 1m 16s) Loss avg.: 0.4356 Grad: 0.2392 LR: 0.00055  \n",
      "Epoch: [6][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4357 Grad: 0.2160 LR: 0.00055  \n",
      "Epoch: [6][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4357 Grad: 0.2187 LR: 0.00055  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 24s) Loss avg.: 0.4450 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4421 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4435 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4439 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.4357  avg_val_loss: 0.4439  time: 1188s\n",
      "Epoch 6 - Accuracy: 0.8093988156746035\n",
      "Epoch 6 - Save Best Score: 0.8094 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/1929] Elapsed 0m 2s (remain 65m 43s) Loss avg.: 0.4512 Grad: 0.2707 LR: 0.00041  \n",
      "Epoch: [7][100/1929] Elapsed 1m 2s (remain 18m 42s) Loss avg.: 0.4306 Grad: 0.2044 LR: 0.00041  \n",
      "Epoch: [7][200/1929] Elapsed 2m 1s (remain 17m 25s) Loss avg.: 0.4304 Grad: 0.2201 LR: 0.00041  \n",
      "Epoch: [7][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4306 Grad: 0.3027 LR: 0.00041  \n",
      "Epoch: [7][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4303 Grad: 0.1988 LR: 0.00041  \n",
      "Epoch: [7][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4305 Grad: 0.2061 LR: 0.00041  \n",
      "Epoch: [7][600/1929] Elapsed 5m 59s (remain 13m 15s) Loss avg.: 0.4309 Grad: 0.2328 LR: 0.00041  \n",
      "Epoch: [7][700/1929] Elapsed 6m 59s (remain 12m 14s) Loss avg.: 0.4309 Grad: 0.2313 LR: 0.00041  \n",
      "Epoch: [7][800/1929] Elapsed 7m 59s (remain 11m 14s) Loss avg.: 0.4311 Grad: 0.2631 LR: 0.00041  \n",
      "Epoch: [7][900/1929] Elapsed 8m 58s (remain 10m 14s) Loss avg.: 0.4310 Grad: 0.2277 LR: 0.00041  \n",
      "Epoch: [7][1000/1929] Elapsed 9m 58s (remain 9m 14s) Loss avg.: 0.4310 Grad: 0.2177 LR: 0.00041  \n",
      "Epoch: [7][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4312 Grad: 0.2137 LR: 0.00041  \n",
      "Epoch: [7][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4312 Grad: 0.1978 LR: 0.00041  \n",
      "Epoch: [7][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4312 Grad: 0.2342 LR: 0.00041  \n",
      "Epoch: [7][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4311 Grad: 0.2009 LR: 0.00041  \n",
      "Epoch: [7][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4311 Grad: 0.1956 LR: 0.00041  \n",
      "Epoch: [7][1600/1929] Elapsed 15m 56s (remain 3m 16s) Loss avg.: 0.4313 Grad: 0.2210 LR: 0.00041  \n",
      "Epoch: [7][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4314 Grad: 0.2213 LR: 0.00041  \n",
      "Epoch: [7][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4316 Grad: 0.2543 LR: 0.00041  \n",
      "Epoch: [7][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4315 Grad: 0.2047 LR: 0.00041  \n",
      "Epoch: [7][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4316 Grad: 0.2895 LR: 0.00041  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 29s) Loss avg.: 0.4393 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4397 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4411 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4415 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.4316  avg_val_loss: 0.4415  time: 1189s\n",
      "Epoch 7 - Accuracy: 0.810353446655075\n",
      "Epoch 7 - Save Best Score: 0.8104 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/1929] Elapsed 0m 1s (remain 60m 24s) Loss avg.: 0.4456 Grad: 0.2099 LR: 0.00029  \n",
      "Epoch: [8][100/1929] Elapsed 1m 1s (remain 18m 34s) Loss avg.: 0.4274 Grad: 0.2295 LR: 0.00029  \n",
      "Epoch: [8][200/1929] Elapsed 2m 1s (remain 17m 22s) Loss avg.: 0.4269 Grad: 0.2344 LR: 0.00029  \n",
      "Epoch: [8][300/1929] Elapsed 3m 1s (remain 16m 18s) Loss avg.: 0.4278 Grad: 0.2275 LR: 0.00029  \n",
      "Epoch: [8][400/1929] Elapsed 4m 0s (remain 15m 16s) Loss avg.: 0.4278 Grad: 0.2416 LR: 0.00029  \n",
      "Epoch: [8][500/1929] Elapsed 5m 0s (remain 14m 15s) Loss avg.: 0.4276 Grad: 0.2167 LR: 0.00029  \n",
      "Epoch: [8][600/1929] Elapsed 5m 59s (remain 13m 15s) Loss avg.: 0.4272 Grad: 0.2170 LR: 0.00029  \n",
      "Epoch: [8][700/1929] Elapsed 6m 59s (remain 12m 14s) Loss avg.: 0.4272 Grad: 0.2267 LR: 0.00029  \n",
      "Epoch: [8][800/1929] Elapsed 7m 59s (remain 11m 14s) Loss avg.: 0.4276 Grad: 0.2030 LR: 0.00029  \n",
      "Epoch: [8][900/1929] Elapsed 8m 58s (remain 10m 14s) Loss avg.: 0.4274 Grad: 0.2152 LR: 0.00029  \n",
      "Epoch: [8][1000/1929] Elapsed 9m 58s (remain 9m 14s) Loss avg.: 0.4274 Grad: 0.2477 LR: 0.00029  \n",
      "Epoch: [8][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4274 Grad: 0.2028 LR: 0.00029  \n",
      "Epoch: [8][1200/1929] Elapsed 11m 57s (remain 7m 15s) Loss avg.: 0.4275 Grad: 0.2612 LR: 0.00029  \n",
      "Epoch: [8][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4276 Grad: 0.2150 LR: 0.00029  \n",
      "Epoch: [8][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4275 Grad: 0.2383 LR: 0.00029  \n",
      "Epoch: [8][1500/1929] Elapsed 14m 56s (remain 4m 15s) Loss avg.: 0.4276 Grad: 0.2151 LR: 0.00029  \n",
      "Epoch: [8][1600/1929] Elapsed 15m 56s (remain 3m 15s) Loss avg.: 0.4275 Grad: 0.1985 LR: 0.00029  \n",
      "Epoch: [8][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4275 Grad: 0.2355 LR: 0.00029  \n",
      "Epoch: [8][1800/1929] Elapsed 17m 55s (remain 1m 16s) Loss avg.: 0.4277 Grad: 0.2603 LR: 0.00029  \n",
      "Epoch: [8][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4276 Grad: 0.2322 LR: 0.00029  \n",
      "Epoch: [8][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4276 Grad: 0.1980 LR: 0.00029  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 29s) Loss avg.: 0.4380 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4383 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4395 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4400 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.4276  avg_val_loss: 0.4400  time: 1188s\n",
      "Epoch 8 - Accuracy: 0.8111375557657525\n",
      "Epoch 8 - Save Best Score: 0.8111 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/1929] Elapsed 0m 1s (remain 60m 46s) Loss avg.: 0.4226 Grad: 0.2420 LR: 0.00019  \n",
      "Epoch: [9][100/1929] Elapsed 1m 1s (remain 18m 35s) Loss avg.: 0.4226 Grad: 0.2258 LR: 0.00019  \n",
      "Epoch: [9][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4231 Grad: 0.2330 LR: 0.00019  \n",
      "Epoch: [9][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4230 Grad: 0.2549 LR: 0.00019  \n",
      "Epoch: [9][400/1929] Elapsed 4m 0s (remain 15m 18s) Loss avg.: 0.4235 Grad: 0.2498 LR: 0.00019  \n",
      "Epoch: [9][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4235 Grad: 0.2499 LR: 0.00019  \n",
      "Epoch: [9][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4232 Grad: 0.2391 LR: 0.00019  \n",
      "Epoch: [9][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4233 Grad: 0.2436 LR: 0.00019  \n",
      "Epoch: [9][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4235 Grad: 0.2848 LR: 0.00019  \n",
      "Epoch: [9][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4236 Grad: 0.2408 LR: 0.00019  \n",
      "Epoch: [9][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4237 Grad: 0.2047 LR: 0.00019  \n",
      "Epoch: [9][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4238 Grad: 0.2517 LR: 0.00019  \n",
      "Epoch: [9][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4238 Grad: 0.2192 LR: 0.00019  \n",
      "Epoch: [9][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4239 Grad: 0.2095 LR: 0.00019  \n",
      "Epoch: [9][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4240 Grad: 0.2599 LR: 0.00019  \n",
      "Epoch: [9][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4240 Grad: 0.2662 LR: 0.00019  \n",
      "Epoch: [9][1600/1929] Elapsed 15m 56s (remain 3m 16s) Loss avg.: 0.4241 Grad: 0.2745 LR: 0.00019  \n",
      "Epoch: [9][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4241 Grad: 0.2118 LR: 0.00019  \n",
      "Epoch: [9][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4241 Grad: 0.2160 LR: 0.00019  \n",
      "Epoch: [9][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4242 Grad: 0.2007 LR: 0.00019  \n",
      "Epoch: [9][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4241 Grad: 0.2419 LR: 0.00019  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 31s) Loss avg.: 0.4369 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4375 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4389 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4394 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.4241  avg_val_loss: 0.4394  time: 1188s\n",
      "Epoch 9 - Accuracy: 0.8116520362788922\n",
      "Epoch 9 - Save Best Score: 0.8117 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/1929] Elapsed 0m 1s (remain 60m 32s) Loss avg.: 0.4258 Grad: 0.2147 LR: 0.00012  \n",
      "Epoch: [10][100/1929] Elapsed 1m 1s (remain 18m 35s) Loss avg.: 0.4222 Grad: 0.2346 LR: 0.00012  \n",
      "Epoch: [10][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4218 Grad: 0.2136 LR: 0.00012  \n",
      "Epoch: [10][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4215 Grad: 0.2213 LR: 0.00012  \n",
      "Epoch: [10][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4213 Grad: 0.2131 LR: 0.00012  \n",
      "Epoch: [10][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4211 Grad: 0.2051 LR: 0.00012  \n",
      "Epoch: [10][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4214 Grad: 0.2119 LR: 0.00012  \n",
      "Epoch: [10][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4211 Grad: 0.2811 LR: 0.00012  \n",
      "Epoch: [10][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4207 Grad: 0.2224 LR: 0.00012  \n",
      "Epoch: [10][900/1929] Elapsed 8m 59s (remain 10m 14s) Loss avg.: 0.4208 Grad: 0.2527 LR: 0.00012  \n",
      "Epoch: [10][1000/1929] Elapsed 9m 58s (remain 9m 14s) Loss avg.: 0.4209 Grad: 0.2332 LR: 0.00012  \n",
      "Epoch: [10][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4211 Grad: 0.2395 LR: 0.00012  \n",
      "Epoch: [10][1200/1929] Elapsed 11m 57s (remain 7m 15s) Loss avg.: 0.4210 Grad: 0.2377 LR: 0.00012  \n",
      "Epoch: [10][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4210 Grad: 0.2442 LR: 0.00012  \n",
      "Epoch: [10][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4211 Grad: 0.2114 LR: 0.00012  \n",
      "Epoch: [10][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4212 Grad: 0.2290 LR: 0.00012  \n",
      "Epoch: [10][1600/1929] Elapsed 15m 56s (remain 3m 15s) Loss avg.: 0.4214 Grad: 0.2459 LR: 0.00012  \n",
      "Epoch: [10][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4215 Grad: 0.2474 LR: 0.00012  \n",
      "Epoch: [10][1800/1929] Elapsed 17m 55s (remain 1m 16s) Loss avg.: 0.4215 Grad: 0.2278 LR: 0.00012  \n",
      "Epoch: [10][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4215 Grad: 0.2213 LR: 0.00012  \n",
      "Epoch: [10][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4215 Grad: 0.2416 LR: 0.00012  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 4m 5s) Loss avg.: 0.4346 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4370 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4385 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4390 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.4215  avg_val_loss: 0.4390  time: 1188s\n",
      "Epoch 10 - Accuracy: 0.811799238918629\n",
      "Epoch 10 - Save Best Score: 0.8118 Model\n",
      "Epoch 10 - Save final model\n",
      "========== fold: 3 result ==========\n",
      "Score: 0.81180\n",
      "========== fold: 4 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load pre-train weight.\n",
      "Epoch: [1][0/1929] Elapsed 0m 1s (remain 61m 10s) Loss avg.: 1.3963 Grad: 0.3499 LR: 0.00100  \n",
      "Epoch: [1][100/1929] Elapsed 1m 1s (remain 18m 34s) Loss avg.: 0.6962 Grad: 1.0620 LR: 0.00100  \n",
      "Epoch: [1][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.6328 Grad: 0.9389 LR: 0.00100  \n",
      "Epoch: [1][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.6015 Grad: 0.6947 LR: 0.00100  \n",
      "Epoch: [1][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.5819 Grad: 0.5886 LR: 0.00100  \n",
      "Epoch: [1][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.5669 Grad: 0.6919 LR: 0.00100  \n",
      "Epoch: [1][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.5563 Grad: 0.4764 LR: 0.00100  \n",
      "Epoch: [1][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.5476 Grad: 0.4018 LR: 0.00100  \n",
      "Epoch: [1][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.5403 Grad: 0.4436 LR: 0.00100  \n",
      "Epoch: [1][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.5344 Grad: 0.6708 LR: 0.00100  \n",
      "Epoch: [1][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.5294 Grad: 0.5167 LR: 0.00100  \n",
      "Epoch: [1][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.5251 Grad: 0.4249 LR: 0.00100  \n",
      "Epoch: [1][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.5212 Grad: 0.3193 LR: 0.00100  \n",
      "Epoch: [1][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.5176 Grad: 0.3002 LR: 0.00100  \n",
      "Epoch: [1][1400/1929] Elapsed 13m 58s (remain 5m 16s) Loss avg.: 0.5145 Grad: 0.3173 LR: 0.00100  \n",
      "Epoch: [1][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.5118 Grad: 0.4605 LR: 0.00100  \n",
      "Epoch: [1][1600/1929] Elapsed 15m 58s (remain 3m 16s) Loss avg.: 0.5093 Grad: 0.3927 LR: 0.00100  \n",
      "Epoch: [1][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.5070 Grad: 0.3837 LR: 0.00100  \n",
      "Epoch: [1][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.5050 Grad: 0.4249 LR: 0.00100  \n",
      "Epoch: [1][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.5030 Grad: 0.3150 LR: 0.00100  \n",
      "Epoch: [1][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.5025 Grad: 0.3361 LR: 0.00100  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 29s) Loss avg.: 0.4556 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4691 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4689 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4696 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.5025  avg_val_loss: 0.4696  time: 1189s\n",
      "Epoch 1 - Accuracy: 0.7958357684925138\n",
      "Epoch 1 - Save Best Score: 0.7958 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1929] Elapsed 0m 2s (remain 64m 49s) Loss avg.: 0.4815 Grad: 0.4135 LR: 0.00098  \n",
      "Epoch: [2][100/1929] Elapsed 1m 1s (remain 18m 40s) Loss avg.: 0.4643 Grad: 0.3736 LR: 0.00098  \n",
      "Epoch: [2][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4633 Grad: 0.3228 LR: 0.00098  \n",
      "Epoch: [2][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4638 Grad: 0.2983 LR: 0.00098  \n",
      "Epoch: [2][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4636 Grad: 0.2739 LR: 0.00098  \n",
      "Epoch: [2][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4631 Grad: 0.2615 LR: 0.00098  \n",
      "Epoch: [2][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4628 Grad: 0.3200 LR: 0.00098  \n",
      "Epoch: [2][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4625 Grad: 0.2869 LR: 0.00098  \n",
      "Epoch: [2][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4623 Grad: 0.2936 LR: 0.00098  \n",
      "Epoch: [2][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4620 Grad: 0.3145 LR: 0.00098  \n",
      "Epoch: [2][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4618 Grad: 0.2916 LR: 0.00098  \n",
      "Epoch: [2][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4616 Grad: 0.2994 LR: 0.00098  \n",
      "Epoch: [2][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4614 Grad: 0.2755 LR: 0.00098  \n",
      "Epoch: [2][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4611 Grad: 0.2674 LR: 0.00098  \n",
      "Epoch: [2][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4607 Grad: 0.3394 LR: 0.00098  \n",
      "Epoch: [2][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4605 Grad: 0.3240 LR: 0.00098  \n",
      "Epoch: [2][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4602 Grad: 0.2913 LR: 0.00098  \n",
      "Epoch: [2][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4600 Grad: 0.2613 LR: 0.00098  \n",
      "Epoch: [2][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4598 Grad: 0.2883 LR: 0.00098  \n",
      "Epoch: [2][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4595 Grad: 0.3135 LR: 0.00098  \n",
      "Epoch: [2][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4594 Grad: 0.3301 LR: 0.00098  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 30s) Loss avg.: 0.4373 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4589 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4579 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4588 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4594  avg_val_loss: 0.4588  time: 1188s\n",
      "Epoch 2 - Accuracy: 0.8013901176017921\n",
      "Epoch 2 - Save Best Score: 0.8014 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1929] Elapsed 0m 2s (remain 64m 49s) Loss avg.: 0.4615 Grad: 0.3924 LR: 0.00091  \n",
      "Epoch: [3][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4501 Grad: 0.3660 LR: 0.00091  \n",
      "Epoch: [3][200/1929] Elapsed 2m 1s (remain 17m 25s) Loss avg.: 0.4501 Grad: 0.3260 LR: 0.00091  \n",
      "Epoch: [3][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4507 Grad: 0.3999 LR: 0.00091  \n",
      "Epoch: [3][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4504 Grad: 0.2263 LR: 0.00091  \n",
      "Epoch: [3][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4506 Grad: 0.3525 LR: 0.00091  \n",
      "Epoch: [3][600/1929] Elapsed 5m 59s (remain 13m 15s) Loss avg.: 0.4507 Grad: 0.3002 LR: 0.00091  \n",
      "Epoch: [3][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4503 Grad: 0.3823 LR: 0.00091  \n",
      "Epoch: [3][800/1929] Elapsed 7m 59s (remain 11m 14s) Loss avg.: 0.4504 Grad: 0.3240 LR: 0.00091  \n",
      "Epoch: [3][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4505 Grad: 0.3315 LR: 0.00091  \n",
      "Epoch: [3][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4504 Grad: 0.2857 LR: 0.00091  \n",
      "Epoch: [3][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4506 Grad: 0.3146 LR: 0.00091  \n",
      "Epoch: [3][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4506 Grad: 0.3615 LR: 0.00091  \n",
      "Epoch: [3][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4506 Grad: 0.2207 LR: 0.00091  \n",
      "Epoch: [3][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4506 Grad: 0.2771 LR: 0.00091  \n",
      "Epoch: [3][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4505 Grad: 0.2955 LR: 0.00091  \n",
      "Epoch: [3][1600/1929] Elapsed 15m 56s (remain 3m 16s) Loss avg.: 0.4504 Grad: 0.2082 LR: 0.00091  \n",
      "Epoch: [3][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4503 Grad: 0.2387 LR: 0.00091  \n",
      "Epoch: [3][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4503 Grad: 0.2399 LR: 0.00091  \n",
      "Epoch: [3][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4501 Grad: 0.2482 LR: 0.00091  \n",
      "Epoch: [3][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4501 Grad: 0.3113 LR: 0.00091  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 36s) Loss avg.: 0.4307 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4494 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4484 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4492 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.4501  avg_val_loss: 0.4492  time: 1188s\n",
      "Epoch 3 - Accuracy: 0.8066136251346321\n",
      "Epoch 3 - Save Best Score: 0.8066 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/1929] Elapsed 0m 1s (remain 60m 39s) Loss avg.: 0.4390 Grad: 0.2219 LR: 0.00081  \n",
      "Epoch: [4][100/1929] Elapsed 1m 1s (remain 18m 35s) Loss avg.: 0.4444 Grad: 0.2344 LR: 0.00081  \n",
      "Epoch: [4][200/1929] Elapsed 2m 1s (remain 17m 22s) Loss avg.: 0.4438 Grad: 0.2427 LR: 0.00081  \n",
      "Epoch: [4][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4434 Grad: 0.2355 LR: 0.00081  \n",
      "Epoch: [4][400/1929] Elapsed 4m 0s (remain 15m 18s) Loss avg.: 0.4435 Grad: 0.3947 LR: 0.00081  \n",
      "Epoch: [4][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4438 Grad: 0.2200 LR: 0.00081  \n",
      "Epoch: [4][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4443 Grad: 0.2350 LR: 0.00081  \n",
      "Epoch: [4][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4442 Grad: 0.2131 LR: 0.00081  \n",
      "Epoch: [4][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4444 Grad: 0.1816 LR: 0.00081  \n",
      "Epoch: [4][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4442 Grad: 0.2061 LR: 0.00081  \n",
      "Epoch: [4][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4441 Grad: 0.2268 LR: 0.00081  \n",
      "Epoch: [4][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4443 Grad: 0.1943 LR: 0.00081  \n",
      "Epoch: [4][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4444 Grad: 0.2044 LR: 0.00081  \n",
      "Epoch: [4][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4443 Grad: 0.1976 LR: 0.00081  \n",
      "Epoch: [4][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4443 Grad: 0.2763 LR: 0.00081  \n",
      "Epoch: [4][1500/1929] Elapsed 14m 56s (remain 4m 15s) Loss avg.: 0.4444 Grad: 0.2607 LR: 0.00081  \n",
      "Epoch: [4][1600/1929] Elapsed 15m 56s (remain 3m 15s) Loss avg.: 0.4444 Grad: 0.2933 LR: 0.00081  \n",
      "Epoch: [4][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4444 Grad: 0.2577 LR: 0.00081  \n",
      "Epoch: [4][1800/1929] Elapsed 17m 55s (remain 1m 16s) Loss avg.: 0.4444 Grad: 0.2296 LR: 0.00081  \n",
      "Epoch: [4][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4444 Grad: 0.2178 LR: 0.00081  \n",
      "Epoch: [4][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4443 Grad: 0.2385 LR: 0.00081  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 35s) Loss avg.: 0.4256 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4456 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4448 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4456 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.4443  avg_val_loss: 0.4456  time: 1188s\n",
      "Epoch 4 - Accuracy: 0.8078888955283919\n",
      "Epoch 4 - Save Best Score: 0.8079 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/1929] Elapsed 0m 1s (remain 61m 37s) Loss avg.: 0.4508 Grad: 0.2274 LR: 0.00069  \n",
      "Epoch: [5][100/1929] Elapsed 1m 1s (remain 18m 34s) Loss avg.: 0.4377 Grad: 0.2136 LR: 0.00069  \n",
      "Epoch: [5][200/1929] Elapsed 2m 1s (remain 17m 22s) Loss avg.: 0.4388 Grad: 0.2361 LR: 0.00069  \n",
      "Epoch: [5][300/1929] Elapsed 3m 0s (remain 16m 18s) Loss avg.: 0.4396 Grad: 0.2405 LR: 0.00069  \n",
      "Epoch: [5][400/1929] Elapsed 4m 0s (remain 15m 16s) Loss avg.: 0.4398 Grad: 0.2370 LR: 0.00069  \n",
      "Epoch: [5][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4397 Grad: 0.2331 LR: 0.00069  \n",
      "Epoch: [5][600/1929] Elapsed 5m 59s (remain 13m 15s) Loss avg.: 0.4398 Grad: 0.2431 LR: 0.00069  \n",
      "Epoch: [5][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4399 Grad: 0.2421 LR: 0.00069  \n",
      "Epoch: [5][800/1929] Elapsed 7m 59s (remain 11m 14s) Loss avg.: 0.4401 Grad: 0.2150 LR: 0.00069  \n",
      "Epoch: [5][900/1929] Elapsed 8m 58s (remain 10m 14s) Loss avg.: 0.4401 Grad: 0.3198 LR: 0.00069  \n",
      "Epoch: [5][1000/1929] Elapsed 9m 58s (remain 9m 14s) Loss avg.: 0.4402 Grad: 0.3036 LR: 0.00069  \n",
      "Epoch: [5][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4400 Grad: 0.2085 LR: 0.00069  \n",
      "Epoch: [5][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4397 Grad: 0.2751 LR: 0.00069  \n",
      "Epoch: [5][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4396 Grad: 0.3193 LR: 0.00069  \n",
      "Epoch: [5][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4396 Grad: 0.2395 LR: 0.00069  \n",
      "Epoch: [5][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4396 Grad: 0.2235 LR: 0.00069  \n",
      "Epoch: [5][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4396 Grad: 0.3045 LR: 0.00069  \n",
      "Epoch: [5][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4396 Grad: 0.1991 LR: 0.00069  \n",
      "Epoch: [5][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4395 Grad: 0.1820 LR: 0.00069  \n",
      "Epoch: [5][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4395 Grad: 0.1853 LR: 0.00069  \n",
      "Epoch: [5][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4395 Grad: 0.2455 LR: 0.00069  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 4m 5s) Loss avg.: 0.4256 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4420 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4417 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4424 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.4395  avg_val_loss: 0.4424  time: 1189s\n",
      "Epoch 5 - Accuracy: 0.809557677929369\n",
      "Epoch 5 - Save Best Score: 0.8096 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/1929] Elapsed 0m 1s (remain 60m 23s) Loss avg.: 0.4317 Grad: 0.2566 LR: 0.00055  \n",
      "Epoch: [6][100/1929] Elapsed 1m 1s (remain 18m 36s) Loss avg.: 0.4322 Grad: 0.1928 LR: 0.00055  \n",
      "Epoch: [6][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4329 Grad: 0.2434 LR: 0.00055  \n",
      "Epoch: [6][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4335 Grad: 0.2419 LR: 0.00055  \n",
      "Epoch: [6][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4340 Grad: 0.2310 LR: 0.00055  \n",
      "Epoch: [6][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4345 Grad: 0.2883 LR: 0.00055  \n",
      "Epoch: [6][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4345 Grad: 0.2166 LR: 0.00055  \n",
      "Epoch: [6][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4344 Grad: 0.2033 LR: 0.00055  \n",
      "Epoch: [6][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4348 Grad: 0.2539 LR: 0.00055  \n",
      "Epoch: [6][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4349 Grad: 0.2206 LR: 0.00055  \n",
      "Epoch: [6][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4351 Grad: 0.2082 LR: 0.00055  \n",
      "Epoch: [6][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4353 Grad: 0.2078 LR: 0.00055  \n",
      "Epoch: [6][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4352 Grad: 0.2327 LR: 0.00055  \n",
      "Epoch: [6][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4352 Grad: 0.2344 LR: 0.00055  \n",
      "Epoch: [6][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4353 Grad: 0.2110 LR: 0.00055  \n",
      "Epoch: [6][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4353 Grad: 0.2940 LR: 0.00055  \n",
      "Epoch: [6][1600/1929] Elapsed 15m 56s (remain 3m 16s) Loss avg.: 0.4353 Grad: 0.2215 LR: 0.00055  \n",
      "Epoch: [6][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4352 Grad: 0.2124 LR: 0.00055  \n",
      "Epoch: [6][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4352 Grad: 0.1828 LR: 0.00055  \n",
      "Epoch: [6][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4352 Grad: 0.2159 LR: 0.00055  \n",
      "Epoch: [6][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4352 Grad: 0.1759 LR: 0.00055  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 29s) Loss avg.: 0.4218 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4415 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4408 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4417 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.4352  avg_val_loss: 0.4417  time: 1188s\n",
      "Epoch 6 - Accuracy: 0.8095256139880401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/1929] Elapsed 0m 1s (remain 61m 6s) Loss avg.: 0.4211 Grad: 0.1874 LR: 0.00041  \n",
      "Epoch: [7][100/1929] Elapsed 1m 1s (remain 18m 35s) Loss avg.: 0.4290 Grad: 0.1870 LR: 0.00041  \n",
      "Epoch: [7][200/1929] Elapsed 2m 1s (remain 17m 22s) Loss avg.: 0.4294 Grad: 0.2337 LR: 0.00041  \n",
      "Epoch: [7][300/1929] Elapsed 3m 0s (remain 16m 18s) Loss avg.: 0.4294 Grad: 0.2215 LR: 0.00041  \n",
      "Epoch: [7][400/1929] Elapsed 4m 0s (remain 15m 16s) Loss avg.: 0.4293 Grad: 0.2146 LR: 0.00041  \n",
      "Epoch: [7][500/1929] Elapsed 5m 0s (remain 14m 15s) Loss avg.: 0.4294 Grad: 0.2143 LR: 0.00041  \n",
      "Epoch: [7][600/1929] Elapsed 5m 59s (remain 13m 15s) Loss avg.: 0.4297 Grad: 0.2578 LR: 0.00041  \n",
      "Epoch: [7][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4301 Grad: 0.2138 LR: 0.00041  \n",
      "Epoch: [7][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4303 Grad: 0.2903 LR: 0.00041  \n",
      "Epoch: [7][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4302 Grad: 0.2215 LR: 0.00041  \n",
      "Epoch: [7][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4301 Grad: 0.1896 LR: 0.00041  \n",
      "Epoch: [7][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4303 Grad: 0.2319 LR: 0.00041  \n",
      "Epoch: [7][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4303 Grad: 0.1793 LR: 0.00041  \n",
      "Epoch: [7][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4305 Grad: 0.2245 LR: 0.00041  \n",
      "Epoch: [7][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4306 Grad: 0.2236 LR: 0.00041  \n",
      "Epoch: [7][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4308 Grad: 0.1884 LR: 0.00041  \n",
      "Epoch: [7][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4308 Grad: 0.1950 LR: 0.00041  \n",
      "Epoch: [7][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4309 Grad: 0.1858 LR: 0.00041  \n",
      "Epoch: [7][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4309 Grad: 0.2617 LR: 0.00041  \n",
      "Epoch: [7][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4310 Grad: 0.2844 LR: 0.00041  \n",
      "Epoch: [7][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4310 Grad: 0.2270 LR: 0.00041  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 33s) Loss avg.: 0.4245 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4385 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4377 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4385 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.4310  avg_val_loss: 0.4385  time: 1189s\n",
      "Epoch 7 - Accuracy: 0.8114756846015837\n",
      "Epoch 7 - Save Best Score: 0.8115 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/1929] Elapsed 0m 2s (remain 65m 6s) Loss avg.: 0.4115 Grad: 0.2018 LR: 0.00029  \n",
      "Epoch: [8][100/1929] Elapsed 1m 1s (remain 18m 41s) Loss avg.: 0.4264 Grad: 0.2600 LR: 0.00029  \n",
      "Epoch: [8][200/1929] Elapsed 2m 1s (remain 17m 25s) Loss avg.: 0.4271 Grad: 0.2193 LR: 0.00029  \n",
      "Epoch: [8][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4270 Grad: 0.2156 LR: 0.00029  \n",
      "Epoch: [8][400/1929] Elapsed 4m 1s (remain 15m 18s) Loss avg.: 0.4267 Grad: 0.2433 LR: 0.00029  \n",
      "Epoch: [8][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4268 Grad: 0.2146 LR: 0.00029  \n",
      "Epoch: [8][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4269 Grad: 0.2054 LR: 0.00029  \n",
      "Epoch: [8][700/1929] Elapsed 7m 0s (remain 12m 15s) Loss avg.: 0.4269 Grad: 0.2042 LR: 0.00029  \n",
      "Epoch: [8][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4267 Grad: 0.2174 LR: 0.00029  \n",
      "Epoch: [8][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4265 Grad: 0.2429 LR: 0.00029  \n",
      "Epoch: [8][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4267 Grad: 0.2480 LR: 0.00029  \n",
      "Epoch: [8][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4268 Grad: 0.2176 LR: 0.00029  \n",
      "Epoch: [8][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4268 Grad: 0.2715 LR: 0.00029  \n",
      "Epoch: [8][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4268 Grad: 0.2284 LR: 0.00029  \n",
      "Epoch: [8][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4269 Grad: 0.2213 LR: 0.00029  \n",
      "Epoch: [8][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4270 Grad: 0.2050 LR: 0.00029  \n",
      "Epoch: [8][1600/1929] Elapsed 15m 56s (remain 3m 16s) Loss avg.: 0.4271 Grad: 0.2472 LR: 0.00029  \n",
      "Epoch: [8][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4272 Grad: 0.1996 LR: 0.00029  \n",
      "Epoch: [8][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4271 Grad: 0.1833 LR: 0.00029  \n",
      "Epoch: [8][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4271 Grad: 0.2040 LR: 0.00029  \n",
      "Epoch: [8][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4271 Grad: 0.2324 LR: 0.00029  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 33s) Loss avg.: 0.4224 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4382 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4376 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4384 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.4271  avg_val_loss: 0.4384  time: 1189s\n",
      "Epoch 8 - Accuracy: 0.8114232163339546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/1929] Elapsed 0m 1s (remain 61m 15s) Loss avg.: 0.4235 Grad: 0.2589 LR: 0.00019  \n",
      "Epoch: [9][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4231 Grad: 0.2319 LR: 0.00019  \n",
      "Epoch: [9][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4235 Grad: 0.2463 LR: 0.00019  \n",
      "Epoch: [9][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4234 Grad: 0.2038 LR: 0.00019  \n",
      "Epoch: [9][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4230 Grad: 0.1953 LR: 0.00019  \n",
      "Epoch: [9][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4231 Grad: 0.2124 LR: 0.00019  \n",
      "Epoch: [9][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4231 Grad: 0.2267 LR: 0.00019  \n",
      "Epoch: [9][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4232 Grad: 0.2021 LR: 0.00019  \n",
      "Epoch: [9][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4232 Grad: 0.2237 LR: 0.00019  \n",
      "Epoch: [9][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4233 Grad: 0.2191 LR: 0.00019  \n",
      "Epoch: [9][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4232 Grad: 0.2506 LR: 0.00019  \n",
      "Epoch: [9][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4233 Grad: 0.1929 LR: 0.00019  \n",
      "Epoch: [9][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4234 Grad: 0.2104 LR: 0.00019  \n",
      "Epoch: [9][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4236 Grad: 0.1947 LR: 0.00019  \n",
      "Epoch: [9][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4235 Grad: 0.2527 LR: 0.00019  \n",
      "Epoch: [9][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4235 Grad: 0.2028 LR: 0.00019  \n",
      "Epoch: [9][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4234 Grad: 0.2069 LR: 0.00019  \n",
      "Epoch: [9][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4234 Grad: 0.2027 LR: 0.00019  \n",
      "Epoch: [9][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4236 Grad: 0.2138 LR: 0.00019  \n",
      "Epoch: [9][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4236 Grad: 0.1915 LR: 0.00019  \n",
      "Epoch: [9][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4237 Grad: 0.2202 LR: 0.00019  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 29s) Loss avg.: 0.4186 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4361 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4353 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4361 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.4237  avg_val_loss: 0.4361  time: 1189s\n",
      "Epoch 9 - Accuracy: 0.8127640720622507\n",
      "Epoch 9 - Save Best Score: 0.8128 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/1929] Elapsed 0m 1s (remain 60m 19s) Loss avg.: 0.4455 Grad: 0.2237 LR: 0.00012  \n",
      "Epoch: [10][100/1929] Elapsed 1m 1s (remain 18m 36s) Loss avg.: 0.4194 Grad: 0.2195 LR: 0.00012  \n",
      "Epoch: [10][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4199 Grad: 0.2395 LR: 0.00012  \n",
      "Epoch: [10][300/1929] Elapsed 3m 0s (remain 16m 18s) Loss avg.: 0.4203 Grad: 0.2335 LR: 0.00012  \n",
      "Epoch: [10][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4203 Grad: 0.2117 LR: 0.00012  \n",
      "Epoch: [10][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4201 Grad: 0.2437 LR: 0.00012  \n",
      "Epoch: [10][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4203 Grad: 0.2111 LR: 0.00012  \n",
      "Epoch: [10][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4203 Grad: 0.2255 LR: 0.00012  \n",
      "Epoch: [10][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4204 Grad: 0.2237 LR: 0.00012  \n",
      "Epoch: [10][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4206 Grad: 0.2804 LR: 0.00012  \n",
      "Epoch: [10][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4208 Grad: 0.2356 LR: 0.00012  \n",
      "Epoch: [10][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4209 Grad: 0.2129 LR: 0.00012  \n",
      "Epoch: [10][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4211 Grad: 0.2809 LR: 0.00012  \n",
      "Epoch: [10][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4210 Grad: 0.2519 LR: 0.00012  \n",
      "Epoch: [10][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4212 Grad: 0.2298 LR: 0.00012  \n",
      "Epoch: [10][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4210 Grad: 0.2326 LR: 0.00012  \n",
      "Epoch: [10][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4211 Grad: 0.2255 LR: 0.00012  \n",
      "Epoch: [10][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4212 Grad: 0.2322 LR: 0.00012  \n",
      "Epoch: [10][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4211 Grad: 0.2360 LR: 0.00012  \n",
      "Epoch: [10][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4211 Grad: 0.2293 LR: 0.00012  \n",
      "Epoch: [10][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4211 Grad: 0.2316 LR: 0.00012  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 31s) Loss avg.: 0.4184 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4355 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4348 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4356 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.4211  avg_val_loss: 0.4356  time: 1189s\n",
      "Epoch 10 - Accuracy: 0.8130045516222169\n",
      "Epoch 10 - Save Best Score: 0.8130 Model\n",
      "Epoch 10 - Save final model\n",
      "========== fold: 4 result ==========\n",
      "Score: 0.81300\n",
      "========== fold: 5 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load pre-train weight.\n",
      "Epoch: [1][0/1929] Elapsed 0m 1s (remain 60m 35s) Loss avg.: 1.3904 Grad: 0.3300 LR: 0.00100  \n",
      "Epoch: [1][100/1929] Elapsed 1m 1s (remain 18m 35s) Loss avg.: 0.6834 Grad: 0.5733 LR: 0.00100  \n",
      "Epoch: [1][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.6236 Grad: 0.6722 LR: 0.00100  \n",
      "Epoch: [1][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.5961 Grad: 0.6129 LR: 0.00100  \n",
      "Epoch: [1][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.5776 Grad: 0.4426 LR: 0.00100  \n",
      "Epoch: [1][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.5637 Grad: 0.6764 LR: 0.00100  \n",
      "Epoch: [1][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.5540 Grad: 0.6376 LR: 0.00100  \n",
      "Epoch: [1][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.5458 Grad: 0.4757 LR: 0.00100  \n",
      "Epoch: [1][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.5389 Grad: 0.4543 LR: 0.00100  \n",
      "Epoch: [1][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.5331 Grad: 0.5135 LR: 0.00100  \n",
      "Epoch: [1][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.5281 Grad: 0.5002 LR: 0.00100  \n",
      "Epoch: [1][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.5239 Grad: 0.3978 LR: 0.00100  \n",
      "Epoch: [1][1200/1929] Elapsed 11m 59s (remain 7m 15s) Loss avg.: 0.5204 Grad: 0.4885 LR: 0.00100  \n",
      "Epoch: [1][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.5172 Grad: 0.5404 LR: 0.00100  \n",
      "Epoch: [1][1400/1929] Elapsed 13m 58s (remain 5m 16s) Loss avg.: 0.5142 Grad: 0.4610 LR: 0.00100  \n",
      "Epoch: [1][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.5117 Grad: 0.4245 LR: 0.00100  \n",
      "Epoch: [1][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.5092 Grad: 0.3442 LR: 0.00100  \n",
      "Epoch: [1][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.5070 Grad: 0.3022 LR: 0.00100  \n",
      "Epoch: [1][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.5048 Grad: 0.3929 LR: 0.00100  \n",
      "Epoch: [1][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.5029 Grad: 0.3796 LR: 0.00100  \n",
      "Epoch: [1][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.5024 Grad: 0.3348 LR: 0.00100  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 56s) Loss avg.: 0.4728 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4700 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4700 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4702 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.5024  avg_val_loss: 0.4702  time: 1189s\n",
      "Epoch 1 - Accuracy: 0.7959305028646216\n",
      "Epoch 1 - Save Best Score: 0.7959 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1929] Elapsed 0m 1s (remain 61m 10s) Loss avg.: 0.4619 Grad: 0.4235 LR: 0.00098  \n",
      "Epoch: [2][100/1929] Elapsed 1m 1s (remain 18m 35s) Loss avg.: 0.4631 Grad: 0.3799 LR: 0.00098  \n",
      "Epoch: [2][200/1929] Elapsed 2m 1s (remain 17m 22s) Loss avg.: 0.4623 Grad: 0.5932 LR: 0.00098  \n",
      "Epoch: [2][300/1929] Elapsed 3m 0s (remain 16m 18s) Loss avg.: 0.4628 Grad: 0.4341 LR: 0.00098  \n",
      "Epoch: [2][400/1929] Elapsed 4m 0s (remain 15m 16s) Loss avg.: 0.4626 Grad: 0.3073 LR: 0.00098  \n",
      "Epoch: [2][500/1929] Elapsed 5m 0s (remain 14m 15s) Loss avg.: 0.4623 Grad: 0.3800 LR: 0.00098  \n",
      "Epoch: [2][600/1929] Elapsed 5m 59s (remain 13m 15s) Loss avg.: 0.4622 Grad: 0.4458 LR: 0.00098  \n",
      "Epoch: [2][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4622 Grad: 0.3974 LR: 0.00098  \n",
      "Epoch: [2][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4621 Grad: 0.3847 LR: 0.00098  \n",
      "Epoch: [2][900/1929] Elapsed 8m 58s (remain 10m 14s) Loss avg.: 0.4619 Grad: 0.3212 LR: 0.00098  \n",
      "Epoch: [2][1000/1929] Elapsed 9m 58s (remain 9m 14s) Loss avg.: 0.4616 Grad: 0.3272 LR: 0.00098  \n",
      "Epoch: [2][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4615 Grad: 0.4432 LR: 0.00098  \n",
      "Epoch: [2][1200/1929] Elapsed 11m 57s (remain 7m 15s) Loss avg.: 0.4615 Grad: 0.2943 LR: 0.00098  \n",
      "Epoch: [2][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4613 Grad: 0.3183 LR: 0.00098  \n",
      "Epoch: [2][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4611 Grad: 0.3437 LR: 0.00098  \n",
      "Epoch: [2][1500/1929] Elapsed 14m 56s (remain 4m 15s) Loss avg.: 0.4608 Grad: 0.3290 LR: 0.00098  \n",
      "Epoch: [2][1600/1929] Elapsed 15m 56s (remain 3m 15s) Loss avg.: 0.4605 Grad: 0.3480 LR: 0.00098  \n",
      "Epoch: [2][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4604 Grad: 0.2626 LR: 0.00098  \n",
      "Epoch: [2][1800/1929] Elapsed 17m 55s (remain 1m 16s) Loss avg.: 0.4601 Grad: 0.2724 LR: 0.00098  \n",
      "Epoch: [2][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4598 Grad: 0.2246 LR: 0.00098  \n",
      "Epoch: [2][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4597 Grad: 0.3194 LR: 0.00098  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 30s) Loss avg.: 0.4603 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4578 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4585 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4587 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4597  avg_val_loss: 0.4587  time: 1188s\n",
      "Epoch 2 - Accuracy: 0.8018958534036602\n",
      "Epoch 2 - Save Best Score: 0.8019 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1929] Elapsed 0m 2s (remain 77m 1s) Loss avg.: 0.4471 Grad: 0.4031 LR: 0.00091  \n",
      "Epoch: [3][100/1929] Elapsed 1m 2s (remain 18m 47s) Loss avg.: 0.4507 Grad: 0.2335 LR: 0.00091  \n",
      "Epoch: [3][200/1929] Elapsed 2m 1s (remain 17m 28s) Loss avg.: 0.4509 Grad: 0.4523 LR: 0.00091  \n",
      "Epoch: [3][300/1929] Elapsed 3m 1s (remain 16m 22s) Loss avg.: 0.4511 Grad: 0.2625 LR: 0.00091  \n",
      "Epoch: [3][400/1929] Elapsed 4m 1s (remain 15m 19s) Loss avg.: 0.4508 Grad: 0.2949 LR: 0.00091  \n",
      "Epoch: [3][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4509 Grad: 0.2531 LR: 0.00091  \n",
      "Epoch: [3][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4510 Grad: 0.3782 LR: 0.00091  \n",
      "Epoch: [3][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4510 Grad: 0.2216 LR: 0.00091  \n",
      "Epoch: [3][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4511 Grad: 0.2810 LR: 0.00091  \n",
      "Epoch: [3][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4512 Grad: 0.3624 LR: 0.00091  \n",
      "Epoch: [3][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4510 Grad: 0.2318 LR: 0.00091  \n",
      "Epoch: [3][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4512 Grad: 0.2777 LR: 0.00091  \n",
      "Epoch: [3][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4512 Grad: 0.4098 LR: 0.00091  \n",
      "Epoch: [3][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4511 Grad: 0.2913 LR: 0.00091  \n",
      "Epoch: [3][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4511 Grad: 0.3270 LR: 0.00091  \n",
      "Epoch: [3][1500/1929] Elapsed 14m 57s (remain 4m 16s) Loss avg.: 0.4509 Grad: 0.2459 LR: 0.00091  \n",
      "Epoch: [3][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4508 Grad: 0.2917 LR: 0.00091  \n",
      "Epoch: [3][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4507 Grad: 0.3056 LR: 0.00091  \n",
      "Epoch: [3][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4506 Grad: 0.2813 LR: 0.00091  \n",
      "Epoch: [3][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4505 Grad: 0.2290 LR: 0.00091  \n",
      "Epoch: [3][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4505 Grad: 0.3008 LR: 0.00091  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 27s) Loss avg.: 0.4675 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4533 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4537 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4540 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.4505  avg_val_loss: 0.4540  time: 1189s\n",
      "Epoch 3 - Accuracy: 0.8042496381875711\n",
      "Epoch 3 - Save Best Score: 0.8042 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/1929] Elapsed 0m 1s (remain 60m 25s) Loss avg.: 0.4481 Grad: 0.2076 LR: 0.00081  \n",
      "Epoch: [4][100/1929] Elapsed 1m 1s (remain 18m 35s) Loss avg.: 0.4459 Grad: 0.2170 LR: 0.00081  \n",
      "Epoch: [4][200/1929] Elapsed 2m 1s (remain 17m 25s) Loss avg.: 0.4449 Grad: 0.2428 LR: 0.00081  \n",
      "Epoch: [4][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4447 Grad: 0.2275 LR: 0.00081  \n",
      "Epoch: [4][400/1929] Elapsed 4m 0s (remain 15m 18s) Loss avg.: 0.4440 Grad: 0.2573 LR: 0.00081  \n",
      "Epoch: [4][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4444 Grad: 0.3092 LR: 0.00081  \n",
      "Epoch: [4][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4443 Grad: 0.2704 LR: 0.00081  \n",
      "Epoch: [4][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4441 Grad: 0.2779 LR: 0.00081  \n",
      "Epoch: [4][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4441 Grad: 0.2954 LR: 0.00081  \n",
      "Epoch: [4][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4442 Grad: 0.2536 LR: 0.00081  \n",
      "Epoch: [4][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4441 Grad: 0.2854 LR: 0.00081  \n",
      "Epoch: [4][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4442 Grad: 0.2253 LR: 0.00081  \n",
      "Epoch: [4][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4442 Grad: 0.2249 LR: 0.00081  \n",
      "Epoch: [4][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4442 Grad: 0.2536 LR: 0.00081  \n",
      "Epoch: [4][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4443 Grad: 0.2451 LR: 0.00081  \n",
      "Epoch: [4][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4443 Grad: 0.3005 LR: 0.00081  \n",
      "Epoch: [4][1600/1929] Elapsed 15m 56s (remain 3m 16s) Loss avg.: 0.4442 Grad: 0.2561 LR: 0.00081  \n",
      "Epoch: [4][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4444 Grad: 0.1974 LR: 0.00081  \n",
      "Epoch: [4][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4444 Grad: 0.2385 LR: 0.00081  \n",
      "Epoch: [4][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4444 Grad: 0.2336 LR: 0.00081  \n",
      "Epoch: [4][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4444 Grad: 0.1944 LR: 0.00081  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 31s) Loss avg.: 0.4542 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4484 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4486 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4488 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.4444  avg_val_loss: 0.4488  time: 1188s\n",
      "Epoch 4 - Accuracy: 0.8065611568670031\n",
      "Epoch 4 - Save Best Score: 0.8066 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/1929] Elapsed 0m 1s (remain 60m 58s) Loss avg.: 0.4648 Grad: 0.2256 LR: 0.00069  \n",
      "Epoch: [5][100/1929] Elapsed 1m 1s (remain 18m 36s) Loss avg.: 0.4391 Grad: 0.2409 LR: 0.00069  \n",
      "Epoch: [5][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4394 Grad: 0.3421 LR: 0.00069  \n",
      "Epoch: [5][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4395 Grad: 0.2366 LR: 0.00069  \n",
      "Epoch: [5][400/1929] Elapsed 4m 1s (remain 15m 18s) Loss avg.: 0.4393 Grad: 0.2141 LR: 0.00069  \n",
      "Epoch: [5][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4388 Grad: 0.2131 LR: 0.00069  \n",
      "Epoch: [5][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4390 Grad: 0.2168 LR: 0.00069  \n",
      "Epoch: [5][700/1929] Elapsed 7m 0s (remain 12m 15s) Loss avg.: 0.4389 Grad: 0.3210 LR: 0.00069  \n",
      "Epoch: [5][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4390 Grad: 0.2067 LR: 0.00069  \n",
      "Epoch: [5][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4392 Grad: 0.2234 LR: 0.00069  \n",
      "Epoch: [5][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4393 Grad: 0.2451 LR: 0.00069  \n",
      "Epoch: [5][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4393 Grad: 0.2065 LR: 0.00069  \n",
      "Epoch: [5][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4394 Grad: 0.1825 LR: 0.00069  \n",
      "Epoch: [5][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4395 Grad: 0.2415 LR: 0.00069  \n",
      "Epoch: [5][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4395 Grad: 0.2677 LR: 0.00069  \n",
      "Epoch: [5][1500/1929] Elapsed 14m 57s (remain 4m 16s) Loss avg.: 0.4395 Grad: 0.2175 LR: 0.00069  \n",
      "Epoch: [5][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4394 Grad: 0.2648 LR: 0.00069  \n",
      "Epoch: [5][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4395 Grad: 0.2267 LR: 0.00069  \n",
      "Epoch: [5][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4396 Grad: 0.1878 LR: 0.00069  \n",
      "Epoch: [5][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4396 Grad: 0.2049 LR: 0.00069  \n",
      "Epoch: [5][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4396 Grad: 0.2079 LR: 0.00069  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 29s) Loss avg.: 0.4567 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4454 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4458 \n",
      "Eval: [214/215] Elapsed 0m 34s (remain 0m 0s) Loss avg.: 0.4461 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.4396  avg_val_loss: 0.4461  time: 1189s\n",
      "Epoch 5 - Accuracy: 0.807766469570591\n",
      "Epoch 5 - Save Best Score: 0.8078 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/1929] Elapsed 0m 1s (remain 60m 16s) Loss avg.: 0.4547 Grad: 0.2012 LR: 0.00055  \n",
      "Epoch: [6][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4351 Grad: 0.2474 LR: 0.00055  \n",
      "Epoch: [6][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4343 Grad: 0.2819 LR: 0.00055  \n",
      "Epoch: [6][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4345 Grad: 0.2559 LR: 0.00055  \n",
      "Epoch: [6][400/1929] Elapsed 4m 0s (remain 15m 18s) Loss avg.: 0.4348 Grad: 0.2253 LR: 0.00055  \n",
      "Epoch: [6][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4349 Grad: 0.2316 LR: 0.00055  \n",
      "Epoch: [6][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4348 Grad: 0.2267 LR: 0.00055  \n",
      "Epoch: [6][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4348 Grad: 0.2302 LR: 0.00055  \n",
      "Epoch: [6][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4347 Grad: 0.2297 LR: 0.00055  \n",
      "Epoch: [6][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4348 Grad: 0.2625 LR: 0.00055  \n",
      "Epoch: [6][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4350 Grad: 0.2402 LR: 0.00055  \n",
      "Epoch: [6][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4351 Grad: 0.1744 LR: 0.00055  \n",
      "Epoch: [6][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4351 Grad: 0.1704 LR: 0.00055  \n",
      "Epoch: [6][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4351 Grad: 0.2660 LR: 0.00055  \n",
      "Epoch: [6][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4353 Grad: 0.2677 LR: 0.00055  \n",
      "Epoch: [6][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4353 Grad: 0.2349 LR: 0.00055  \n",
      "Epoch: [6][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4353 Grad: 0.2134 LR: 0.00055  \n",
      "Epoch: [6][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4353 Grad: 0.2797 LR: 0.00055  \n",
      "Epoch: [6][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4353 Grad: 0.1729 LR: 0.00055  \n",
      "Epoch: [6][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4353 Grad: 0.1921 LR: 0.00055  \n",
      "Epoch: [6][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4353 Grad: 0.1918 LR: 0.00055  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 59s) Loss avg.: 0.4542 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4429 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4435 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4438 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.4353  avg_val_loss: 0.4438  time: 1189s\n",
      "Epoch 6 - Accuracy: 0.8085068551249109\n",
      "Epoch 6 - Save Best Score: 0.8085 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/1929] Elapsed 0m 1s (remain 60m 45s) Loss avg.: 0.4400 Grad: 0.2822 LR: 0.00041  \n",
      "Epoch: [7][100/1929] Elapsed 1m 1s (remain 18m 35s) Loss avg.: 0.4301 Grad: 0.2551 LR: 0.00041  \n",
      "Epoch: [7][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4304 Grad: 0.2047 LR: 0.00041  \n",
      "Epoch: [7][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4304 Grad: 0.1942 LR: 0.00041  \n",
      "Epoch: [7][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4307 Grad: 0.2324 LR: 0.00041  \n",
      "Epoch: [7][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4305 Grad: 0.2250 LR: 0.00041  \n",
      "Epoch: [7][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4306 Grad: 0.2464 LR: 0.00041  \n",
      "Epoch: [7][700/1929] Elapsed 7m 0s (remain 12m 15s) Loss avg.: 0.4306 Grad: 0.2211 LR: 0.00041  \n",
      "Epoch: [7][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4307 Grad: 0.1770 LR: 0.00041  \n",
      "Epoch: [7][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4309 Grad: 0.1984 LR: 0.00041  \n",
      "Epoch: [7][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4308 Grad: 0.2155 LR: 0.00041  \n",
      "Epoch: [7][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4309 Grad: 0.2289 LR: 0.00041  \n",
      "Epoch: [7][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4309 Grad: 0.2177 LR: 0.00041  \n",
      "Epoch: [7][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4309 Grad: 0.1961 LR: 0.00041  \n",
      "Epoch: [7][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4310 Grad: 0.1922 LR: 0.00041  \n",
      "Epoch: [7][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4311 Grad: 0.2148 LR: 0.00041  \n",
      "Epoch: [7][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4312 Grad: 0.2519 LR: 0.00041  \n",
      "Epoch: [7][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4312 Grad: 0.2462 LR: 0.00041  \n",
      "Epoch: [7][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4311 Grad: 0.2803 LR: 0.00041  \n",
      "Epoch: [7][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4311 Grad: 0.2503 LR: 0.00041  \n",
      "Epoch: [7][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4311 Grad: 0.2563 LR: 0.00041  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 32s) Loss avg.: 0.4542 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4407 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4412 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4414 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.4311  avg_val_loss: 0.4414  time: 1189s\n",
      "Epoch 7 - Accuracy: 0.8101085947394732\n",
      "Epoch 7 - Save Best Score: 0.8101 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/1929] Elapsed 0m 1s (remain 60m 44s) Loss avg.: 0.4346 Grad: 0.2584 LR: 0.00029  \n",
      "Epoch: [8][100/1929] Elapsed 1m 1s (remain 18m 35s) Loss avg.: 0.4254 Grad: 0.2066 LR: 0.00029  \n",
      "Epoch: [8][200/1929] Elapsed 2m 1s (remain 17m 22s) Loss avg.: 0.4261 Grad: 0.2115 LR: 0.00029  \n",
      "Epoch: [8][300/1929] Elapsed 3m 0s (remain 16m 18s) Loss avg.: 0.4259 Grad: 0.2576 LR: 0.00029  \n",
      "Epoch: [8][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4260 Grad: 0.2388 LR: 0.00029  \n",
      "Epoch: [8][500/1929] Elapsed 5m 0s (remain 14m 15s) Loss avg.: 0.4265 Grad: 0.2329 LR: 0.00029  \n",
      "Epoch: [8][600/1929] Elapsed 5m 59s (remain 13m 15s) Loss avg.: 0.4265 Grad: 0.2116 LR: 0.00029  \n",
      "Epoch: [8][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4266 Grad: 0.2165 LR: 0.00029  \n",
      "Epoch: [8][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4266 Grad: 0.2075 LR: 0.00029  \n",
      "Epoch: [8][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4266 Grad: 0.1996 LR: 0.00029  \n",
      "Epoch: [8][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4267 Grad: 0.2141 LR: 0.00029  \n",
      "Epoch: [8][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4270 Grad: 0.2637 LR: 0.00029  \n",
      "Epoch: [8][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4269 Grad: 0.1890 LR: 0.00029  \n",
      "Epoch: [8][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4268 Grad: 0.2163 LR: 0.00029  \n",
      "Epoch: [8][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4270 Grad: 0.1923 LR: 0.00029  \n",
      "Epoch: [8][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4270 Grad: 0.2334 LR: 0.00029  \n",
      "Epoch: [8][1600/1929] Elapsed 15m 56s (remain 3m 16s) Loss avg.: 0.4271 Grad: 0.2259 LR: 0.00029  \n",
      "Epoch: [8][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4271 Grad: 0.2171 LR: 0.00029  \n",
      "Epoch: [8][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4271 Grad: 0.2150 LR: 0.00029  \n",
      "Epoch: [8][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4272 Grad: 0.2095 LR: 0.00029  \n",
      "Epoch: [8][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4272 Grad: 0.2120 LR: 0.00029  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 33s) Loss avg.: 0.4518 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4382 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4387 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4389 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.4272  avg_val_loss: 0.4389  time: 1189s\n",
      "Epoch 8 - Accuracy: 0.8111973112927744\n",
      "Epoch 8 - Save Best Score: 0.8112 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/1929] Elapsed 0m 2s (remain 64m 59s) Loss avg.: 0.4342 Grad: 0.2103 LR: 0.00019  \n",
      "Epoch: [9][100/1929] Elapsed 1m 2s (remain 18m 43s) Loss avg.: 0.4257 Grad: 0.2041 LR: 0.00019  \n",
      "Epoch: [9][200/1929] Elapsed 2m 1s (remain 17m 26s) Loss avg.: 0.4244 Grad: 0.3266 LR: 0.00019  \n",
      "Epoch: [9][300/1929] Elapsed 3m 1s (remain 16m 21s) Loss avg.: 0.4236 Grad: 0.2089 LR: 0.00019  \n",
      "Epoch: [9][400/1929] Elapsed 4m 1s (remain 15m 19s) Loss avg.: 0.4238 Grad: 0.2342 LR: 0.00019  \n",
      "Epoch: [9][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4236 Grad: 0.2345 LR: 0.00019  \n",
      "Epoch: [9][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4237 Grad: 0.2727 LR: 0.00019  \n",
      "Epoch: [9][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4237 Grad: 0.2085 LR: 0.00019  \n",
      "Epoch: [9][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4238 Grad: 0.2324 LR: 0.00019  \n",
      "Epoch: [9][900/1929] Elapsed 9m 0s (remain 10m 16s) Loss avg.: 0.4236 Grad: 0.2024 LR: 0.00019  \n",
      "Epoch: [9][1000/1929] Elapsed 9m 59s (remain 9m 16s) Loss avg.: 0.4235 Grad: 0.2282 LR: 0.00019  \n",
      "Epoch: [9][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4235 Grad: 0.2087 LR: 0.00019  \n",
      "Epoch: [9][1200/1929] Elapsed 11m 59s (remain 7m 15s) Loss avg.: 0.4235 Grad: 0.2428 LR: 0.00019  \n",
      "Epoch: [9][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4234 Grad: 0.2134 LR: 0.00019  \n",
      "Epoch: [9][1400/1929] Elapsed 13m 58s (remain 5m 16s) Loss avg.: 0.4235 Grad: 0.2045 LR: 0.00019  \n",
      "Epoch: [9][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4235 Grad: 0.2249 LR: 0.00019  \n",
      "Epoch: [9][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4235 Grad: 0.2299 LR: 0.00019  \n",
      "Epoch: [9][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4236 Grad: 0.2099 LR: 0.00019  \n",
      "Epoch: [9][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4236 Grad: 0.2872 LR: 0.00019  \n",
      "Epoch: [9][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4237 Grad: 0.2322 LR: 0.00019  \n",
      "Epoch: [9][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4237 Grad: 0.2247 LR: 0.00019  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 27s) Loss avg.: 0.4495 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4383 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4387 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4390 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.4237  avg_val_loss: 0.4390  time: 1189s\n",
      "Epoch 9 - Accuracy: 0.811251237012282\n",
      "Epoch 9 - Save Best Score: 0.8113 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/1929] Elapsed 0m 1s (remain 60m 23s) Loss avg.: 0.4027 Grad: 0.2430 LR: 0.00012  \n",
      "Epoch: [10][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4201 Grad: 0.2177 LR: 0.00012  \n",
      "Epoch: [10][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4210 Grad: 0.2139 LR: 0.00012  \n",
      "Epoch: [10][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4206 Grad: 0.2453 LR: 0.00012  \n",
      "Epoch: [10][400/1929] Elapsed 4m 0s (remain 15m 18s) Loss avg.: 0.4205 Grad: 0.2324 LR: 0.00012  \n",
      "Epoch: [10][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4200 Grad: 0.2299 LR: 0.00012  \n",
      "Epoch: [10][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4199 Grad: 0.2059 LR: 0.00012  \n",
      "Epoch: [10][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4199 Grad: 0.2288 LR: 0.00012  \n",
      "Epoch: [10][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4200 Grad: 0.2417 LR: 0.00012  \n",
      "Epoch: [10][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4201 Grad: 0.2176 LR: 0.00012  \n",
      "Epoch: [10][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4202 Grad: 0.2120 LR: 0.00012  \n",
      "Epoch: [10][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4206 Grad: 0.2144 LR: 0.00012  \n",
      "Epoch: [10][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4207 Grad: 0.2472 LR: 0.00012  \n",
      "Epoch: [10][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4208 Grad: 0.2292 LR: 0.00012  \n",
      "Epoch: [10][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4208 Grad: 0.2067 LR: 0.00012  \n",
      "Epoch: [10][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4209 Grad: 0.2456 LR: 0.00012  \n",
      "Epoch: [10][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4210 Grad: 0.2305 LR: 0.00012  \n",
      "Epoch: [10][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4211 Grad: 0.2246 LR: 0.00012  \n",
      "Epoch: [10][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4211 Grad: 0.2171 LR: 0.00012  \n",
      "Epoch: [10][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4211 Grad: 0.2430 LR: 0.00012  \n",
      "Epoch: [10][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4211 Grad: 0.2212 LR: 0.00012  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 28s) Loss avg.: 0.4500 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4375 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4380 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4382 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.4211  avg_val_loss: 0.4382  time: 1189s\n",
      "Epoch 10 - Accuracy: 0.8116258021450776\n",
      "Epoch 10 - Save Best Score: 0.8116 Model\n",
      "Epoch 10 - Save final model\n",
      "========== fold: 5 result ==========\n",
      "Score: 0.81163\n",
      "========== fold: 6 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load pre-train weight.\n",
      "Epoch: [1][0/1929] Elapsed 0m 1s (remain 61m 14s) Loss avg.: 1.3973 Grad: 0.3345 LR: 0.00100  \n",
      "Epoch: [1][100/1929] Elapsed 1m 1s (remain 18m 35s) Loss avg.: 0.6985 Grad: 1.0737 LR: 0.00100  \n",
      "Epoch: [1][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.6358 Grad: 0.7248 LR: 0.00100  \n",
      "Epoch: [1][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.6054 Grad: 0.6079 LR: 0.00100  \n",
      "Epoch: [1][400/1929] Elapsed 4m 1s (remain 15m 19s) Loss avg.: 0.5850 Grad: 0.7866 LR: 0.00100  \n",
      "Epoch: [1][500/1929] Elapsed 5m 1s (remain 14m 18s) Loss avg.: 0.5703 Grad: 0.5010 LR: 0.00100  \n",
      "Epoch: [1][600/1929] Elapsed 6m 0s (remain 13m 17s) Loss avg.: 0.5594 Grad: 0.5601 LR: 0.00100  \n",
      "Epoch: [1][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.5509 Grad: 0.6258 LR: 0.00100  \n",
      "Epoch: [1][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.5436 Grad: 0.5897 LR: 0.00100  \n",
      "Epoch: [1][900/1929] Elapsed 9m 0s (remain 10m 16s) Loss avg.: 0.5377 Grad: 0.3825 LR: 0.00100  \n",
      "Epoch: [1][1000/1929] Elapsed 9m 59s (remain 9m 16s) Loss avg.: 0.5324 Grad: 0.4653 LR: 0.00100  \n",
      "Epoch: [1][1100/1929] Elapsed 10m 59s (remain 8m 16s) Loss avg.: 0.5279 Grad: 0.5270 LR: 0.00100  \n",
      "Epoch: [1][1200/1929] Elapsed 11m 59s (remain 7m 16s) Loss avg.: 0.5239 Grad: 0.6231 LR: 0.00100  \n",
      "Epoch: [1][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.5204 Grad: 0.4223 LR: 0.00100  \n",
      "Epoch: [1][1400/1929] Elapsed 13m 58s (remain 5m 16s) Loss avg.: 0.5175 Grad: 0.4575 LR: 0.00100  \n",
      "Epoch: [1][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.5147 Grad: 0.3520 LR: 0.00100  \n",
      "Epoch: [1][1600/1929] Elapsed 15m 58s (remain 3m 16s) Loss avg.: 0.5122 Grad: 0.4411 LR: 0.00100  \n",
      "Epoch: [1][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.5100 Grad: 0.4871 LR: 0.00100  \n",
      "Epoch: [1][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.5079 Grad: 0.2675 LR: 0.00100  \n",
      "Epoch: [1][1900/1929] Elapsed 18m 57s (remain 0m 16s) Loss avg.: 0.5059 Grad: 0.3444 LR: 0.00100  \n",
      "Epoch: [1][1928/1929] Elapsed 19m 14s (remain 0m 0s) Loss avg.: 0.5054 Grad: 0.3180 LR: 0.00100  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 26s) Loss avg.: 0.4670 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4684 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4675 \n",
      "Eval: [214/215] Elapsed 0m 34s (remain 0m 0s) Loss avg.: 0.4679 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.5054  avg_val_loss: 0.4679  time: 1190s\n",
      "Epoch 1 - Accuracy: 0.7975613915167556\n",
      "Epoch 1 - Save Best Score: 0.7976 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1929] Elapsed 0m 1s (remain 60m 19s) Loss avg.: 0.4538 Grad: 0.3311 LR: 0.00098  \n",
      "Epoch: [2][100/1929] Elapsed 1m 1s (remain 18m 35s) Loss avg.: 0.4649 Grad: 0.3948 LR: 0.00098  \n",
      "Epoch: [2][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4645 Grad: 0.4322 LR: 0.00098  \n",
      "Epoch: [2][300/1929] Elapsed 3m 0s (remain 16m 18s) Loss avg.: 0.4650 Grad: 0.3059 LR: 0.00098  \n",
      "Epoch: [2][400/1929] Elapsed 4m 0s (remain 15m 16s) Loss avg.: 0.4650 Grad: 0.3489 LR: 0.00098  \n",
      "Epoch: [2][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4645 Grad: 0.3967 LR: 0.00098  \n",
      "Epoch: [2][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4644 Grad: 0.2779 LR: 0.00098  \n",
      "Epoch: [2][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4640 Grad: 0.4626 LR: 0.00098  \n",
      "Epoch: [2][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4639 Grad: 0.4000 LR: 0.00098  \n",
      "Epoch: [2][900/1929] Elapsed 8m 58s (remain 10m 14s) Loss avg.: 0.4635 Grad: 0.3625 LR: 0.00098  \n",
      "Epoch: [2][1000/1929] Elapsed 9m 58s (remain 9m 14s) Loss avg.: 0.4634 Grad: 0.3384 LR: 0.00098  \n",
      "Epoch: [2][1100/1929] Elapsed 10m 58s (remain 8m 14s) Loss avg.: 0.4633 Grad: 0.3224 LR: 0.00098  \n",
      "Epoch: [2][1200/1929] Elapsed 11m 57s (remain 7m 15s) Loss avg.: 0.4629 Grad: 0.2749 LR: 0.00098  \n",
      "Epoch: [2][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4626 Grad: 0.3004 LR: 0.00098  \n",
      "Epoch: [2][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4623 Grad: 0.2823 LR: 0.00098  \n",
      "Epoch: [2][1500/1929] Elapsed 14m 56s (remain 4m 15s) Loss avg.: 0.4621 Grad: 0.2470 LR: 0.00098  \n",
      "Epoch: [2][1600/1929] Elapsed 15m 56s (remain 3m 15s) Loss avg.: 0.4618 Grad: 0.2635 LR: 0.00098  \n",
      "Epoch: [2][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4616 Grad: 0.4577 LR: 0.00098  \n",
      "Epoch: [2][1800/1929] Elapsed 17m 55s (remain 1m 16s) Loss avg.: 0.4614 Grad: 0.2450 LR: 0.00098  \n",
      "Epoch: [2][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4612 Grad: 0.2695 LR: 0.00098  \n",
      "Epoch: [2][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4611 Grad: 0.4109 LR: 0.00098  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 4m 9s) Loss avg.: 0.4573 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4600 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4585 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4588 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4611  avg_val_loss: 0.4588  time: 1188s\n",
      "Epoch 2 - Accuracy: 0.801662661103087\n",
      "Epoch 2 - Save Best Score: 0.8017 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1929] Elapsed 0m 1s (remain 60m 21s) Loss avg.: 0.4574 Grad: 0.3125 LR: 0.00091  \n",
      "Epoch: [3][100/1929] Elapsed 1m 1s (remain 18m 36s) Loss avg.: 0.4516 Grad: 0.2953 LR: 0.00091  \n",
      "Epoch: [3][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4518 Grad: 0.2726 LR: 0.00091  \n",
      "Epoch: [3][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4518 Grad: 0.3260 LR: 0.00091  \n",
      "Epoch: [3][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4518 Grad: 0.3425 LR: 0.00091  \n",
      "Epoch: [3][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4523 Grad: 0.2360 LR: 0.00091  \n",
      "Epoch: [3][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4518 Grad: 0.2335 LR: 0.00091  \n",
      "Epoch: [3][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4519 Grad: 0.2405 LR: 0.00091  \n",
      "Epoch: [3][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4521 Grad: 0.4089 LR: 0.00091  \n",
      "Epoch: [3][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4522 Grad: 0.2475 LR: 0.00091  \n",
      "Epoch: [3][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4523 Grad: 0.2511 LR: 0.00091  \n",
      "Epoch: [3][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4520 Grad: 0.3934 LR: 0.00091  \n",
      "Epoch: [3][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4520 Grad: 0.2427 LR: 0.00091  \n",
      "Epoch: [3][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4520 Grad: 0.2611 LR: 0.00091  \n",
      "Epoch: [3][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4519 Grad: 0.2406 LR: 0.00091  \n",
      "Epoch: [3][1500/1929] Elapsed 14m 57s (remain 4m 16s) Loss avg.: 0.4520 Grad: 0.2481 LR: 0.00091  \n",
      "Epoch: [3][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4518 Grad: 0.3807 LR: 0.00091  \n",
      "Epoch: [3][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4518 Grad: 0.3110 LR: 0.00091  \n",
      "Epoch: [3][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4518 Grad: 0.2501 LR: 0.00091  \n",
      "Epoch: [3][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4517 Grad: 0.3508 LR: 0.00091  \n",
      "Epoch: [3][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4517 Grad: 0.2344 LR: 0.00091  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 35s) Loss avg.: 0.4522 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4569 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4555 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4558 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.4517  avg_val_loss: 0.4558  time: 1189s\n",
      "Epoch 3 - Accuracy: 0.8032746028807994\n",
      "Epoch 3 - Save Best Score: 0.8033 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/1929] Elapsed 0m 2s (remain 65m 7s) Loss avg.: 0.4491 Grad: 0.3237 LR: 0.00081  \n",
      "Epoch: [4][100/1929] Elapsed 1m 1s (remain 18m 40s) Loss avg.: 0.4464 Grad: 0.2737 LR: 0.00081  \n",
      "Epoch: [4][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4454 Grad: 0.2534 LR: 0.00081  \n",
      "Epoch: [4][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4453 Grad: 0.2216 LR: 0.00081  \n",
      "Epoch: [4][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4451 Grad: 0.2212 LR: 0.00081  \n",
      "Epoch: [4][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4454 Grad: 0.2657 LR: 0.00081  \n",
      "Epoch: [4][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4453 Grad: 0.2119 LR: 0.00081  \n",
      "Epoch: [4][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4451 Grad: 0.2626 LR: 0.00081  \n",
      "Epoch: [4][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4454 Grad: 0.2221 LR: 0.00081  \n",
      "Epoch: [4][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4455 Grad: 0.2816 LR: 0.00081  \n",
      "Epoch: [4][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4455 Grad: 0.2025 LR: 0.00081  \n",
      "Epoch: [4][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4454 Grad: 0.2801 LR: 0.00081  \n",
      "Epoch: [4][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4456 Grad: 0.2918 LR: 0.00081  \n",
      "Epoch: [4][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4457 Grad: 0.2388 LR: 0.00081  \n",
      "Epoch: [4][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4456 Grad: 0.1952 LR: 0.00081  \n",
      "Epoch: [4][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4456 Grad: 0.3477 LR: 0.00081  \n",
      "Epoch: [4][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4456 Grad: 0.2283 LR: 0.00081  \n",
      "Epoch: [4][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4456 Grad: 0.2666 LR: 0.00081  \n",
      "Epoch: [4][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4455 Grad: 0.3416 LR: 0.00081  \n",
      "Epoch: [4][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4455 Grad: 0.2068 LR: 0.00081  \n",
      "Epoch: [4][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4455 Grad: 0.2955 LR: 0.00081  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 34s) Loss avg.: 0.4407 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4514 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4499 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4501 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.4455  avg_val_loss: 0.4501  time: 1189s\n",
      "Epoch 4 - Accuracy: 0.8059242503960625\n",
      "Epoch 4 - Save Best Score: 0.8059 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/1929] Elapsed 0m 1s (remain 62m 28s) Loss avg.: 0.4297 Grad: 0.2314 LR: 0.00069  \n",
      "Epoch: [5][100/1929] Elapsed 1m 1s (remain 18m 36s) Loss avg.: 0.4409 Grad: 0.2679 LR: 0.00069  \n",
      "Epoch: [5][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4416 Grad: 0.1970 LR: 0.00069  \n",
      "Epoch: [5][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4409 Grad: 0.1985 LR: 0.00069  \n",
      "Epoch: [5][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4405 Grad: 0.2858 LR: 0.00069  \n",
      "Epoch: [5][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4406 Grad: 0.2124 LR: 0.00069  \n",
      "Epoch: [5][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4406 Grad: 0.2113 LR: 0.00069  \n",
      "Epoch: [5][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4404 Grad: 0.2562 LR: 0.00069  \n",
      "Epoch: [5][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4405 Grad: 0.3216 LR: 0.00069  \n",
      "Epoch: [5][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4404 Grad: 0.2524 LR: 0.00069  \n",
      "Epoch: [5][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4404 Grad: 0.3110 LR: 0.00069  \n",
      "Epoch: [5][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4405 Grad: 0.1972 LR: 0.00069  \n",
      "Epoch: [5][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4406 Grad: 0.2966 LR: 0.00069  \n",
      "Epoch: [5][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4407 Grad: 0.3000 LR: 0.00069  \n",
      "Epoch: [5][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4406 Grad: 0.1871 LR: 0.00069  \n",
      "Epoch: [5][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4405 Grad: 0.2201 LR: 0.00069  \n",
      "Epoch: [5][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4407 Grad: 0.3019 LR: 0.00069  \n",
      "Epoch: [5][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4407 Grad: 0.2469 LR: 0.00069  \n",
      "Epoch: [5][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4407 Grad: 0.2219 LR: 0.00069  \n",
      "Epoch: [5][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4407 Grad: 0.1841 LR: 0.00069  \n",
      "Epoch: [5][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4407 Grad: 0.2159 LR: 0.00069  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 28s) Loss avg.: 0.4391 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4473 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4461 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4463 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.4407  avg_val_loss: 0.4463  time: 1189s\n",
      "Epoch 5 - Accuracy: 0.8074720642911173\n",
      "Epoch 5 - Save Best Score: 0.8075 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/1929] Elapsed 0m 1s (remain 60m 25s) Loss avg.: 0.4424 Grad: 0.2609 LR: 0.00055  \n",
      "Epoch: [6][100/1929] Elapsed 1m 1s (remain 18m 36s) Loss avg.: 0.4354 Grad: 0.2466 LR: 0.00055  \n",
      "Epoch: [6][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4349 Grad: 0.2534 LR: 0.00055  \n",
      "Epoch: [6][300/1929] Elapsed 3m 1s (remain 16m 21s) Loss avg.: 0.4356 Grad: 0.3243 LR: 0.00055  \n",
      "Epoch: [6][400/1929] Elapsed 4m 1s (remain 15m 18s) Loss avg.: 0.4356 Grad: 0.2214 LR: 0.00055  \n",
      "Epoch: [6][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4359 Grad: 0.2396 LR: 0.00055  \n",
      "Epoch: [6][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4358 Grad: 0.2260 LR: 0.00055  \n",
      "Epoch: [6][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4360 Grad: 0.2406 LR: 0.00055  \n",
      "Epoch: [6][800/1929] Elapsed 8m 0s (remain 11m 15s) Loss avg.: 0.4362 Grad: 0.2306 LR: 0.00055  \n",
      "Epoch: [6][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4361 Grad: 0.1933 LR: 0.00055  \n",
      "Epoch: [6][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4363 Grad: 0.2326 LR: 0.00055  \n",
      "Epoch: [6][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4364 Grad: 0.2231 LR: 0.00055  \n",
      "Epoch: [6][1200/1929] Elapsed 11m 59s (remain 7m 15s) Loss avg.: 0.4364 Grad: 0.2330 LR: 0.00055  \n",
      "Epoch: [6][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4363 Grad: 0.2090 LR: 0.00055  \n",
      "Epoch: [6][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4364 Grad: 0.2290 LR: 0.00055  \n",
      "Epoch: [6][1500/1929] Elapsed 14m 57s (remain 4m 16s) Loss avg.: 0.4363 Grad: 0.2699 LR: 0.00055  \n",
      "Epoch: [6][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4363 Grad: 0.2239 LR: 0.00055  \n",
      "Epoch: [6][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4363 Grad: 0.2256 LR: 0.00055  \n",
      "Epoch: [6][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4362 Grad: 0.2863 LR: 0.00055  \n",
      "Epoch: [6][1900/1929] Elapsed 18m 57s (remain 0m 16s) Loss avg.: 0.4363 Grad: 0.2023 LR: 0.00055  \n",
      "Epoch: [6][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4363 Grad: 0.1841 LR: 0.00055  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 28s) Loss avg.: 0.4390 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4436 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4421 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4424 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.4363  avg_val_loss: 0.4424  time: 1190s\n",
      "Epoch 6 - Accuracy: 0.8094337945196894\n",
      "Epoch 6 - Save Best Score: 0.8094 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/1929] Elapsed 0m 1s (remain 61m 1s) Loss avg.: 0.4204 Grad: 0.2405 LR: 0.00041  \n",
      "Epoch: [7][100/1929] Elapsed 1m 1s (remain 18m 35s) Loss avg.: 0.4309 Grad: 0.2161 LR: 0.00041  \n",
      "Epoch: [7][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4303 Grad: 0.1806 LR: 0.00041  \n",
      "Epoch: [7][300/1929] Elapsed 3m 1s (remain 16m 18s) Loss avg.: 0.4306 Grad: 0.2300 LR: 0.00041  \n",
      "Epoch: [7][400/1929] Elapsed 4m 0s (remain 15m 16s) Loss avg.: 0.4307 Grad: 0.1942 LR: 0.00041  \n",
      "Epoch: [7][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4310 Grad: 0.2108 LR: 0.00041  \n",
      "Epoch: [7][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4312 Grad: 0.2072 LR: 0.00041  \n",
      "Epoch: [7][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4315 Grad: 0.2470 LR: 0.00041  \n",
      "Epoch: [7][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4316 Grad: 0.1982 LR: 0.00041  \n",
      "Epoch: [7][900/1929] Elapsed 8m 59s (remain 10m 14s) Loss avg.: 0.4316 Grad: 0.2337 LR: 0.00041  \n",
      "Epoch: [7][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4316 Grad: 0.2027 LR: 0.00041  \n",
      "Epoch: [7][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4316 Grad: 0.1939 LR: 0.00041  \n",
      "Epoch: [7][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4318 Grad: 0.2150 LR: 0.00041  \n",
      "Epoch: [7][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4320 Grad: 0.2885 LR: 0.00041  \n",
      "Epoch: [7][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4320 Grad: 0.2569 LR: 0.00041  \n",
      "Epoch: [7][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4320 Grad: 0.2002 LR: 0.00041  \n",
      "Epoch: [7][1600/1929] Elapsed 15m 56s (remain 3m 15s) Loss avg.: 0.4320 Grad: 0.3119 LR: 0.00041  \n",
      "Epoch: [7][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4320 Grad: 0.2039 LR: 0.00041  \n",
      "Epoch: [7][1800/1929] Elapsed 17m 55s (remain 1m 16s) Loss avg.: 0.4320 Grad: 0.2162 LR: 0.00041  \n",
      "Epoch: [7][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4320 Grad: 0.3102 LR: 0.00041  \n",
      "Epoch: [7][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4321 Grad: 0.2015 LR: 0.00041  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 4m 1s) Loss avg.: 0.4342 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4419 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4406 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4408 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.4321  avg_val_loss: 0.4408  time: 1188s\n",
      "Epoch 7 - Accuracy: 0.8099366154178005\n",
      "Epoch 7 - Save Best Score: 0.8099 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/1929] Elapsed 0m 1s (remain 60m 39s) Loss avg.: 0.4262 Grad: 0.2546 LR: 0.00029  \n",
      "Epoch: [8][100/1929] Elapsed 1m 1s (remain 18m 34s) Loss avg.: 0.4289 Grad: 0.2551 LR: 0.00029  \n",
      "Epoch: [8][200/1929] Elapsed 2m 1s (remain 17m 22s) Loss avg.: 0.4274 Grad: 0.2109 LR: 0.00029  \n",
      "Epoch: [8][300/1929] Elapsed 3m 0s (remain 16m 18s) Loss avg.: 0.4269 Grad: 0.2294 LR: 0.00029  \n",
      "Epoch: [8][400/1929] Elapsed 4m 0s (remain 15m 16s) Loss avg.: 0.4274 Grad: 0.2514 LR: 0.00029  \n",
      "Epoch: [8][500/1929] Elapsed 5m 0s (remain 14m 15s) Loss avg.: 0.4274 Grad: 0.2195 LR: 0.00029  \n",
      "Epoch: [8][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4273 Grad: 0.2422 LR: 0.00029  \n",
      "Epoch: [8][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4274 Grad: 0.2258 LR: 0.00029  \n",
      "Epoch: [8][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4276 Grad: 0.2225 LR: 0.00029  \n",
      "Epoch: [8][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4277 Grad: 0.1979 LR: 0.00029  \n",
      "Epoch: [8][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4277 Grad: 0.2340 LR: 0.00029  \n",
      "Epoch: [8][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4278 Grad: 0.2190 LR: 0.00029  \n",
      "Epoch: [8][1200/1929] Elapsed 11m 57s (remain 7m 15s) Loss avg.: 0.4277 Grad: 0.2294 LR: 0.00029  \n",
      "Epoch: [8][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4278 Grad: 0.2329 LR: 0.00029  \n",
      "Epoch: [8][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4277 Grad: 0.2721 LR: 0.00029  \n",
      "Epoch: [8][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4277 Grad: 0.2334 LR: 0.00029  \n",
      "Epoch: [8][1600/1929] Elapsed 15m 56s (remain 3m 15s) Loss avg.: 0.4276 Grad: 0.2136 LR: 0.00029  \n",
      "Epoch: [8][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4278 Grad: 0.2241 LR: 0.00029  \n",
      "Epoch: [8][1800/1929] Elapsed 17m 55s (remain 1m 16s) Loss avg.: 0.4278 Grad: 0.2143 LR: 0.00029  \n",
      "Epoch: [8][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4279 Grad: 0.2397 LR: 0.00029  \n",
      "Epoch: [8][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4280 Grad: 0.2142 LR: 0.00029  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 27s) Loss avg.: 0.4375 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4410 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4394 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4397 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.4280  avg_val_loss: 0.4397  time: 1188s\n",
      "Epoch 8 - Accuracy: 0.810758618277321\n",
      "Epoch 8 - Save Best Score: 0.8108 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/1929] Elapsed 0m 1s (remain 61m 17s) Loss avg.: 0.4466 Grad: 0.2117 LR: 0.00019  \n",
      "Epoch: [9][100/1929] Elapsed 1m 1s (remain 18m 36s) Loss avg.: 0.4264 Grad: 0.2260 LR: 0.00019  \n",
      "Epoch: [9][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4249 Grad: 0.2090 LR: 0.00019  \n",
      "Epoch: [9][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4253 Grad: 0.2145 LR: 0.00019  \n",
      "Epoch: [9][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4247 Grad: 0.2265 LR: 0.00019  \n",
      "Epoch: [9][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4242 Grad: 0.2232 LR: 0.00019  \n",
      "Epoch: [9][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4241 Grad: 0.2589 LR: 0.00019  \n",
      "Epoch: [9][700/1929] Elapsed 7m 0s (remain 12m 15s) Loss avg.: 0.4244 Grad: 0.2284 LR: 0.00019  \n",
      "Epoch: [9][800/1929] Elapsed 8m 0s (remain 11m 15s) Loss avg.: 0.4245 Grad: 0.2532 LR: 0.00019  \n",
      "Epoch: [9][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4244 Grad: 0.2246 LR: 0.00019  \n",
      "Epoch: [9][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4244 Grad: 0.2213 LR: 0.00019  \n",
      "Epoch: [9][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4244 Grad: 0.2307 LR: 0.00019  \n",
      "Epoch: [9][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4245 Grad: 0.2263 LR: 0.00019  \n",
      "Epoch: [9][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4243 Grad: 0.2235 LR: 0.00019  \n",
      "Epoch: [9][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4242 Grad: 0.2364 LR: 0.00019  \n",
      "Epoch: [9][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4243 Grad: 0.2321 LR: 0.00019  \n",
      "Epoch: [9][1600/1929] Elapsed 15m 58s (remain 3m 16s) Loss avg.: 0.4245 Grad: 0.2269 LR: 0.00019  \n",
      "Epoch: [9][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4245 Grad: 0.2595 LR: 0.00019  \n",
      "Epoch: [9][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4245 Grad: 0.2075 LR: 0.00019  \n",
      "Epoch: [9][1900/1929] Elapsed 18m 57s (remain 0m 16s) Loss avg.: 0.4245 Grad: 0.2258 LR: 0.00019  \n",
      "Epoch: [9][1928/1929] Elapsed 19m 14s (remain 0m 0s) Loss avg.: 0.4245 Grad: 0.2622 LR: 0.00019  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 32s) Loss avg.: 0.4338 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4401 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4386 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4388 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.4245  avg_val_loss: 0.4388  time: 1190s\n",
      "Epoch 9 - Accuracy: 0.8112395773972533\n",
      "Epoch 9 - Save Best Score: 0.8112 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/1929] Elapsed 0m 2s (remain 64m 49s) Loss avg.: 0.3968 Grad: 0.2432 LR: 0.00012  \n",
      "Epoch: [10][100/1929] Elapsed 1m 1s (remain 18m 42s) Loss avg.: 0.4208 Grad: 0.2499 LR: 0.00012  \n",
      "Epoch: [10][200/1929] Elapsed 2m 1s (remain 17m 26s) Loss avg.: 0.4212 Grad: 0.2439 LR: 0.00012  \n",
      "Epoch: [10][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4213 Grad: 0.2510 LR: 0.00012  \n",
      "Epoch: [10][400/1929] Elapsed 4m 0s (remain 15m 18s) Loss avg.: 0.4211 Grad: 0.2770 LR: 0.00012  \n",
      "Epoch: [10][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4209 Grad: 0.2277 LR: 0.00012  \n",
      "Epoch: [10][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4216 Grad: 0.2281 LR: 0.00012  \n",
      "Epoch: [10][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4214 Grad: 0.2260 LR: 0.00012  \n",
      "Epoch: [10][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4215 Grad: 0.2127 LR: 0.00012  \n",
      "Epoch: [10][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4216 Grad: 0.2130 LR: 0.00012  \n",
      "Epoch: [10][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4215 Grad: 0.2231 LR: 0.00012  \n",
      "Epoch: [10][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4217 Grad: 0.2270 LR: 0.00012  \n",
      "Epoch: [10][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4218 Grad: 0.2219 LR: 0.00012  \n",
      "Epoch: [10][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4219 Grad: 0.2282 LR: 0.00012  \n",
      "Epoch: [10][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4219 Grad: 0.2175 LR: 0.00012  \n",
      "Epoch: [10][1500/1929] Elapsed 14m 57s (remain 4m 16s) Loss avg.: 0.4219 Grad: 0.2071 LR: 0.00012  \n",
      "Epoch: [10][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4219 Grad: 0.2306 LR: 0.00012  \n",
      "Epoch: [10][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4218 Grad: 0.2622 LR: 0.00012  \n",
      "Epoch: [10][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4219 Grad: 0.2409 LR: 0.00012  \n",
      "Epoch: [10][1900/1929] Elapsed 18m 57s (remain 0m 16s) Loss avg.: 0.4218 Grad: 0.2354 LR: 0.00012  \n",
      "Epoch: [10][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4219 Grad: 0.2196 LR: 0.00012  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 29s) Loss avg.: 0.4337 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4393 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4377 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4380 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.4219  avg_val_loss: 0.4380  time: 1189s\n",
      "Epoch 10 - Accuracy: 0.8115048336391553\n",
      "Epoch 10 - Save Best Score: 0.8115 Model\n",
      "Epoch 10 - Save final model\n",
      "========== fold: 6 result ==========\n",
      "Score: 0.81150\n",
      "========== fold: 7 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load pre-train weight.\n",
      "Epoch: [1][0/1929] Elapsed 0m 1s (remain 60m 52s) Loss avg.: 1.4034 Grad: 0.3895 LR: 0.00100  \n",
      "Epoch: [1][100/1929] Elapsed 1m 1s (remain 18m 36s) Loss avg.: 0.7100 Grad: 0.8094 LR: 0.00100  \n",
      "Epoch: [1][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.6402 Grad: 0.5947 LR: 0.00100  \n",
      "Epoch: [1][300/1929] Elapsed 3m 1s (remain 16m 21s) Loss avg.: 0.6067 Grad: 0.9274 LR: 0.00100  \n",
      "Epoch: [1][400/1929] Elapsed 4m 1s (remain 15m 19s) Loss avg.: 0.5852 Grad: 0.5514 LR: 0.00100  \n",
      "Epoch: [1][500/1929] Elapsed 5m 1s (remain 14m 18s) Loss avg.: 0.5703 Grad: 0.5996 LR: 0.00100  \n",
      "Epoch: [1][600/1929] Elapsed 6m 1s (remain 13m 17s) Loss avg.: 0.5587 Grad: 0.5042 LR: 0.00100  \n",
      "Epoch: [1][700/1929] Elapsed 7m 0s (remain 12m 17s) Loss avg.: 0.5500 Grad: 0.5380 LR: 0.00100  \n",
      "Epoch: [1][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.5430 Grad: 0.4001 LR: 0.00100  \n",
      "Epoch: [1][900/1929] Elapsed 9m 0s (remain 10m 16s) Loss avg.: 0.5371 Grad: 0.4752 LR: 0.00100  \n",
      "Epoch: [1][1000/1929] Elapsed 10m 0s (remain 9m 16s) Loss avg.: 0.5319 Grad: 0.4186 LR: 0.00100  \n",
      "Epoch: [1][1100/1929] Elapsed 11m 0s (remain 8m 16s) Loss avg.: 0.5276 Grad: 0.6028 LR: 0.00100  \n",
      "Epoch: [1][1200/1929] Elapsed 12m 0s (remain 7m 16s) Loss avg.: 0.5236 Grad: 0.4682 LR: 0.00100  \n",
      "Epoch: [1][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.5200 Grad: 0.4373 LR: 0.00100  \n",
      "Epoch: [1][1400/1929] Elapsed 13m 59s (remain 5m 16s) Loss avg.: 0.5170 Grad: 0.4304 LR: 0.00100  \n",
      "Epoch: [1][1500/1929] Elapsed 14m 59s (remain 4m 16s) Loss avg.: 0.5144 Grad: 0.3164 LR: 0.00100  \n",
      "Epoch: [1][1600/1929] Elapsed 15m 58s (remain 3m 16s) Loss avg.: 0.5118 Grad: 0.5942 LR: 0.00100  \n",
      "Epoch: [1][1700/1929] Elapsed 16m 58s (remain 2m 16s) Loss avg.: 0.5096 Grad: 0.4198 LR: 0.00100  \n",
      "Epoch: [1][1800/1929] Elapsed 17m 58s (remain 1m 16s) Loss avg.: 0.5075 Grad: 0.3516 LR: 0.00100  \n",
      "Epoch: [1][1900/1929] Elapsed 18m 57s (remain 0m 16s) Loss avg.: 0.5055 Grad: 0.2826 LR: 0.00100  \n",
      "Epoch: [1][1928/1929] Elapsed 19m 14s (remain 0m 0s) Loss avg.: 0.5050 Grad: 0.4027 LR: 0.00100  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 21s) Loss avg.: 0.4347 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4676 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4690 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4696 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.5050  avg_val_loss: 0.4696  time: 1190s\n",
      "Epoch 1 - Accuracy: 0.7963706533319536\n",
      "Epoch 1 - Save Best Score: 0.7964 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1929] Elapsed 0m 1s (remain 60m 22s) Loss avg.: 0.4726 Grad: 0.5146 LR: 0.00098  \n",
      "Epoch: [2][100/1929] Elapsed 1m 1s (remain 18m 35s) Loss avg.: 0.4667 Grad: 0.3344 LR: 0.00098  \n",
      "Epoch: [2][200/1929] Elapsed 2m 1s (remain 17m 22s) Loss avg.: 0.4661 Grad: 0.3882 LR: 0.00098  \n",
      "Epoch: [2][300/1929] Elapsed 3m 0s (remain 16m 18s) Loss avg.: 0.4657 Grad: 0.3008 LR: 0.00098  \n",
      "Epoch: [2][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4654 Grad: 0.3216 LR: 0.00098  \n",
      "Epoch: [2][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4650 Grad: 0.3459 LR: 0.00098  \n",
      "Epoch: [2][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4648 Grad: 0.4052 LR: 0.00098  \n",
      "Epoch: [2][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4644 Grad: 0.2784 LR: 0.00098  \n",
      "Epoch: [2][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4640 Grad: 0.3913 LR: 0.00098  \n",
      "Epoch: [2][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4638 Grad: 0.2798 LR: 0.00098  \n",
      "Epoch: [2][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4637 Grad: 0.3776 LR: 0.00098  \n",
      "Epoch: [2][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4634 Grad: 0.3524 LR: 0.00098  \n",
      "Epoch: [2][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4631 Grad: 0.3036 LR: 0.00098  \n",
      "Epoch: [2][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4627 Grad: 0.4494 LR: 0.00098  \n",
      "Epoch: [2][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4624 Grad: 0.4137 LR: 0.00098  \n",
      "Epoch: [2][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4621 Grad: 0.4621 LR: 0.00098  \n",
      "Epoch: [2][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4619 Grad: 0.3307 LR: 0.00098  \n",
      "Epoch: [2][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4617 Grad: 0.3267 LR: 0.00098  \n",
      "Epoch: [2][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4614 Grad: 0.3271 LR: 0.00098  \n",
      "Epoch: [2][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4612 Grad: 0.2725 LR: 0.00098  \n",
      "Epoch: [2][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4611 Grad: 0.2839 LR: 0.00098  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 26s) Loss avg.: 0.4157 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4552 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4565 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4571 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4611  avg_val_loss: 0.4571  time: 1189s\n",
      "Epoch 2 - Accuracy: 0.8024788341550932\n",
      "Epoch 2 - Save Best Score: 0.8025 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1929] Elapsed 0m 1s (remain 61m 17s) Loss avg.: 0.4795 Grad: 0.2706 LR: 0.00091  \n",
      "Epoch: [3][100/1929] Elapsed 1m 1s (remain 18m 36s) Loss avg.: 0.4516 Grad: 0.2896 LR: 0.00091  \n",
      "Epoch: [3][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4511 Grad: 0.2766 LR: 0.00091  \n",
      "Epoch: [3][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4521 Grad: 0.3156 LR: 0.00091  \n",
      "Epoch: [3][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4522 Grad: 0.2646 LR: 0.00091  \n",
      "Epoch: [3][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4523 Grad: 0.3159 LR: 0.00091  \n",
      "Epoch: [3][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4520 Grad: 0.2514 LR: 0.00091  \n",
      "Epoch: [3][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4522 Grad: 0.3744 LR: 0.00091  \n",
      "Epoch: [3][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4520 Grad: 0.2104 LR: 0.00091  \n",
      "Epoch: [3][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4521 Grad: 0.2904 LR: 0.00091  \n",
      "Epoch: [3][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4520 Grad: 0.2653 LR: 0.00091  \n",
      "Epoch: [3][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4520 Grad: 0.2979 LR: 0.00091  \n",
      "Epoch: [3][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4519 Grad: 0.2242 LR: 0.00091  \n",
      "Epoch: [3][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4519 Grad: 0.2735 LR: 0.00091  \n",
      "Epoch: [3][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4518 Grad: 0.3039 LR: 0.00091  \n",
      "Epoch: [3][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4518 Grad: 0.3044 LR: 0.00091  \n",
      "Epoch: [3][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4517 Grad: 0.2148 LR: 0.00091  \n",
      "Epoch: [3][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4516 Grad: 0.2430 LR: 0.00091  \n",
      "Epoch: [3][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4516 Grad: 0.2773 LR: 0.00091  \n",
      "Epoch: [3][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4515 Grad: 0.2242 LR: 0.00091  \n",
      "Epoch: [3][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4515 Grad: 0.2102 LR: 0.00091  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 4m 2s) Loss avg.: 0.4133 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4501 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4512 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4518 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.4515  avg_val_loss: 0.4518  time: 1189s\n",
      "Epoch 3 - Accuracy: 0.8047568314413179\n",
      "Epoch 3 - Save Best Score: 0.8048 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/1929] Elapsed 0m 1s (remain 60m 35s) Loss avg.: 0.4342 Grad: 0.2852 LR: 0.00081  \n",
      "Epoch: [4][100/1929] Elapsed 1m 1s (remain 18m 34s) Loss avg.: 0.4460 Grad: 0.2107 LR: 0.00081  \n",
      "Epoch: [4][200/1929] Elapsed 2m 1s (remain 17m 22s) Loss avg.: 0.4451 Grad: 0.2341 LR: 0.00081  \n",
      "Epoch: [4][300/1929] Elapsed 3m 0s (remain 16m 18s) Loss avg.: 0.4449 Grad: 0.2469 LR: 0.00081  \n",
      "Epoch: [4][400/1929] Elapsed 4m 0s (remain 15m 16s) Loss avg.: 0.4450 Grad: 0.3040 LR: 0.00081  \n",
      "Epoch: [4][500/1929] Elapsed 5m 0s (remain 14m 15s) Loss avg.: 0.4447 Grad: 0.2256 LR: 0.00081  \n",
      "Epoch: [4][600/1929] Elapsed 5m 59s (remain 13m 15s) Loss avg.: 0.4451 Grad: 0.2727 LR: 0.00081  \n",
      "Epoch: [4][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4451 Grad: 0.2202 LR: 0.00081  \n",
      "Epoch: [4][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4452 Grad: 0.2705 LR: 0.00081  \n",
      "Epoch: [4][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4452 Grad: 0.2863 LR: 0.00081  \n",
      "Epoch: [4][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4452 Grad: 0.2360 LR: 0.00081  \n",
      "Epoch: [4][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4452 Grad: 0.2575 LR: 0.00081  \n",
      "Epoch: [4][1200/1929] Elapsed 11m 57s (remain 7m 15s) Loss avg.: 0.4452 Grad: 0.2820 LR: 0.00081  \n",
      "Epoch: [4][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4453 Grad: 0.2745 LR: 0.00081  \n",
      "Epoch: [4][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4453 Grad: 0.2591 LR: 0.00081  \n",
      "Epoch: [4][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4453 Grad: 0.2350 LR: 0.00081  \n",
      "Epoch: [4][1600/1929] Elapsed 15m 56s (remain 3m 16s) Loss avg.: 0.4454 Grad: 0.2591 LR: 0.00081  \n",
      "Epoch: [4][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4455 Grad: 0.2185 LR: 0.00081  \n",
      "Epoch: [4][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4456 Grad: 0.2612 LR: 0.00081  \n",
      "Epoch: [4][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4456 Grad: 0.2343 LR: 0.00081  \n",
      "Epoch: [4][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4455 Grad: 0.2294 LR: 0.00081  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 30s) Loss avg.: 0.4067 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4487 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4499 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4504 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.4455  avg_val_loss: 0.4504  time: 1188s\n",
      "Epoch 4 - Accuracy: 0.8057712179488113\n",
      "Epoch 4 - Save Best Score: 0.8058 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/1929] Elapsed 0m 2s (remain 64m 47s) Loss avg.: 0.4419 Grad: 0.3433 LR: 0.00069  \n",
      "Epoch: [5][100/1929] Elapsed 1m 2s (remain 18m 42s) Loss avg.: 0.4392 Grad: 0.2085 LR: 0.00069  \n",
      "Epoch: [5][200/1929] Elapsed 2m 1s (remain 17m 25s) Loss avg.: 0.4393 Grad: 0.2472 LR: 0.00069  \n",
      "Epoch: [5][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4394 Grad: 0.2100 LR: 0.00069  \n",
      "Epoch: [5][400/1929] Elapsed 4m 0s (remain 15m 18s) Loss avg.: 0.4393 Grad: 0.2735 LR: 0.00069  \n",
      "Epoch: [5][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4399 Grad: 0.2208 LR: 0.00069  \n",
      "Epoch: [5][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4398 Grad: 0.3591 LR: 0.00069  \n",
      "Epoch: [5][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4397 Grad: 0.1805 LR: 0.00069  \n",
      "Epoch: [5][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4397 Grad: 0.2726 LR: 0.00069  \n",
      "Epoch: [5][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4398 Grad: 0.2436 LR: 0.00069  \n",
      "Epoch: [5][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4399 Grad: 0.1863 LR: 0.00069  \n",
      "Epoch: [5][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4400 Grad: 0.2657 LR: 0.00069  \n",
      "Epoch: [5][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4401 Grad: 0.1925 LR: 0.00069  \n",
      "Epoch: [5][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4401 Grad: 0.2044 LR: 0.00069  \n",
      "Epoch: [5][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4402 Grad: 0.2007 LR: 0.00069  \n",
      "Epoch: [5][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4404 Grad: 0.2176 LR: 0.00069  \n",
      "Epoch: [5][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4405 Grad: 0.2346 LR: 0.00069  \n",
      "Epoch: [5][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4406 Grad: 0.2289 LR: 0.00069  \n",
      "Epoch: [5][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4405 Grad: 0.2142 LR: 0.00069  \n",
      "Epoch: [5][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4406 Grad: 0.2190 LR: 0.00069  \n",
      "Epoch: [5][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4406 Grad: 0.1886 LR: 0.00069  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 26s) Loss avg.: 0.4089 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4440 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4451 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4456 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.4406  avg_val_loss: 0.4456  time: 1189s\n",
      "Epoch 5 - Accuracy: 0.8077154587548405\n",
      "Epoch 5 - Save Best Score: 0.8077 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/1929] Elapsed 0m 1s (remain 60m 34s) Loss avg.: 0.4140 Grad: 0.1858 LR: 0.00055  \n",
      "Epoch: [6][100/1929] Elapsed 1m 1s (remain 18m 36s) Loss avg.: 0.4361 Grad: 0.3307 LR: 0.00055  \n",
      "Epoch: [6][200/1929] Elapsed 2m 1s (remain 17m 25s) Loss avg.: 0.4351 Grad: 0.2311 LR: 0.00055  \n",
      "Epoch: [6][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4348 Grad: 0.2047 LR: 0.00055  \n",
      "Epoch: [6][400/1929] Elapsed 4m 0s (remain 15m 18s) Loss avg.: 0.4344 Grad: 0.1955 LR: 0.00055  \n",
      "Epoch: [6][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4347 Grad: 0.2918 LR: 0.00055  \n",
      "Epoch: [6][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4352 Grad: 0.2382 LR: 0.00055  \n",
      "Epoch: [6][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4354 Grad: 0.2667 LR: 0.00055  \n",
      "Epoch: [6][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4357 Grad: 0.2156 LR: 0.00055  \n",
      "Epoch: [6][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4357 Grad: 0.2764 LR: 0.00055  \n",
      "Epoch: [6][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4357 Grad: 0.2222 LR: 0.00055  \n",
      "Epoch: [6][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4358 Grad: 0.2585 LR: 0.00055  \n",
      "Epoch: [6][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4358 Grad: 0.2375 LR: 0.00055  \n",
      "Epoch: [6][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4357 Grad: 0.1972 LR: 0.00055  \n",
      "Epoch: [6][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4357 Grad: 0.2270 LR: 0.00055  \n",
      "Epoch: [6][1500/1929] Elapsed 14m 57s (remain 4m 16s) Loss avg.: 0.4359 Grad: 0.2147 LR: 0.00055  \n",
      "Epoch: [6][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4361 Grad: 0.1739 LR: 0.00055  \n",
      "Epoch: [6][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4360 Grad: 0.2767 LR: 0.00055  \n",
      "Epoch: [6][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4361 Grad: 0.2135 LR: 0.00055  \n",
      "Epoch: [6][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4362 Grad: 0.3243 LR: 0.00055  \n",
      "Epoch: [6][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4362 Grad: 0.2453 LR: 0.00055  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 34s) Loss avg.: 0.4080 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4434 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4449 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4455 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.4362  avg_val_loss: 0.4455  time: 1189s\n",
      "Epoch 6 - Accuracy: 0.8081045984064221\n",
      "Epoch 6 - Save Best Score: 0.8081 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/1929] Elapsed 0m 1s (remain 61m 47s) Loss avg.: 0.4310 Grad: 0.3713 LR: 0.00041  \n",
      "Epoch: [7][100/1929] Elapsed 1m 1s (remain 18m 38s) Loss avg.: 0.4304 Grad: 0.2931 LR: 0.00041  \n",
      "Epoch: [7][200/1929] Elapsed 2m 1s (remain 17m 25s) Loss avg.: 0.4307 Grad: 0.2507 LR: 0.00041  \n",
      "Epoch: [7][300/1929] Elapsed 3m 1s (remain 16m 21s) Loss avg.: 0.4306 Grad: 0.1908 LR: 0.00041  \n",
      "Epoch: [7][400/1929] Elapsed 4m 1s (remain 15m 19s) Loss avg.: 0.4311 Grad: 0.2249 LR: 0.00041  \n",
      "Epoch: [7][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4316 Grad: 0.2853 LR: 0.00041  \n",
      "Epoch: [7][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4316 Grad: 0.2553 LR: 0.00041  \n",
      "Epoch: [7][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4315 Grad: 0.2123 LR: 0.00041  \n",
      "Epoch: [7][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4315 Grad: 0.2656 LR: 0.00041  \n",
      "Epoch: [7][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4313 Grad: 0.2584 LR: 0.00041  \n",
      "Epoch: [7][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4317 Grad: 0.2529 LR: 0.00041  \n",
      "Epoch: [7][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4315 Grad: 0.2553 LR: 0.00041  \n",
      "Epoch: [7][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4317 Grad: 0.2859 LR: 0.00041  \n",
      "Epoch: [7][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4317 Grad: 0.2369 LR: 0.00041  \n",
      "Epoch: [7][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4318 Grad: 0.2282 LR: 0.00041  \n",
      "Epoch: [7][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4318 Grad: 0.2019 LR: 0.00041  \n",
      "Epoch: [7][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4318 Grad: 0.2356 LR: 0.00041  \n",
      "Epoch: [7][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4318 Grad: 0.2292 LR: 0.00041  \n",
      "Epoch: [7][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4319 Grad: 0.2388 LR: 0.00041  \n",
      "Epoch: [7][1900/1929] Elapsed 18m 57s (remain 0m 16s) Loss avg.: 0.4319 Grad: 0.2414 LR: 0.00041  \n",
      "Epoch: [7][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4320 Grad: 0.3091 LR: 0.00041  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 35s) Loss avg.: 0.4039 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4398 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4411 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4416 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.4320  avg_val_loss: 0.4416  time: 1189s\n",
      "Epoch 7 - Accuracy: 0.8098389661419354\n",
      "Epoch 7 - Save Best Score: 0.8098 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/1929] Elapsed 0m 1s (remain 60m 43s) Loss avg.: 0.4285 Grad: 0.2467 LR: 0.00029  \n",
      "Epoch: [8][100/1929] Elapsed 1m 1s (remain 18m 36s) Loss avg.: 0.4286 Grad: 0.2324 LR: 0.00029  \n",
      "Epoch: [8][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4284 Grad: 0.2289 LR: 0.00029  \n",
      "Epoch: [8][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4280 Grad: 0.2524 LR: 0.00029  \n",
      "Epoch: [8][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4281 Grad: 0.2228 LR: 0.00029  \n",
      "Epoch: [8][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4278 Grad: 0.2130 LR: 0.00029  \n",
      "Epoch: [8][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4281 Grad: 0.2173 LR: 0.00029  \n",
      "Epoch: [8][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4280 Grad: 0.2224 LR: 0.00029  \n",
      "Epoch: [8][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4279 Grad: 0.2812 LR: 0.00029  \n",
      "Epoch: [8][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4278 Grad: 0.2539 LR: 0.00029  \n",
      "Epoch: [8][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4277 Grad: 0.2659 LR: 0.00029  \n",
      "Epoch: [8][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4279 Grad: 0.2155 LR: 0.00029  \n",
      "Epoch: [8][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4279 Grad: 0.2339 LR: 0.00029  \n",
      "Epoch: [8][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4278 Grad: 0.2463 LR: 0.00029  \n",
      "Epoch: [8][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4278 Grad: 0.2627 LR: 0.00029  \n",
      "Epoch: [8][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4279 Grad: 0.2156 LR: 0.00029  \n",
      "Epoch: [8][1600/1929] Elapsed 15m 56s (remain 3m 16s) Loss avg.: 0.4279 Grad: 0.2073 LR: 0.00029  \n",
      "Epoch: [8][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4279 Grad: 0.2503 LR: 0.00029  \n",
      "Epoch: [8][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4279 Grad: 0.2181 LR: 0.00029  \n",
      "Epoch: [8][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4280 Grad: 0.2244 LR: 0.00029  \n",
      "Epoch: [8][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4281 Grad: 0.3019 LR: 0.00029  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 58s) Loss avg.: 0.4024 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4371 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4385 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4390 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.4281  avg_val_loss: 0.4390  time: 1189s\n",
      "Epoch 8 - Accuracy: 0.8113620033550543\n",
      "Epoch 8 - Save Best Score: 0.8114 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/1929] Elapsed 0m 1s (remain 60m 58s) Loss avg.: 0.4171 Grad: 0.2892 LR: 0.00019  \n",
      "Epoch: [9][100/1929] Elapsed 1m 1s (remain 18m 33s) Loss avg.: 0.4241 Grad: 0.2028 LR: 0.00019  \n",
      "Epoch: [9][200/1929] Elapsed 2m 1s (remain 17m 21s) Loss avg.: 0.4239 Grad: 0.2792 LR: 0.00019  \n",
      "Epoch: [9][300/1929] Elapsed 3m 0s (remain 16m 18s) Loss avg.: 0.4240 Grad: 0.2153 LR: 0.00019  \n",
      "Epoch: [9][400/1929] Elapsed 4m 0s (remain 15m 16s) Loss avg.: 0.4241 Grad: 0.2573 LR: 0.00019  \n",
      "Epoch: [9][500/1929] Elapsed 5m 0s (remain 14m 15s) Loss avg.: 0.4242 Grad: 0.2443 LR: 0.00019  \n",
      "Epoch: [9][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4241 Grad: 0.2160 LR: 0.00019  \n",
      "Epoch: [9][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4240 Grad: 0.2429 LR: 0.00019  \n",
      "Epoch: [9][800/1929] Elapsed 7m 59s (remain 11m 14s) Loss avg.: 0.4241 Grad: 0.2742 LR: 0.00019  \n",
      "Epoch: [9][900/1929] Elapsed 8m 58s (remain 10m 14s) Loss avg.: 0.4240 Grad: 0.2156 LR: 0.00019  \n",
      "Epoch: [9][1000/1929] Elapsed 9m 58s (remain 9m 14s) Loss avg.: 0.4241 Grad: 0.2234 LR: 0.00019  \n",
      "Epoch: [9][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4242 Grad: 0.2193 LR: 0.00019  \n",
      "Epoch: [9][1200/1929] Elapsed 11m 57s (remain 7m 15s) Loss avg.: 0.4243 Grad: 0.2201 LR: 0.00019  \n",
      "Epoch: [9][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4244 Grad: 0.2266 LR: 0.00019  \n",
      "Epoch: [9][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4245 Grad: 0.2277 LR: 0.00019  \n",
      "Epoch: [9][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4246 Grad: 0.2319 LR: 0.00019  \n",
      "Epoch: [9][1600/1929] Elapsed 15m 56s (remain 3m 16s) Loss avg.: 0.4245 Grad: 0.2151 LR: 0.00019  \n",
      "Epoch: [9][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4246 Grad: 0.2406 LR: 0.00019  \n",
      "Epoch: [9][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4246 Grad: 0.2193 LR: 0.00019  \n",
      "Epoch: [9][1900/1929] Elapsed 18m 55s (remain 0m 16s) Loss avg.: 0.4246 Grad: 0.2097 LR: 0.00019  \n",
      "Epoch: [9][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4246 Grad: 0.2123 LR: 0.00019  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 37s) Loss avg.: 0.4000 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4364 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4379 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4384 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.4246  avg_val_loss: 0.4384  time: 1188s\n",
      "Epoch 9 - Accuracy: 0.8116053978187775\n",
      "Epoch 9 - Save Best Score: 0.8116 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/1929] Elapsed 0m 1s (remain 60m 28s) Loss avg.: 0.4150 Grad: 0.1967 LR: 0.00012  \n",
      "Epoch: [10][100/1929] Elapsed 1m 1s (remain 18m 35s) Loss avg.: 0.4214 Grad: 0.2108 LR: 0.00012  \n",
      "Epoch: [10][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4206 Grad: 0.2401 LR: 0.00012  \n",
      "Epoch: [10][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4212 Grad: 0.2132 LR: 0.00012  \n",
      "Epoch: [10][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4215 Grad: 0.2303 LR: 0.00012  \n",
      "Epoch: [10][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4217 Grad: 0.2490 LR: 0.00012  \n",
      "Epoch: [10][600/1929] Elapsed 6m 0s (remain 13m 15s) Loss avg.: 0.4219 Grad: 0.2089 LR: 0.00012  \n",
      "Epoch: [10][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4221 Grad: 0.2310 LR: 0.00012  \n",
      "Epoch: [10][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4219 Grad: 0.2014 LR: 0.00012  \n",
      "Epoch: [10][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4219 Grad: 0.2686 LR: 0.00012  \n",
      "Epoch: [10][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4218 Grad: 0.2383 LR: 0.00012  \n",
      "Epoch: [10][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4218 Grad: 0.2424 LR: 0.00012  \n",
      "Epoch: [10][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4220 Grad: 0.2402 LR: 0.00012  \n",
      "Epoch: [10][1300/1929] Elapsed 12m 57s (remain 6m 15s) Loss avg.: 0.4220 Grad: 0.2524 LR: 0.00012  \n",
      "Epoch: [10][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4221 Grad: 0.2302 LR: 0.00012  \n",
      "Epoch: [10][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4221 Grad: 0.2872 LR: 0.00012  \n",
      "Epoch: [10][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4220 Grad: 0.2534 LR: 0.00012  \n",
      "Epoch: [10][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4219 Grad: 0.2252 LR: 0.00012  \n",
      "Epoch: [10][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4219 Grad: 0.2540 LR: 0.00012  \n",
      "Epoch: [10][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4220 Grad: 0.2322 LR: 0.00012  \n",
      "Epoch: [10][1928/1929] Elapsed 19m 12s (remain 0m 0s) Loss avg.: 0.4220 Grad: 0.2339 LR: 0.00012  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 34s) Loss avg.: 0.3986 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4361 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4375 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4381 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.4220  avg_val_loss: 0.4381  time: 1189s\n",
      "Epoch 10 - Accuracy: 0.8116564086345279\n",
      "Epoch 10 - Save Best Score: 0.8117 Model\n",
      "Epoch 10 - Save final model\n",
      "========== fold: 7 result ==========\n",
      "Score: 0.81166\n",
      "========== fold: 8 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load pre-train weight.\n",
      "Epoch: [1][0/1929] Elapsed 0m 2s (remain 65m 16s) Loss avg.: 1.3965 Grad: 0.3519 LR: 0.00100  \n",
      "Epoch: [1][100/1929] Elapsed 1m 2s (remain 18m 42s) Loss avg.: 0.7022 Grad: 0.7898 LR: 0.00100  \n",
      "Epoch: [1][200/1929] Elapsed 2m 1s (remain 17m 27s) Loss avg.: 0.6341 Grad: 0.6242 LR: 0.00100  \n",
      "Epoch: [1][300/1929] Elapsed 3m 1s (remain 16m 21s) Loss avg.: 0.6010 Grad: 0.5542 LR: 0.00100  \n",
      "Epoch: [1][400/1929] Elapsed 4m 1s (remain 15m 19s) Loss avg.: 0.5801 Grad: 0.6988 LR: 0.00100  \n",
      "Epoch: [1][500/1929] Elapsed 5m 1s (remain 14m 17s) Loss avg.: 0.5648 Grad: 0.5629 LR: 0.00100  \n",
      "Epoch: [1][600/1929] Elapsed 6m 0s (remain 13m 17s) Loss avg.: 0.5539 Grad: 0.4368 LR: 0.00100  \n",
      "Epoch: [1][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.5452 Grad: 0.6940 LR: 0.00100  \n",
      "Epoch: [1][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.5381 Grad: 0.5456 LR: 0.00100  \n",
      "Epoch: [1][900/1929] Elapsed 9m 0s (remain 10m 16s) Loss avg.: 0.5324 Grad: 0.3052 LR: 0.00100  \n",
      "Epoch: [1][1000/1929] Elapsed 10m 0s (remain 9m 16s) Loss avg.: 0.5275 Grad: 0.4153 LR: 0.00100  \n",
      "Epoch: [1][1100/1929] Elapsed 10m 59s (remain 8m 16s) Loss avg.: 0.5232 Grad: 0.4106 LR: 0.00100  \n",
      "Epoch: [1][1200/1929] Elapsed 11m 59s (remain 7m 16s) Loss avg.: 0.5196 Grad: 0.4141 LR: 0.00100  \n",
      "Epoch: [1][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.5162 Grad: 0.6937 LR: 0.00100  \n",
      "Epoch: [1][1400/1929] Elapsed 13m 58s (remain 5m 16s) Loss avg.: 0.5135 Grad: 0.3099 LR: 0.00100  \n",
      "Epoch: [1][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.5108 Grad: 0.4897 LR: 0.00100  \n",
      "Epoch: [1][1600/1929] Elapsed 15m 58s (remain 3m 16s) Loss avg.: 0.5084 Grad: 0.4084 LR: 0.00100  \n",
      "Epoch: [1][1700/1929] Elapsed 16m 58s (remain 2m 16s) Loss avg.: 0.5062 Grad: 0.3055 LR: 0.00100  \n",
      "Epoch: [1][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.5041 Grad: 0.3542 LR: 0.00100  \n",
      "Epoch: [1][1900/1929] Elapsed 18m 57s (remain 0m 16s) Loss avg.: 0.5024 Grad: 0.3396 LR: 0.00100  \n",
      "Epoch: [1][1928/1929] Elapsed 19m 14s (remain 0m 0s) Loss avg.: 0.5019 Grad: 0.3598 LR: 0.00100  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 33s) Loss avg.: 0.4654 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4741 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4734 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4740 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.5019  avg_val_loss: 0.4740  time: 1190s\n",
      "Epoch 1 - Accuracy: 0.7934178558259453\n",
      "Epoch 1 - Save Best Score: 0.7934 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1929] Elapsed 0m 1s (remain 60m 32s) Loss avg.: 0.4440 Grad: 0.4162 LR: 0.00098  \n",
      "Epoch: [2][100/1929] Elapsed 1m 1s (remain 18m 36s) Loss avg.: 0.4638 Grad: 0.3140 LR: 0.00098  \n",
      "Epoch: [2][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4641 Grad: 0.3084 LR: 0.00098  \n",
      "Epoch: [2][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4634 Grad: 0.3332 LR: 0.00098  \n",
      "Epoch: [2][400/1929] Elapsed 4m 0s (remain 15m 18s) Loss avg.: 0.4636 Grad: 0.2944 LR: 0.00098  \n",
      "Epoch: [2][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4635 Grad: 0.2809 LR: 0.00098  \n",
      "Epoch: [2][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4635 Grad: 0.3532 LR: 0.00098  \n",
      "Epoch: [2][700/1929] Elapsed 6m 59s (remain 12m 15s) Loss avg.: 0.4627 Grad: 0.4812 LR: 0.00098  \n",
      "Epoch: [2][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4623 Grad: 0.2701 LR: 0.00098  \n",
      "Epoch: [2][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4621 Grad: 0.3597 LR: 0.00098  \n",
      "Epoch: [2][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4618 Grad: 0.2884 LR: 0.00098  \n",
      "Epoch: [2][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4616 Grad: 0.2661 LR: 0.00098  \n",
      "Epoch: [2][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4613 Grad: 0.2146 LR: 0.00098  \n",
      "Epoch: [2][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4610 Grad: 0.2350 LR: 0.00098  \n",
      "Epoch: [2][1400/1929] Elapsed 13m 57s (remain 5m 15s) Loss avg.: 0.4606 Grad: 0.2787 LR: 0.00098  \n",
      "Epoch: [2][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4603 Grad: 0.3685 LR: 0.00098  \n",
      "Epoch: [2][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4602 Grad: 0.2733 LR: 0.00098  \n",
      "Epoch: [2][1700/1929] Elapsed 16m 56s (remain 2m 16s) Loss avg.: 0.4600 Grad: 0.3492 LR: 0.00098  \n",
      "Epoch: [2][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4598 Grad: 0.3116 LR: 0.00098  \n",
      "Epoch: [2][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4597 Grad: 0.2959 LR: 0.00098  \n",
      "Epoch: [2][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4596 Grad: 0.2915 LR: 0.00098  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 32s) Loss avg.: 0.4557 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4574 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4570 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4575 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4596  avg_val_loss: 0.4575  time: 1189s\n",
      "Epoch 2 - Accuracy: 0.8025327598746008\n",
      "Epoch 2 - Save Best Score: 0.8025 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1929] Elapsed 0m 1s (remain 61m 29s) Loss avg.: 0.4484 Grad: 0.2712 LR: 0.00091  \n",
      "Epoch: [3][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4492 Grad: 0.3404 LR: 0.00091  \n",
      "Epoch: [3][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4499 Grad: 0.3410 LR: 0.00091  \n",
      "Epoch: [3][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4507 Grad: 0.3869 LR: 0.00091  \n",
      "Epoch: [3][400/1929] Elapsed 4m 1s (remain 15m 19s) Loss avg.: 0.4506 Grad: 0.3723 LR: 0.00091  \n",
      "Epoch: [3][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4511 Grad: 0.3303 LR: 0.00091  \n",
      "Epoch: [3][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4510 Grad: 0.3026 LR: 0.00091  \n",
      "Epoch: [3][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4509 Grad: 0.3271 LR: 0.00091  \n",
      "Epoch: [3][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4508 Grad: 0.2402 LR: 0.00091  \n",
      "Epoch: [3][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4507 Grad: 0.2172 LR: 0.00091  \n",
      "Epoch: [3][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4508 Grad: 0.2795 LR: 0.00091  \n",
      "Epoch: [3][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4506 Grad: 0.2577 LR: 0.00091  \n",
      "Epoch: [3][1200/1929] Elapsed 11m 59s (remain 7m 15s) Loss avg.: 0.4504 Grad: 0.3433 LR: 0.00091  \n",
      "Epoch: [3][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4505 Grad: 0.2449 LR: 0.00091  \n",
      "Epoch: [3][1400/1929] Elapsed 13m 58s (remain 5m 16s) Loss avg.: 0.4503 Grad: 0.2584 LR: 0.00091  \n",
      "Epoch: [3][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4503 Grad: 0.2567 LR: 0.00091  \n",
      "Epoch: [3][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4503 Grad: 0.2261 LR: 0.00091  \n",
      "Epoch: [3][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4503 Grad: 0.2944 LR: 0.00091  \n",
      "Epoch: [3][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4503 Grad: 0.2338 LR: 0.00091  \n",
      "Epoch: [3][1900/1929] Elapsed 18m 57s (remain 0m 16s) Loss avg.: 0.4502 Grad: 0.2064 LR: 0.00091  \n",
      "Epoch: [3][1928/1929] Elapsed 19m 14s (remain 0m 0s) Loss avg.: 0.4502 Grad: 0.4359 LR: 0.00091  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 31s) Loss avg.: 0.4514 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4532 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4529 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4534 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.4502  avg_val_loss: 0.4534  time: 1190s\n",
      "Epoch 3 - Accuracy: 0.8037949132014534\n",
      "Epoch 3 - Save Best Score: 0.8038 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/1929] Elapsed 0m 1s (remain 61m 0s) Loss avg.: 0.4531 Grad: 0.3007 LR: 0.00081  \n",
      "Epoch: [4][100/1929] Elapsed 1m 1s (remain 18m 38s) Loss avg.: 0.4442 Grad: 0.2262 LR: 0.00081  \n",
      "Epoch: [4][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4442 Grad: 0.2712 LR: 0.00081  \n",
      "Epoch: [4][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4441 Grad: 0.2335 LR: 0.00081  \n",
      "Epoch: [4][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4438 Grad: 0.2189 LR: 0.00081  \n",
      "Epoch: [4][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4441 Grad: 0.2088 LR: 0.00081  \n",
      "Epoch: [4][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4443 Grad: 0.2212 LR: 0.00081  \n",
      "Epoch: [4][700/1929] Elapsed 7m 0s (remain 12m 15s) Loss avg.: 0.4444 Grad: 0.2191 LR: 0.00081  \n",
      "Epoch: [4][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4444 Grad: 0.2191 LR: 0.00081  \n",
      "Epoch: [4][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4446 Grad: 0.2491 LR: 0.00081  \n",
      "Epoch: [4][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4448 Grad: 0.2463 LR: 0.00081  \n",
      "Epoch: [4][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4447 Grad: 0.2113 LR: 0.00081  \n",
      "Epoch: [4][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4446 Grad: 0.1922 LR: 0.00081  \n",
      "Epoch: [4][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4445 Grad: 0.2120 LR: 0.00081  \n",
      "Epoch: [4][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4446 Grad: 0.2159 LR: 0.00081  \n",
      "Epoch: [4][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4446 Grad: 0.2813 LR: 0.00081  \n",
      "Epoch: [4][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4445 Grad: 0.1919 LR: 0.00081  \n",
      "Epoch: [4][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4444 Grad: 0.3369 LR: 0.00081  \n",
      "Epoch: [4][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4443 Grad: 0.2459 LR: 0.00081  \n",
      "Epoch: [4][1900/1929] Elapsed 18m 57s (remain 0m 16s) Loss avg.: 0.4442 Grad: 0.2733 LR: 0.00081  \n",
      "Epoch: [4][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4443 Grad: 0.2269 LR: 0.00081  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 4m 9s) Loss avg.: 0.4433 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4489 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4485 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4489 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.4443  avg_val_loss: 0.4489  time: 1190s\n",
      "Epoch 4 - Accuracy: 0.806135580918457\n",
      "Epoch 4 - Save Best Score: 0.8061 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/1929] Elapsed 0m 1s (remain 61m 49s) Loss avg.: 0.4415 Grad: 0.2395 LR: 0.00069  \n",
      "Epoch: [5][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4402 Grad: 0.1980 LR: 0.00069  \n",
      "Epoch: [5][200/1929] Elapsed 2m 1s (remain 17m 25s) Loss avg.: 0.4397 Grad: 0.2381 LR: 0.00069  \n",
      "Epoch: [5][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4389 Grad: 0.2324 LR: 0.00069  \n",
      "Epoch: [5][400/1929] Elapsed 4m 1s (remain 15m 18s) Loss avg.: 0.4385 Grad: 0.3042 LR: 0.00069  \n",
      "Epoch: [5][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4386 Grad: 0.2605 LR: 0.00069  \n",
      "Epoch: [5][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4390 Grad: 0.1978 LR: 0.00069  \n",
      "Epoch: [5][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4389 Grad: 0.2299 LR: 0.00069  \n",
      "Epoch: [5][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4390 Grad: 0.2499 LR: 0.00069  \n",
      "Epoch: [5][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4392 Grad: 0.2755 LR: 0.00069  \n",
      "Epoch: [5][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4392 Grad: 0.2751 LR: 0.00069  \n",
      "Epoch: [5][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4395 Grad: 0.2390 LR: 0.00069  \n",
      "Epoch: [5][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4394 Grad: 0.2161 LR: 0.00069  \n",
      "Epoch: [5][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4395 Grad: 0.1747 LR: 0.00069  \n",
      "Epoch: [5][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4395 Grad: 0.2724 LR: 0.00069  \n",
      "Epoch: [5][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4395 Grad: 0.1885 LR: 0.00069  \n",
      "Epoch: [5][1600/1929] Elapsed 15m 58s (remain 3m 16s) Loss avg.: 0.4395 Grad: 0.1802 LR: 0.00069  \n",
      "Epoch: [5][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4395 Grad: 0.3332 LR: 0.00069  \n",
      "Epoch: [5][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4395 Grad: 0.1818 LR: 0.00069  \n",
      "Epoch: [5][1900/1929] Elapsed 18m 57s (remain 0m 16s) Loss avg.: 0.4395 Grad: 0.1780 LR: 0.00069  \n",
      "Epoch: [5][1928/1929] Elapsed 19m 14s (remain 0m 0s) Loss avg.: 0.4395 Grad: 0.2433 LR: 0.00069  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 33s) Loss avg.: 0.4472 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4467 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4460 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4465 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.4395  avg_val_loss: 0.4465  time: 1190s\n",
      "Epoch 5 - Accuracy: 0.8073685852077379\n",
      "Epoch 5 - Save Best Score: 0.8074 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/1929] Elapsed 0m 2s (remain 65m 6s) Loss avg.: 0.4379 Grad: 0.2554 LR: 0.00055  \n",
      "Epoch: [6][100/1929] Elapsed 1m 2s (remain 18m 42s) Loss avg.: 0.4334 Grad: 0.2308 LR: 0.00055  \n",
      "Epoch: [6][200/1929] Elapsed 2m 1s (remain 17m 25s) Loss avg.: 0.4335 Grad: 0.2832 LR: 0.00055  \n",
      "Epoch: [6][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4342 Grad: 0.1802 LR: 0.00055  \n",
      "Epoch: [6][400/1929] Elapsed 4m 1s (remain 15m 18s) Loss avg.: 0.4346 Grad: 0.2301 LR: 0.00055  \n",
      "Epoch: [6][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4352 Grad: 0.3057 LR: 0.00055  \n",
      "Epoch: [6][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4351 Grad: 0.2436 LR: 0.00055  \n",
      "Epoch: [6][700/1929] Elapsed 7m 0s (remain 12m 15s) Loss avg.: 0.4349 Grad: 0.1965 LR: 0.00055  \n",
      "Epoch: [6][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4351 Grad: 0.2265 LR: 0.00055  \n",
      "Epoch: [6][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4350 Grad: 0.2089 LR: 0.00055  \n",
      "Epoch: [6][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4352 Grad: 0.1978 LR: 0.00055  \n",
      "Epoch: [6][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4353 Grad: 0.1791 LR: 0.00055  \n",
      "Epoch: [6][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4352 Grad: 0.2580 LR: 0.00055  \n",
      "Epoch: [6][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4351 Grad: 0.1967 LR: 0.00055  \n",
      "Epoch: [6][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4351 Grad: 0.2065 LR: 0.00055  \n",
      "Epoch: [6][1500/1929] Elapsed 14m 57s (remain 4m 16s) Loss avg.: 0.4351 Grad: 0.2151 LR: 0.00055  \n",
      "Epoch: [6][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4352 Grad: 0.2322 LR: 0.00055  \n",
      "Epoch: [6][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4352 Grad: 0.2048 LR: 0.00055  \n",
      "Epoch: [6][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4352 Grad: 0.1994 LR: 0.00055  \n",
      "Epoch: [6][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4352 Grad: 0.2152 LR: 0.00055  \n",
      "Epoch: [6][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4352 Grad: 0.2060 LR: 0.00055  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 34s) Loss avg.: 0.4391 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4433 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4429 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4433 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.4352  avg_val_loss: 0.4433  time: 1189s\n",
      "Epoch 6 - Accuracy: 0.8093463474069745\n",
      "Epoch 6 - Save Best Score: 0.8093 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/1929] Elapsed 0m 1s (remain 60m 49s) Loss avg.: 0.4310 Grad: 0.1967 LR: 0.00041  \n",
      "Epoch: [7][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4303 Grad: 0.2402 LR: 0.00041  \n",
      "Epoch: [7][200/1929] Elapsed 2m 1s (remain 17m 26s) Loss avg.: 0.4294 Grad: 0.1781 LR: 0.00041  \n",
      "Epoch: [7][300/1929] Elapsed 3m 1s (remain 16m 21s) Loss avg.: 0.4302 Grad: 0.2110 LR: 0.00041  \n",
      "Epoch: [7][400/1929] Elapsed 4m 1s (remain 15m 19s) Loss avg.: 0.4303 Grad: 0.2520 LR: 0.00041  \n",
      "Epoch: [7][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4305 Grad: 0.2065 LR: 0.00041  \n",
      "Epoch: [7][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4303 Grad: 0.2036 LR: 0.00041  \n",
      "Epoch: [7][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4302 Grad: 0.2469 LR: 0.00041  \n",
      "Epoch: [7][800/1929] Elapsed 8m 0s (remain 11m 15s) Loss avg.: 0.4307 Grad: 0.2064 LR: 0.00041  \n",
      "Epoch: [7][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4308 Grad: 0.2039 LR: 0.00041  \n",
      "Epoch: [7][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4308 Grad: 0.2067 LR: 0.00041  \n",
      "Epoch: [7][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4309 Grad: 0.2176 LR: 0.00041  \n",
      "Epoch: [7][1200/1929] Elapsed 11m 59s (remain 7m 15s) Loss avg.: 0.4310 Grad: 0.2658 LR: 0.00041  \n",
      "Epoch: [7][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4310 Grad: 0.2054 LR: 0.00041  \n",
      "Epoch: [7][1400/1929] Elapsed 13m 58s (remain 5m 16s) Loss avg.: 0.4310 Grad: 0.1880 LR: 0.00041  \n",
      "Epoch: [7][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4311 Grad: 0.2644 LR: 0.00041  \n",
      "Epoch: [7][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4312 Grad: 0.1879 LR: 0.00041  \n",
      "Epoch: [7][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4311 Grad: 0.1848 LR: 0.00041  \n",
      "Epoch: [7][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4312 Grad: 0.1997 LR: 0.00041  \n",
      "Epoch: [7][1900/1929] Elapsed 18m 57s (remain 0m 16s) Loss avg.: 0.4311 Grad: 0.2086 LR: 0.00041  \n",
      "Epoch: [7][1928/1929] Elapsed 19m 14s (remain 0m 0s) Loss avg.: 0.4311 Grad: 0.2210 LR: 0.00041  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 29s) Loss avg.: 0.4393 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4421 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4418 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4423 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.4311  avg_val_loss: 0.4423  time: 1190s\n",
      "Epoch 7 - Accuracy: 0.8097690084517635\n",
      "Epoch 7 - Save Best Score: 0.8098 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/1929] Elapsed 0m 1s (remain 61m 11s) Loss avg.: 0.4050 Grad: 0.2269 LR: 0.00029  \n",
      "Epoch: [8][100/1929] Elapsed 1m 1s (remain 18m 36s) Loss avg.: 0.4267 Grad: 0.2039 LR: 0.00029  \n",
      "Epoch: [8][200/1929] Elapsed 2m 1s (remain 17m 23s) Loss avg.: 0.4261 Grad: 0.1924 LR: 0.00029  \n",
      "Epoch: [8][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4261 Grad: 0.2097 LR: 0.00029  \n",
      "Epoch: [8][400/1929] Elapsed 4m 1s (remain 15m 18s) Loss avg.: 0.4258 Grad: 0.2098 LR: 0.00029  \n",
      "Epoch: [8][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4257 Grad: 0.2148 LR: 0.00029  \n",
      "Epoch: [8][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4261 Grad: 0.2194 LR: 0.00029  \n",
      "Epoch: [8][700/1929] Elapsed 7m 0s (remain 12m 15s) Loss avg.: 0.4262 Grad: 0.2430 LR: 0.00029  \n",
      "Epoch: [8][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4263 Grad: 0.2686 LR: 0.00029  \n",
      "Epoch: [8][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4263 Grad: 0.2253 LR: 0.00029  \n",
      "Epoch: [8][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4266 Grad: 0.2476 LR: 0.00029  \n",
      "Epoch: [8][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4266 Grad: 0.2458 LR: 0.00029  \n",
      "Epoch: [8][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4266 Grad: 0.2607 LR: 0.00029  \n",
      "Epoch: [8][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4268 Grad: 0.2067 LR: 0.00029  \n",
      "Epoch: [8][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4267 Grad: 0.2253 LR: 0.00029  \n",
      "Epoch: [8][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4268 Grad: 0.2282 LR: 0.00029  \n",
      "Epoch: [8][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4269 Grad: 0.2179 LR: 0.00029  \n",
      "Epoch: [8][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4269 Grad: 0.2195 LR: 0.00029  \n",
      "Epoch: [8][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4270 Grad: 0.2516 LR: 0.00029  \n",
      "Epoch: [8][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4271 Grad: 0.2683 LR: 0.00029  \n",
      "Epoch: [8][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4272 Grad: 0.2267 LR: 0.00029  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 32s) Loss avg.: 0.4369 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4399 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4395 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4399 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.4272  avg_val_loss: 0.4399  time: 1190s\n",
      "Epoch 8 - Accuracy: 0.8107440437585351\n",
      "Epoch 8 - Save Best Score: 0.8107 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/1929] Elapsed 0m 1s (remain 61m 49s) Loss avg.: 0.4257 Grad: 0.2384 LR: 0.00019  \n",
      "Epoch: [9][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4243 Grad: 0.2112 LR: 0.00019  \n",
      "Epoch: [9][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4230 Grad: 0.2035 LR: 0.00019  \n",
      "Epoch: [9][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4229 Grad: 0.2374 LR: 0.00019  \n",
      "Epoch: [9][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4228 Grad: 0.2027 LR: 0.00019  \n",
      "Epoch: [9][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4231 Grad: 0.1999 LR: 0.00019  \n",
      "Epoch: [9][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4230 Grad: 0.2709 LR: 0.00019  \n",
      "Epoch: [9][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4231 Grad: 0.2392 LR: 0.00019  \n",
      "Epoch: [9][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4234 Grad: 0.2200 LR: 0.00019  \n",
      "Epoch: [9][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4233 Grad: 0.2330 LR: 0.00019  \n",
      "Epoch: [9][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4234 Grad: 0.2196 LR: 0.00019  \n",
      "Epoch: [9][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4235 Grad: 0.3381 LR: 0.00019  \n",
      "Epoch: [9][1200/1929] Elapsed 11m 59s (remain 7m 15s) Loss avg.: 0.4236 Grad: 0.2557 LR: 0.00019  \n",
      "Epoch: [9][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.4237 Grad: 0.2391 LR: 0.00019  \n",
      "Epoch: [9][1400/1929] Elapsed 13m 58s (remain 5m 16s) Loss avg.: 0.4236 Grad: 0.2506 LR: 0.00019  \n",
      "Epoch: [9][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4236 Grad: 0.2326 LR: 0.00019  \n",
      "Epoch: [9][1600/1929] Elapsed 15m 58s (remain 3m 16s) Loss avg.: 0.4236 Grad: 0.1973 LR: 0.00019  \n",
      "Epoch: [9][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4236 Grad: 0.2426 LR: 0.00019  \n",
      "Epoch: [9][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4237 Grad: 0.2269 LR: 0.00019  \n",
      "Epoch: [9][1900/1929] Elapsed 18m 57s (remain 0m 16s) Loss avg.: 0.4237 Grad: 0.2422 LR: 0.00019  \n",
      "Epoch: [9][1928/1929] Elapsed 19m 14s (remain 0m 0s) Loss avg.: 0.4238 Grad: 0.2262 LR: 0.00019  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 4m 50s) Loss avg.: 0.4362 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4389 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4386 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4390 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.4238  avg_val_loss: 0.4390  time: 1190s\n",
      "Epoch 9 - Accuracy: 0.8109407997621438\n",
      "Epoch 9 - Save Best Score: 0.8109 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/1929] Elapsed 0m 1s (remain 61m 19s) Loss avg.: 0.4229 Grad: 0.2180 LR: 0.00012  \n",
      "Epoch: [10][100/1929] Elapsed 1m 1s (remain 18m 38s) Loss avg.: 0.4209 Grad: 0.2097 LR: 0.00012  \n",
      "Epoch: [10][200/1929] Elapsed 2m 1s (remain 17m 25s) Loss avg.: 0.4207 Grad: 0.2042 LR: 0.00012  \n",
      "Epoch: [10][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4205 Grad: 0.2166 LR: 0.00012  \n",
      "Epoch: [10][400/1929] Elapsed 4m 1s (remain 15m 18s) Loss avg.: 0.4208 Grad: 0.2199 LR: 0.00012  \n",
      "Epoch: [10][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4206 Grad: 0.2477 LR: 0.00012  \n",
      "Epoch: [10][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4207 Grad: 0.2219 LR: 0.00012  \n",
      "Epoch: [10][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4205 Grad: 0.2185 LR: 0.00012  \n",
      "Epoch: [10][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4206 Grad: 0.2460 LR: 0.00012  \n",
      "Epoch: [10][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4206 Grad: 0.2248 LR: 0.00012  \n",
      "Epoch: [10][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4207 Grad: 0.2164 LR: 0.00012  \n",
      "Epoch: [10][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4208 Grad: 0.2427 LR: 0.00012  \n",
      "Epoch: [10][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4209 Grad: 0.2393 LR: 0.00012  \n",
      "Epoch: [10][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4208 Grad: 0.2243 LR: 0.00012  \n",
      "Epoch: [10][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4207 Grad: 0.2349 LR: 0.00012  \n",
      "Epoch: [10][1500/1929] Elapsed 14m 57s (remain 4m 16s) Loss avg.: 0.4208 Grad: 0.2131 LR: 0.00012  \n",
      "Epoch: [10][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4210 Grad: 0.2128 LR: 0.00012  \n",
      "Epoch: [10][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4210 Grad: 0.2227 LR: 0.00012  \n",
      "Epoch: [10][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4210 Grad: 0.2347 LR: 0.00012  \n",
      "Epoch: [10][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4211 Grad: 0.2683 LR: 0.00012  \n",
      "Epoch: [10][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4212 Grad: 0.2228 LR: 0.00012  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 36s) Loss avg.: 0.4344 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4381 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4376 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4381 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.4212  avg_val_loss: 0.4381  time: 1189s\n",
      "Epoch 10 - Accuracy: 0.811429046141469\n",
      "Epoch 10 - Save Best Score: 0.8114 Model\n",
      "Epoch 10 - Save final model\n",
      "========== fold: 8 result ==========\n",
      "Score: 0.81143\n",
      "========== fold: 9 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load pre-train weight.\n",
      "Epoch: [1][0/1929] Elapsed 0m 1s (remain 62m 56s) Loss avg.: 1.3970 Grad: 0.3706 LR: 0.00100  \n",
      "Epoch: [1][100/1929] Elapsed 1m 1s (remain 18m 38s) Loss avg.: 0.6945 Grad: 0.5884 LR: 0.00100  \n",
      "Epoch: [1][200/1929] Elapsed 2m 1s (remain 17m 26s) Loss avg.: 0.6309 Grad: 0.5877 LR: 0.00100  \n",
      "Epoch: [1][300/1929] Elapsed 3m 1s (remain 16m 22s) Loss avg.: 0.6005 Grad: 0.8615 LR: 0.00100  \n",
      "Epoch: [1][400/1929] Elapsed 4m 1s (remain 15m 20s) Loss avg.: 0.5815 Grad: 0.8059 LR: 0.00100  \n",
      "Epoch: [1][500/1929] Elapsed 5m 1s (remain 14m 18s) Loss avg.: 0.5676 Grad: 0.4923 LR: 0.00100  \n",
      "Epoch: [1][600/1929] Elapsed 6m 1s (remain 13m 18s) Loss avg.: 0.5569 Grad: 0.4533 LR: 0.00100  \n",
      "Epoch: [1][700/1929] Elapsed 7m 0s (remain 12m 17s) Loss avg.: 0.5485 Grad: 0.5088 LR: 0.00100  \n",
      "Epoch: [1][800/1929] Elapsed 8m 0s (remain 11m 17s) Loss avg.: 0.5412 Grad: 0.6085 LR: 0.00100  \n",
      "Epoch: [1][900/1929] Elapsed 9m 0s (remain 10m 16s) Loss avg.: 0.5353 Grad: 0.4452 LR: 0.00100  \n",
      "Epoch: [1][1000/1929] Elapsed 10m 0s (remain 9m 16s) Loss avg.: 0.5305 Grad: 0.4525 LR: 0.00100  \n",
      "Epoch: [1][1100/1929] Elapsed 11m 0s (remain 8m 16s) Loss avg.: 0.5260 Grad: 0.4141 LR: 0.00100  \n",
      "Epoch: [1][1200/1929] Elapsed 11m 59s (remain 7m 16s) Loss avg.: 0.5223 Grad: 0.6315 LR: 0.00100  \n",
      "Epoch: [1][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.5190 Grad: 0.4889 LR: 0.00100  \n",
      "Epoch: [1][1400/1929] Elapsed 13m 59s (remain 5m 16s) Loss avg.: 0.5160 Grad: 0.2860 LR: 0.00100  \n",
      "Epoch: [1][1500/1929] Elapsed 14m 59s (remain 4m 16s) Loss avg.: 0.5133 Grad: 0.3949 LR: 0.00100  \n",
      "Epoch: [1][1600/1929] Elapsed 15m 58s (remain 3m 16s) Loss avg.: 0.5108 Grad: 0.4072 LR: 0.00100  \n",
      "Epoch: [1][1700/1929] Elapsed 16m 58s (remain 2m 16s) Loss avg.: 0.5085 Grad: 0.5303 LR: 0.00100  \n",
      "Epoch: [1][1800/1929] Elapsed 17m 58s (remain 1m 16s) Loss avg.: 0.5064 Grad: 0.5040 LR: 0.00100  \n",
      "Epoch: [1][1900/1929] Elapsed 18m 57s (remain 0m 16s) Loss avg.: 0.5044 Grad: 0.4067 LR: 0.00100  \n",
      "Epoch: [1][1928/1929] Elapsed 19m 14s (remain 0m 0s) Loss avg.: 0.5040 Grad: 0.4410 LR: 0.00100  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 35s) Loss avg.: 0.4601 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4708 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4713 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4720 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.5040  avg_val_loss: 0.4720  time: 1190s\n",
      "Epoch 1 - Accuracy: 0.7948796800601636\n",
      "Epoch 1 - Save Best Score: 0.7949 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1929] Elapsed 0m 2s (remain 66m 24s) Loss avg.: 0.4699 Grad: 0.5035 LR: 0.00098  \n",
      "Epoch: [2][100/1929] Elapsed 1m 2s (remain 18m 44s) Loss avg.: 0.4654 Grad: 0.4325 LR: 0.00098  \n",
      "Epoch: [2][200/1929] Elapsed 2m 1s (remain 17m 27s) Loss avg.: 0.4645 Grad: 0.3415 LR: 0.00098  \n",
      "Epoch: [2][300/1929] Elapsed 3m 1s (remain 16m 21s) Loss avg.: 0.4653 Grad: 0.5049 LR: 0.00098  \n",
      "Epoch: [2][400/1929] Elapsed 4m 1s (remain 15m 19s) Loss avg.: 0.4648 Grad: 0.4221 LR: 0.00098  \n",
      "Epoch: [2][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4642 Grad: 0.2910 LR: 0.00098  \n",
      "Epoch: [2][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4640 Grad: 0.4179 LR: 0.00098  \n",
      "Epoch: [2][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4636 Grad: 0.4707 LR: 0.00098  \n",
      "Epoch: [2][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4634 Grad: 0.2861 LR: 0.00098  \n",
      "Epoch: [2][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4631 Grad: 0.3326 LR: 0.00098  \n",
      "Epoch: [2][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4629 Grad: 0.2863 LR: 0.00098  \n",
      "Epoch: [2][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4625 Grad: 0.3043 LR: 0.00098  \n",
      "Epoch: [2][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4621 Grad: 0.2600 LR: 0.00098  \n",
      "Epoch: [2][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4618 Grad: 0.3216 LR: 0.00098  \n",
      "Epoch: [2][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4616 Grad: 0.3269 LR: 0.00098  \n",
      "Epoch: [2][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4615 Grad: 0.3291 LR: 0.00098  \n",
      "Epoch: [2][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4611 Grad: 0.3379 LR: 0.00098  \n",
      "Epoch: [2][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4608 Grad: 0.2806 LR: 0.00098  \n",
      "Epoch: [2][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4606 Grad: 0.3765 LR: 0.00098  \n",
      "Epoch: [2][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4603 Grad: 0.3075 LR: 0.00098  \n",
      "Epoch: [2][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4603 Grad: 0.2928 LR: 0.00098  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 36s) Loss avg.: 0.4471 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4580 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4583 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4589 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4603  avg_val_loss: 0.4589  time: 1189s\n",
      "Epoch 2 - Accuracy: 0.8012720639996269\n",
      "Epoch 2 - Save Best Score: 0.8013 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1929] Elapsed 0m 1s (remain 62m 14s) Loss avg.: 0.4304 Grad: 0.3626 LR: 0.00091  \n",
      "Epoch: [3][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4518 Grad: 0.3118 LR: 0.00091  \n",
      "Epoch: [3][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4518 Grad: 0.2955 LR: 0.00091  \n",
      "Epoch: [3][300/1929] Elapsed 3m 1s (remain 16m 21s) Loss avg.: 0.4517 Grad: 0.2851 LR: 0.00091  \n",
      "Epoch: [3][400/1929] Elapsed 4m 1s (remain 15m 19s) Loss avg.: 0.4515 Grad: 0.2735 LR: 0.00091  \n",
      "Epoch: [3][500/1929] Elapsed 5m 1s (remain 14m 17s) Loss avg.: 0.4513 Grad: 0.3510 LR: 0.00091  \n",
      "Epoch: [3][600/1929] Elapsed 6m 0s (remain 13m 17s) Loss avg.: 0.4514 Grad: 0.3197 LR: 0.00091  \n",
      "Epoch: [3][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4515 Grad: 0.2680 LR: 0.00091  \n",
      "Epoch: [3][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4513 Grad: 0.2497 LR: 0.00091  \n",
      "Epoch: [3][900/1929] Elapsed 8m 59s (remain 10m 16s) Loss avg.: 0.4512 Grad: 0.3352 LR: 0.00091  \n",
      "Epoch: [3][1000/1929] Elapsed 9m 59s (remain 9m 16s) Loss avg.: 0.4511 Grad: 0.2851 LR: 0.00091  \n",
      "Epoch: [3][1100/1929] Elapsed 10m 59s (remain 8m 16s) Loss avg.: 0.4513 Grad: 0.2900 LR: 0.00091  \n",
      "Epoch: [3][1200/1929] Elapsed 11m 59s (remain 7m 16s) Loss avg.: 0.4513 Grad: 0.2412 LR: 0.00091  \n",
      "Epoch: [3][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.4512 Grad: 0.2994 LR: 0.00091  \n",
      "Epoch: [3][1400/1929] Elapsed 13m 58s (remain 5m 16s) Loss avg.: 0.4510 Grad: 0.2906 LR: 0.00091  \n",
      "Epoch: [3][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4510 Grad: 0.2413 LR: 0.00091  \n",
      "Epoch: [3][1600/1929] Elapsed 15m 58s (remain 3m 16s) Loss avg.: 0.4510 Grad: 0.3305 LR: 0.00091  \n",
      "Epoch: [3][1700/1929] Elapsed 16m 58s (remain 2m 16s) Loss avg.: 0.4509 Grad: 0.2650 LR: 0.00091  \n",
      "Epoch: [3][1800/1929] Elapsed 17m 58s (remain 1m 16s) Loss avg.: 0.4508 Grad: 0.2654 LR: 0.00091  \n",
      "Epoch: [3][1900/1929] Elapsed 18m 57s (remain 0m 16s) Loss avg.: 0.4507 Grad: 0.2483 LR: 0.00091  \n",
      "Epoch: [3][1928/1929] Elapsed 19m 14s (remain 0m 0s) Loss avg.: 0.4506 Grad: 0.2244 LR: 0.00091  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 35s) Loss avg.: 0.4417 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4522 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4527 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4534 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.4506  avg_val_loss: 0.4534  time: 1190s\n",
      "Epoch 3 - Accuracy: 0.8043312554927717\n",
      "Epoch 3 - Save Best Score: 0.8043 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/1929] Elapsed 0m 1s (remain 62m 4s) Loss avg.: 0.4551 Grad: 0.2459 LR: 0.00081  \n",
      "Epoch: [4][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4446 Grad: 0.2601 LR: 0.00081  \n",
      "Epoch: [4][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4443 Grad: 0.2634 LR: 0.00081  \n",
      "Epoch: [4][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4451 Grad: 0.2668 LR: 0.00081  \n",
      "Epoch: [4][400/1929] Elapsed 4m 1s (remain 15m 18s) Loss avg.: 0.4453 Grad: 0.2722 LR: 0.00081  \n",
      "Epoch: [4][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4447 Grad: 0.3394 LR: 0.00081  \n",
      "Epoch: [4][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4446 Grad: 0.2945 LR: 0.00081  \n",
      "Epoch: [4][700/1929] Elapsed 7m 0s (remain 12m 15s) Loss avg.: 0.4445 Grad: 0.2578 LR: 0.00081  \n",
      "Epoch: [4][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4446 Grad: 0.3440 LR: 0.00081  \n",
      "Epoch: [4][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4446 Grad: 0.2444 LR: 0.00081  \n",
      "Epoch: [4][1000/1929] Elapsed 9m 58s (remain 9m 15s) Loss avg.: 0.4446 Grad: 0.2468 LR: 0.00081  \n",
      "Epoch: [4][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4447 Grad: 0.2267 LR: 0.00081  \n",
      "Epoch: [4][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4447 Grad: 0.2038 LR: 0.00081  \n",
      "Epoch: [4][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4446 Grad: 0.2726 LR: 0.00081  \n",
      "Epoch: [4][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4447 Grad: 0.2912 LR: 0.00081  \n",
      "Epoch: [4][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4448 Grad: 0.3049 LR: 0.00081  \n",
      "Epoch: [4][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4449 Grad: 0.2601 LR: 0.00081  \n",
      "Epoch: [4][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4449 Grad: 0.2550 LR: 0.00081  \n",
      "Epoch: [4][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4449 Grad: 0.2555 LR: 0.00081  \n",
      "Epoch: [4][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4448 Grad: 0.2135 LR: 0.00081  \n",
      "Epoch: [4][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4448 Grad: 0.2185 LR: 0.00081  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 34s) Loss avg.: 0.4331 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4467 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4470 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4478 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.4448  avg_val_loss: 0.4478  time: 1189s\n",
      "Epoch 4 - Accuracy: 0.8072957126138087\n",
      "Epoch 4 - Save Best Score: 0.8073 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/1929] Elapsed 0m 1s (remain 62m 2s) Loss avg.: 0.4598 Grad: 0.2275 LR: 0.00069  \n",
      "Epoch: [5][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4386 Grad: 0.2775 LR: 0.00069  \n",
      "Epoch: [5][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4385 Grad: 0.2959 LR: 0.00069  \n",
      "Epoch: [5][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4386 Grad: 0.2849 LR: 0.00069  \n",
      "Epoch: [5][400/1929] Elapsed 4m 1s (remain 15m 18s) Loss avg.: 0.4390 Grad: 0.3178 LR: 0.00069  \n",
      "Epoch: [5][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4388 Grad: 0.2269 LR: 0.00069  \n",
      "Epoch: [5][600/1929] Elapsed 6m 0s (remain 13m 17s) Loss avg.: 0.4387 Grad: 0.2315 LR: 0.00069  \n",
      "Epoch: [5][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4392 Grad: 0.1966 LR: 0.00069  \n",
      "Epoch: [5][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4395 Grad: 0.2810 LR: 0.00069  \n",
      "Epoch: [5][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4395 Grad: 0.2298 LR: 0.00069  \n",
      "Epoch: [5][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4397 Grad: 0.1907 LR: 0.00069  \n",
      "Epoch: [5][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4397 Grad: 0.3205 LR: 0.00069  \n",
      "Epoch: [5][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4397 Grad: 0.2264 LR: 0.00069  \n",
      "Epoch: [5][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4395 Grad: 0.2168 LR: 0.00069  \n",
      "Epoch: [5][1400/1929] Elapsed 13m 58s (remain 5m 16s) Loss avg.: 0.4396 Grad: 0.3227 LR: 0.00069  \n",
      "Epoch: [5][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4397 Grad: 0.2106 LR: 0.00069  \n",
      "Epoch: [5][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4398 Grad: 0.2553 LR: 0.00069  \n",
      "Epoch: [5][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4399 Grad: 0.2826 LR: 0.00069  \n",
      "Epoch: [5][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4399 Grad: 0.2714 LR: 0.00069  \n",
      "Epoch: [5][1900/1929] Elapsed 18m 57s (remain 0m 16s) Loss avg.: 0.4399 Grad: 0.2654 LR: 0.00069  \n",
      "Epoch: [5][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4400 Grad: 0.2207 LR: 0.00069  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 4m 8s) Loss avg.: 0.4321 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4448 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4447 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4454 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.4400  avg_val_loss: 0.4454  time: 1190s\n",
      "Epoch 5 - Accuracy: 0.8076396712571543\n",
      "Epoch 5 - Save Best Score: 0.8076 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/1929] Elapsed 0m 1s (remain 61m 53s) Loss avg.: 0.4380 Grad: 0.2390 LR: 0.00055  \n",
      "Epoch: [6][100/1929] Elapsed 1m 1s (remain 18m 38s) Loss avg.: 0.4342 Grad: 0.2345 LR: 0.00055  \n",
      "Epoch: [6][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4348 Grad: 0.2385 LR: 0.00055  \n",
      "Epoch: [6][300/1929] Elapsed 3m 1s (remain 16m 19s) Loss avg.: 0.4346 Grad: 0.2202 LR: 0.00055  \n",
      "Epoch: [6][400/1929] Elapsed 4m 0s (remain 15m 17s) Loss avg.: 0.4345 Grad: 0.2177 LR: 0.00055  \n",
      "Epoch: [6][500/1929] Elapsed 5m 0s (remain 14m 16s) Loss avg.: 0.4347 Grad: 0.2254 LR: 0.00055  \n",
      "Epoch: [6][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4349 Grad: 0.2375 LR: 0.00055  \n",
      "Epoch: [6][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4348 Grad: 0.2294 LR: 0.00055  \n",
      "Epoch: [6][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4352 Grad: 0.2185 LR: 0.00055  \n",
      "Epoch: [6][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4354 Grad: 0.2188 LR: 0.00055  \n",
      "Epoch: [6][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4355 Grad: 0.2022 LR: 0.00055  \n",
      "Epoch: [6][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4356 Grad: 0.2205 LR: 0.00055  \n",
      "Epoch: [6][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4355 Grad: 0.2792 LR: 0.00055  \n",
      "Epoch: [6][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4355 Grad: 0.2127 LR: 0.00055  \n",
      "Epoch: [6][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4356 Grad: 0.1981 LR: 0.00055  \n",
      "Epoch: [6][1500/1929] Elapsed 14m 57s (remain 4m 16s) Loss avg.: 0.4355 Grad: 0.2426 LR: 0.00055  \n",
      "Epoch: [6][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4355 Grad: 0.2241 LR: 0.00055  \n",
      "Epoch: [6][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4355 Grad: 0.2112 LR: 0.00055  \n",
      "Epoch: [6][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4355 Grad: 0.2628 LR: 0.00055  \n",
      "Epoch: [6][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4355 Grad: 0.2202 LR: 0.00055  \n",
      "Epoch: [6][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4355 Grad: 0.2252 LR: 0.00055  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 30s) Loss avg.: 0.4304 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4412 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4414 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4421 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.4355  avg_val_loss: 0.4421  time: 1189s\n",
      "Epoch 6 - Accuracy: 0.8101217118063805\n",
      "Epoch 6 - Save Best Score: 0.8101 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/1929] Elapsed 0m 2s (remain 65m 28s) Loss avg.: 0.4400 Grad: 0.2844 LR: 0.00041  \n",
      "Epoch: [7][100/1929] Elapsed 1m 2s (remain 18m 42s) Loss avg.: 0.4310 Grad: 0.2361 LR: 0.00041  \n",
      "Epoch: [7][200/1929] Elapsed 2m 1s (remain 17m 25s) Loss avg.: 0.4316 Grad: 0.2206 LR: 0.00041  \n",
      "Epoch: [7][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4311 Grad: 0.2043 LR: 0.00041  \n",
      "Epoch: [7][400/1929] Elapsed 4m 0s (remain 15m 18s) Loss avg.: 0.4314 Grad: 0.2162 LR: 0.00041  \n",
      "Epoch: [7][500/1929] Elapsed 5m 0s (remain 14m 17s) Loss avg.: 0.4310 Grad: 0.2140 LR: 0.00041  \n",
      "Epoch: [7][600/1929] Elapsed 6m 0s (remain 13m 16s) Loss avg.: 0.4312 Grad: 0.2277 LR: 0.00041  \n",
      "Epoch: [7][700/1929] Elapsed 7m 0s (remain 12m 15s) Loss avg.: 0.4309 Grad: 0.2155 LR: 0.00041  \n",
      "Epoch: [7][800/1929] Elapsed 7m 59s (remain 11m 15s) Loss avg.: 0.4312 Grad: 0.2439 LR: 0.00041  \n",
      "Epoch: [7][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4314 Grad: 0.2089 LR: 0.00041  \n",
      "Epoch: [7][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4312 Grad: 0.2524 LR: 0.00041  \n",
      "Epoch: [7][1100/1929] Elapsed 10m 58s (remain 8m 15s) Loss avg.: 0.4312 Grad: 0.2140 LR: 0.00041  \n",
      "Epoch: [7][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4312 Grad: 0.2208 LR: 0.00041  \n",
      "Epoch: [7][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4313 Grad: 0.2371 LR: 0.00041  \n",
      "Epoch: [7][1400/1929] Elapsed 13m 58s (remain 5m 15s) Loss avg.: 0.4314 Grad: 0.2511 LR: 0.00041  \n",
      "Epoch: [7][1500/1929] Elapsed 14m 57s (remain 4m 15s) Loss avg.: 0.4315 Grad: 0.2653 LR: 0.00041  \n",
      "Epoch: [7][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4315 Grad: 0.2449 LR: 0.00041  \n",
      "Epoch: [7][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4315 Grad: 0.2231 LR: 0.00041  \n",
      "Epoch: [7][1800/1929] Elapsed 17m 56s (remain 1m 16s) Loss avg.: 0.4315 Grad: 0.2797 LR: 0.00041  \n",
      "Epoch: [7][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4315 Grad: 0.2522 LR: 0.00041  \n",
      "Epoch: [7][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4315 Grad: 0.2635 LR: 0.00041  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 36s) Loss avg.: 0.4263 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4389 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4394 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4401 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.4315  avg_val_loss: 0.4401  time: 1189s\n",
      "Epoch 7 - Accuracy: 0.8107863098630141\n",
      "Epoch 7 - Save Best Score: 0.8108 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/1929] Elapsed 0m 1s (remain 61m 48s) Loss avg.: 0.4359 Grad: 0.2060 LR: 0.00029  \n",
      "Epoch: [8][100/1929] Elapsed 1m 1s (remain 18m 38s) Loss avg.: 0.4293 Grad: 0.2200 LR: 0.00029  \n",
      "Epoch: [8][200/1929] Elapsed 2m 1s (remain 17m 26s) Loss avg.: 0.4286 Grad: 0.2302 LR: 0.00029  \n",
      "Epoch: [8][300/1929] Elapsed 3m 1s (remain 16m 21s) Loss avg.: 0.4281 Grad: 0.2375 LR: 0.00029  \n",
      "Epoch: [8][400/1929] Elapsed 4m 1s (remain 15m 19s) Loss avg.: 0.4279 Grad: 0.2304 LR: 0.00029  \n",
      "Epoch: [8][500/1929] Elapsed 5m 1s (remain 14m 17s) Loss avg.: 0.4282 Grad: 0.2218 LR: 0.00029  \n",
      "Epoch: [8][600/1929] Elapsed 6m 0s (remain 13m 17s) Loss avg.: 0.4280 Grad: 0.3283 LR: 0.00029  \n",
      "Epoch: [8][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4277 Grad: 0.2503 LR: 0.00029  \n",
      "Epoch: [8][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4276 Grad: 0.2435 LR: 0.00029  \n",
      "Epoch: [8][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4277 Grad: 0.2106 LR: 0.00029  \n",
      "Epoch: [8][1000/1929] Elapsed 9m 59s (remain 9m 16s) Loss avg.: 0.4274 Grad: 0.2198 LR: 0.00029  \n",
      "Epoch: [8][1100/1929] Elapsed 10m 59s (remain 8m 16s) Loss avg.: 0.4273 Grad: 0.2023 LR: 0.00029  \n",
      "Epoch: [8][1200/1929] Elapsed 11m 59s (remain 7m 16s) Loss avg.: 0.4274 Grad: 0.2215 LR: 0.00029  \n",
      "Epoch: [8][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.4273 Grad: 0.2494 LR: 0.00029  \n",
      "Epoch: [8][1400/1929] Elapsed 13m 58s (remain 5m 16s) Loss avg.: 0.4274 Grad: 0.2313 LR: 0.00029  \n",
      "Epoch: [8][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4275 Grad: 0.2745 LR: 0.00029  \n",
      "Epoch: [8][1600/1929] Elapsed 15m 58s (remain 3m 16s) Loss avg.: 0.4275 Grad: 0.2829 LR: 0.00029  \n",
      "Epoch: [8][1700/1929] Elapsed 16m 58s (remain 2m 16s) Loss avg.: 0.4275 Grad: 0.2343 LR: 0.00029  \n",
      "Epoch: [8][1800/1929] Elapsed 17m 58s (remain 1m 16s) Loss avg.: 0.4276 Grad: 0.2644 LR: 0.00029  \n",
      "Epoch: [8][1900/1929] Elapsed 18m 57s (remain 0m 16s) Loss avg.: 0.4276 Grad: 0.2865 LR: 0.00029  \n",
      "Epoch: [8][1928/1929] Elapsed 19m 14s (remain 0m 0s) Loss avg.: 0.4277 Grad: 0.2338 LR: 0.00029  \n",
      "Eval: [0/215] Elapsed 0m 0s (remain 3m 27s) Loss avg.: 0.4271 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4383 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4387 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4394 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.4277  avg_val_loss: 0.4394  time: 1190s\n",
      "Epoch 8 - Accuracy: 0.8112264603303461\n",
      "Epoch 8 - Save Best Score: 0.8112 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/1929] Elapsed 0m 1s (remain 61m 49s) Loss avg.: 0.4266 Grad: 0.2636 LR: 0.00019  \n",
      "Epoch: [9][100/1929] Elapsed 1m 1s (remain 18m 38s) Loss avg.: 0.4226 Grad: 0.2008 LR: 0.00019  \n",
      "Epoch: [9][200/1929] Elapsed 2m 1s (remain 17m 25s) Loss avg.: 0.4230 Grad: 0.2196 LR: 0.00019  \n",
      "Epoch: [9][300/1929] Elapsed 3m 1s (remain 16m 22s) Loss avg.: 0.4228 Grad: 0.2003 LR: 0.00019  \n",
      "Epoch: [9][400/1929] Elapsed 4m 1s (remain 15m 19s) Loss avg.: 0.4231 Grad: 0.2059 LR: 0.00019  \n",
      "Epoch: [9][500/1929] Elapsed 5m 1s (remain 14m 18s) Loss avg.: 0.4230 Grad: 0.2790 LR: 0.00019  \n",
      "Epoch: [9][600/1929] Elapsed 6m 0s (remain 13m 17s) Loss avg.: 0.4232 Grad: 0.2675 LR: 0.00019  \n",
      "Epoch: [9][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4235 Grad: 0.2529 LR: 0.00019  \n",
      "Epoch: [9][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4236 Grad: 0.2103 LR: 0.00019  \n",
      "Epoch: [9][900/1929] Elapsed 9m 0s (remain 10m 16s) Loss avg.: 0.4237 Grad: 0.2048 LR: 0.00019  \n",
      "Epoch: [9][1000/1929] Elapsed 9m 59s (remain 9m 16s) Loss avg.: 0.4238 Grad: 0.2207 LR: 0.00019  \n",
      "Epoch: [9][1100/1929] Elapsed 10m 59s (remain 8m 16s) Loss avg.: 0.4238 Grad: 0.2192 LR: 0.00019  \n",
      "Epoch: [9][1200/1929] Elapsed 11m 59s (remain 7m 16s) Loss avg.: 0.4238 Grad: 0.2573 LR: 0.00019  \n",
      "Epoch: [9][1300/1929] Elapsed 12m 59s (remain 6m 16s) Loss avg.: 0.4238 Grad: 0.2272 LR: 0.00019  \n",
      "Epoch: [9][1400/1929] Elapsed 13m 59s (remain 5m 16s) Loss avg.: 0.4240 Grad: 0.2058 LR: 0.00019  \n",
      "Epoch: [9][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4240 Grad: 0.2158 LR: 0.00019  \n",
      "Epoch: [9][1600/1929] Elapsed 15m 58s (remain 3m 16s) Loss avg.: 0.4240 Grad: 0.2253 LR: 0.00019  \n",
      "Epoch: [9][1700/1929] Elapsed 16m 58s (remain 2m 16s) Loss avg.: 0.4240 Grad: 0.2272 LR: 0.00019  \n",
      "Epoch: [9][1800/1929] Elapsed 17m 58s (remain 1m 16s) Loss avg.: 0.4241 Grad: 0.2305 LR: 0.00019  \n",
      "Epoch: [9][1900/1929] Elapsed 18m 58s (remain 0m 16s) Loss avg.: 0.4242 Grad: 0.2515 LR: 0.00019  \n",
      "Epoch: [9][1928/1929] Elapsed 19m 14s (remain 0m 0s) Loss avg.: 0.4242 Grad: 0.1949 LR: 0.00019  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 3m 36s) Loss avg.: 0.4266 \n",
      "Eval: [100/215] Elapsed 0m 16s (remain 0m 19s) Loss avg.: 0.4372 \n",
      "Eval: [200/215] Elapsed 0m 32s (remain 0m 2s) Loss avg.: 0.4373 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4380 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.4242  avg_val_loss: 0.4380  time: 1191s\n",
      "Epoch 9 - Accuracy: 0.8116928449314925\n",
      "Epoch 9 - Save Best Score: 0.8117 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/1929] Elapsed 0m 1s (remain 60m 17s) Loss avg.: 0.4178 Grad: 0.2188 LR: 0.00012  \n",
      "Epoch: [10][100/1929] Elapsed 1m 1s (remain 18m 37s) Loss avg.: 0.4195 Grad: 0.2329 LR: 0.00012  \n",
      "Epoch: [10][200/1929] Elapsed 2m 1s (remain 17m 24s) Loss avg.: 0.4206 Grad: 0.2480 LR: 0.00012  \n",
      "Epoch: [10][300/1929] Elapsed 3m 1s (remain 16m 20s) Loss avg.: 0.4206 Grad: 0.2623 LR: 0.00012  \n",
      "Epoch: [10][400/1929] Elapsed 4m 1s (remain 15m 18s) Loss avg.: 0.4207 Grad: 0.2363 LR: 0.00012  \n",
      "Epoch: [10][500/1929] Elapsed 5m 1s (remain 14m 18s) Loss avg.: 0.4208 Grad: 0.2788 LR: 0.00012  \n",
      "Epoch: [10][600/1929] Elapsed 6m 0s (remain 13m 17s) Loss avg.: 0.4207 Grad: 0.2270 LR: 0.00012  \n",
      "Epoch: [10][700/1929] Elapsed 7m 0s (remain 12m 16s) Loss avg.: 0.4207 Grad: 0.2362 LR: 0.00012  \n",
      "Epoch: [10][800/1929] Elapsed 8m 0s (remain 11m 16s) Loss avg.: 0.4209 Grad: 0.2117 LR: 0.00012  \n",
      "Epoch: [10][900/1929] Elapsed 8m 59s (remain 10m 15s) Loss avg.: 0.4209 Grad: 0.2276 LR: 0.00012  \n",
      "Epoch: [10][1000/1929] Elapsed 9m 59s (remain 9m 15s) Loss avg.: 0.4210 Grad: 0.2070 LR: 0.00012  \n",
      "Epoch: [10][1100/1929] Elapsed 10m 59s (remain 8m 15s) Loss avg.: 0.4211 Grad: 0.2576 LR: 0.00012  \n",
      "Epoch: [10][1200/1929] Elapsed 11m 58s (remain 7m 15s) Loss avg.: 0.4210 Grad: 0.2669 LR: 0.00012  \n",
      "Epoch: [10][1300/1929] Elapsed 12m 58s (remain 6m 15s) Loss avg.: 0.4212 Grad: 0.2338 LR: 0.00012  \n",
      "Epoch: [10][1400/1929] Elapsed 13m 58s (remain 5m 16s) Loss avg.: 0.4214 Grad: 0.2363 LR: 0.00012  \n",
      "Epoch: [10][1500/1929] Elapsed 14m 58s (remain 4m 16s) Loss avg.: 0.4216 Grad: 0.2184 LR: 0.00012  \n",
      "Epoch: [10][1600/1929] Elapsed 15m 57s (remain 3m 16s) Loss avg.: 0.4216 Grad: 0.2197 LR: 0.00012  \n",
      "Epoch: [10][1700/1929] Elapsed 16m 57s (remain 2m 16s) Loss avg.: 0.4216 Grad: 0.2327 LR: 0.00012  \n",
      "Epoch: [10][1800/1929] Elapsed 17m 57s (remain 1m 16s) Loss avg.: 0.4216 Grad: 0.2469 LR: 0.00012  \n",
      "Epoch: [10][1900/1929] Elapsed 18m 56s (remain 0m 16s) Loss avg.: 0.4216 Grad: 0.2488 LR: 0.00012  \n",
      "Epoch: [10][1928/1929] Elapsed 19m 13s (remain 0m 0s) Loss avg.: 0.4216 Grad: 0.2423 LR: 0.00012  \n",
      "Eval: [0/215] Elapsed 0m 1s (remain 4m 7s) Loss avg.: 0.4253 \n",
      "Eval: [100/215] Elapsed 0m 17s (remain 0m 19s) Loss avg.: 0.4368 \n",
      "Eval: [200/215] Elapsed 0m 33s (remain 0m 2s) Loss avg.: 0.4370 \n",
      "Eval: [214/215] Elapsed 0m 35s (remain 0m 0s) Loss avg.: 0.4377 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.4216  avg_val_loss: 0.4377  time: 1190s\n",
      "Epoch 10 - Accuracy: 0.811914377617037\n",
      "Epoch 10 - Save Best Score: 0.8119 Model\n",
      "Epoch 10 - Save final model\n",
      "========== fold: 9 result ==========\n",
      "Score: 0.81191\n",
      "========== CV ==========\n",
      "Score: 0.81191\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "hungry-geese-train-by-episode.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2945.71762,
   "end_time": "2021-05-12T03:50:02.012348",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-12T03:00:56.294728",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04a486aa6f454d8f92e388dba1b9ee21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0857c0fa22b544488d65bb2c7dad18ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f905db5005be40b194ea150c8b0deb9f",
      "max": 1001,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "value": 1001
     }
    },
    "4134662bdbe04a918d9809632e268ef8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0857c0fa22b544488d65bb2c7dad18ee",
       "IPY_MODEL_e33e4f894b424988b316c468bc9225ce"
      ],
      "layout": "IPY_MODEL_8ddb49ac3c91409f99a569a061a70b3d"
     }
    },
    "507d2b6a02bb43d0bb4c8c2734f19cbb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ddb49ac3c91409f99a569a061a70b3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c96b7bfbdf0243a8ae1dbb3d9aedf123": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e33e4f894b424988b316c468bc9225ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_507d2b6a02bb43d0bb4c8c2734f19cbb",
      "placeholder": "​",
      "style": "IPY_MODEL_04a486aa6f454d8f92e388dba1b9ee21",
      "value": " 1001/1001 [03:35&lt;00:00,  4.64it/s]"
     }
    },
    "f905db5005be40b194ea150c8b0deb9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abroad-piece",
    "papermill": {
     "duration": 0.025714,
     "end_time": "2021-05-12T03:01:02.640708",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.614994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About this notebook ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pressing-commercial",
    "papermill": {
     "duration": 0.024272,
     "end_time": "2021-05-12T03:01:02.689850",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.665578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "german-ethics",
    "papermill": {
     "duration": 1.852306,
     "end_time": "2021-05-12T03:01:04.566362",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.714056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "apparent-fiction",
    "papermill": {
     "duration": 0.030961,
     "end_time": "2021-05-12T03:01:04.622818",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.591857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "editorial-haiti",
    "papermill": {
     "duration": 0.024908,
     "end_time": "2021-05-12T03:01:05.115280",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.090372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "opened-python",
    "papermill": {
     "duration": 0.035637,
     "end_time": "2021-05-12T03:01:05.176119",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.140482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 440\n",
    "\n",
    "    n_class = 4\n",
    "    n_fold = 10\n",
    "\n",
    "    geese_net_layers = 12\n",
    "    geese_net_filters = 32\n",
    "\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "\n",
    "    num_workers = 4\n",
    "    batch_size = 3200\n",
    "\n",
    "    scheduler = \"CosineAnnealingWarmRestarts\"\n",
    "    # factor = 0.2  # ReduceLROnPlateau\n",
    "    # patience = 4  # ReduceLROnPlateau\n",
    "    # eps = 1e-6  # ReduceLROnPlateau\n",
    "    # T_max = 10  # CosineAnnealingLR\n",
    "    T_0 = 10  # CosineAnnealingWarmRestarts\n",
    "\n",
    "    criterion = \"CrossEntropyLoss\"\n",
    "    lr = 1e-3\n",
    "    min_lr = 1e-4\n",
    "    weight_decay = 1e-5\n",
    "\n",
    "    epochs = 10\n",
    "    model_name = \"geese_net\"\n",
    "    pre_train_file = \"\"\n",
    "\n",
    "    print_freq = 100\n",
    "\n",
    "    train = True\n",
    "    tuning = False\n",
    "    debug = False\n",
    "    apex = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "contained-singles",
    "papermill": {
     "duration": 0.031266,
     "end_time": "2021-05-12T03:01:05.235456",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.204190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.tuning:\n",
    "    Config.epochs = 2\n",
    "\n",
    "if Config.debug:\n",
    "    Config.epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dietary-track",
    "papermill": {
     "duration": 0.031421,
     "end_time": "2021-05-12T03:01:05.292382",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.260961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.apex:\n",
    "    from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "invalid-dispute",
    "papermill": {
     "duration": 0.169531,
     "end_time": "2021-05-12T03:01:05.488665",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.319134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robust-humanity",
    "papermill": {
     "duration": 0.024539,
     "end_time": "2021-05-12T03:01:04.672270",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.647731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "designed-effect",
    "papermill": {
     "duration": 0.031167,
     "end_time": "2021-05-12T03:01:04.728079",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.696912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"../input/hungrygeeseepisode/hungry-geese-episode/\"\n",
    "OUTPUT_DIR = \"pre-models/\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "special-broadcast",
    "outputId": "c440e1e9-5651-42ee-eb0f-08c822d7471a",
    "papermill": {
     "duration": 0.31211,
     "end_time": "2021-05-12T03:01:05.064722",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.752612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22251\n"
     ]
    }
   ],
   "source": [
    "paths = [path for path in glob.glob(BASE_DIR + \"*.json\") if \"info\" not in path]\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10251\n"
     ]
    }
   ],
   "source": [
    "# fit for memory size...\n",
    "# paths = paths[-12000:]\n",
    "paths = paths[:-12000]\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    paths = paths[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "treated-serum",
    "papermill": {
     "duration": 0.025219,
     "end_time": "2021-05-12T03:01:05.539482",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.514263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gothic-alloy",
    "papermill": {
     "duration": 0.070842,
     "end_time": "2021-05-12T03:01:05.642364",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.571522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=Config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "experienced-correspondence",
    "papermill": {
     "duration": 0.053842,
     "end_time": "2021-05-12T03:01:05.741858",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.688016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reverse_ns(y):\n",
    "    if y == 0:\n",
    "        return 1\n",
    "    if y == 1:\n",
    "        return 0\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_we(y):\n",
    "    if y == 2:\n",
    "        return 3\n",
    "    if y == 3:\n",
    "        return 2\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_nswe(y):\n",
    "    return reverse_ns(reverse_we(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "further-transaction",
    "papermill": {
     "duration": 0.042365,
     "end_time": "2021-05-12T03:01:05.826807",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.784442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_position_map = {}\n",
    "for pos in range(77):\n",
    "    position = []\n",
    "    position.append((11 * (1 + pos // 11) + pos % 11) % 77)\n",
    "    position.append((11 * (-1 + pos // 11) + pos % 11) % 77)\n",
    "    position.append((11 * (pos // 11) + (pos + 1) % 11) % 77)\n",
    "    position.append((11 * (pos // 11) + (pos - 1) % 11) % 77)\n",
    "    next_position_map[pos] = set(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "naughty-clause",
    "papermill": {
     "duration": 0.058537,
     "end_time": "2021-05-12T03:01:05.928292",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.869755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_input(obses):\n",
    "    b = np.zeros((17, 7 * 11), dtype=np.float16)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "        pid = (p - obs[\"index\"]) % 4\n",
    "\n",
    "        # head position\n",
    "        for pos in pos_list[:1]:\n",
    "            b[0 + pid, pos] = 1\n",
    "        # tip position\n",
    "        for pos in pos_list[-1:]:\n",
    "            b[4 + pid, pos] = 1\n",
    "        # whole position\n",
    "        for pos in pos_list:\n",
    "            b[8 + pid, pos] = 1\n",
    "\n",
    "    # previous head position\n",
    "    if len(obses) > 1:\n",
    "        obs_prev = obses[-2]\n",
    "        for p, pos_list in enumerate(obs_prev[\"geese\"]):\n",
    "            for pos in pos_list[:1]:\n",
    "                b[12 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    # food\n",
    "    for pos in obs[\"food\"]:\n",
    "        b[16, pos] = 1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reverse_cube(obses):\n",
    "    \"\"\"\n",
    "    尻尾から順番に 1, 0.9, 0.8, ... という並び\n",
    "    \"\"\"\n",
    "    b = np.zeros((4, 7 * 11), dtype=np.float16)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, geese in enumerate(obs[\"geese\"]):\n",
    "        # whole position reverse\n",
    "        for num_reverse, pos in enumerate(geese[::-1]):\n",
    "            b[(p - obs[\"index\"]) % 4, pos] = 1 - num_reverse * 0.1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_disappear_cube(obses):\n",
    "    \"\"\"\n",
    "    次になくなる場所: 1\n",
    "    次になくなる可能性のある場所: 0.5\n",
    "    \"\"\"\n",
    "    b = np.zeros((4, 7 * 11), dtype=np.float16)\n",
    "    obs = obses[-1]\n",
    "    step = obs[\"step\"]\n",
    "\n",
    "    # foodを食べる可能性があるか。\n",
    "    eat_food_possibility = defaultdict(int)\n",
    "    for p, geese in enumerate(obs[\"geese\"]):\n",
    "        for pos in geese[:1]:\n",
    "            if not next_position_map[pos].isdisjoint(obs[\"food\"]):\n",
    "                eat_food_possibility[p] = 1\n",
    "\n",
    "    if (step % 40) == 39:  # 1つ短くなる\n",
    "        for p, geese in enumerate(obs[\"geese\"]):\n",
    "            if eat_food_possibility[p]:  # 尻尾が1、尻尾の１つ前0.5\n",
    "                for pos in geese[-1:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 1\n",
    "                for pos in geese[-2:-1]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 0.5\n",
    "            else:  # 食べる可能性なし -> 尻尾が1, 尻尾の1つ前1\n",
    "                for pos in geese[-2:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 1\n",
    "    else:  # 1つ短くならない\n",
    "        for p, geese in enumerate(obs[\"geese\"]):\n",
    "            if eat_food_possibility[p]:  # 食べる可能性があり -> 尻尾を0.5\n",
    "                for pos in geese[-1:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 0.5\n",
    "            else:  # 食べる可能性なし # 尻尾を1\n",
    "                for pos in geese[-1:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(obses):\n",
    "    b = np.zeros((7 * 11), dtype=np.float16)\n",
    "    obs = obses[-1]\n",
    "    step = obs[\"step\"]\n",
    "\n",
    "    my_goose = obs[\"geese\"][obs[\"index\"]]\n",
    "    my_length = len(my_goose)\n",
    "\n",
    "    # num step\n",
    "    b[0] = step % 200\n",
    "    b[1] = step % 40\n",
    "\n",
    "    \"\"\"\n",
    "    2-5: geese length\n",
    "    6-8: 1 if my_length is greater than opponent length\n",
    "    9-11: difference between my_length and opponent length\n",
    "    \"\"\"\n",
    "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "        pid = (p - obs[\"index\"]) % 4\n",
    "\n",
    "        p_length = len(pos_list)\n",
    "        b[2 + pid] = p_length\n",
    "\n",
    "        if pid == 0:\n",
    "            continue\n",
    "\n",
    "        if my_length > p_length:\n",
    "            b[5 + pid] = 1\n",
    "            b[8 + pid] = my_length - p_length\n",
    "        else:\n",
    "            b[5 + pid] = 0\n",
    "            b[8 + pid] = p_length - my_length\n",
    "\n",
    "    \"\"\"\n",
    "    12-14: difference between my head position and opponent one\n",
    "    \"\"\"\n",
    "    if my_length != 0:\n",
    "\n",
    "        for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "            pid = (p - obs[\"index\"]) % 4\n",
    "\n",
    "            if pid == 0 or len(pos_list) == 0:\n",
    "                continue\n",
    "\n",
    "            diff = abs(my_goose[0] - pos_list[0])\n",
    "            x_ = diff % 11\n",
    "            x = min(x_, 11 - x_)\n",
    "            y_ = diff // 11\n",
    "            y = min(y_, 7 - y_)\n",
    "            b[11 + pid] = x + y\n",
    "\n",
    "    return b.reshape(1, 7, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pretty-aaron",
    "papermill": {
     "duration": 0.042985,
     "end_time": "2021-05-12T03:01:06.014038",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.971053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "international-secret",
    "papermill": {
     "duration": 0.064855,
     "end_time": "2021-05-12T03:01:06.121648",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.056793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset_from_json(filepath, json_object=None, standing=0):\n",
    "    if json_object is None:\n",
    "        json_open = open(path, \"r\")\n",
    "        json_load = json.load(json_open)\n",
    "    else:\n",
    "        json_load = json_object\n",
    "\n",
    "    try:\n",
    "        winner_index = np.argmax(np.argsort(json_load[\"rewards\"]) == 3 - standing)\n",
    "\n",
    "        obses = []\n",
    "        X = []\n",
    "        y = []\n",
    "        actions = {\"NORTH\": 0, \"SOUTH\": 1, \"WEST\": 2, \"EAST\": 3}\n",
    "\n",
    "        for i in range(len(json_load[\"steps\"]) - 1):\n",
    "            if json_load[\"steps\"][i][winner_index][\"status\"] == \"ACTIVE\":\n",
    "                y_ = json_load[\"steps\"][i + 1][winner_index][\"action\"]\n",
    "                if y_ is not None:\n",
    "                    step = json_load[\"steps\"][i]\n",
    "                    step[winner_index][\"observation\"][\"geese\"] = step[0][\"observation\"][\"geese\"]\n",
    "                    step[winner_index][\"observation\"][\"food\"] = step[0][\"observation\"][\"food\"]\n",
    "                    step[winner_index][\"observation\"][\"step\"] = step[0][\"observation\"][\"step\"]\n",
    "                    obses.append(step[winner_index][\"observation\"])\n",
    "                    y.append(actions[y_])\n",
    "\n",
    "                    y.append(reverse_ns(actions[y_]))  # 上下反転\n",
    "                    y.append(reverse_we(actions[y_]))  # 左右反転\n",
    "                    y.append(reverse_nswe(actions[y_]))  # 上下左右反転\n",
    "\n",
    "        for j in range(len(obses)):\n",
    "            # X_ = make_input(obses[: j + 1])\n",
    "\n",
    "            # 反転可能な特徴量\n",
    "            X_ = []\n",
    "            X_.append(make_input(obses[: j + 1]))\n",
    "            X_.append(get_reverse_cube(obses[: j + 1]))\n",
    "            X_.append(get_next_disappear_cube(obses[: j + 1]))\n",
    "\n",
    "            # 反転不可能な特徴量\n",
    "            X_i = []\n",
    "            X_i.append(get_features(obses[: j + 1]))\n",
    "\n",
    "            X_ = np.concatenate(X_)\n",
    "            X_i = np.concatenate(X_i)\n",
    "\n",
    "            X.append(np.concatenate([X_, X_i]))\n",
    "            X.append(np.concatenate([X_[:, ::-1, :], X_i]))  # 上下反転\n",
    "            X.append(np.concatenate([X_[:, :, ::-1], X_i]))  # 左右反転\n",
    "            X.append(np.concatenate([X_[:, ::-1, ::-1], X_i]))  # 上下左右反転\n",
    "\n",
    "        X = np.array(X, dtype=np.float16)  # [starting_step:]\n",
    "        y = np.array(y, dtype=np.uint8)  # [starting_step:]\n",
    "\n",
    "        return X, y\n",
    "    except Exception as e:\n",
    "        if Config.debug:\n",
    "            raise Exception from e\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "4134662bdbe04a918d9809632e268ef8",
      "8ddb49ac3c91409f99a569a061a70b3d",
      "0857c0fa22b544488d65bb2c7dad18ee",
      "e33e4f894b424988b316c468bc9225ce",
      "c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "f905db5005be40b194ea150c8b0deb9f",
      "04a486aa6f454d8f92e388dba1b9ee21",
      "507d2b6a02bb43d0bb4c8c2734f19cbb"
     ]
    },
    "id": "handled-pleasure",
    "outputId": "955c1c6b-36bc-4b30-dc44-b72b05398f8c",
    "papermill": {
     "duration": 15.320591,
     "end_time": "2021-05-12T03:01:21.474816",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.154225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5b91db25944260a81221580f6fb03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10251.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num episode: 6381992\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for path in tqdm(paths[: int(len(paths))]):\n",
    "    X, y = create_dataset_from_json(path, standing=0)  # use only winners' moves\n",
    "    if X is not 0:\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "persistent-loading",
    "papermill": {
     "duration": 112.92618,
     "end_time": "2021-05-12T03:03:14.428162",
     "exception": false,
     "start_time": "2021-05-12T03:01:21.501982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# X_train, unique_index = np.unique(X_train, axis=0, return_index=True)  # remove duplicate\n",
    "# y_train = y_train[unique_index]\n",
    "\n",
    "# y_train = np.eye(4, dtype=\"uint8\")[y_train]  # to categorical\n",
    "\n",
    "# print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_:\n",
    "    X_train_sum_obs = X_train.reshape(X_train.shape[0], -1).sum(1)\n",
    "    X_train_group = np.unique(X_train_sum_obs)\n",
    "    X_train_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_:\n",
    "    X_train_unique = []\n",
    "    y_train_unique = []\n",
    "    for group in tqdm(X_train_group):\n",
    "        group_index = np.where(X_train_sum_obs == group)\n",
    "\n",
    "        X_train_ = X_train[group_index]\n",
    "        y_train_ = y_train[group_index]\n",
    "\n",
    "        X_train_, unique_index = np.unique(X_train_, axis=0, return_index=True)  # remove duplicate\n",
    "        y_train_ = y_train_[unique_index]\n",
    "\n",
    "        X_train_unique.append(X_train_)\n",
    "        y_train_unique.append(y_train_)\n",
    "\n",
    "    X_train = np.concatenate(X_train_unique)\n",
    "    y_train = np.concatenate(y_train_unique)\n",
    "\n",
    "    print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_:\n",
    "    del X_train_sum_obs\n",
    "    del X_train_group\n",
    "    del X_train_unique\n",
    "    del y_train_unique\n",
    "    del X_train_\n",
    "    del y_train_\n",
    "    del group_index\n",
    "    del unique_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "micro-french",
    "papermill": {
     "duration": 0.033413,
     "end_time": "2021-05-12T03:03:15.360395",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.326982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    X_train = X_train[:1000]\n",
    "    y_train = y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "wrong-pastor",
    "outputId": "406a2f1d-0b8a-46bf-ca01-546f3110c301",
    "papermill": {
     "duration": 0.036161,
     "end_time": "2021-05-12T03:03:15.425149",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.388988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6381987</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6381988</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6381989</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6381990</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6381991</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6381992 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         action\n",
       "0             3\n",
       "1             3\n",
       "2             2\n",
       "3             2\n",
       "4             3\n",
       "...         ...\n",
       "6381987       2\n",
       "6381988       3\n",
       "6381989       3\n",
       "6381990       2\n",
       "6381991       2\n",
       "\n",
       "[6381992 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(y_train, dtype=np.uint8)\n",
    "y_df.columns = [\"action\"]\n",
    "y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "touched-coordinate",
    "papermill": {
     "duration": 0.027968,
     "end_time": "2021-05-12T03:03:15.557122",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.529154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "moving-skill",
    "outputId": "7542c4b4-f7d3-444c-8450-50bffddb1892",
    "papermill": {
     "duration": 0.202337,
     "end_time": "2021-05-12T03:03:15.787529",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.585192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  action\n",
      "0     0         152973\n",
      "      1         152972\n",
      "      2         166127\n",
      "      3         166128\n",
      "1     0         152973\n",
      "      1         152972\n",
      "      2         166127\n",
      "      3         166128\n",
      "2     0         152972\n",
      "      1         152972\n",
      "      2         166127\n",
      "      3         166128\n",
      "3     0         152972\n",
      "      1         152972\n",
      "      2         166127\n",
      "      3         166128\n",
      "4     0         152972\n",
      "      1         152972\n",
      "      2         166128\n",
      "      3         166127\n",
      "5     0         152972\n",
      "      1         152972\n",
      "      2         166128\n",
      "      3         166127\n",
      "6     0         152972\n",
      "      1         152972\n",
      "      2         166128\n",
      "      3         166127\n",
      "7     0         152972\n",
      "      1         152972\n",
      "      2         166128\n",
      "      3         166127\n",
      "8     0         152972\n",
      "      1         152973\n",
      "      2         166127\n",
      "      3         166127\n",
      "9     0         152972\n",
      "      1         152973\n",
      "      2         166127\n",
      "      3         166127\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "folds = y_df.copy()\n",
    "Fold = StratifiedKFold(n_splits=Config.n_fold, shuffle=True, random_state=Config.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[\"action\"])):\n",
    "    folds.loc[val_index, \"fold\"] = int(n)\n",
    "folds[\"fold\"] = folds[\"fold\"].astype(np.uint8)\n",
    "print(folds.groupby([\"fold\", \"action\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "creative-football",
    "papermill": {
     "duration": 0.029031,
     "end_time": "2021-05-12T03:03:15.845114",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.816083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "other-murder",
    "papermill": {
     "duration": 0.037264,
     "end_time": "2021-05-12T03:03:15.911219",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.873955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, array, label):\n",
    "        self.array = array\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx], torch.tensor(self.label[idx]).long()\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, array):\n",
    "        self.array = array\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adjusted-delhi",
    "outputId": "39504950-84bc-4692-8b90-8a5b64f741e0",
    "papermill": {
     "duration": 0.063691,
     "end_time": "2021-05-12T03:03:16.003693",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.940002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "if Config.debug or False:\n",
    "    train_ds = TrainDataset(X_train, y_train)\n",
    "\n",
    "    for i in range(1):\n",
    "        obs, action = train_ds[i]\n",
    "        print(obs.shape, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceramic-startup",
    "papermill": {
     "duration": 0.02876,
     "end_time": "2021-05-12T03:03:16.061575",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.032815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "unique-trick",
    "papermill": {
     "duration": 0.039055,
     "end_time": "2021-05-12T03:03:16.130239",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.091184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TorusConv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
    "        super().__init__()\n",
    "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([x[:, :, :, -self.edge_size[1] :], x, x[:, :, :, : self.edge_size[1]]], dim=3)\n",
    "        h = torch.cat([h[:, :, -self.edge_size[0] :], h, h[:, :, : self.edge_size[0]]], dim=2)\n",
    "        h = self.conv(h)\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "jspEE71c2Yma"
   },
   "outputs": [],
   "source": [
    "class GeeseNetAlpha(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = Config.geese_net_layers\n",
    "        filters = Config.geese_net_filters\n",
    "        dim = 324\n",
    "\n",
    "        self.embed_step = nn.Embedding(200, 11)\n",
    "        self.embed_hunger = nn.Embedding(40, 6)\n",
    "        self.embed_length = nn.Embedding(100, 7)\n",
    "        self.embed_diff_len = nn.Embedding(100, 8)\n",
    "        self.embed_diff_head = nn.Embedding(9, 5)\n",
    "\n",
    "        self.conv0 = TorusConv2d(25, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.attention = nn.MultiheadAttention(dim, 1)\n",
    "\n",
    "        self.head_p1 = nn.Linear(dim, dim // 2, bias=False)\n",
    "        self.head_p2 = nn.Linear(dim // 2, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(dim, dim // 2, bias=False)\n",
    "        self.head_v2 = nn.Linear(dim // 2, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        x_feats = x[:, -1].view(x.size(0), -1).long()\n",
    "\n",
    "        # Embedding for features\n",
    "        e_step = self.embed_step(x_feats[:, 0])\n",
    "        e_hung = self.embed_hunger(x_feats[:, 1])\n",
    "        e_leng = self.embed_length(x_feats[:, 2:6]).view(x.size(0), -1)\n",
    "        e_diff_lb = x_feats[:, 6:9]\n",
    "        e_diff_l = self.embed_diff_len(x_feats[:, 9:12]).view(x.size(0), -1)\n",
    "        e_diff_h = self.embed_diff_head(x_feats[:, 12:15]).view(x.size(0), -1)\n",
    "\n",
    "        x = x[:, :-1].float()\n",
    "\n",
    "        # CNN for observation\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        # Extract head position\n",
    "        h_head = (h * x[:, :1]).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        h_head2 = (h * x[:, 1:2]).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        h_head3 = (h * x[:, 2:3]).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        h_head4 = (h * x[:, 3:4]).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        h_avg1 = h.view(h.size(0), h.size(1), -1).mean(-1)\n",
    "        h_avg2 = h.view(h.size(0), h.size(1), -1).mean(1)\n",
    "\n",
    "        # Merge features\n",
    "        h = torch.cat(\n",
    "            [\n",
    "                h_head,\n",
    "                h_head2,\n",
    "                h_head3,\n",
    "                h_head4,\n",
    "                h_avg1,\n",
    "                h_avg2,\n",
    "                e_step,\n",
    "                e_hung,\n",
    "                e_leng,\n",
    "                e_diff_lb,\n",
    "                e_diff_l,\n",
    "                e_diff_h,\n",
    "            ],\n",
    "            1,\n",
    "        ).view(1, h.size(0), -1)\n",
    "\n",
    "        h, _ = self.attention(h, h, h)\n",
    "\n",
    "        h_p = F.relu_(self.head_p1(h.view(x.size(0), -1)))\n",
    "        p = self.head_p2(h_p)\n",
    "\n",
    "        h_v = F.relu_(self.head_v1(h.view(x.size(0), -1)))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p, \"value\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "objective-victoria",
    "outputId": "1ab137a5-e26e-4b9c-ff85-95fef713b755",
    "papermill": {
     "duration": 4.955868,
     "end_time": "2021-05-12T03:03:21.187355",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.231487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "if Config.debug or False:\n",
    "    model = GeeseNetAlpha()\n",
    "    # print(model)\n",
    "\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"params: {params:,}\")\n",
    "\n",
    "    train_ds = TrainDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "    for obs, action in train_loader:\n",
    "        print(f\"input shape: {obs.shape}\")\n",
    "        output = model(obs)\n",
    "        print(output)\n",
    "        print(f\"{torch.argmax(output['policy'], dim=1)}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "military-fiction",
    "papermill": {
     "duration": 0.033001,
     "end_time": "2021-05-12T03:03:21.255277",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.222276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sophisticated-hearts",
    "papermill": {
     "duration": 0.031759,
     "end_time": "2021-05-12T03:03:21.319849",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.288090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "designing-detective",
    "papermill": {
     "duration": 0.03139,
     "end_time": "2021-05-12T03:03:21.383038",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.351648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "passive-cooper",
    "papermill": {
     "duration": 0.038846,
     "end_time": "2021-05-12T03:03:21.454085",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.415239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(result_df):\n",
    "    preds = result_df[\"preds\"].values\n",
    "    labels = result_df[\"action\"].values\n",
    "    score = get_score(labels, preds)\n",
    "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thirty-tracy",
    "papermill": {
     "duration": 0.0293,
     "end_time": "2021-05-12T03:03:21.514179",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.484879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "introductory-brooklyn",
    "papermill": {
     "duration": 0.039424,
     "end_time": "2021-05-12T03:03:21.582969",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.543545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "raising-laugh",
    "papermill": {
     "duration": 0.042063,
     "end_time": "2021-05-12T03:03:21.654559",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.612496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (obs, action) in enumerate(train_loader):\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        y_preds = model(obs)[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "        if Config.apex:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), Config.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % Config.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print(\n",
    "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
    "                f\"Loss avg.: {losses.avg:.4f} \"\n",
    "                f\"Grad: {grad_norm:.4f} \"\n",
    "                f\"LR: {scheduler.get_last_lr()[0]:.5f}  \"\n",
    "            )\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "plain-neighbor",
    "papermill": {
     "duration": 0.041056,
     "end_time": "2021-05-12T03:03:21.726585",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.685529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (obs, action) in enumerate(valid_loader):\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(obs)[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print(\n",
    "                f\"Eval: [{step}/{len(valid_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
    "                f\"Loss avg.: {losses.avg:.4f} \"\n",
    "            )\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "integrated-classification",
    "papermill": {
     "duration": 0.029832,
     "end_time": "2021-05-12T03:03:21.786427",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.756595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "harmful-explanation",
    "papermill": {
     "duration": 0.05136,
     "end_time": "2021-05-12T03:03:21.868561",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.817201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(folds, fold):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    # X_train_folds = X_train[folds[\"fold\"] != fold]\n",
    "    # X_valid_folds = X_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    # y_train_folds = y_train[folds[\"fold\"] != fold]\n",
    "    y_valid_folds = y_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    # y_df_train_folds = y_df[folds[\"fold\"] != fold]\n",
    "    y_df_valid_folds = y_df[folds[\"fold\"] == fold]\n",
    "\n",
    "    # train_dataset = TrainDataset(X_train[folds[\"fold\"] != fold], y_train[folds[\"fold\"] != fold])\n",
    "    # valid_dataset = TrainDataset(X_train[folds[\"fold\"] == fold], y_valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        TrainDataset(X_train[folds[\"fold\"] != fold], y_train[folds[\"fold\"] != fold]),\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        TrainDataset(X_train[folds[\"fold\"] == fold], y_valid_folds),\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if Config.scheduler == \"ReduceLROnPlateau\":\n",
    "            scheduler = ReduceLROnPlateau(\n",
    "                optimizer, mode=\"min\", factor=Config.factor, patience=Config.patience, verbose=True, eps=Config.eps\n",
    "            )\n",
    "        elif Config.scheduler == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=Config.T_max, eta_min=Config.min_lr, last_epoch=-1)\n",
    "        elif Config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "            scheduler = CosineAnnealingWarmRestarts(\n",
    "                optimizer, T_0=Config.T_0, T_mult=1, eta_min=Config.min_lr, last_epoch=-1\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = GeeseNetAlpha()\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, Config.pre_train_file)))\n",
    "    except:\n",
    "        print(f\"Failed to load pre-train weight.\")\n",
    "\n",
    "    # Disable training for value network\n",
    "    for param in model.head_v1.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.head_v2.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Use multi GPU\n",
    "    if device == torch.device(\"cuda\") and not Config.apex:\n",
    "        model = torch.nn.DataParallel(model)  # make parallel\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=Config.lr, weight_decay=Config.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # apex\n",
    "    # ====================================================\n",
    "    if Config.apex:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
    "\n",
    "    # ====================================================\n",
    "    # Criterion\n",
    "    # ====================================================\n",
    "    def get_criterion():\n",
    "        if Config.criterion == \"CrossEntropyLoss\":\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        return criterion\n",
    "\n",
    "    criterion = get_criterion()\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    best_score = 0.0\n",
    "    best_loss = np.inf\n",
    "    best_preds = None\n",
    "\n",
    "    for epoch in range(Config.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "\n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(y_valid_folds, preds.argmax(1))\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Accuracy: {score}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_best.pth\")\n",
    "            best_preds = preds\n",
    "\n",
    "        if epoch == Config.epochs - 1:\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save final model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_final.pth\")\n",
    "\n",
    "    if Config.train:\n",
    "        y_df_valid_folds[[str(c) for c in range(Config.n_class)]] = best_preds\n",
    "        y_df_valid_folds[\"preds\"] = best_preds.argmax(1)\n",
    "\n",
    "        return y_df_valid_folds\n",
    "\n",
    "    if Config.tuning:\n",
    "        score = get_score(y_df_valid_folds[\"action\"].values, best_preds.argmax(1))\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    Config.geese_net_layers = trial.suggest_int(\"layers\", 6, 18)\n",
    "    Config.geese_net_filters = trial.suggest_int(\"filters\", 32, 128)\n",
    "\n",
    "    score = train_loop(folds, 0)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "complimentary-wright",
    "papermill": {
     "duration": 0.030218,
     "end_time": "2021-05-12T03:03:21.928896",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.898678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "particular-adaptation",
    "papermill": {
     "duration": 0.04089,
     "end_time": "2021-05-12T03:03:22.000150",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.959260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if Config.train:\n",
    "        # train\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(Config.n_fold):\n",
    "            _oof_df = train_loop(folds, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df)\n",
    "            break  # fold 1つだけ\n",
    "        # CV result\n",
    "        # LOGGER.info(f\"========== CV ==========\")\n",
    "        # get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
    "\n",
    "    if Config.tuning:\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=10)\n",
    "\n",
    "        trial = study.best_trial\n",
    "        print(\"Best trial:\")\n",
    "        print(\"  Value: \", trial.value)\n",
    "        print(\"  Params: \")\n",
    "        for key, value in trial.params.items():\n",
    "            print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "backed-journal",
    "outputId": "c9f0ff3d-795e-466b-e22e-9ba21d08c874",
    "papermill": {
     "duration": 2797.64711,
     "end_time": "2021-05-12T03:49:59.678400",
     "exception": false,
     "start_time": "2021-05-12T03:03:22.031290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load pre-train weight.\n",
      "Epoch: [1][0/1794] Elapsed 0m 3s (remain 106m 4s) Loss avg.: 1.4126 Grad: 1.0745 LR: 0.00100  \n",
      "Epoch: [1][100/1794] Elapsed 0m 32s (remain 9m 2s) Loss avg.: 0.7706 Grad: 1.0980 LR: 0.00100  \n",
      "Epoch: [1][200/1794] Elapsed 1m 1s (remain 8m 4s) Loss avg.: 0.6814 Grad: 0.9063 LR: 0.00100  \n",
      "Epoch: [1][300/1794] Elapsed 1m 30s (remain 7m 26s) Loss avg.: 0.6432 Grad: 0.8570 LR: 0.00100  \n",
      "Epoch: [1][400/1794] Elapsed 1m 59s (remain 6m 53s) Loss avg.: 0.6189 Grad: 0.9146 LR: 0.00100  \n",
      "Epoch: [1][500/1794] Elapsed 2m 28s (remain 6m 22s) Loss avg.: 0.6014 Grad: 1.3915 LR: 0.00100  \n",
      "Epoch: [1][600/1794] Elapsed 2m 57s (remain 5m 51s) Loss avg.: 0.5878 Grad: 1.3533 LR: 0.00100  \n",
      "Epoch: [1][700/1794] Elapsed 3m 26s (remain 5m 21s) Loss avg.: 0.5772 Grad: 1.1665 LR: 0.00100  \n",
      "Epoch: [1][800/1794] Elapsed 3m 55s (remain 4m 51s) Loss avg.: 0.5686 Grad: 0.7836 LR: 0.00100  \n",
      "Epoch: [1][900/1794] Elapsed 4m 24s (remain 4m 22s) Loss avg.: 0.5611 Grad: 0.7663 LR: 0.00100  \n",
      "Epoch: [1][1000/1794] Elapsed 4m 53s (remain 3m 52s) Loss avg.: 0.5552 Grad: 0.5278 LR: 0.00100  \n",
      "Epoch: [1][1100/1794] Elapsed 5m 22s (remain 3m 23s) Loss avg.: 0.5500 Grad: 0.5929 LR: 0.00100  \n",
      "Epoch: [1][1200/1794] Elapsed 5m 51s (remain 2m 53s) Loss avg.: 0.5454 Grad: 0.6045 LR: 0.00100  \n",
      "Epoch: [1][1300/1794] Elapsed 6m 20s (remain 2m 24s) Loss avg.: 0.5413 Grad: 0.5263 LR: 0.00100  \n",
      "Epoch: [1][1400/1794] Elapsed 6m 49s (remain 1m 54s) Loss avg.: 0.5377 Grad: 0.8472 LR: 0.00100  \n",
      "Epoch: [1][1500/1794] Elapsed 7m 18s (remain 1m 25s) Loss avg.: 0.5344 Grad: 0.7873 LR: 0.00100  \n",
      "Epoch: [1][1600/1794] Elapsed 7m 47s (remain 0m 56s) Loss avg.: 0.5316 Grad: 0.9271 LR: 0.00100  \n",
      "Epoch: [1][1700/1794] Elapsed 8m 16s (remain 0m 27s) Loss avg.: 0.5290 Grad: 0.6459 LR: 0.00100  \n",
      "Epoch: [1][1793/1794] Elapsed 8m 43s (remain 0m 0s) Loss avg.: 0.5267 Grad: 0.5754 LR: 0.00100  \n",
      "Eval: [0/200] Elapsed 0m 0s (remain 2m 26s) Loss avg.: 0.4551 \n",
      "Eval: [100/200] Elapsed 0m 8s (remain 0m 8s) Loss avg.: 0.4806 \n",
      "Eval: [199/200] Elapsed 0m 16s (remain 0m 0s) Loss avg.: 0.4827 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.5267  avg_val_loss: 0.4827  time: 541s\n",
      "Epoch 1 - Accuracy: 0.7898088373550611\n",
      "Epoch 1 - Save Best Score: 0.7898 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1794] Elapsed 0m 1s (remain 41m 26s) Loss avg.: 0.5057 Grad: 0.7053 LR: 0.00098  \n",
      "Epoch: [2][100/1794] Elapsed 0m 30s (remain 8m 27s) Loss avg.: 0.4805 Grad: 0.8124 LR: 0.00098  \n",
      "Epoch: [2][200/1794] Elapsed 0m 59s (remain 7m 48s) Loss avg.: 0.4793 Grad: 0.6930 LR: 0.00098  \n",
      "Epoch: [2][300/1794] Elapsed 1m 28s (remain 7m 17s) Loss avg.: 0.4804 Grad: 0.4962 LR: 0.00098  \n",
      "Epoch: [2][400/1794] Elapsed 1m 57s (remain 6m 46s) Loss avg.: 0.4805 Grad: 0.5619 LR: 0.00098  \n",
      "Epoch: [2][500/1794] Elapsed 2m 26s (remain 6m 16s) Loss avg.: 0.4803 Grad: 0.4345 LR: 0.00098  \n",
      "Epoch: [2][600/1794] Elapsed 2m 55s (remain 5m 47s) Loss avg.: 0.4798 Grad: 0.5748 LR: 0.00098  \n",
      "Epoch: [2][700/1794] Elapsed 3m 24s (remain 5m 18s) Loss avg.: 0.4790 Grad: 0.4678 LR: 0.00098  \n",
      "Epoch: [2][800/1794] Elapsed 3m 53s (remain 4m 49s) Loss avg.: 0.4788 Grad: 0.6104 LR: 0.00098  \n",
      "Epoch: [2][900/1794] Elapsed 4m 22s (remain 4m 19s) Loss avg.: 0.4783 Grad: 0.6998 LR: 0.00098  \n",
      "Epoch: [2][1000/1794] Elapsed 4m 50s (remain 3m 50s) Loss avg.: 0.4781 Grad: 0.5249 LR: 0.00098  \n",
      "Epoch: [2][1100/1794] Elapsed 5m 19s (remain 3m 21s) Loss avg.: 0.4777 Grad: 0.4930 LR: 0.00098  \n",
      "Epoch: [2][1200/1794] Elapsed 5m 48s (remain 2m 52s) Loss avg.: 0.4773 Grad: 0.4115 LR: 0.00098  \n",
      "Epoch: [2][1300/1794] Elapsed 6m 17s (remain 2m 23s) Loss avg.: 0.4771 Grad: 0.4994 LR: 0.00098  \n",
      "Epoch: [2][1400/1794] Elapsed 6m 47s (remain 1m 54s) Loss avg.: 0.4769 Grad: 0.5058 LR: 0.00098  \n",
      "Epoch: [2][1500/1794] Elapsed 7m 16s (remain 1m 25s) Loss avg.: 0.4766 Grad: 0.4240 LR: 0.00098  \n",
      "Epoch: [2][1600/1794] Elapsed 7m 45s (remain 0m 56s) Loss avg.: 0.4762 Grad: 0.5674 LR: 0.00098  \n",
      "Epoch: [2][1700/1794] Elapsed 8m 14s (remain 0m 27s) Loss avg.: 0.4760 Grad: 0.5367 LR: 0.00098  \n",
      "Epoch: [2][1793/1794] Elapsed 8m 40s (remain 0m 0s) Loss avg.: 0.4758 Grad: 0.4072 LR: 0.00098  \n",
      "Eval: [0/200] Elapsed 0m 0s (remain 2m 29s) Loss avg.: 0.4352 \n",
      "Eval: [100/200] Elapsed 0m 8s (remain 0m 8s) Loss avg.: 0.4674 \n",
      "Eval: [199/200] Elapsed 0m 16s (remain 0m 0s) Loss avg.: 0.4695 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4758  avg_val_loss: 0.4695  time: 538s\n",
      "Epoch 2 - Accuracy: 0.7964854277655907\n",
      "Epoch 2 - Save Best Score: 0.7965 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1794] Elapsed 0m 1s (remain 43m 55s) Loss avg.: 0.4700 Grad: 0.5338 LR: 0.00091  \n",
      "Epoch: [3][100/1794] Elapsed 0m 30s (remain 8m 31s) Loss avg.: 0.4667 Grad: 0.5614 LR: 0.00091  \n",
      "Epoch: [3][200/1794] Elapsed 0m 59s (remain 7m 53s) Loss avg.: 0.4664 Grad: 0.5605 LR: 0.00091  \n",
      "Epoch: [3][300/1794] Elapsed 1m 28s (remain 7m 20s) Loss avg.: 0.4658 Grad: 0.6559 LR: 0.00091  \n",
      "Epoch: [3][400/1794] Elapsed 1m 57s (remain 6m 49s) Loss avg.: 0.4659 Grad: 0.4052 LR: 0.00091  \n",
      "Epoch: [3][500/1794] Elapsed 2m 26s (remain 6m 19s) Loss avg.: 0.4664 Grad: 0.3396 LR: 0.00091  \n",
      "Epoch: [3][600/1794] Elapsed 2m 56s (remain 5m 49s) Loss avg.: 0.4662 Grad: 0.5704 LR: 0.00091  \n",
      "Epoch: [3][700/1794] Elapsed 3m 25s (remain 5m 19s) Loss avg.: 0.4657 Grad: 0.4209 LR: 0.00091  \n",
      "Epoch: [3][800/1794] Elapsed 3m 54s (remain 4m 50s) Loss avg.: 0.4656 Grad: 0.4056 LR: 0.00091  \n",
      "Epoch: [3][900/1794] Elapsed 4m 23s (remain 4m 20s) Loss avg.: 0.4658 Grad: 0.5724 LR: 0.00091  \n",
      "Epoch: [3][1000/1794] Elapsed 4m 52s (remain 3m 51s) Loss avg.: 0.4658 Grad: 0.4636 LR: 0.00091  \n",
      "Epoch: [3][1100/1794] Elapsed 5m 21s (remain 3m 22s) Loss avg.: 0.4658 Grad: 0.5149 LR: 0.00091  \n",
      "Epoch: [3][1200/1794] Elapsed 5m 50s (remain 2m 53s) Loss avg.: 0.4659 Grad: 0.5806 LR: 0.00091  \n",
      "Epoch: [3][1300/1794] Elapsed 6m 19s (remain 2m 23s) Loss avg.: 0.4658 Grad: 0.5879 LR: 0.00091  \n",
      "Epoch: [3][1400/1794] Elapsed 6m 48s (remain 1m 54s) Loss avg.: 0.4658 Grad: 0.3220 LR: 0.00091  \n",
      "Epoch: [3][1500/1794] Elapsed 7m 17s (remain 1m 25s) Loss avg.: 0.4657 Grad: 0.4879 LR: 0.00091  \n",
      "Epoch: [3][1600/1794] Elapsed 7m 47s (remain 0m 56s) Loss avg.: 0.4658 Grad: 0.3409 LR: 0.00091  \n",
      "Epoch: [3][1700/1794] Elapsed 8m 15s (remain 0m 27s) Loss avg.: 0.4656 Grad: 0.3380 LR: 0.00091  \n",
      "Epoch: [3][1793/1794] Elapsed 8m 43s (remain 0m 0s) Loss avg.: 0.4655 Grad: 0.5864 LR: 0.00091  \n",
      "Eval: [0/200] Elapsed 0m 0s (remain 2m 29s) Loss avg.: 0.4385 \n",
      "Eval: [100/200] Elapsed 0m 8s (remain 0m 8s) Loss avg.: 0.4625 \n",
      "Eval: [199/200] Elapsed 0m 16s (remain 0m 0s) Loss avg.: 0.4647 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.4655  avg_val_loss: 0.4647  time: 540s\n",
      "Epoch 3 - Accuracy: 0.7987151363209025\n",
      "Epoch 3 - Save Best Score: 0.7987 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/1794] Elapsed 0m 1s (remain 41m 21s) Loss avg.: 0.4556 Grad: 0.3991 LR: 0.00081  \n",
      "Epoch: [4][100/1794] Elapsed 0m 30s (remain 8m 28s) Loss avg.: 0.4588 Grad: 0.3424 LR: 0.00081  \n",
      "Epoch: [4][200/1794] Elapsed 0m 59s (remain 7m 50s) Loss avg.: 0.4600 Grad: 0.3638 LR: 0.00081  \n",
      "Epoch: [4][300/1794] Elapsed 1m 28s (remain 7m 17s) Loss avg.: 0.4602 Grad: 0.5142 LR: 0.00081  \n",
      "Epoch: [4][400/1794] Elapsed 1m 57s (remain 6m 47s) Loss avg.: 0.4600 Grad: 0.4954 LR: 0.00081  \n",
      "Epoch: [4][500/1794] Elapsed 2m 26s (remain 6m 16s) Loss avg.: 0.4600 Grad: 0.4509 LR: 0.00081  \n",
      "Epoch: [4][600/1794] Elapsed 2m 55s (remain 5m 47s) Loss avg.: 0.4604 Grad: 0.4398 LR: 0.00081  \n",
      "Epoch: [4][700/1794] Elapsed 3m 24s (remain 5m 18s) Loss avg.: 0.4599 Grad: 0.6407 LR: 0.00081  \n",
      "Epoch: [4][800/1794] Elapsed 3m 53s (remain 4m 49s) Loss avg.: 0.4599 Grad: 0.4257 LR: 0.00081  \n",
      "Epoch: [4][900/1794] Elapsed 4m 22s (remain 4m 20s) Loss avg.: 0.4599 Grad: 0.3944 LR: 0.00081  \n",
      "Epoch: [4][1000/1794] Elapsed 4m 51s (remain 3m 50s) Loss avg.: 0.4597 Grad: 0.4457 LR: 0.00081  \n",
      "Epoch: [4][1100/1794] Elapsed 5m 20s (remain 3m 21s) Loss avg.: 0.4598 Grad: 0.5833 LR: 0.00081  \n",
      "Epoch: [4][1200/1794] Elapsed 5m 49s (remain 2m 52s) Loss avg.: 0.4597 Grad: 0.4916 LR: 0.00081  \n",
      "Epoch: [4][1300/1794] Elapsed 6m 18s (remain 2m 23s) Loss avg.: 0.4597 Grad: 0.3302 LR: 0.00081  \n",
      "Epoch: [4][1400/1794] Elapsed 6m 47s (remain 1m 54s) Loss avg.: 0.4596 Grad: 0.3631 LR: 0.00081  \n",
      "Epoch: [4][1500/1794] Elapsed 7m 16s (remain 1m 25s) Loss avg.: 0.4595 Grad: 0.5903 LR: 0.00081  \n",
      "Epoch: [4][1600/1794] Elapsed 7m 45s (remain 0m 56s) Loss avg.: 0.4596 Grad: 0.4106 LR: 0.00081  \n",
      "Epoch: [4][1700/1794] Elapsed 8m 14s (remain 0m 27s) Loss avg.: 0.4595 Grad: 0.4660 LR: 0.00081  \n",
      "Epoch: [4][1793/1794] Elapsed 8m 41s (remain 0m 0s) Loss avg.: 0.4595 Grad: 0.4759 LR: 0.00081  \n",
      "Eval: [0/200] Elapsed 0m 0s (remain 2m 26s) Loss avg.: 0.4342 \n",
      "Eval: [100/200] Elapsed 0m 8s (remain 0m 8s) Loss avg.: 0.4616 \n",
      "Eval: [199/200] Elapsed 0m 16s (remain 0m 0s) Loss avg.: 0.4634 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.4595  avg_val_loss: 0.4634  time: 539s\n",
      "Epoch 4 - Accuracy: 0.7991162644938891\n",
      "Epoch 4 - Save Best Score: 0.7991 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/1794] Elapsed 0m 1s (remain 44m 48s) Loss avg.: 0.4691 Grad: 0.4792 LR: 0.00069  \n",
      "Epoch: [5][100/1794] Elapsed 0m 30s (remain 8m 32s) Loss avg.: 0.4534 Grad: 0.3588 LR: 0.00069  \n",
      "Epoch: [5][200/1794] Elapsed 0m 59s (remain 7m 53s) Loss avg.: 0.4544 Grad: 0.4103 LR: 0.00069  \n",
      "Epoch: [5][300/1794] Elapsed 1m 28s (remain 7m 20s) Loss avg.: 0.4544 Grad: 0.5985 LR: 0.00069  \n",
      "Epoch: [5][400/1794] Elapsed 1m 58s (remain 6m 50s) Loss avg.: 0.4539 Grad: 0.4865 LR: 0.00069  \n",
      "Epoch: [5][500/1794] Elapsed 2m 27s (remain 6m 19s) Loss avg.: 0.4543 Grad: 0.3719 LR: 0.00069  \n",
      "Epoch: [5][600/1794] Elapsed 2m 56s (remain 5m 49s) Loss avg.: 0.4544 Grad: 0.3574 LR: 0.00069  \n",
      "Epoch: [5][700/1794] Elapsed 3m 25s (remain 5m 20s) Loss avg.: 0.4546 Grad: 0.3612 LR: 0.00069  \n",
      "Epoch: [5][800/1794] Elapsed 3m 54s (remain 4m 50s) Loss avg.: 0.4546 Grad: 0.5201 LR: 0.00069  \n",
      "Epoch: [5][900/1794] Elapsed 4m 23s (remain 4m 21s) Loss avg.: 0.4544 Grad: 0.3487 LR: 0.00069  \n",
      "Epoch: [5][1000/1794] Elapsed 4m 52s (remain 3m 51s) Loss avg.: 0.4544 Grad: 0.4453 LR: 0.00069  \n",
      "Epoch: [5][1100/1794] Elapsed 5m 21s (remain 3m 22s) Loss avg.: 0.4546 Grad: 0.3799 LR: 0.00069  \n",
      "Epoch: [5][1200/1794] Elapsed 5m 50s (remain 2m 53s) Loss avg.: 0.4546 Grad: 0.2925 LR: 0.00069  \n",
      "Epoch: [5][1300/1794] Elapsed 6m 19s (remain 2m 23s) Loss avg.: 0.4546 Grad: 0.4037 LR: 0.00069  \n",
      "Epoch: [5][1400/1794] Elapsed 6m 48s (remain 1m 54s) Loss avg.: 0.4547 Grad: 0.3673 LR: 0.00069  \n",
      "Epoch: [5][1500/1794] Elapsed 7m 17s (remain 1m 25s) Loss avg.: 0.4547 Grad: 0.5336 LR: 0.00069  \n",
      "Epoch: [5][1600/1794] Elapsed 7m 46s (remain 0m 56s) Loss avg.: 0.4546 Grad: 0.4215 LR: 0.00069  \n",
      "Epoch: [5][1700/1794] Elapsed 8m 15s (remain 0m 27s) Loss avg.: 0.4546 Grad: 0.4384 LR: 0.00069  \n",
      "Epoch: [5][1793/1794] Elapsed 8m 42s (remain 0m 0s) Loss avg.: 0.4547 Grad: 0.3268 LR: 0.00069  \n",
      "Eval: [0/200] Elapsed 0m 0s (remain 2m 26s) Loss avg.: 0.4268 \n",
      "Eval: [100/200] Elapsed 0m 8s (remain 0m 8s) Loss avg.: 0.4538 \n",
      "Eval: [199/200] Elapsed 0m 16s (remain 0m 0s) Loss avg.: 0.4560 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.4547  avg_val_loss: 0.4560  time: 539s\n",
      "Epoch 5 - Accuracy: 0.8029034785333751\n",
      "Epoch 5 - Save Best Score: 0.8029 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/1794] Elapsed 0m 1s (remain 42m 26s) Loss avg.: 0.4402 Grad: 0.3685 LR: 0.00055  \n",
      "Epoch: [6][100/1794] Elapsed 0m 30s (remain 8m 26s) Loss avg.: 0.4516 Grad: 0.3568 LR: 0.00055  \n",
      "Epoch: [6][200/1794] Elapsed 0m 59s (remain 7m 48s) Loss avg.: 0.4502 Grad: 0.3990 LR: 0.00055  \n",
      "Epoch: [6][300/1794] Elapsed 1m 28s (remain 7m 16s) Loss avg.: 0.4498 Grad: 0.3793 LR: 0.00055  \n",
      "Epoch: [6][400/1794] Elapsed 1m 57s (remain 6m 46s) Loss avg.: 0.4500 Grad: 0.4265 LR: 0.00055  \n",
      "Epoch: [6][500/1794] Elapsed 2m 26s (remain 6m 17s) Loss avg.: 0.4501 Grad: 0.4202 LR: 0.00055  \n",
      "Epoch: [6][600/1794] Elapsed 2m 55s (remain 5m 47s) Loss avg.: 0.4502 Grad: 0.3246 LR: 0.00055  \n",
      "Epoch: [6][700/1794] Elapsed 3m 24s (remain 5m 18s) Loss avg.: 0.4503 Grad: 0.5350 LR: 0.00055  \n",
      "Epoch: [6][800/1794] Elapsed 3m 53s (remain 4m 49s) Loss avg.: 0.4505 Grad: 0.3006 LR: 0.00055  \n",
      "Epoch: [6][900/1794] Elapsed 4m 22s (remain 4m 20s) Loss avg.: 0.4505 Grad: 0.5226 LR: 0.00055  \n",
      "Epoch: [6][1000/1794] Elapsed 4m 51s (remain 3m 50s) Loss avg.: 0.4504 Grad: 0.4959 LR: 0.00055  \n",
      "Epoch: [6][1100/1794] Elapsed 5m 20s (remain 3m 21s) Loss avg.: 0.4504 Grad: 0.4789 LR: 0.00055  \n",
      "Epoch: [6][1200/1794] Elapsed 5m 49s (remain 2m 52s) Loss avg.: 0.4503 Grad: 0.3114 LR: 0.00055  \n",
      "Epoch: [6][1300/1794] Elapsed 6m 19s (remain 2m 23s) Loss avg.: 0.4502 Grad: 0.4102 LR: 0.00055  \n",
      "Epoch: [6][1400/1794] Elapsed 6m 48s (remain 1m 54s) Loss avg.: 0.4502 Grad: 0.3280 LR: 0.00055  \n",
      "Epoch: [6][1500/1794] Elapsed 7m 17s (remain 1m 25s) Loss avg.: 0.4504 Grad: 0.3764 LR: 0.00055  \n",
      "Epoch: [6][1600/1794] Elapsed 7m 46s (remain 0m 56s) Loss avg.: 0.4504 Grad: 0.4213 LR: 0.00055  \n",
      "Epoch: [6][1700/1794] Elapsed 8m 15s (remain 0m 27s) Loss avg.: 0.4502 Grad: 0.3839 LR: 0.00055  \n",
      "Epoch: [6][1793/1794] Elapsed 8m 42s (remain 0m 0s) Loss avg.: 0.4503 Grad: 0.3376 LR: 0.00055  \n",
      "Eval: [0/200] Elapsed 0m 0s (remain 2m 26s) Loss avg.: 0.4240 \n",
      "Eval: [100/200] Elapsed 0m 8s (remain 0m 8s) Loss avg.: 0.4523 \n",
      "Eval: [199/200] Elapsed 0m 16s (remain 0m 0s) Loss avg.: 0.4544 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.4503  avg_val_loss: 0.4544  time: 540s\n",
      "Epoch 6 - Accuracy: 0.8039235349420244\n",
      "Epoch 6 - Save Best Score: 0.8039 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/1794] Elapsed 0m 1s (remain 43m 46s) Loss avg.: 0.4374 Grad: 0.3070 LR: 0.00041  \n",
      "Epoch: [7][100/1794] Elapsed 0m 30s (remain 8m 35s) Loss avg.: 0.4470 Grad: 0.4263 LR: 0.00041  \n",
      "Epoch: [7][200/1794] Elapsed 0m 59s (remain 7m 53s) Loss avg.: 0.4478 Grad: 0.4581 LR: 0.00041  \n",
      "Epoch: [7][300/1794] Elapsed 1m 28s (remain 7m 20s) Loss avg.: 0.4473 Grad: 0.3623 LR: 0.00041  \n",
      "Epoch: [7][400/1794] Elapsed 1m 57s (remain 6m 49s) Loss avg.: 0.4477 Grad: 0.4550 LR: 0.00041  \n",
      "Epoch: [7][500/1794] Elapsed 2m 26s (remain 6m 18s) Loss avg.: 0.4470 Grad: 0.3230 LR: 0.00041  \n",
      "Epoch: [7][600/1794] Elapsed 2m 55s (remain 5m 48s) Loss avg.: 0.4466 Grad: 0.3533 LR: 0.00041  \n",
      "Epoch: [7][700/1794] Elapsed 3m 24s (remain 5m 19s) Loss avg.: 0.4468 Grad: 0.5908 LR: 0.00041  \n",
      "Epoch: [7][800/1794] Elapsed 3m 53s (remain 4m 49s) Loss avg.: 0.4467 Grad: 0.4448 LR: 0.00041  \n",
      "Epoch: [7][900/1794] Elapsed 4m 23s (remain 4m 20s) Loss avg.: 0.4467 Grad: 0.4171 LR: 0.00041  \n",
      "Epoch: [7][1000/1794] Elapsed 4m 52s (remain 3m 51s) Loss avg.: 0.4464 Grad: 0.4382 LR: 0.00041  \n",
      "Epoch: [7][1100/1794] Elapsed 5m 21s (remain 3m 22s) Loss avg.: 0.4464 Grad: 0.4633 LR: 0.00041  \n",
      "Epoch: [7][1200/1794] Elapsed 5m 50s (remain 2m 52s) Loss avg.: 0.4464 Grad: 0.2838 LR: 0.00041  \n",
      "Epoch: [7][1300/1794] Elapsed 6m 19s (remain 2m 23s) Loss avg.: 0.4466 Grad: 0.3066 LR: 0.00041  \n",
      "Epoch: [7][1400/1794] Elapsed 6m 48s (remain 1m 54s) Loss avg.: 0.4466 Grad: 0.4527 LR: 0.00041  \n",
      "Epoch: [7][1500/1794] Elapsed 7m 17s (remain 1m 25s) Loss avg.: 0.4466 Grad: 0.4064 LR: 0.00041  \n",
      "Epoch: [7][1600/1794] Elapsed 7m 46s (remain 0m 56s) Loss avg.: 0.4466 Grad: 0.3943 LR: 0.00041  \n",
      "Epoch: [7][1700/1794] Elapsed 8m 15s (remain 0m 27s) Loss avg.: 0.4466 Grad: 0.3534 LR: 0.00041  \n",
      "Epoch: [7][1793/1794] Elapsed 8m 42s (remain 0m 0s) Loss avg.: 0.4467 Grad: 0.3403 LR: 0.00041  \n",
      "Eval: [0/200] Elapsed 0m 0s (remain 2m 28s) Loss avg.: 0.4171 \n",
      "Eval: [100/200] Elapsed 0m 8s (remain 0m 8s) Loss avg.: 0.4493 \n",
      "Eval: [199/200] Elapsed 0m 16s (remain 0m 0s) Loss avg.: 0.4513 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.4467  avg_val_loss: 0.4513  time: 540s\n",
      "Epoch 7 - Accuracy: 0.8050219366969602\n",
      "Epoch 7 - Save Best Score: 0.8050 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/1794] Elapsed 0m 1s (remain 40m 45s) Loss avg.: 0.4174 Grad: 0.2912 LR: 0.00029  \n",
      "Epoch: [8][100/1794] Elapsed 0m 30s (remain 8m 27s) Loss avg.: 0.4425 Grad: 0.3412 LR: 0.00029  \n",
      "Epoch: [8][200/1794] Elapsed 0m 59s (remain 7m 49s) Loss avg.: 0.4427 Grad: 0.3515 LR: 0.00029  \n",
      "Epoch: [8][300/1794] Elapsed 1m 28s (remain 7m 17s) Loss avg.: 0.4425 Grad: 0.3788 LR: 0.00029  \n",
      "Epoch: [8][400/1794] Elapsed 1m 57s (remain 6m 47s) Loss avg.: 0.4424 Grad: 0.2969 LR: 0.00029  \n",
      "Epoch: [8][500/1794] Elapsed 2m 26s (remain 6m 17s) Loss avg.: 0.4426 Grad: 0.3366 LR: 0.00029  \n",
      "Epoch: [8][600/1794] Elapsed 2m 55s (remain 5m 48s) Loss avg.: 0.4429 Grad: 0.3967 LR: 0.00029  \n",
      "Epoch: [8][700/1794] Elapsed 3m 24s (remain 5m 18s) Loss avg.: 0.4428 Grad: 0.4355 LR: 0.00029  \n",
      "Epoch: [8][800/1794] Elapsed 3m 53s (remain 4m 49s) Loss avg.: 0.4427 Grad: 0.3034 LR: 0.00029  \n",
      "Epoch: [8][900/1794] Elapsed 4m 22s (remain 4m 20s) Loss avg.: 0.4431 Grad: 0.5039 LR: 0.00029  \n",
      "Epoch: [8][1000/1794] Elapsed 4m 51s (remain 3m 51s) Loss avg.: 0.4431 Grad: 0.2632 LR: 0.00029  \n",
      "Epoch: [8][1100/1794] Elapsed 5m 20s (remain 3m 21s) Loss avg.: 0.4432 Grad: 0.5501 LR: 0.00029  \n",
      "Epoch: [8][1200/1794] Elapsed 5m 49s (remain 2m 52s) Loss avg.: 0.4432 Grad: 0.3583 LR: 0.00029  \n",
      "Epoch: [8][1300/1794] Elapsed 6m 18s (remain 2m 23s) Loss avg.: 0.4430 Grad: 0.2999 LR: 0.00029  \n",
      "Epoch: [8][1400/1794] Elapsed 6m 48s (remain 1m 54s) Loss avg.: 0.4432 Grad: 0.3025 LR: 0.00029  \n",
      "Epoch: [8][1500/1794] Elapsed 7m 17s (remain 1m 25s) Loss avg.: 0.4434 Grad: 0.3852 LR: 0.00029  \n",
      "Epoch: [8][1600/1794] Elapsed 7m 46s (remain 0m 56s) Loss avg.: 0.4433 Grad: 0.3457 LR: 0.00029  \n",
      "Epoch: [8][1700/1794] Elapsed 8m 15s (remain 0m 27s) Loss avg.: 0.4434 Grad: 0.4016 LR: 0.00029  \n",
      "Epoch: [8][1793/1794] Elapsed 8m 42s (remain 0m 0s) Loss avg.: 0.4434 Grad: 0.4315 LR: 0.00029  \n",
      "Eval: [0/200] Elapsed 0m 0s (remain 2m 31s) Loss avg.: 0.4145 \n",
      "Eval: [100/200] Elapsed 0m 8s (remain 0m 8s) Loss avg.: 0.4481 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.4434  avg_val_loss: 0.4501  time: 539s\n",
      "Epoch 8 - Accuracy: 0.8054810404261987\n",
      "Epoch 8 - Save Best Score: 0.8055 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: [199/200] Elapsed 0m 16s (remain 0m 0s) Loss avg.: 0.4501 \n",
      "Epoch: [9][0/1794] Elapsed 0m 1s (remain 44m 0s) Loss avg.: 0.4340 Grad: 0.4222 LR: 0.00019  \n",
      "Epoch: [9][100/1794] Elapsed 0m 30s (remain 8m 36s) Loss avg.: 0.4383 Grad: 0.3655 LR: 0.00019  \n",
      "Epoch: [9][200/1794] Elapsed 0m 59s (remain 7m 54s) Loss avg.: 0.4398 Grad: 0.4049 LR: 0.00019  \n",
      "Epoch: [9][300/1794] Elapsed 1m 28s (remain 7m 20s) Loss avg.: 0.4409 Grad: 0.2714 LR: 0.00019  \n",
      "Epoch: [9][400/1794] Elapsed 1m 57s (remain 6m 49s) Loss avg.: 0.4404 Grad: 0.4010 LR: 0.00019  \n",
      "Epoch: [9][500/1794] Elapsed 2m 26s (remain 6m 19s) Loss avg.: 0.4405 Grad: 0.3322 LR: 0.00019  \n",
      "Epoch: [9][600/1794] Elapsed 2m 56s (remain 5m 49s) Loss avg.: 0.4405 Grad: 0.3308 LR: 0.00019  \n",
      "Epoch: [9][700/1794] Elapsed 3m 25s (remain 5m 19s) Loss avg.: 0.4407 Grad: 0.4179 LR: 0.00019  \n",
      "Epoch: [9][800/1794] Elapsed 3m 54s (remain 4m 50s) Loss avg.: 0.4407 Grad: 0.3431 LR: 0.00019  \n",
      "Epoch: [9][900/1794] Elapsed 4m 23s (remain 4m 21s) Loss avg.: 0.4406 Grad: 0.3045 LR: 0.00019  \n",
      "Epoch: [9][1000/1794] Elapsed 4m 52s (remain 3m 51s) Loss avg.: 0.4406 Grad: 0.3498 LR: 0.00019  \n",
      "Epoch: [9][1100/1794] Elapsed 5m 21s (remain 3m 22s) Loss avg.: 0.4408 Grad: 0.3046 LR: 0.00019  \n",
      "Epoch: [9][1200/1794] Elapsed 5m 50s (remain 2m 53s) Loss avg.: 0.4408 Grad: 0.3539 LR: 0.00019  \n",
      "Epoch: [9][1300/1794] Elapsed 6m 19s (remain 2m 23s) Loss avg.: 0.4408 Grad: 0.3960 LR: 0.00019  \n",
      "Epoch: [9][1400/1794] Elapsed 6m 49s (remain 1m 54s) Loss avg.: 0.4407 Grad: 0.3487 LR: 0.00019  \n",
      "Epoch: [9][1500/1794] Elapsed 7m 18s (remain 1m 25s) Loss avg.: 0.4406 Grad: 0.3329 LR: 0.00019  \n",
      "Epoch: [9][1600/1794] Elapsed 7m 47s (remain 0m 56s) Loss avg.: 0.4407 Grad: 0.4894 LR: 0.00019  \n",
      "Epoch: [9][1700/1794] Elapsed 8m 16s (remain 0m 27s) Loss avg.: 0.4407 Grad: 0.3943 LR: 0.00019  \n",
      "Epoch: [9][1793/1794] Elapsed 8m 43s (remain 0m 0s) Loss avg.: 0.4407 Grad: 0.3233 LR: 0.00019  \n",
      "Eval: [0/200] Elapsed 0m 0s (remain 2m 24s) Loss avg.: 0.4137 \n",
      "Eval: [100/200] Elapsed 0m 8s (remain 0m 8s) Loss avg.: 0.4467 \n",
      "Eval: [199/200] Elapsed 0m 16s (remain 0m 0s) Loss avg.: 0.4488 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.4407  avg_val_loss: 0.4488  time: 540s\n",
      "Epoch 9 - Accuracy: 0.8062112190535882\n",
      "Epoch 9 - Save Best Score: 0.8062 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/1794] Elapsed 0m 1s (remain 40m 56s) Loss avg.: 0.4314 Grad: 0.3215 LR: 0.00012  \n",
      "Epoch: [10][100/1794] Elapsed 0m 30s (remain 8m 29s) Loss avg.: 0.4403 Grad: 0.3150 LR: 0.00012  \n",
      "Epoch: [10][200/1794] Elapsed 0m 59s (remain 7m 50s) Loss avg.: 0.4385 Grad: 0.2875 LR: 0.00012  \n",
      "Epoch: [10][300/1794] Elapsed 1m 28s (remain 7m 18s) Loss avg.: 0.4385 Grad: 0.3171 LR: 0.00012  \n",
      "Epoch: [10][400/1794] Elapsed 1m 57s (remain 6m 48s) Loss avg.: 0.4389 Grad: 0.3276 LR: 0.00012  \n",
      "Epoch: [10][500/1794] Elapsed 2m 26s (remain 6m 18s) Loss avg.: 0.4386 Grad: 0.4329 LR: 0.00012  \n",
      "Epoch: [10][600/1794] Elapsed 2m 55s (remain 5m 49s) Loss avg.: 0.4387 Grad: 0.4370 LR: 0.00012  \n",
      "Epoch: [10][700/1794] Elapsed 3m 25s (remain 5m 19s) Loss avg.: 0.4388 Grad: 0.4442 LR: 0.00012  \n",
      "Epoch: [10][800/1794] Elapsed 3m 54s (remain 4m 50s) Loss avg.: 0.4386 Grad: 0.3318 LR: 0.00012  \n",
      "Epoch: [10][900/1794] Elapsed 4m 23s (remain 4m 20s) Loss avg.: 0.4385 Grad: 0.3075 LR: 0.00012  \n",
      "Epoch: [10][1000/1794] Elapsed 4m 52s (remain 3m 51s) Loss avg.: 0.4385 Grad: 0.4360 LR: 0.00012  \n",
      "Epoch: [10][1100/1794] Elapsed 5m 21s (remain 3m 22s) Loss avg.: 0.4384 Grad: 0.3998 LR: 0.00012  \n",
      "Epoch: [10][1200/1794] Elapsed 5m 50s (remain 2m 53s) Loss avg.: 0.4384 Grad: 0.3102 LR: 0.00012  \n",
      "Epoch: [10][1300/1794] Elapsed 6m 19s (remain 2m 23s) Loss avg.: 0.4385 Grad: 0.3313 LR: 0.00012  \n",
      "Epoch: [10][1400/1794] Elapsed 6m 48s (remain 1m 54s) Loss avg.: 0.4385 Grad: 0.3003 LR: 0.00012  \n",
      "Epoch: [10][1500/1794] Elapsed 7m 18s (remain 1m 25s) Loss avg.: 0.4387 Grad: 0.3861 LR: 0.00012  \n",
      "Epoch: [10][1600/1794] Elapsed 7m 47s (remain 0m 56s) Loss avg.: 0.4388 Grad: 0.3635 LR: 0.00012  \n",
      "Epoch: [10][1700/1794] Elapsed 8m 16s (remain 0m 27s) Loss avg.: 0.4388 Grad: 0.3938 LR: 0.00012  \n",
      "Epoch: [10][1793/1794] Elapsed 8m 43s (remain 0m 0s) Loss avg.: 0.4388 Grad: 0.3775 LR: 0.00012  \n",
      "Eval: [0/200] Elapsed 0m 0s (remain 2m 33s) Loss avg.: 0.4158 \n",
      "Eval: [100/200] Elapsed 0m 8s (remain 0m 8s) Loss avg.: 0.4460 \n",
      "Eval: [199/200] Elapsed 0m 16s (remain 0m 0s) Loss avg.: 0.4480 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.4388  avg_val_loss: 0.4480  time: 540s\n",
      "Epoch 10 - Accuracy: 0.8065042306486995\n",
      "Epoch 10 - Save Best Score: 0.8065 Model\n",
      "Epoch 10 - Save final model\n",
      "========== fold: 0 result ==========\n",
      "Score: 0.80650\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "hungry-geese-train-by-episode.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2945.71762,
   "end_time": "2021-05-12T03:50:02.012348",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-12T03:00:56.294728",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04a486aa6f454d8f92e388dba1b9ee21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0857c0fa22b544488d65bb2c7dad18ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f905db5005be40b194ea150c8b0deb9f",
      "max": 1001,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "value": 1001
     }
    },
    "4134662bdbe04a918d9809632e268ef8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0857c0fa22b544488d65bb2c7dad18ee",
       "IPY_MODEL_e33e4f894b424988b316c468bc9225ce"
      ],
      "layout": "IPY_MODEL_8ddb49ac3c91409f99a569a061a70b3d"
     }
    },
    "507d2b6a02bb43d0bb4c8c2734f19cbb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ddb49ac3c91409f99a569a061a70b3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c96b7bfbdf0243a8ae1dbb3d9aedf123": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e33e4f894b424988b316c468bc9225ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_507d2b6a02bb43d0bb4c8c2734f19cbb",
      "placeholder": "​",
      "style": "IPY_MODEL_04a486aa6f454d8f92e388dba1b9ee21",
      "value": " 1001/1001 [03:35&lt;00:00,  4.64it/s]"
     }
    },
    "f905db5005be40b194ea150c8b0deb9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

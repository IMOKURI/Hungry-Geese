{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abroad-piece",
    "papermill": {
     "duration": 0.025714,
     "end_time": "2021-05-12T03:01:02.640708",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.614994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About this notebook ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pressing-commercial",
    "papermill": {
     "duration": 0.024272,
     "end_time": "2021-05-12T03:01:02.689850",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.665578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "german-ethics",
    "papermill": {
     "duration": 1.852306,
     "end_time": "2021-05-12T03:01:04.566362",
     "exception": false,
     "start_time": "2021-05-12T03:01:02.714056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "apparent-fiction",
    "papermill": {
     "duration": 0.030961,
     "end_time": "2021-05-12T03:01:04.622818",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.591857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "editorial-haiti",
    "papermill": {
     "duration": 0.024908,
     "end_time": "2021-05-12T03:01:05.115280",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.090372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "opened-python",
    "papermill": {
     "duration": 0.035637,
     "end_time": "2021-05-12T03:01:05.176119",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.140482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 440\n",
    "\n",
    "    n_class = 4\n",
    "    n_fold = 10\n",
    "\n",
    "    geese_net_layers = 12\n",
    "    geese_net_filters = 32\n",
    "\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "\n",
    "    num_workers = 4\n",
    "    batch_size = 3200\n",
    "\n",
    "    scheduler = \"CosineAnnealingWarmRestarts\"\n",
    "    # factor = 0.2  # ReduceLROnPlateau\n",
    "    # patience = 4  # ReduceLROnPlateau\n",
    "    # eps = 1e-6  # ReduceLROnPlateau\n",
    "    # T_max = 10  # CosineAnnealingLR\n",
    "    T_0 = 10  # CosineAnnealingWarmRestarts\n",
    "\n",
    "    criterion = \"CrossEntropyLoss\"\n",
    "    lr = 1e-3\n",
    "    min_lr = 1e-4\n",
    "    weight_decay = 1e-5\n",
    "\n",
    "    epochs = 10\n",
    "    model_name = \"geese_net\"\n",
    "    pre_train_file = \"\"\n",
    "\n",
    "    print_freq = 100\n",
    "\n",
    "    train = True\n",
    "    tuning = False\n",
    "    debug = False\n",
    "    apex = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "contained-singles",
    "papermill": {
     "duration": 0.031266,
     "end_time": "2021-05-12T03:01:05.235456",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.204190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.tuning:\n",
    "    Config.epochs = 2\n",
    "\n",
    "if Config.debug:\n",
    "    Config.epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dietary-track",
    "papermill": {
     "duration": 0.031421,
     "end_time": "2021-05-12T03:01:05.292382",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.260961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.apex:\n",
    "    from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "invalid-dispute",
    "papermill": {
     "duration": 0.169531,
     "end_time": "2021-05-12T03:01:05.488665",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.319134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robust-humanity",
    "papermill": {
     "duration": 0.024539,
     "end_time": "2021-05-12T03:01:04.672270",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.647731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "designed-effect",
    "papermill": {
     "duration": 0.031167,
     "end_time": "2021-05-12T03:01:04.728079",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.696912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"../input/hungrygeeseepisode/hungry-geese-episode/\"\n",
    "OUTPUT_DIR = \"pre-models/\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "special-broadcast",
    "outputId": "c440e1e9-5651-42ee-eb0f-08c822d7471a",
    "papermill": {
     "duration": 0.31211,
     "end_time": "2021-05-12T03:01:05.064722",
     "exception": false,
     "start_time": "2021-05-12T03:01:04.752612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23946\n"
     ]
    }
   ],
   "source": [
    "paths = [path for path in glob.glob(BASE_DIR + \"*.json\") if \"info\" not in path]\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n"
     ]
    }
   ],
   "source": [
    "# fit for memory size...\n",
    "paths = paths[-11000:]\n",
    "# paths = paths[:-11000]\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    paths = paths[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "treated-serum",
    "papermill": {
     "duration": 0.025219,
     "end_time": "2021-05-12T03:01:05.539482",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.514263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gothic-alloy",
    "papermill": {
     "duration": 0.070842,
     "end_time": "2021-05-12T03:01:05.642364",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.571522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=Config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "experienced-correspondence",
    "papermill": {
     "duration": 0.053842,
     "end_time": "2021-05-12T03:01:05.741858",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.688016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reverse_ns(y):\n",
    "    if y == 0:\n",
    "        return 1\n",
    "    if y == 1:\n",
    "        return 0\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_we(y):\n",
    "    if y == 2:\n",
    "        return 3\n",
    "    if y == 3:\n",
    "        return 2\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse_nswe(y):\n",
    "    return reverse_ns(reverse_we(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "further-transaction",
    "papermill": {
     "duration": 0.042365,
     "end_time": "2021-05-12T03:01:05.826807",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.784442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_position_map = {}\n",
    "for pos in range(77):\n",
    "    position = []\n",
    "    position.append((11 * (1 + pos // 11) + pos % 11) % 77)\n",
    "    position.append((11 * (-1 + pos // 11) + pos % 11) % 77)\n",
    "    position.append((11 * (pos // 11) + (pos + 1) % 11) % 77)\n",
    "    position.append((11 * (pos // 11) + (pos - 1) % 11) % 77)\n",
    "    next_position_map[pos] = set(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "naughty-clause",
    "papermill": {
     "duration": 0.058537,
     "end_time": "2021-05-12T03:01:05.928292",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.869755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_input(obses):\n",
    "    b = np.zeros((17, 7 * 11), dtype=np.float16)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, pos_list in enumerate(obs[\"geese\"]):\n",
    "        pid = (p - obs[\"index\"]) % 4\n",
    "\n",
    "        # head position\n",
    "        for pos in pos_list[:1]:\n",
    "            b[0 + pid, pos] = 1\n",
    "        # tip position\n",
    "        for pos in pos_list[-1:]:\n",
    "            b[4 + pid, pos] = 1\n",
    "        # whole position\n",
    "        for pos in pos_list:\n",
    "            b[8 + pid, pos] = 1\n",
    "\n",
    "    # previous head position\n",
    "    if len(obses) > 1:\n",
    "        obs_prev = obses[-2]\n",
    "        for p, pos_list in enumerate(obs_prev[\"geese\"]):\n",
    "            for pos in pos_list[:1]:\n",
    "                b[12 + (p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    # food\n",
    "    for pos in obs[\"food\"]:\n",
    "        b[16, pos] = 1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reverse_cube(obses):\n",
    "    \"\"\"\n",
    "    尻尾から順番に 1, 0.9, 0.8, ... という並び\n",
    "    \"\"\"\n",
    "    b = np.zeros((4, 7 * 11), dtype=np.float16)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    for p, geese in enumerate(obs[\"geese\"]):\n",
    "        # whole position reverse\n",
    "        for num_reverse, pos in enumerate(geese[::-1]):\n",
    "            b[(p - obs[\"index\"]) % 4, pos] = 1 - num_reverse * 0.1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_disappear_cube(obses):\n",
    "    \"\"\"\n",
    "    次になくなる場所: 1\n",
    "    次になくなる可能性のある場所: 0.5\n",
    "    \"\"\"\n",
    "    b = np.zeros((4, 7 * 11), dtype=np.float16)\n",
    "    obs = obses[-1]\n",
    "    step = obs[\"step\"]\n",
    "\n",
    "    # foodを食べる可能性があるか。\n",
    "    eat_food_possibility = defaultdict(int)\n",
    "    for p, geese in enumerate(obs[\"geese\"]):\n",
    "        for pos in geese[:1]:\n",
    "            if not next_position_map[pos].isdisjoint(obs[\"food\"]):\n",
    "                eat_food_possibility[p] = 1\n",
    "\n",
    "    if (step % 40) == 39:  # 1つ短くなる\n",
    "        for p, geese in enumerate(obs[\"geese\"]):\n",
    "            if eat_food_possibility[p]:  # 尻尾が1、尻尾の１つ前0.5\n",
    "                for pos in geese[-1:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 1\n",
    "                for pos in geese[-2:-1]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 0.5\n",
    "            else:  # 食べる可能性なし -> 尻尾が1, 尻尾の1つ前1\n",
    "                for pos in geese[-2:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 1\n",
    "    else:  # 1つ短くならない\n",
    "        for p, geese in enumerate(obs[\"geese\"]):\n",
    "            if eat_food_possibility[p]:  # 食べる可能性があり -> 尻尾を0.5\n",
    "                for pos in geese[-1:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 0.5\n",
    "            else:  # 食べる可能性なし # 尻尾を1\n",
    "                for pos in geese[-1:]:\n",
    "                    b[(p - obs[\"index\"]) % 4, pos] = 1\n",
    "\n",
    "    return b.reshape(-1, 7, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_step_cube_v2(obses):\n",
    "    \"\"\"\n",
    "    step0: 0, step199: 1\n",
    "    step0: 0, step39 + 40n: 1\n",
    "    \"\"\"\n",
    "    b = np.zeros((1, 7, 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "    step = obs[\"step\"]\n",
    "\n",
    "    b[:, :, :5] = (step % 200) / 199\n",
    "    b[:, :, 5:] = (step % 40) / 39\n",
    "\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_cube(obses):\n",
    "    b = np.zeros((2, 7, 11), dtype=np.float32)\n",
    "    obs = obses[-1]\n",
    "\n",
    "    my_length = len(obs[\"geese\"][obs[\"index\"]])\n",
    "    opposite1_length = len(obs[\"geese\"][(obs[\"index\"] + 1) % 4])\n",
    "    opposite2_length = len(obs[\"geese\"][(obs[\"index\"] + 2) % 4])\n",
    "    opposite3_length = len(obs[\"geese\"][(obs[\"index\"] + 3) % 4])\n",
    "\n",
    "    b[0] = my_length / 10\n",
    "    max_opposite_length = max(opposite1_length, opposite2_length, opposite3_length)\n",
    "    b[1, :, 0:2] = (my_length - max_opposite_length) / 10\n",
    "    b[1, :, 2:5] = (my_length - opposite1_length) / 10\n",
    "    b[1, :, 5:8] = (my_length - opposite2_length) / 10\n",
    "    b[1, :, 8:11] = (my_length - opposite3_length) / 10\n",
    "\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pretty-aaron",
    "papermill": {
     "duration": 0.042985,
     "end_time": "2021-05-12T03:01:06.014038",
     "exception": false,
     "start_time": "2021-05-12T03:01:05.971053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "international-secret",
    "papermill": {
     "duration": 0.064855,
     "end_time": "2021-05-12T03:01:06.121648",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.056793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset_from_json(filepath, json_object=None, standing=0):\n",
    "    if json_object is None:\n",
    "        json_open = open(path, \"r\")\n",
    "        json_load = json.load(json_open)\n",
    "    else:\n",
    "        json_load = json_object\n",
    "\n",
    "    try:\n",
    "        winner_index = np.argmax(np.argsort(json_load[\"rewards\"]) == 3 - standing)\n",
    "\n",
    "        obses = []\n",
    "        X = []\n",
    "        y = []\n",
    "        actions = {\"NORTH\": 0, \"SOUTH\": 1, \"WEST\": 2, \"EAST\": 3}\n",
    "\n",
    "        for i in range(len(json_load[\"steps\"]) - 1):\n",
    "            if json_load[\"steps\"][i][winner_index][\"status\"] == \"ACTIVE\":\n",
    "                y_ = json_load[\"steps\"][i + 1][winner_index][\"action\"]\n",
    "                if y_ is not None:\n",
    "                    step = json_load[\"steps\"][i]\n",
    "                    step[winner_index][\"observation\"][\"geese\"] = step[0][\"observation\"][\"geese\"]\n",
    "                    step[winner_index][\"observation\"][\"food\"] = step[0][\"observation\"][\"food\"]\n",
    "                    step[winner_index][\"observation\"][\"step\"] = step[0][\"observation\"][\"step\"]\n",
    "                    obses.append(step[winner_index][\"observation\"])\n",
    "                    y.append(actions[y_])\n",
    "\n",
    "                    y.append(reverse_ns(actions[y_]))  # 上下反転\n",
    "                    y.append(reverse_we(actions[y_]))  # 左右反転\n",
    "                    y.append(reverse_nswe(actions[y_]))  # 上下左右反転\n",
    "\n",
    "        for j in range(len(obses)):\n",
    "            # X_ = make_input(obses[: j + 1])\n",
    "\n",
    "            # 反転可能な特徴量\n",
    "            X_ = []\n",
    "            X_.append(make_input(obses[: j + 1]))\n",
    "            X_.append(get_reverse_cube(obses[: j + 1]))\n",
    "            X_.append(get_next_disappear_cube(obses[: j + 1]))\n",
    "\n",
    "            # 反転不可能な特徴量\n",
    "            X_i = []\n",
    "            X_i.append(get_step_cube_v2(obses[: j + 1]))\n",
    "            X_i.append(get_length_cube(obses[: j + 1]))\n",
    "\n",
    "            X_ = np.concatenate(X_)\n",
    "            X_i = np.concatenate(X_i)\n",
    "\n",
    "            X.append(np.concatenate([X_, X_i]))\n",
    "            X.append(np.concatenate([X_[:, ::-1, :], X_i]))  # 上下反転\n",
    "            X.append(np.concatenate([X_[:, :, ::-1], X_i]))  # 左右反転\n",
    "            X.append(np.concatenate([X_[:, ::-1, ::-1], X_i]))  # 上下左右反転\n",
    "\n",
    "        X = np.array(X, dtype=np.float16)  # [starting_step:]\n",
    "        y = np.array(y, dtype=np.uint8)  # [starting_step:]\n",
    "\n",
    "        return X, y\n",
    "    except Exception as e:\n",
    "        if Config.debug:\n",
    "            raise Exception from e\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "4134662bdbe04a918d9809632e268ef8",
      "8ddb49ac3c91409f99a569a061a70b3d",
      "0857c0fa22b544488d65bb2c7dad18ee",
      "e33e4f894b424988b316c468bc9225ce",
      "c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "f905db5005be40b194ea150c8b0deb9f",
      "04a486aa6f454d8f92e388dba1b9ee21",
      "507d2b6a02bb43d0bb4c8c2734f19cbb"
     ]
    },
    "id": "handled-pleasure",
    "outputId": "955c1c6b-36bc-4b30-dc44-b72b05398f8c",
    "papermill": {
     "duration": 15.320591,
     "end_time": "2021-05-12T03:01:21.474816",
     "exception": false,
     "start_time": "2021-05-12T03:01:06.154225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76182294d1884f66a977d6e9895d7fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num episode: 6895004\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for path in tqdm(paths[: int(len(paths))]):\n",
    "    X, y = create_dataset_from_json(path, standing=0)  # use only winners' moves\n",
    "    if X is not 0:\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "persistent-loading",
    "papermill": {
     "duration": 112.92618,
     "end_time": "2021-05-12T03:03:14.428162",
     "exception": false,
     "start_time": "2021-05-12T03:01:21.501982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# X_train, unique_index = np.unique(X_train, axis=0, return_index=True)  # remove duplicate\n",
    "# y_train = y_train[unique_index]\n",
    "\n",
    "# y_train = np.eye(4, dtype=\"uint8\")[y_train]  # to categorical\n",
    "\n",
    "# print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_:\n",
    "    X_train_sum_obs = X_train.reshape(X_train.shape[0], -1).sum(1)\n",
    "    X_train_group = np.unique(X_train_sum_obs)\n",
    "    X_train_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_:\n",
    "    X_train_unique = []\n",
    "    y_train_unique = []\n",
    "    for group in tqdm(X_train_group):\n",
    "        group_index = np.where(X_train_sum_obs == group)\n",
    "\n",
    "        X_train_ = X_train[group_index]\n",
    "        y_train_ = y_train[group_index]\n",
    "\n",
    "        X_train_, unique_index = np.unique(X_train_, axis=0, return_index=True)  # remove duplicate\n",
    "        y_train_ = y_train_[unique_index]\n",
    "\n",
    "        X_train_unique.append(X_train_)\n",
    "        y_train_unique.append(y_train_)\n",
    "\n",
    "    X_train = np.concatenate(X_train_unique)\n",
    "    y_train = np.concatenate(y_train_unique)\n",
    "\n",
    "    print(f\"Num episode: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_:\n",
    "    del X_train_sum_obs\n",
    "    del X_train_group\n",
    "    del X_train_unique\n",
    "    del y_train_unique\n",
    "    del X_train_\n",
    "    del y_train_\n",
    "    del group_index\n",
    "    del unique_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "micro-french",
    "papermill": {
     "duration": 0.033413,
     "end_time": "2021-05-12T03:03:15.360395",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.326982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.debug:\n",
    "    X_train = X_train[:1000]\n",
    "    y_train = y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "wrong-pastor",
    "outputId": "406a2f1d-0b8a-46bf-ca01-546f3110c301",
    "papermill": {
     "duration": 0.036161,
     "end_time": "2021-05-12T03:03:15.425149",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.388988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6894999</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6895000</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6895001</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6895002</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6895003</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6895004 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         action\n",
       "0             0\n",
       "1             1\n",
       "2             0\n",
       "3             1\n",
       "4             3\n",
       "...         ...\n",
       "6894999       3\n",
       "6895000       1\n",
       "6895001       0\n",
       "6895002       1\n",
       "6895003       0\n",
       "\n",
       "[6895004 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(y_train, dtype=np.uint8)\n",
    "y_df.columns = [\"action\"]\n",
    "y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "touched-coordinate",
    "papermill": {
     "duration": 0.027968,
     "end_time": "2021-05-12T03:03:15.557122",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.529154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "moving-skill",
    "outputId": "7542c4b4-f7d3-444c-8450-50bffddb1892",
    "papermill": {
     "duration": 0.202337,
     "end_time": "2021-05-12T03:03:15.787529",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.585192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  action\n",
      "0     0         165612\n",
      "      1         165612\n",
      "      2         179139\n",
      "      3         179138\n",
      "1     0         165612\n",
      "      1         165612\n",
      "      2         179139\n",
      "      3         179138\n",
      "2     0         165612\n",
      "      1         165611\n",
      "      2         179139\n",
      "      3         179139\n",
      "3     0         165612\n",
      "      1         165611\n",
      "      2         179139\n",
      "      3         179139\n",
      "4     0         165612\n",
      "      1         165611\n",
      "      2         179138\n",
      "      3         179139\n",
      "5     0         165612\n",
      "      1         165611\n",
      "      2         179138\n",
      "      3         179139\n",
      "6     0         165611\n",
      "      1         165612\n",
      "      2         179138\n",
      "      3         179139\n",
      "7     0         165611\n",
      "      1         165612\n",
      "      2         179138\n",
      "      3         179139\n",
      "8     0         165611\n",
      "      1         165612\n",
      "      2         179139\n",
      "      3         179138\n",
      "9     0         165611\n",
      "      1         165612\n",
      "      2         179139\n",
      "      3         179138\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "folds = y_df.copy()\n",
    "Fold = StratifiedKFold(n_splits=Config.n_fold, shuffle=True, random_state=Config.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[\"action\"])):\n",
    "    folds.loc[val_index, \"fold\"] = int(n)\n",
    "folds[\"fold\"] = folds[\"fold\"].astype(np.uint8)\n",
    "print(folds.groupby([\"fold\", \"action\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "creative-football",
    "papermill": {
     "duration": 0.029031,
     "end_time": "2021-05-12T03:03:15.845114",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.816083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "other-murder",
    "papermill": {
     "duration": 0.037264,
     "end_time": "2021-05-12T03:03:15.911219",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.873955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, array, label):\n",
    "        self.array = array\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx], torch.tensor(self.label[idx]).long()\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, array):\n",
    "        self.array = array\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.array.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adjusted-delhi",
    "outputId": "39504950-84bc-4692-8b90-8a5b64f741e0",
    "papermill": {
     "duration": 0.063691,
     "end_time": "2021-05-12T03:03:16.003693",
     "exception": false,
     "start_time": "2021-05-12T03:03:15.940002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "if Config.debug or False:\n",
    "    train_ds = TrainDataset(X_train, y_train)\n",
    "\n",
    "    for i in range(1):\n",
    "        obs, action = train_ds[i]\n",
    "        print(obs.shape, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceramic-startup",
    "papermill": {
     "duration": 0.02876,
     "end_time": "2021-05-12T03:03:16.061575",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.032815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "unique-trick",
    "papermill": {
     "duration": 0.039055,
     "end_time": "2021-05-12T03:03:16.130239",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.091184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TorusConv2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
    "        super().__init__()\n",
    "        self.edge_size = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n",
    "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.cat([x[:, :, :, -self.edge_size[1] :], x, x[:, :, :, : self.edge_size[1]]], dim=3)\n",
    "        h = torch.cat([h[:, :, -self.edge_size[0] :], h, h[:, :, : self.edge_size[0]]], dim=2)\n",
    "        h = self.conv(h)\n",
    "        h = self.bn(h) if self.bn is not None else h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "jspEE71c2Yma"
   },
   "outputs": [],
   "source": [
    "class GeeseNetAlpha(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = Config.geese_net_layers\n",
    "        filters = Config.geese_net_filters\n",
    "        dim = 64\n",
    "\n",
    "        self.conv0 = TorusConv2d(28, filters, (3, 3), True)\n",
    "        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n",
    "\n",
    "        self.head_p1 = nn.Linear(dim, dim // 2, bias=False)\n",
    "        self.head_p2 = nn.Linear(dim // 2, 4, bias=False)\n",
    "        self.head_v1 = nn.Linear(dim, dim // 2, bias=False)\n",
    "        self.head_v2 = nn.Linear(dim // 2, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, _=None):\n",
    "        # CNN for observation\n",
    "        h = F.relu_(self.conv0(x))\n",
    "        for block in self.blocks:\n",
    "            h = F.relu_(h + block(h))\n",
    "\n",
    "        # Extract head position\n",
    "        h_head = (h * x[:, :1]).view(h.size(0), h.size(1), -1).sum(-1)\n",
    "        h_avg = h.view(h.size(0), h.size(1), -1).mean(-1)\n",
    "\n",
    "        # Merge features\n",
    "        h = torch.cat([h_head, h_avg], 1).view(1, h.size(0), -1)\n",
    "\n",
    "        h_p = F.relu_(self.head_p1(h.view(x.size(0), -1)))\n",
    "        p = self.head_p2(h_p)\n",
    "\n",
    "        h_v = F.relu_(self.head_v1(h.view(x.size(0), -1)))\n",
    "        v = torch.tanh(self.head_v2(h_v))\n",
    "\n",
    "        return {\"policy\": p, \"value\": v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "objective-victoria",
    "outputId": "1ab137a5-e26e-4b9c-ff85-95fef713b755",
    "papermill": {
     "duration": 4.955868,
     "end_time": "2021-05-12T03:03:21.187355",
     "exception": false,
     "start_time": "2021-05-12T03:03:16.231487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "if Config.debug or False:\n",
    "    model = GeeseNetAlpha()\n",
    "    # print(model)\n",
    "\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"params: {params:,}\")\n",
    "\n",
    "    train_ds = TrainDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "    for obs, action in train_loader:\n",
    "        print(f\"input shape: {obs.shape}\")\n",
    "        output = model(obs)\n",
    "        print(output)\n",
    "        print(f\"{torch.argmax(output['policy'], dim=1)}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "military-fiction",
    "papermill": {
     "duration": 0.033001,
     "end_time": "2021-05-12T03:03:21.255277",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.222276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sophisticated-hearts",
    "papermill": {
     "duration": 0.031759,
     "end_time": "2021-05-12T03:03:21.319849",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.288090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "designing-detective",
    "papermill": {
     "duration": 0.03139,
     "end_time": "2021-05-12T03:03:21.383038",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.351648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "passive-cooper",
    "papermill": {
     "duration": 0.038846,
     "end_time": "2021-05-12T03:03:21.454085",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.415239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(result_df):\n",
    "    preds = result_df[\"preds\"].values\n",
    "    labels = result_df[\"action\"].values\n",
    "    score = get_score(labels, preds)\n",
    "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thirty-tracy",
    "papermill": {
     "duration": 0.0293,
     "end_time": "2021-05-12T03:03:21.514179",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.484879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "introductory-brooklyn",
    "papermill": {
     "duration": 0.039424,
     "end_time": "2021-05-12T03:03:21.582969",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.543545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "raising-laugh",
    "papermill": {
     "duration": 0.042063,
     "end_time": "2021-05-12T03:03:21.654559",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.612496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (obs, action) in enumerate(train_loader):\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        y_preds = model(obs)[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "        if Config.apex:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), Config.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % Config.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print(\n",
    "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
    "                f\"Loss avg.: {losses.avg:.4f} \"\n",
    "                f\"Grad: {grad_norm:.4f} \"\n",
    "                f\"LR: {scheduler.get_last_lr()[0]:.5f}  \"\n",
    "            )\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "plain-neighbor",
    "papermill": {
     "duration": 0.041056,
     "end_time": "2021-05-12T03:03:21.726585",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.685529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (obs, action) in enumerate(valid_loader):\n",
    "        obs = obs.to(device)\n",
    "        action = action.to(device)\n",
    "        batch_size = action.size(0)\n",
    "\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(obs)[\"policy\"]\n",
    "\n",
    "        loss = criterion(y_preds, action)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        if Config.gradient_accumulation_steps > 1:\n",
    "            loss = loss / Config.gradient_accumulation_steps\n",
    "\n",
    "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print(\n",
    "                f\"Eval: [{step}/{len(valid_loader)}] \"\n",
    "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
    "                f\"Loss avg.: {losses.avg:.4f} \"\n",
    "            )\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "integrated-classification",
    "papermill": {
     "duration": 0.029832,
     "end_time": "2021-05-12T03:03:21.786427",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.756595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "harmful-explanation",
    "papermill": {
     "duration": 0.05136,
     "end_time": "2021-05-12T03:03:21.868561",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.817201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(folds, fold):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ====================================================\n",
    "    # X_train_folds = X_train[folds[\"fold\"] != fold]\n",
    "    # X_valid_folds = X_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    # y_train_folds = y_train[folds[\"fold\"] != fold]\n",
    "    y_valid_folds = y_train[folds[\"fold\"] == fold]\n",
    "\n",
    "    # y_df_train_folds = y_df[folds[\"fold\"] != fold]\n",
    "    y_df_valid_folds = y_df[folds[\"fold\"] == fold]\n",
    "\n",
    "    # train_dataset = TrainDataset(X_train[folds[\"fold\"] != fold], y_train[folds[\"fold\"] != fold])\n",
    "    # valid_dataset = TrainDataset(X_train[folds[\"fold\"] == fold], y_valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        TrainDataset(X_train[folds[\"fold\"] != fold], y_train[folds[\"fold\"] != fold]),\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        TrainDataset(X_train[folds[\"fold\"] == fold], y_valid_folds),\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if Config.scheduler == \"ReduceLROnPlateau\":\n",
    "            scheduler = ReduceLROnPlateau(\n",
    "                optimizer, mode=\"min\", factor=Config.factor, patience=Config.patience, verbose=True, eps=Config.eps\n",
    "            )\n",
    "        elif Config.scheduler == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=Config.T_max, eta_min=Config.min_lr, last_epoch=-1)\n",
    "        elif Config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "            scheduler = CosineAnnealingWarmRestarts(\n",
    "                optimizer, T_0=Config.T_0, T_mult=1, eta_min=Config.min_lr, last_epoch=-1\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = GeeseNetAlpha()\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, Config.pre_train_file)))\n",
    "    except:\n",
    "        print(f\"Failed to load pre-train weight.\")\n",
    "\n",
    "    # Disable training for value network\n",
    "    for param in model.head_v1.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.head_v2.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Use multi GPU\n",
    "    if device == torch.device(\"cuda\") and not Config.apex:\n",
    "        model = torch.nn.DataParallel(model)  # make parallel\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=Config.lr, weight_decay=Config.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # apex\n",
    "    # ====================================================\n",
    "    if Config.apex:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
    "\n",
    "    # ====================================================\n",
    "    # Criterion\n",
    "    # ====================================================\n",
    "    def get_criterion():\n",
    "        if Config.criterion == \"CrossEntropyLoss\":\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        return criterion\n",
    "\n",
    "    criterion = get_criterion()\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    best_score = 0.0\n",
    "    best_loss = np.inf\n",
    "    best_preds = None\n",
    "\n",
    "    for epoch in range(Config.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "\n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(y_valid_folds, preds.argmax(1))\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Accuracy: {score}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_best.pth\")\n",
    "            best_preds = preds\n",
    "\n",
    "        if epoch == Config.epochs - 1:\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save final model\")\n",
    "            torch.save(model.module.state_dict(), OUTPUT_DIR + f\"{Config.model_name}_fold{fold}_final.pth\")\n",
    "\n",
    "    if Config.train:\n",
    "        y_df_valid_folds[[str(c) for c in range(Config.n_class)]] = best_preds\n",
    "        y_df_valid_folds[\"preds\"] = best_preds.argmax(1)\n",
    "\n",
    "        return y_df_valid_folds\n",
    "\n",
    "    if Config.tuning:\n",
    "        score = get_score(y_df_valid_folds[\"action\"].values, best_preds.argmax(1))\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    Config.geese_net_layers = trial.suggest_int(\"layers\", 6, 18)\n",
    "    Config.geese_net_filters = trial.suggest_int(\"filters\", 32, 128)\n",
    "\n",
    "    score = train_loop(folds, 0)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "complimentary-wright",
    "papermill": {
     "duration": 0.030218,
     "end_time": "2021-05-12T03:03:21.928896",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.898678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "particular-adaptation",
    "papermill": {
     "duration": 0.04089,
     "end_time": "2021-05-12T03:03:22.000150",
     "exception": false,
     "start_time": "2021-05-12T03:03:21.959260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if Config.train:\n",
    "        # train\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(Config.n_fold):\n",
    "            _oof_df = train_loop(folds, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df)\n",
    "            break  # fold 1つだけ\n",
    "        # CV result\n",
    "        # LOGGER.info(f\"========== CV ==========\")\n",
    "        # get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
    "\n",
    "    if Config.tuning:\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=10)\n",
    "\n",
    "        trial = study.best_trial\n",
    "        print(\"Best trial:\")\n",
    "        print(\"  Value: \", trial.value)\n",
    "        print(\"  Params: \")\n",
    "        for key, value in trial.params.items():\n",
    "            print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "backed-journal",
    "outputId": "c9f0ff3d-795e-466b-e22e-9ba21d08c874",
    "papermill": {
     "duration": 2797.64711,
     "end_time": "2021-05-12T03:49:59.678400",
     "exception": false,
     "start_time": "2021-05-12T03:03:22.031290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load pre-train weight.\n",
      "Epoch: [1][0/1939] Elapsed 0m 5s (remain 176m 58s) Loss avg.: 1.4449 Grad: 1.4373 LR: 0.00100  \n",
      "Epoch: [1][100/1939] Elapsed 0m 32s (remain 9m 43s) Loss avg.: 0.7371 Grad: 0.8285 LR: 0.00100  \n",
      "Epoch: [1][200/1939] Elapsed 0m 58s (remain 8m 27s) Loss avg.: 0.6626 Grad: 0.7770 LR: 0.00100  \n",
      "Epoch: [1][300/1939] Elapsed 1m 25s (remain 7m 44s) Loss avg.: 0.6293 Grad: 1.2885 LR: 0.00100  \n",
      "Epoch: [1][400/1939] Elapsed 1m 52s (remain 7m 9s) Loss avg.: 0.6083 Grad: 0.8248 LR: 0.00100  \n",
      "Epoch: [1][500/1939] Elapsed 2m 18s (remain 6m 38s) Loss avg.: 0.5925 Grad: 0.7615 LR: 0.00100  \n",
      "Epoch: [1][600/1939] Elapsed 2m 45s (remain 6m 8s) Loss avg.: 0.5805 Grad: 0.6266 LR: 0.00100  \n",
      "Epoch: [1][700/1939] Elapsed 3m 12s (remain 5m 39s) Loss avg.: 0.5708 Grad: 0.5905 LR: 0.00100  \n",
      "Epoch: [1][800/1939] Elapsed 3m 38s (remain 5m 10s) Loss avg.: 0.5630 Grad: 0.6249 LR: 0.00100  \n",
      "Epoch: [1][900/1939] Elapsed 4m 5s (remain 4m 42s) Loss avg.: 0.5563 Grad: 0.8497 LR: 0.00100  \n",
      "Epoch: [1][1000/1939] Elapsed 4m 31s (remain 4m 14s) Loss avg.: 0.5506 Grad: 0.8174 LR: 0.00100  \n",
      "Epoch: [1][1100/1939] Elapsed 4m 58s (remain 3m 47s) Loss avg.: 0.5456 Grad: 0.6672 LR: 0.00100  \n",
      "Epoch: [1][1200/1939] Elapsed 5m 25s (remain 3m 19s) Loss avg.: 0.5412 Grad: 0.7034 LR: 0.00100  \n",
      "Epoch: [1][1300/1939] Elapsed 5m 51s (remain 2m 52s) Loss avg.: 0.5374 Grad: 0.7046 LR: 0.00100  \n",
      "Epoch: [1][1400/1939] Elapsed 6m 18s (remain 2m 25s) Loss avg.: 0.5339 Grad: 0.7987 LR: 0.00100  \n",
      "Epoch: [1][1500/1939] Elapsed 6m 45s (remain 1m 58s) Loss avg.: 0.5307 Grad: 0.5729 LR: 0.00100  \n",
      "Epoch: [1][1600/1939] Elapsed 7m 11s (remain 1m 31s) Loss avg.: 0.5280 Grad: 0.7073 LR: 0.00100  \n",
      "Epoch: [1][1700/1939] Elapsed 7m 37s (remain 1m 4s) Loss avg.: 0.5254 Grad: 0.4518 LR: 0.00100  \n",
      "Epoch: [1][1800/1939] Elapsed 8m 4s (remain 0m 37s) Loss avg.: 0.5229 Grad: 0.4738 LR: 0.00100  \n",
      "Epoch: [1][1900/1939] Elapsed 8m 30s (remain 0m 10s) Loss avg.: 0.5207 Grad: 0.5519 LR: 0.00100  \n",
      "Epoch: [1][1938/1939] Elapsed 8m 40s (remain 0m 0s) Loss avg.: 0.5198 Grad: 0.7089 LR: 0.00100  \n",
      "Eval: [0/216] Elapsed 0m 2s (remain 7m 16s) Loss avg.: 0.5035 \n",
      "Eval: [100/216] Elapsed 0m 9s (remain 0m 10s) Loss avg.: 0.4803 \n",
      "Eval: [200/216] Elapsed 0m 16s (remain 0m 1s) Loss avg.: 0.4795 \n",
      "Eval: [215/216] Elapsed 0m 17s (remain 0m 0s) Loss avg.: 0.4798 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.5198  avg_val_loss: 0.4798  time: 544s\n",
      "Epoch 1 - Accuracy: 0.7909198101235532\n",
      "Epoch 1 - Save Best Score: 0.7909 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1939] Elapsed 0m 2s (remain 79m 13s) Loss avg.: 0.4544 Grad: 0.6062 LR: 0.00098  \n",
      "Epoch: [2][100/1939] Elapsed 0m 28s (remain 8m 45s) Loss avg.: 0.4744 Grad: 0.6369 LR: 0.00098  \n",
      "Epoch: [2][200/1939] Elapsed 0m 55s (remain 8m 0s) Loss avg.: 0.4761 Grad: 0.8979 LR: 0.00098  \n",
      "Epoch: [2][300/1939] Elapsed 1m 21s (remain 7m 25s) Loss avg.: 0.4767 Grad: 0.5278 LR: 0.00098  \n",
      "Epoch: [2][400/1939] Elapsed 1m 48s (remain 6m 55s) Loss avg.: 0.4762 Grad: 0.8478 LR: 0.00098  \n",
      "Epoch: [2][500/1939] Elapsed 2m 14s (remain 6m 26s) Loss avg.: 0.4759 Grad: 0.5130 LR: 0.00098  \n",
      "Epoch: [2][600/1939] Elapsed 2m 40s (remain 5m 58s) Loss avg.: 0.4757 Grad: 0.6531 LR: 0.00098  \n",
      "Epoch: [2][700/1939] Elapsed 3m 7s (remain 5m 30s) Loss avg.: 0.4754 Grad: 0.4858 LR: 0.00098  \n",
      "Epoch: [2][800/1939] Elapsed 3m 33s (remain 5m 3s) Loss avg.: 0.4750 Grad: 0.5972 LR: 0.00098  \n",
      "Epoch: [2][900/1939] Elapsed 4m 0s (remain 4m 36s) Loss avg.: 0.4748 Grad: 0.6272 LR: 0.00098  \n",
      "Epoch: [2][1000/1939] Elapsed 4m 26s (remain 4m 9s) Loss avg.: 0.4745 Grad: 0.7701 LR: 0.00098  \n",
      "Epoch: [2][1100/1939] Elapsed 4m 52s (remain 3m 42s) Loss avg.: 0.4739 Grad: 0.6313 LR: 0.00098  \n",
      "Epoch: [2][1200/1939] Elapsed 5m 19s (remain 3m 16s) Loss avg.: 0.4736 Grad: 0.4263 LR: 0.00098  \n",
      "Epoch: [2][1300/1939] Elapsed 5m 45s (remain 2m 49s) Loss avg.: 0.4734 Grad: 0.4993 LR: 0.00098  \n",
      "Epoch: [2][1400/1939] Elapsed 6m 12s (remain 2m 22s) Loss avg.: 0.4732 Grad: 0.4663 LR: 0.00098  \n",
      "Epoch: [2][1500/1939] Elapsed 6m 38s (remain 1m 56s) Loss avg.: 0.4729 Grad: 0.8590 LR: 0.00098  \n",
      "Epoch: [2][1600/1939] Elapsed 7m 4s (remain 1m 29s) Loss avg.: 0.4725 Grad: 0.5537 LR: 0.00098  \n",
      "Epoch: [2][1700/1939] Elapsed 7m 31s (remain 1m 3s) Loss avg.: 0.4725 Grad: 0.5367 LR: 0.00098  \n",
      "Epoch: [2][1800/1939] Elapsed 7m 57s (remain 0m 36s) Loss avg.: 0.4724 Grad: 0.5745 LR: 0.00098  \n",
      "Epoch: [2][1900/1939] Elapsed 8m 24s (remain 0m 10s) Loss avg.: 0.4722 Grad: 0.4986 LR: 0.00098  \n",
      "Epoch: [2][1938/1939] Elapsed 8m 34s (remain 0m 0s) Loss avg.: 0.4721 Grad: 0.4592 LR: 0.00098  \n",
      "Eval: [0/216] Elapsed 0m 1s (remain 6m 30s) Loss avg.: 0.4919 \n",
      "Eval: [100/216] Elapsed 0m 8s (remain 0m 10s) Loss avg.: 0.4692 \n",
      "Eval: [200/216] Elapsed 0m 16s (remain 0m 1s) Loss avg.: 0.4684 \n",
      "Eval: [215/216] Elapsed 0m 17s (remain 0m 0s) Loss avg.: 0.4687 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4721  avg_val_loss: 0.4687  time: 538s\n",
      "Epoch 2 - Accuracy: 0.7963512743273758\n",
      "Epoch 2 - Save Best Score: 0.7964 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1939] Elapsed 0m 2s (remain 80m 23s) Loss avg.: 0.4734 Grad: 0.5383 LR: 0.00091  \n",
      "Epoch: [3][100/1939] Elapsed 0m 28s (remain 8m 45s) Loss avg.: 0.4636 Grad: 0.4700 LR: 0.00091  \n",
      "Epoch: [3][200/1939] Elapsed 0m 55s (remain 7m 57s) Loss avg.: 0.4632 Grad: 0.6735 LR: 0.00091  \n",
      "Epoch: [3][300/1939] Elapsed 1m 21s (remain 7m 23s) Loss avg.: 0.4633 Grad: 0.5315 LR: 0.00091  \n",
      "Epoch: [3][400/1939] Elapsed 1m 47s (remain 6m 53s) Loss avg.: 0.4632 Grad: 0.5472 LR: 0.00091  \n",
      "Epoch: [3][500/1939] Elapsed 2m 14s (remain 6m 25s) Loss avg.: 0.4629 Grad: 0.4681 LR: 0.00091  \n",
      "Epoch: [3][600/1939] Elapsed 2m 40s (remain 5m 57s) Loss avg.: 0.4629 Grad: 0.5789 LR: 0.00091  \n",
      "Epoch: [3][700/1939] Elapsed 3m 6s (remain 5m 30s) Loss avg.: 0.4628 Grad: 0.4538 LR: 0.00091  \n",
      "Epoch: [3][800/1939] Elapsed 3m 33s (remain 5m 2s) Loss avg.: 0.4628 Grad: 0.5717 LR: 0.00091  \n",
      "Epoch: [3][900/1939] Elapsed 3m 59s (remain 4m 36s) Loss avg.: 0.4627 Grad: 0.4937 LR: 0.00091  \n",
      "Epoch: [3][1000/1939] Elapsed 4m 25s (remain 4m 9s) Loss avg.: 0.4628 Grad: 0.5700 LR: 0.00091  \n",
      "Epoch: [3][1100/1939] Elapsed 4m 52s (remain 3m 42s) Loss avg.: 0.4628 Grad: 0.4094 LR: 0.00091  \n",
      "Epoch: [3][1200/1939] Elapsed 5m 18s (remain 3m 15s) Loss avg.: 0.4629 Grad: 0.4703 LR: 0.00091  \n",
      "Epoch: [3][1300/1939] Elapsed 5m 45s (remain 2m 49s) Loss avg.: 0.4629 Grad: 0.4548 LR: 0.00091  \n",
      "Epoch: [3][1400/1939] Elapsed 6m 11s (remain 2m 22s) Loss avg.: 0.4628 Grad: 0.3549 LR: 0.00091  \n",
      "Epoch: [3][1500/1939] Elapsed 6m 37s (remain 1m 56s) Loss avg.: 0.4627 Grad: 0.3949 LR: 0.00091  \n",
      "Epoch: [3][1600/1939] Elapsed 7m 4s (remain 1m 29s) Loss avg.: 0.4627 Grad: 0.3608 LR: 0.00091  \n",
      "Epoch: [3][1700/1939] Elapsed 7m 30s (remain 1m 3s) Loss avg.: 0.4624 Grad: 0.5200 LR: 0.00091  \n",
      "Epoch: [3][1800/1939] Elapsed 7m 56s (remain 0m 36s) Loss avg.: 0.4623 Grad: 0.5157 LR: 0.00091  \n",
      "Epoch: [3][1900/1939] Elapsed 8m 23s (remain 0m 10s) Loss avg.: 0.4623 Grad: 0.3551 LR: 0.00091  \n",
      "Epoch: [3][1938/1939] Elapsed 8m 33s (remain 0m 0s) Loss avg.: 0.4622 Grad: 0.3305 LR: 0.00091  \n",
      "Eval: [0/216] Elapsed 0m 2s (remain 7m 33s) Loss avg.: 0.4835 \n",
      "Eval: [100/216] Elapsed 0m 9s (remain 0m 10s) Loss avg.: 0.4639 \n",
      "Eval: [200/216] Elapsed 0m 16s (remain 0m 1s) Loss avg.: 0.4630 \n",
      "Eval: [215/216] Elapsed 0m 17s (remain 0m 0s) Loss avg.: 0.4633 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.4622  avg_val_loss: 0.4633  time: 538s\n",
      "Epoch 3 - Accuracy: 0.7990213212163579\n",
      "Epoch 3 - Save Best Score: 0.7990 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/1939] Elapsed 0m 2s (remain 84m 21s) Loss avg.: 0.4546 Grad: 0.4773 LR: 0.00081  \n",
      "Epoch: [4][100/1939] Elapsed 0m 29s (remain 8m 49s) Loss avg.: 0.4586 Grad: 0.3567 LR: 0.00081  \n",
      "Epoch: [4][200/1939] Elapsed 0m 55s (remain 7m 59s) Loss avg.: 0.4584 Grad: 0.3786 LR: 0.00081  \n",
      "Epoch: [4][300/1939] Elapsed 1m 21s (remain 7m 25s) Loss avg.: 0.4583 Grad: 0.5174 LR: 0.00081  \n",
      "Epoch: [4][400/1939] Elapsed 1m 48s (remain 6m 54s) Loss avg.: 0.4579 Grad: 0.3665 LR: 0.00081  \n",
      "Epoch: [4][500/1939] Elapsed 2m 14s (remain 6m 25s) Loss avg.: 0.4577 Grad: 0.4484 LR: 0.00081  \n",
      "Epoch: [4][600/1939] Elapsed 2m 40s (remain 5m 57s) Loss avg.: 0.4575 Grad: 0.3332 LR: 0.00081  \n",
      "Epoch: [4][700/1939] Elapsed 3m 7s (remain 5m 30s) Loss avg.: 0.4574 Grad: 0.4156 LR: 0.00081  \n",
      "Epoch: [4][800/1939] Elapsed 3m 33s (remain 5m 3s) Loss avg.: 0.4572 Grad: 0.3647 LR: 0.00081  \n",
      "Epoch: [4][900/1939] Elapsed 3m 59s (remain 4m 36s) Loss avg.: 0.4572 Grad: 0.4915 LR: 0.00081  \n",
      "Epoch: [4][1000/1939] Elapsed 4m 26s (remain 4m 9s) Loss avg.: 0.4572 Grad: 0.4223 LR: 0.00081  \n",
      "Epoch: [4][1100/1939] Elapsed 4m 52s (remain 3m 42s) Loss avg.: 0.4569 Grad: 0.3276 LR: 0.00081  \n",
      "Epoch: [4][1200/1939] Elapsed 5m 19s (remain 3m 16s) Loss avg.: 0.4567 Grad: 0.4915 LR: 0.00081  \n",
      "Epoch: [4][1300/1939] Elapsed 5m 45s (remain 2m 49s) Loss avg.: 0.4565 Grad: 0.3144 LR: 0.00081  \n",
      "Epoch: [4][1400/1939] Elapsed 6m 11s (remain 2m 22s) Loss avg.: 0.4566 Grad: 0.4552 LR: 0.00081  \n",
      "Epoch: [4][1500/1939] Elapsed 6m 38s (remain 1m 56s) Loss avg.: 0.4565 Grad: 0.4676 LR: 0.00081  \n",
      "Epoch: [4][1600/1939] Elapsed 7m 4s (remain 1m 29s) Loss avg.: 0.4565 Grad: 0.5052 LR: 0.00081  \n",
      "Epoch: [4][1700/1939] Elapsed 7m 31s (remain 1m 3s) Loss avg.: 0.4565 Grad: 0.5675 LR: 0.00081  \n",
      "Epoch: [4][1800/1939] Elapsed 7m 57s (remain 0m 36s) Loss avg.: 0.4564 Grad: 0.3297 LR: 0.00081  \n",
      "Epoch: [4][1900/1939] Elapsed 8m 23s (remain 0m 10s) Loss avg.: 0.4565 Grad: 0.4564 LR: 0.00081  \n",
      "Epoch: [4][1938/1939] Elapsed 8m 34s (remain 0m 0s) Loss avg.: 0.4564 Grad: 0.3584 LR: 0.00081  \n",
      "Eval: [0/216] Elapsed 0m 1s (remain 6m 22s) Loss avg.: 0.4770 \n",
      "Eval: [100/216] Elapsed 0m 8s (remain 0m 10s) Loss avg.: 0.4579 \n",
      "Eval: [200/216] Elapsed 0m 16s (remain 0m 1s) Loss avg.: 0.4570 \n",
      "Eval: [215/216] Elapsed 0m 17s (remain 0m 0s) Loss avg.: 0.4573 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.4564  avg_val_loss: 0.4573  time: 538s\n",
      "Epoch 4 - Accuracy: 0.801892963171917\n",
      "Epoch 4 - Save Best Score: 0.8019 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/1939] Elapsed 0m 2s (remain 81m 10s) Loss avg.: 0.4643 Grad: 0.4150 LR: 0.00069  \n",
      "Epoch: [5][100/1939] Elapsed 0m 28s (remain 8m 46s) Loss avg.: 0.4502 Grad: 0.3692 LR: 0.00069  \n",
      "Epoch: [5][200/1939] Elapsed 0m 55s (remain 7m 57s) Loss avg.: 0.4515 Grad: 0.4073 LR: 0.00069  \n",
      "Epoch: [5][300/1939] Elapsed 1m 21s (remain 7m 24s) Loss avg.: 0.4516 Grad: 0.4178 LR: 0.00069  \n",
      "Epoch: [5][400/1939] Elapsed 1m 47s (remain 6m 54s) Loss avg.: 0.4516 Grad: 0.5391 LR: 0.00069  \n",
      "Epoch: [5][500/1939] Elapsed 2m 14s (remain 6m 26s) Loss avg.: 0.4517 Grad: 0.3171 LR: 0.00069  \n",
      "Epoch: [5][600/1939] Elapsed 2m 40s (remain 5m 58s) Loss avg.: 0.4514 Grad: 0.3344 LR: 0.00069  \n",
      "Epoch: [5][700/1939] Elapsed 3m 7s (remain 5m 30s) Loss avg.: 0.4516 Grad: 0.4106 LR: 0.00069  \n",
      "Epoch: [5][800/1939] Elapsed 3m 33s (remain 5m 3s) Loss avg.: 0.4517 Grad: 0.3520 LR: 0.00069  \n",
      "Epoch: [5][900/1939] Elapsed 3m 59s (remain 4m 36s) Loss avg.: 0.4517 Grad: 0.4630 LR: 0.00069  \n",
      "Epoch: [5][1000/1939] Elapsed 4m 26s (remain 4m 9s) Loss avg.: 0.4517 Grad: 0.5213 LR: 0.00069  \n",
      "Epoch: [5][1100/1939] Elapsed 4m 52s (remain 3m 42s) Loss avg.: 0.4517 Grad: 0.4305 LR: 0.00069  \n",
      "Epoch: [5][1200/1939] Elapsed 5m 19s (remain 3m 16s) Loss avg.: 0.4517 Grad: 0.3430 LR: 0.00069  \n",
      "Epoch: [5][1300/1939] Elapsed 5m 45s (remain 2m 49s) Loss avg.: 0.4517 Grad: 0.4439 LR: 0.00069  \n",
      "Epoch: [5][1400/1939] Elapsed 6m 12s (remain 2m 22s) Loss avg.: 0.4517 Grad: 0.3181 LR: 0.00069  \n",
      "Epoch: [5][1500/1939] Elapsed 6m 38s (remain 1m 56s) Loss avg.: 0.4519 Grad: 0.3689 LR: 0.00069  \n",
      "Epoch: [5][1600/1939] Elapsed 7m 4s (remain 1m 29s) Loss avg.: 0.4518 Grad: 0.3973 LR: 0.00069  \n",
      "Epoch: [5][1700/1939] Elapsed 7m 31s (remain 1m 3s) Loss avg.: 0.4518 Grad: 0.3144 LR: 0.00069  \n",
      "Epoch: [5][1800/1939] Elapsed 7m 57s (remain 0m 36s) Loss avg.: 0.4517 Grad: 0.4978 LR: 0.00069  \n",
      "Epoch: [5][1900/1939] Elapsed 8m 23s (remain 0m 10s) Loss avg.: 0.4518 Grad: 0.4871 LR: 0.00069  \n",
      "Epoch: [5][1938/1939] Elapsed 8m 34s (remain 0m 0s) Loss avg.: 0.4517 Grad: 0.3617 LR: 0.00069  \n",
      "Eval: [0/216] Elapsed 0m 1s (remain 6m 21s) Loss avg.: 0.4810 \n",
      "Eval: [100/216] Elapsed 0m 8s (remain 0m 10s) Loss avg.: 0.4569 \n",
      "Eval: [200/216] Elapsed 0m 16s (remain 0m 1s) Loss avg.: 0.4557 \n",
      "Eval: [215/216] Elapsed 0m 17s (remain 0m 0s) Loss avg.: 0.4560 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.4517  avg_val_loss: 0.4560  time: 539s\n",
      "Epoch 5 - Accuracy: 0.8026166749576867\n",
      "Epoch 5 - Save Best Score: 0.8026 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/1939] Elapsed 0m 2s (remain 87m 25s) Loss avg.: 0.4494 Grad: 0.3937 LR: 0.00055  \n",
      "Epoch: [6][100/1939] Elapsed 0m 29s (remain 8m 52s) Loss avg.: 0.4479 Grad: 0.5524 LR: 0.00055  \n",
      "Epoch: [6][200/1939] Elapsed 0m 55s (remain 8m 1s) Loss avg.: 0.4469 Grad: 0.3930 LR: 0.00055  \n",
      "Epoch: [6][300/1939] Elapsed 1m 22s (remain 7m 26s) Loss avg.: 0.4471 Grad: 0.3603 LR: 0.00055  \n",
      "Epoch: [6][400/1939] Elapsed 1m 48s (remain 6m 55s) Loss avg.: 0.4470 Grad: 0.4068 LR: 0.00055  \n",
      "Epoch: [6][500/1939] Elapsed 2m 14s (remain 6m 27s) Loss avg.: 0.4474 Grad: 0.3563 LR: 0.00055  \n",
      "Epoch: [6][600/1939] Elapsed 2m 41s (remain 5m 58s) Loss avg.: 0.4473 Grad: 0.5206 LR: 0.00055  \n",
      "Epoch: [6][700/1939] Elapsed 3m 7s (remain 5m 31s) Loss avg.: 0.4475 Grad: 0.3407 LR: 0.00055  \n",
      "Epoch: [6][800/1939] Elapsed 3m 33s (remain 5m 3s) Loss avg.: 0.4475 Grad: 0.3701 LR: 0.00055  \n",
      "Epoch: [6][900/1939] Elapsed 4m 0s (remain 4m 36s) Loss avg.: 0.4474 Grad: 0.3570 LR: 0.00055  \n",
      "Epoch: [6][1000/1939] Elapsed 4m 26s (remain 4m 10s) Loss avg.: 0.4475 Grad: 0.3052 LR: 0.00055  \n",
      "Epoch: [6][1100/1939] Elapsed 4m 53s (remain 3m 43s) Loss avg.: 0.4474 Grad: 0.3045 LR: 0.00055  \n",
      "Epoch: [6][1200/1939] Elapsed 5m 19s (remain 3m 16s) Loss avg.: 0.4477 Grad: 0.3155 LR: 0.00055  \n",
      "Epoch: [6][1300/1939] Elapsed 5m 46s (remain 2m 49s) Loss avg.: 0.4477 Grad: 0.3318 LR: 0.00055  \n",
      "Epoch: [6][1400/1939] Elapsed 6m 12s (remain 2m 23s) Loss avg.: 0.4478 Grad: 0.4185 LR: 0.00055  \n",
      "Epoch: [6][1500/1939] Elapsed 6m 38s (remain 1m 56s) Loss avg.: 0.4477 Grad: 0.5165 LR: 0.00055  \n",
      "Epoch: [6][1600/1939] Elapsed 7m 5s (remain 1m 29s) Loss avg.: 0.4477 Grad: 0.3865 LR: 0.00055  \n",
      "Epoch: [6][1700/1939] Elapsed 7m 31s (remain 1m 3s) Loss avg.: 0.4478 Grad: 0.3405 LR: 0.00055  \n",
      "Epoch: [6][1800/1939] Elapsed 7m 58s (remain 0m 36s) Loss avg.: 0.4478 Grad: 0.4144 LR: 0.00055  \n",
      "Epoch: [6][1900/1939] Elapsed 8m 24s (remain 0m 10s) Loss avg.: 0.4478 Grad: 0.4041 LR: 0.00055  \n",
      "Epoch: [6][1938/1939] Elapsed 8m 34s (remain 0m 0s) Loss avg.: 0.4478 Grad: 0.3582 LR: 0.00055  \n",
      "Eval: [0/216] Elapsed 0m 1s (remain 6m 22s) Loss avg.: 0.4735 \n",
      "Eval: [100/216] Elapsed 0m 8s (remain 0m 10s) Loss avg.: 0.4522 \n",
      "Eval: [200/216] Elapsed 0m 16s (remain 0m 1s) Loss avg.: 0.4517 \n",
      "Eval: [215/216] Elapsed 0m 17s (remain 0m 0s) Loss avg.: 0.4519 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.4478  avg_val_loss: 0.4519  time: 539s\n",
      "Epoch 6 - Accuracy: 0.8039944829666672\n",
      "Epoch 6 - Save Best Score: 0.8040 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/1939] Elapsed 0m 2s (remain 78m 29s) Loss avg.: 0.4486 Grad: 0.2756 LR: 0.00041  \n",
      "Epoch: [7][100/1939] Elapsed 0m 28s (remain 8m 45s) Loss avg.: 0.4456 Grad: 0.4144 LR: 0.00041  \n",
      "Epoch: [7][200/1939] Elapsed 0m 55s (remain 7m 57s) Loss avg.: 0.4452 Grad: 0.3573 LR: 0.00041  \n",
      "Epoch: [7][300/1939] Elapsed 1m 21s (remain 7m 24s) Loss avg.: 0.4449 Grad: 0.3711 LR: 0.00041  \n",
      "Epoch: [7][400/1939] Elapsed 1m 48s (remain 6m 55s) Loss avg.: 0.4446 Grad: 0.3064 LR: 0.00041  \n",
      "Epoch: [7][500/1939] Elapsed 2m 14s (remain 6m 26s) Loss avg.: 0.4445 Grad: 0.4230 LR: 0.00041  \n",
      "Epoch: [7][600/1939] Elapsed 2m 41s (remain 5m 58s) Loss avg.: 0.4444 Grad: 0.5443 LR: 0.00041  \n",
      "Epoch: [7][700/1939] Elapsed 3m 7s (remain 5m 31s) Loss avg.: 0.4444 Grad: 0.3171 LR: 0.00041  \n",
      "Epoch: [7][800/1939] Elapsed 3m 34s (remain 5m 4s) Loss avg.: 0.4444 Grad: 0.4300 LR: 0.00041  \n",
      "Epoch: [7][900/1939] Elapsed 4m 0s (remain 4m 37s) Loss avg.: 0.4443 Grad: 0.5158 LR: 0.00041  \n",
      "Epoch: [7][1000/1939] Elapsed 4m 26s (remain 4m 10s) Loss avg.: 0.4444 Grad: 0.6574 LR: 0.00041  \n",
      "Epoch: [7][1100/1939] Elapsed 4m 53s (remain 3m 43s) Loss avg.: 0.4444 Grad: 0.3522 LR: 0.00041  \n",
      "Epoch: [7][1200/1939] Elapsed 5m 19s (remain 3m 16s) Loss avg.: 0.4443 Grad: 0.4502 LR: 0.00041  \n",
      "Epoch: [7][1300/1939] Elapsed 5m 46s (remain 2m 49s) Loss avg.: 0.4443 Grad: 0.4234 LR: 0.00041  \n",
      "Epoch: [7][1400/1939] Elapsed 6m 12s (remain 2m 23s) Loss avg.: 0.4443 Grad: 0.4597 LR: 0.00041  \n",
      "Epoch: [7][1500/1939] Elapsed 6m 39s (remain 1m 56s) Loss avg.: 0.4444 Grad: 0.3708 LR: 0.00041  \n",
      "Epoch: [7][1600/1939] Elapsed 7m 5s (remain 1m 29s) Loss avg.: 0.4443 Grad: 0.5519 LR: 0.00041  \n",
      "Epoch: [7][1700/1939] Elapsed 7m 31s (remain 1m 3s) Loss avg.: 0.4443 Grad: 0.4209 LR: 0.00041  \n",
      "Epoch: [7][1800/1939] Elapsed 7m 58s (remain 0m 36s) Loss avg.: 0.4444 Grad: 0.3652 LR: 0.00041  \n",
      "Epoch: [7][1900/1939] Elapsed 8m 24s (remain 0m 10s) Loss avg.: 0.4444 Grad: 0.4984 LR: 0.00041  \n",
      "Epoch: [7][1938/1939] Elapsed 8m 34s (remain 0m 0s) Loss avg.: 0.4445 Grad: 0.4964 LR: 0.00041  \n",
      "Eval: [0/216] Elapsed 0m 1s (remain 6m 59s) Loss avg.: 0.4693 \n",
      "Eval: [100/216] Elapsed 0m 9s (remain 0m 10s) Loss avg.: 0.4501 \n",
      "Eval: [200/216] Elapsed 0m 16s (remain 0m 1s) Loss avg.: 0.4493 \n",
      "Eval: [215/216] Elapsed 0m 17s (remain 0m 0s) Loss avg.: 0.4496 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.4445  avg_val_loss: 0.4496  time: 539s\n",
      "Epoch 7 - Accuracy: 0.8054433568624266\n",
      "Epoch 7 - Save Best Score: 0.8054 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/1939] Elapsed 0m 2s (remain 86m 45s) Loss avg.: 0.4451 Grad: 0.4499 LR: 0.00029  \n",
      "Epoch: [8][100/1939] Elapsed 0m 29s (remain 8m 53s) Loss avg.: 0.4409 Grad: 0.3836 LR: 0.00029  \n",
      "Epoch: [8][200/1939] Elapsed 0m 55s (remain 8m 1s) Loss avg.: 0.4411 Grad: 0.3394 LR: 0.00029  \n",
      "Epoch: [8][300/1939] Elapsed 1m 22s (remain 7m 26s) Loss avg.: 0.4417 Grad: 0.4234 LR: 0.00029  \n",
      "Epoch: [8][400/1939] Elapsed 1m 48s (remain 6m 55s) Loss avg.: 0.4415 Grad: 0.4837 LR: 0.00029  \n",
      "Epoch: [8][500/1939] Elapsed 2m 14s (remain 6m 26s) Loss avg.: 0.4416 Grad: 0.4744 LR: 0.00029  \n",
      "Epoch: [8][600/1939] Elapsed 2m 41s (remain 5m 58s) Loss avg.: 0.4417 Grad: 0.3926 LR: 0.00029  \n",
      "Epoch: [8][700/1939] Elapsed 3m 7s (remain 5m 30s) Loss avg.: 0.4414 Grad: 0.3569 LR: 0.00029  \n",
      "Epoch: [8][800/1939] Elapsed 3m 33s (remain 5m 3s) Loss avg.: 0.4413 Grad: 0.4826 LR: 0.00029  \n",
      "Epoch: [8][900/1939] Elapsed 4m 0s (remain 4m 36s) Loss avg.: 0.4414 Grad: 0.3129 LR: 0.00029  \n",
      "Epoch: [8][1000/1939] Elapsed 4m 26s (remain 4m 9s) Loss avg.: 0.4412 Grad: 0.4265 LR: 0.00029  \n",
      "Epoch: [8][1100/1939] Elapsed 4m 53s (remain 3m 43s) Loss avg.: 0.4411 Grad: 0.3570 LR: 0.00029  \n",
      "Epoch: [8][1200/1939] Elapsed 5m 19s (remain 3m 16s) Loss avg.: 0.4411 Grad: 0.4569 LR: 0.00029  \n",
      "Epoch: [8][1300/1939] Elapsed 5m 45s (remain 2m 49s) Loss avg.: 0.4413 Grad: 0.3391 LR: 0.00029  \n",
      "Epoch: [8][1400/1939] Elapsed 6m 12s (remain 2m 22s) Loss avg.: 0.4413 Grad: 0.4695 LR: 0.00029  \n",
      "Epoch: [8][1500/1939] Elapsed 6m 38s (remain 1m 56s) Loss avg.: 0.4414 Grad: 0.3819 LR: 0.00029  \n",
      "Epoch: [8][1600/1939] Elapsed 7m 5s (remain 1m 29s) Loss avg.: 0.4414 Grad: 0.5136 LR: 0.00029  \n",
      "Epoch: [8][1700/1939] Elapsed 7m 31s (remain 1m 3s) Loss avg.: 0.4415 Grad: 0.3554 LR: 0.00029  \n",
      "Epoch: [8][1800/1939] Elapsed 7m 57s (remain 0m 36s) Loss avg.: 0.4415 Grad: 0.5672 LR: 0.00029  \n",
      "Epoch: [8][1900/1939] Elapsed 8m 24s (remain 0m 10s) Loss avg.: 0.4415 Grad: 0.3434 LR: 0.00029  \n",
      "Epoch: [8][1938/1939] Elapsed 8m 34s (remain 0m 0s) Loss avg.: 0.4415 Grad: 0.3678 LR: 0.00029  \n",
      "Eval: [0/216] Elapsed 0m 1s (remain 6m 28s) Loss avg.: 0.4670 \n",
      "Eval: [100/216] Elapsed 0m 9s (remain 0m 10s) Loss avg.: 0.4481 \n",
      "Eval: [200/216] Elapsed 0m 16s (remain 0m 1s) Loss avg.: 0.4474 \n",
      "Eval: [215/216] Elapsed 0m 17s (remain 0m 0s) Loss avg.: 0.4477 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.4415  avg_val_loss: 0.4477  time: 539s\n",
      "Epoch 8 - Accuracy: 0.8065107954883314\n",
      "Epoch 8 - Save Best Score: 0.8065 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/1939] Elapsed 0m 2s (remain 80m 7s) Loss avg.: 0.4547 Grad: 0.3702 LR: 0.00019  \n",
      "Epoch: [9][100/1939] Elapsed 0m 28s (remain 8m 46s) Loss avg.: 0.4387 Grad: 0.2755 LR: 0.00019  \n",
      "Epoch: [9][200/1939] Elapsed 0m 55s (remain 7m 58s) Loss avg.: 0.4371 Grad: 0.3271 LR: 0.00019  \n",
      "Epoch: [9][300/1939] Elapsed 1m 21s (remain 7m 24s) Loss avg.: 0.4376 Grad: 0.4638 LR: 0.00019  \n",
      "Epoch: [9][400/1939] Elapsed 1m 48s (remain 6m 55s) Loss avg.: 0.4376 Grad: 0.3087 LR: 0.00019  \n",
      "Epoch: [9][500/1939] Elapsed 2m 14s (remain 6m 26s) Loss avg.: 0.4377 Grad: 0.3873 LR: 0.00019  \n",
      "Epoch: [9][600/1939] Elapsed 2m 41s (remain 5m 58s) Loss avg.: 0.4381 Grad: 0.3257 LR: 0.00019  \n",
      "Epoch: [9][700/1939] Elapsed 3m 7s (remain 5m 31s) Loss avg.: 0.4384 Grad: 0.3246 LR: 0.00019  \n",
      "Epoch: [9][800/1939] Elapsed 3m 33s (remain 5m 3s) Loss avg.: 0.4385 Grad: 0.3149 LR: 0.00019  \n",
      "Epoch: [9][900/1939] Elapsed 4m 0s (remain 4m 36s) Loss avg.: 0.4384 Grad: 0.3274 LR: 0.00019  \n",
      "Epoch: [9][1000/1939] Elapsed 4m 26s (remain 4m 9s) Loss avg.: 0.4384 Grad: 0.3633 LR: 0.00019  \n",
      "Epoch: [9][1100/1939] Elapsed 4m 53s (remain 3m 43s) Loss avg.: 0.4385 Grad: 0.4908 LR: 0.00019  \n",
      "Epoch: [9][1200/1939] Elapsed 5m 19s (remain 3m 16s) Loss avg.: 0.4386 Grad: 0.3048 LR: 0.00019  \n",
      "Epoch: [9][1300/1939] Elapsed 5m 46s (remain 2m 49s) Loss avg.: 0.4386 Grad: 0.3028 LR: 0.00019  \n",
      "Epoch: [9][1400/1939] Elapsed 6m 12s (remain 2m 23s) Loss avg.: 0.4387 Grad: 0.4729 LR: 0.00019  \n",
      "Epoch: [9][1500/1939] Elapsed 6m 38s (remain 1m 56s) Loss avg.: 0.4387 Grad: 0.4141 LR: 0.00019  \n",
      "Epoch: [9][1600/1939] Elapsed 7m 5s (remain 1m 29s) Loss avg.: 0.4388 Grad: 0.4233 LR: 0.00019  \n",
      "Epoch: [9][1700/1939] Elapsed 7m 31s (remain 1m 3s) Loss avg.: 0.4388 Grad: 0.3353 LR: 0.00019  \n",
      "Epoch: [9][1800/1939] Elapsed 7m 57s (remain 0m 36s) Loss avg.: 0.4390 Grad: 0.3549 LR: 0.00019  \n",
      "Epoch: [9][1900/1939] Elapsed 8m 24s (remain 0m 10s) Loss avg.: 0.4390 Grad: 0.4251 LR: 0.00019  \n",
      "Epoch: [9][1938/1939] Elapsed 8m 34s (remain 0m 0s) Loss avg.: 0.4390 Grad: 0.4368 LR: 0.00019  \n",
      "Eval: [0/216] Elapsed 0m 1s (remain 6m 49s) Loss avg.: 0.4677 \n",
      "Eval: [100/216] Elapsed 0m 9s (remain 0m 10s) Loss avg.: 0.4460 \n",
      "Eval: [200/216] Elapsed 0m 16s (remain 0m 1s) Loss avg.: 0.4454 \n",
      "Eval: [215/216] Elapsed 0m 17s (remain 0m 0s) Loss avg.: 0.4456 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.4390  avg_val_loss: 0.4456  time: 539s\n",
      "Epoch 9 - Accuracy: 0.8074694597977378\n",
      "Epoch 9 - Save Best Score: 0.8075 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/1939] Elapsed 0m 2s (remain 80m 24s) Loss avg.: 0.4176 Grad: 0.3715 LR: 0.00012  \n",
      "Epoch: [10][100/1939] Elapsed 0m 28s (remain 8m 45s) Loss avg.: 0.4361 Grad: 0.3741 LR: 0.00012  \n",
      "Epoch: [10][200/1939] Elapsed 0m 55s (remain 7m 57s) Loss avg.: 0.4365 Grad: 0.3060 LR: 0.00012  \n",
      "Epoch: [10][300/1939] Elapsed 1m 21s (remain 7m 23s) Loss avg.: 0.4365 Grad: 0.3329 LR: 0.00012  \n",
      "Epoch: [10][400/1939] Elapsed 1m 47s (remain 6m 53s) Loss avg.: 0.4368 Grad: 0.3914 LR: 0.00012  \n",
      "Epoch: [10][500/1939] Elapsed 2m 14s (remain 6m 25s) Loss avg.: 0.4369 Grad: 0.3335 LR: 0.00012  \n",
      "Epoch: [10][600/1939] Elapsed 2m 40s (remain 5m 57s) Loss avg.: 0.4371 Grad: 0.3590 LR: 0.00012  \n",
      "Epoch: [10][700/1939] Elapsed 3m 6s (remain 5m 29s) Loss avg.: 0.4370 Grad: 0.3930 LR: 0.00012  \n",
      "Epoch: [10][800/1939] Elapsed 3m 33s (remain 5m 3s) Loss avg.: 0.4370 Grad: 0.4152 LR: 0.00012  \n",
      "Epoch: [10][900/1939] Elapsed 3m 59s (remain 4m 36s) Loss avg.: 0.4370 Grad: 0.3321 LR: 0.00012  \n",
      "Epoch: [10][1000/1939] Elapsed 4m 26s (remain 4m 9s) Loss avg.: 0.4369 Grad: 0.3088 LR: 0.00012  \n",
      "Epoch: [10][1100/1939] Elapsed 4m 52s (remain 3m 42s) Loss avg.: 0.4371 Grad: 0.4755 LR: 0.00012  \n",
      "Epoch: [10][1200/1939] Elapsed 5m 18s (remain 3m 15s) Loss avg.: 0.4374 Grad: 0.4796 LR: 0.00012  \n",
      "Epoch: [10][1300/1939] Elapsed 5m 45s (remain 2m 49s) Loss avg.: 0.4373 Grad: 0.3019 LR: 0.00012  \n",
      "Epoch: [10][1400/1939] Elapsed 6m 11s (remain 2m 22s) Loss avg.: 0.4373 Grad: 0.3419 LR: 0.00012  \n",
      "Epoch: [10][1500/1939] Elapsed 6m 37s (remain 1m 56s) Loss avg.: 0.4375 Grad: 0.3223 LR: 0.00012  \n",
      "Epoch: [10][1600/1939] Elapsed 7m 4s (remain 1m 29s) Loss avg.: 0.4374 Grad: 0.3131 LR: 0.00012  \n",
      "Epoch: [10][1700/1939] Elapsed 7m 30s (remain 1m 3s) Loss avg.: 0.4373 Grad: 0.3791 LR: 0.00012  \n",
      "Epoch: [10][1800/1939] Elapsed 7m 57s (remain 0m 36s) Loss avg.: 0.4373 Grad: 0.3646 LR: 0.00012  \n",
      "Epoch: [10][1900/1939] Elapsed 8m 23s (remain 0m 10s) Loss avg.: 0.4373 Grad: 0.3654 LR: 0.00012  \n",
      "Epoch: [10][1938/1939] Elapsed 8m 33s (remain 0m 0s) Loss avg.: 0.4373 Grad: 0.3753 LR: 0.00012  \n",
      "Eval: [0/216] Elapsed 0m 2s (remain 7m 22s) Loss avg.: 0.4670 \n",
      "Eval: [100/216] Elapsed 0m 9s (remain 0m 10s) Loss avg.: 0.4455 \n",
      "Eval: [200/216] Elapsed 0m 16s (remain 0m 1s) Loss avg.: 0.4449 \n",
      "Eval: [215/216] Elapsed 0m 17s (remain 0m 0s) Loss avg.: 0.4451 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.4373  avg_val_loss: 0.4451  time: 538s\n",
      "Epoch 10 - Accuracy: 0.807598538653316\n",
      "Epoch 10 - Save Best Score: 0.8076 Model\n",
      "Epoch 10 - Save final model\n",
      "========== fold: 0 result ==========\n",
      "Score: 0.80760\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "hungry-geese-train-by-episode.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2945.71762,
   "end_time": "2021-05-12T03:50:02.012348",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-12T03:00:56.294728",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04a486aa6f454d8f92e388dba1b9ee21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0857c0fa22b544488d65bb2c7dad18ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f905db5005be40b194ea150c8b0deb9f",
      "max": 1001,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c96b7bfbdf0243a8ae1dbb3d9aedf123",
      "value": 1001
     }
    },
    "4134662bdbe04a918d9809632e268ef8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0857c0fa22b544488d65bb2c7dad18ee",
       "IPY_MODEL_e33e4f894b424988b316c468bc9225ce"
      ],
      "layout": "IPY_MODEL_8ddb49ac3c91409f99a569a061a70b3d"
     }
    },
    "507d2b6a02bb43d0bb4c8c2734f19cbb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ddb49ac3c91409f99a569a061a70b3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c96b7bfbdf0243a8ae1dbb3d9aedf123": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e33e4f894b424988b316c468bc9225ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_507d2b6a02bb43d0bb4c8c2734f19cbb",
      "placeholder": "​",
      "style": "IPY_MODEL_04a486aa6f454d8f92e388dba1b9ee21",
      "value": " 1001/1001 [03:35&lt;00:00,  4.64it/s]"
     }
    },
    "f905db5005be40b194ea150c8b0deb9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
